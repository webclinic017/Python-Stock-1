{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3139d-1ac0-4486-80f0-e54d08259ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "ee726465-0b88-46f7-877f-5aee84616ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import shap\n",
    "import numpy as np\n",
    "import ZCA as zca\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as plt\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython\n",
    "\n",
    "import os\n",
    "os.environ['R_HOME'] = '/mnt/distvol/R/4.0.5/lib64/R/'\n",
    "import rpy2.robjects as R\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import arange\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import seaborn as sns\n",
    "from ModelDiagnostics import Plot\n",
    "from sklearn.cluster import DBSCAN\n",
    "from clustergram import Clustergram\n",
    "import urbangrammar_graphics as ugg\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "\n",
    "import dtale\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "id": "78bf8827-4f34-413b-9a4d-bd6565e33372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001\n",
    "    #print(\"p = {:g}\".format(p))    \n",
    "    if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "        #print(p)\n",
    "        #print(alpha)\n",
    "        print(\"The null hypothesis can be rejected\")\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        #xt, _ = stats.boxcox(x)        \n",
    "        print(_)\n",
    "        xt = pd.DataFrame(xt)\n",
    "        \n",
    "        return _, pd.DataFrame(xt).set_index(x.index)\n",
    "    else:\n",
    "        print(\"The null hypothesis cannot be rejected\")    \n",
    "        return 1, pd.DataFrame(x)\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    power = PowerTransformer(method='yeo-johnson')\n",
    "    power.lambdas_ = lambdas.values\n",
    "    return(power.inverse_transform([data]))\n",
    "    #return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.yeojohnson((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        l, inner_scale = testNormal(data.iloc[:,i])\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def inverse_yeo(og, data_, lambda_):\n",
    "    values = []\n",
    "    for i in range(0,len(og)):\n",
    "        X = og[i]\n",
    "        X_trans = data_[i]\n",
    "        if X >= 0 and lambda_ == 0:\n",
    "            X = exp(X_trans) - 1\n",
    "        elif X >= 0 and lambda_ != 0:\n",
    "            X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
    "        elif X < 0 and lambda_ != 2:\n",
    "            X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
    "        elif X < 0 and lambda_ == 2:\n",
    "            X = 1 - exp(-X_trans)\n",
    "        \n",
    "        values.append(X)\n",
    "    return(pd.DataFrame(values))\n",
    "\n",
    "\n",
    "def revert_yeo (og, data_, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data_.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data_.iloc[:,i]\n",
    "        else:\n",
    "            p#ower = PowerTransformer(method='yeo-johnson')\n",
    "            #power.lambdas_ = lambdas.iloc[i].values\n",
    "            #revert = pd.DataFrame(power.inverse_transform([data.iloc[:,i].values]))\n",
    "            #return inv_boxcox(data, lambdas.values)\n",
    "            revert = pd.DataFrame(inverse_yeo(og.iloc[:,i].values,data_.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data_.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data_.columns\n",
    "    return reverted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "id": "2ec9d431-186e-4171-8a8a-378ab2ab2e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_deltas(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(d)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def get_residuals(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(r)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def arfima_predict(data_, ahead):\n",
    "\n",
    "    R.r('''\n",
    "               f_ <- function(values, ahead) {\n",
    "                        #system(\"which openssl\")\n",
    "                        print(nrow(values))\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x,drop=FALSE]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              #return(r)\n",
    "                              \n",
    "                              pred <- predict(varvefd, ahead)\n",
    "                              #print(ahead)\n",
    "                              #print(pred)\n",
    "                              #print(pred)\n",
    "                              return(as.data.frame(pred)[,1,drop=TRUE])\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f_ = R.globalenv['f_']\n",
    "    d_=R.conversion.rpy2py((r_f_(R.conversion.py2rpy(data_),ahead)))\n",
    "    return(d_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "id": "e43598e7-17dd-4ced-b588-e8870d3df933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "def arima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #arima residual adjusted\n",
    "    \n",
    "    window = 15\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    model = AutoReg(train_resid.values, lags=15)\n",
    "    model_fit = model.fit()\n",
    "    coef = model_fit.params\n",
    "    # walk forward over time steps in test\n",
    "    history = train_resid[len(train_resid)-window:]\n",
    "    history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]    \n",
    "        error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        length = len(history)\n",
    "        lag = [history[i] for i in range(length-window,length)]\n",
    "        pred_error = coef[0]\n",
    "        for d in range(window):\n",
    "            pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        yhat = yhat + pred_error\n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af9904-08a5-4d5f-90f7-1b4c5d4652df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9bb80-d23a-4a60-964b-41dad96d6411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "id": "1235085d-f98a-4b9d-a118-29a6f154af93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom statsmodels.tsa.ar_model import AutoReg\\n\\nresiduals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\\n\\ny_adjusted = predicteds.copy()\\n\\nfor i in range(0,len(y_test)):    \\n    \\n    if i == 0:\\n        forecast_r = arfima_predict(residuals_train.values)\\n        \\n    else:\\n        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\\n        \\n        residuals = pd.concat([residuals_train,residuals_test],axis=0)\\n        \\n        forecast_r = arfima_predict(residuals.values)\\n        \\n    print(forecast_r)\\n    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\\n    #print(adjusted)\\n    \\n    \\n    \\n    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\\n    #ar_s_model = AutoReg(residuals, lags=15)\\n    #model_fit = model.fit()\\n    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\\n\\n    #improved_forecast = forecast + estimated error\\n\\n    #print('Coef=%s' % (model_fit.params))\\n\""
      ]
     },
     "execution_count": 1448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arfima residual adjusted\n",
    "def arfima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #train_resid = get_deltas(y_train)\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    y_adjusted = predicted.copy()\n",
    "\n",
    "    forecast_r = arfima_predict(train_resid.values, len(y_test))  \n",
    "    print(len(forecast_r))\n",
    "    \n",
    "    # walk forward over time steps in test\n",
    "    #history = train_resid[len(train_resid):-1]\n",
    "    #history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]\n",
    "        #error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        #length = len(history)\n",
    "        #lag = [history[i] for i in range(length-window,length)]\n",
    "        #pred_error = coef[0]\n",
    "        #for d in range(window):\n",
    "            #pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        #print(yhat)\n",
    "        #print(pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] )\n",
    "        yhat = yhat + pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] \n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        #history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))\n",
    "\n",
    "'''\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "residuals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\n",
    "\n",
    "y_adjusted = predicteds.copy()\n",
    "\n",
    "for i in range(0,len(y_test)):    \n",
    "    \n",
    "    if i == 0:\n",
    "        forecast_r = arfima_predict(residuals_train.values)\n",
    "        \n",
    "    else:\n",
    "        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\n",
    "        \n",
    "        residuals = pd.concat([residuals_train,residuals_test],axis=0)\n",
    "        \n",
    "        forecast_r = arfima_predict(residuals.values)\n",
    "        \n",
    "    print(forecast_r)\n",
    "    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\n",
    "    #print(adjusted)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\n",
    "    #ar_s_model = AutoReg(residuals, lags=15)\n",
    "    #model_fit = model.fit()\n",
    "    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\n",
    "\n",
    "    #improved_forecast = forecast + estimated error\n",
    "\n",
    "    #print('Coef=%s' % (model_fit.params))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a133da3-b0fd-4741-a0aa-db8cc75f878d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weights(d, num_k):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    \n",
    "    for k in range(1, num_k):\n",
    "        w_k = np.append(w_k, -w_k[-1] * ((d - k + 1)) / k)\n",
    "        \n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def get_weights_floored(d, num_k, floor=1e-3):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$ provided weight above a minimum value\n",
    "    (floor) for the weights to prevent computation of weights for the entire\n",
    "    time series.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "        floor (float): minimum value for the weights for computational efficiency.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    k = 1\n",
    "    \n",
    "    while k < num_k:\n",
    "        w_k_latest = -w_k[-1] * ((d - k + 1)) / k\n",
    "        if abs(w_k_latest) <= floor:\n",
    "            break\n",
    "\n",
    "        w_k = np.append(w_k, w_k_latest)\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def frac_diff(df, d, floor=1e-3):\n",
    "    r\"\"\"Fractionally difference time series via CPU.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe of raw time series values.\n",
    "        d (float): differencing value from 0 to 1 where > 1 has no FD.\n",
    "        floor (float): minimum value of weights, ignoring anything smaller.\n",
    "    \"\"\"\n",
    "    # Get weights window\n",
    "    weights = get_weights_floored(d=d, num_k=len(df), floor=floor)\n",
    "    weights_window_size = len(weights)\n",
    "    \n",
    "    # Reverse weights\n",
    "    weights = weights[::-1]\n",
    "    \n",
    "    # Blank fractionally differenced series to be filled\n",
    "    df_fd = []\n",
    "\n",
    "    # Slide window of time series, to calculated fractionally differenced values\n",
    "    # per window\n",
    "    for idx in range(weights_window_size, df.shape[0]):\n",
    "        # Dot product of weights and original values\n",
    "        # to get fractionally differenced values\n",
    "        date_idx = df.index[idx]\n",
    "        df_fd.append(np.dot(weights.T, df.iloc[idx - weights_window_size:idx]).item())\n",
    "    \n",
    "    # Return FD values and weights\n",
    "    df_fd = pd.DataFrame(df_fd)\n",
    "    \n",
    "    return df_fd, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e53d3-2864-4d69-a45a-ce48217e4fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "d949ef06-ae96-4828-b02b-21a92a11b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxl = 5\n",
    "train_size = .7\n",
    "t_size = 1-train_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "id": "62e6233b-8abf-4f78-83f5-a3e7a2e26fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = pd.read_csv('/mnt/distvol/combined_set.csv')\n",
    "all_data.index = all_data.iloc[:,0]\n",
    "all_data = all_data.iloc[:,1:]\n",
    "\n",
    "filter_ = all_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "ca4d80c7-99c2-4070-b6f4-1b19d28520f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003-06-29\n",
      "2005-04-17\n",
      "2007-02-04\n",
      "2008-11-23\n",
      "2010-09-12\n",
      "2012-07-01\n",
      "2014-04-20\n",
      "2016-02-07\n",
      "2017-11-26\n",
      "2019-09-15\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "id": "8b2b9636-4857-4aaa-b13d-e2077e957c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose Y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0faf97c2c0d418193f2ca420d2516cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Y', options=('DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f3(Y):\n",
    "    \n",
    "    #Y = x\n",
    "    #output_slider_variable.value\n",
    "    internalFilter = filter_.copy()\n",
    "    internalFilter.remove(Y)\n",
    "    all_data_ = pd.concat([all_data[Y],all_data[internalFilter]], axis=1)    \n",
    "    #print(all_data_.describe())\n",
    "    display(all_data_.describe())\n",
    "    #x_ticks = all_data_.index[np.arange(0, len(all_data.index), int(len(internalFilter)/5))]\n",
    "    x_ticks  = []\n",
    "    for index, element in enumerate(all_data_.index):\n",
    "        if index % int(np.round(len(all_data_.index)/10)) == 0:\n",
    "            x_ticks.append(element)\n",
    "    plt.plot(all_data_[Y])\n",
    "    plt.xticks(x_ticks, rotation = 45)\n",
    "    plt.show()        \n",
    "    plt.hist(all_data_[Y], bins='auto')\n",
    "    plt.show()\n",
    "    diff = pd.DataFrame((all_data_[Y].pct_change())).dropna()\n",
    "    plt.hist(diff, bins='auto')\n",
    "    plt.show()\n",
    "    return(all_data_)\n",
    "    \n",
    "out = interactive(f3, Y=filter_)\n",
    "\n",
    "#output_slider_variable.observe(f4, 'value')\n",
    "\n",
    "print(\"choose Y\")\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "id": "4ee2cc18-8baf-4f8a-bcd2-9562b62237fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 02:22:07,108 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:12,387 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,367 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,551 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:15,762 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,589 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,758 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:17,216 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,142 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,361 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,987 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:19,640 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,630 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,887 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,128 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,665 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(out.result, test_size=tsize, shuffle=False)\n",
    "\n",
    "d = get_deltas(train)\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "id": "2d87fad8-9555-4fe1-a82f-18243715d650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 1487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "id": "2ed2b0f5-1e32-4e6a-8e54-ea4dbe225df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "id": "33e1c5c4-9718-4cbb-a820-9fd94e3fc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "from fracdiff import fdiff\n",
    "\n",
    "cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "def getDifferenced(i, data):\n",
    "    #v = d[[i]]\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\n",
    "    #print(i)\n",
    "    a = np.array(data.iloc[:, i])\n",
    "    \n",
    "    return fdiff(a, n=d[i], axis=0)\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "id": "2070d863-3329-4f28-8b4e-a74b5480cc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndifferenced = pd.DataFrame()\\nfor f in range(0,len(futures01)):\\n    value = pd.DataFrame(futures01[f].result())\\n    differenced = pd.concat([differenced,value],axis=1)\\n    \\ndifferenced.columns = train.columns\\ndifferenced.index = train.index\\n'"
      ]
     },
     "execution_count": 1517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "differenced = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, out.result))\n",
    "    #print(value)\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = out.result.columns\n",
    "differenced.index = out.result.index    \n",
    "\n",
    "'''\n",
    "\n",
    "differenced_train = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, train))\n",
    "    #print(value)\n",
    "    differenced_train = pd.concat([differenced_train,value],axis=1)\n",
    "    \n",
    "differenced_train.columns = train.columns\n",
    "differenced_train.index = train.index    \n",
    "\n",
    "differenced_test = pd.DataFrame()\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, test))\n",
    "    differenced_test = pd.concat([differenced_test,value],axis=1)\n",
    "\n",
    "differenced_test.columns = test.columns\n",
    "differenced_test.index = test.index\n",
    "\n",
    "differenced = pd.DataFrame()\n",
    "differenced = pd.concat([differenced_train,differenced_test],axis=0)\n",
    "'''\n",
    "differenced = pd.concat([out.result.iloc[:,0],differenced.iloc[:,1:]],axis=1)\n",
    "\n",
    "#pool01 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "#futures01 = [pool01.submit(getDifferenced, args) for args in (range(0,len(d)))]\n",
    "\n",
    "#wait(futures01, timeout=None, return_when=ALL_COMPLETED)\n",
    "#'''\n",
    "\n",
    "'''\n",
    "differenced = pd.DataFrame()\n",
    "for f in range(0,len(futures01)):\n",
    "    value = pd.DataFrame(futures01[f].result())\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = train.columns\n",
    "differenced.index = train.index\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d32f-b9a1-4196-9d43-1359b65f1c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "f492f94d-cba1-455a-b1d4-157a346f6d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://slurmw01:40000'"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = dtale.show(out.result)\n",
    "d_.open_browser()\n",
    "d_._url  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "4273fdd8-d805-4928-b7dd-bda427cf51fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport concurrent.futures\\nfrom concurrent.futures import wait, ALL_COMPLETED\\nfrom fracdiff import fdiff\\n\\ncores = int(len(os.sched_getaffinity(0)))\\n\\ndef getDifferenced(i):\\n    #v = d[[i]]\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\\n    \\n    a = np.array(out.result.iloc[:, i])\\n    \\n    return fdiff(a, n=d[i], axis=0)\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\\n\\npool01 = concurrent.futures.ProcessPoolExecutor(cores)\\n\\nfutures01 = [pool01.submit(getDifferenced, args) for args in range(0,len(d))]\\n\\nwait(futures01, timeout=None, return_when=ALL_COMPLETED)\\n'"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfa758-3cf3-4410-bfc6-85105b37a19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e2820-110a-4786-9035-98543c301b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for f in range(0,len(futures01)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "        plt.hist(Differenced_Set.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        Differenced_Set.iloc[:,1].plot()\n",
    "        plt.show()\n",
    "        plt.hist(all_data.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        all_data.iloc[:,1].plot()\n",
    "        plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce862ad-f7fc-4f0b-b376-c29d32d01281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b6b7d-d0c5-4077-b822-d79e626067b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "3d49f670-bbdb-42a8-b9e3-e75e1b60e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = out.result.corr()\n",
    "#.abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0016982-6857-424e-868a-da44b16ff66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece4be0-8244-434e-b66e-9c1f39a7c2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "id": "4d4a92b7-e5b3-49ed-b31f-5959f90e8fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "def critical_r(n, alpha = .05 ):\n",
    "    df = n - 2\n",
    "    critical_t = scipy.stats.t.isf(alpha / 2, df)\n",
    "    critical_r = np.sqrt( (critical.t^2) / ( (critical.t^2) + df ) )\n",
    "    return(critical_r)\n",
    "\n",
    "def xcorr(x, y, maxlags=10):\n",
    "    Nx = len(x)\n",
    "    if Nx != len(y):\n",
    "        raise ValueError('x and y must be equal length')\n",
    "\n",
    "    c = np.correlate(x, y, mode=2)\n",
    "\n",
    "    if maxlags is None:\n",
    "        maxlags = Nx - 1\n",
    "\n",
    "    if maxlags >= Nx or maxlags < 1:\n",
    "        raise ValueError('maxlags must be None or strictly positive < %d' % Nx)\n",
    "\n",
    "    c = c[Nx - 1 - maxlags:Nx + maxlags]\n",
    "\n",
    "    return c\n",
    "\n",
    "def getLagged_Set(set_, og):\n",
    "\n",
    "    train, test = train_test_split(set_, test_size=tsize, shuffle=False)\n",
    "    \n",
    "    residuals = pd.DataFrame(np.transpose(get_residuals(train).reshape(len(train.columns),len(train))))\n",
    "    #print(residuals)\n",
    "\n",
    "    residuals.columns = train.columns\n",
    "    residuals.index = train.index\n",
    "\n",
    "    #print(len(train))\n",
    "    #set_.index = all_data.index\n",
    "    \n",
    "    Lagged_Differenced_Set = pd.DataFrame()\n",
    "    Lagged_Set = pd.DataFrame()\n",
    "    lags = []\n",
    "    lagcorrs = []\n",
    "    ogcorrs = []\n",
    "\n",
    "    for f in range(1,len(train.columns)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "\n",
    "        data_1 = residuals.iloc[:,0]\n",
    "        data_2 = residuals.iloc[:,f]\n",
    "\n",
    "        ogc = np.array(pd.concat([data_1 - np.mean(data_1),data_2 - np.mean(data_2)],axis=1).corr())[1,0]    \n",
    "        ogcorrs.append(ogc)\n",
    "\n",
    "        #corr = xcorr(data_1 - np.mean(data_1), data_2 - np.mean(data_2),maxlags=5)\n",
    "\n",
    "        set1 = data_1 - np.mean(data_1)\n",
    "        set2 = data_2 - np.mean(data_2)\n",
    "\n",
    "        corrs_ = []\n",
    "        for i in range(0,maxl):\n",
    "            c = np.array((pd.concat([set1,set2.shift(i)],axis=1).dropna()).corr())[0,1]\n",
    "            corrs_.append(c)\n",
    "\n",
    "        #corr = np.correlate(data_1 - np.mean(data_1), data_2 - np.mean(data_2),mode='full')\n",
    "        #plt.plot(corr)\n",
    "        #plt.show()\n",
    "\n",
    "        #lag = corr.argmax() - (len(data_1) - 1)\n",
    "        lag = abs(pd.Series(corrs_)).idxmax()\n",
    "\n",
    "        #print(corr)\n",
    "        lagc = np.array(pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1).corr())[1,0]\n",
    "\n",
    "        #print(lag)\n",
    "\n",
    "        #print(ogc)\n",
    "        #print(lagc)\n",
    "\n",
    "        #print(lag)\n",
    "        #plt.plot(data_1, 'r*')\n",
    "        #plt.plot(data_2, 'b*')\n",
    "\n",
    "        lag_merged = pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1)\n",
    "\n",
    "        #x_ticks = all_data.index[np.arange(0, len(all_data.index), 5)]\n",
    "        #plt.xticks(x_ticks, rotation = 45)    \n",
    "        #plt.show()\n",
    "\n",
    "        #plt.scatter(data_2.shift(lag),data_1)\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_acf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_pacf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #y = data_1\n",
    "        #X = data_2\n",
    "        #reg = LinearRegression().fit(X, y)\n",
    "\n",
    "        #print(reg.score(X, y),reg.coef_,reg.intercept_)\n",
    "\n",
    "        #model = sm.OLS(y,X)\n",
    "        #results = model.fit()\n",
    "        #print(results.summary())\n",
    "\n",
    "        #Lagged_Differenced_Set = pd.concat([Lagged_Differenced_Set,data_2.shift(lag)],axis=1)\n",
    "        #TrainO_Lagged_Set = pd.concat([TrainO_Lagged_Set,all_data.iloc[:,f].shift(lag)],axis=1)\n",
    "        #if lag>0:\n",
    "            #lag = 0\n",
    "\n",
    "        Lagged_Set = pd.concat([Lagged_Set,og.iloc[:,f].shift(lag)],axis=1)\n",
    "\n",
    "        lagcorrs.append(lagc)\n",
    "\n",
    "        lags.append(lag)\n",
    "\n",
    "    Lagged_Set.index = set_.index\n",
    "    #stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(lagcorrs),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    \n",
    "    #print(Lagged_Set)\n",
    "    #return stats, pd.concat([data_1,Lagged_Set],axis=1),  pd.concat([data_1,Lagged_Differenced_Set],axis=1)\n",
    "    return stats, pd.concat([set_.iloc[:,0],Lagged_Set],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "id": "23eb26a0-bb46-4fd9-b9b8-2de6a3a7f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['^SP500TR', 'DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10',\n",
       "       'T5YIFR', 'BAMLHYH0A0HYM2TRIV', 'BAMLCC0A1AAATRIV', 'DGS1',\n",
       "       'BAMLCC0A4BBBTRIV', 'IC4WSA', 'WILLMICROCAPPR', 'WILLLRGCAPVAL',\n",
       "       'T5YIE', 'WTB3MS', 'WGS3MO', 'TWEXB', 'DEXCHUS', 'DEXUSUK', 'TEDRATE',\n",
       "       'VIXCLS', 'NFCI', 'BAA10Y', 'BAMLC0A0CM', 'BAMLH0A3HYC', 'DCOILBRENTEU',\n",
       "       'DCOILWTICO', 'DFF', 'DGS1MO', 'DGS30', 'DGS5', 'ICSA', 'M1', 'STLFSI2',\n",
       "       'T10Y2Y', 'T10Y3M', 'TREAST', 'QQQ', 'DIA', 'IYR', 'EWG', 'EWU', 'EWJ',\n",
       "       'EZU', 'EWZ', 'ILF', 'EWW', 'LQD', 'SHY', 'IEF', 'TLT', 'ETH', 'BCH',\n",
       "       'LTC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLK', 'XLU',\n",
       "       'MMM', 'AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'GS',\n",
       "       'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE',\n",
       "       'PG', 'TRV', 'UNH', 'VZ', 'WMT', 'WBA', 'DIS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "id": "3e80173c-962f-4b0e-b170-8186d5f9b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lagged_Set = pd.DataFrame()\n",
    "Lagged_Differenced_Set = pd.DataFrame()\n",
    "\n",
    "#'''\n",
    "#Lagged_Differenced_Set_offset = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),out.result.iloc[:,1:].pct_change()],axis=1)\n",
    "differenced_set = out.result.pct_change()\n",
    "differenced_set = differenced_set.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "ls_stats, Lagged_Differenced_Set= getLagged_Set(differenced_set, out.result)\n",
    "lso_stats, Lagged_Differenced_Set_offset= getLagged_Set(pd.concat([differenced_set.iloc[:,0].shift(-1),differenced_set.iloc[:,1:]],axis=1), out.result)\n",
    "#add in last period of y\n",
    "Lagged_Differenced_Set_offset = pd.concat([Lagged_Differenced_Set_offset.iloc[:,0],differenced_set.iloc[:,0],Lagged_Differenced_Set_offset.iloc[:,1:]],axis=1)\n",
    "#Lagged_Set_offset.index = out.result.index\n",
    "Lagged_Differenced_Set.dropna(inplace= True)\n",
    "#Lagged_Set_offset.columns = out.result.columns\n",
    "\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "\n",
    "#Lagged_Differenced_Set.dropna(inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "57b19b33-dfd6-4233-8e3c-4f266a9ce8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "2003-09-30    0.060820\n",
       "2003-12-31    0.076878\n",
       "2004-03-31   -0.004395\n",
       "2004-06-30   -0.012870\n",
       "2004-09-30    0.057999\n",
       "2004-12-31    0.029813\n",
       "2005-03-31   -0.003927\n",
       "2005-06-30    0.040415\n",
       "2005-09-30    0.009843\n",
       "2005-12-31    0.048335\n",
       "Name: ^SP500TR, dtype: float64"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e943c-2c5b-4cc8-86ca-87a1dab05a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "id": "29c83e18-ed0b-446d-89a3-86ea42e5672c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "^SP500TR       0\n",
       "AXP            0\n",
       "MMM            0\n",
       "XLU            0\n",
       "XLK            0\n",
       "              ..\n",
       "BAMLH0A3HYC    0\n",
       "BAMLC0A0CM     0\n",
       "BAA10Y         0\n",
       "ICSA           0\n",
       "DIS            0\n",
       "Length: 92, dtype: int64"
      ]
     },
     "execution_count": 1695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "temp = pd.DataFrame()\n",
    "temp = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),Lagged_Set_offset.iloc[:,1:].pct_change()],axis=1).copy()\n",
    "Lagged_Differenced_Set_offset = pd.DataFrame()\n",
    "Lagged_Differenced_Set_offset = temp.copy()\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "Lagged_Differenced_Set_offset\n",
    "Lagged_Differenced_Set_offset = Lagged_Differenced_Set_offset.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "#Lagged_Differenced_Set_offset.fillna(0)\n",
    "#preprocessing.StandardScaler().fit(Lagged_Differenced_Set_offset)\n",
    "'''\n",
    "np.sum(Lagged_Differenced_Set_offset.isin([np.inf, -np.inf, np.NaN])).sort_values(kind=\"quicksort\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "id": "8cfbc252-b567-48e9-86f9-9e57df0ac45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0  0         0\n",
      "0          DGS10  0  0.293900\n",
      "1           DTB3  1 -0.003070\n",
      "2         DGS3MO  0  0.112961\n",
      "3   MORTGAGE30US  0  0.080523\n",
      "4         DFII10  0  0.052994\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.544979\n",
      "86            VZ  0  0.511754\n",
      "87           WMT  0  0.407511\n",
      "88           WBA  0  0.457171\n",
      "89           DIS  0  0.730196\n",
      "\n",
      "[90 rows x 3 columns]\n",
      "               0  0         0\n",
      "0          DGS10  3 -0.042244\n",
      "1           DTB3  3 -0.089426\n",
      "2         DGS3MO  3 -0.088654\n",
      "3   MORTGAGE30US  3 -0.145695\n",
      "4         DFII10  2  0.041021\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.273665\n",
      "86            VZ  3  0.080712\n",
      "87           WMT  1 -0.086052\n",
      "88           WBA  3  0.151340\n",
      "89           DIS  1 -0.092398\n",
      "\n",
      "[90 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ls_stats)\n",
    "print(lso_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "id": "53aa28e7-3712-466f-96fd-7bbf115714ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SP500TR</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>DTB3</th>\n",
       "      <th>DGS3MO</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>DFII10</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>BAMLHYH0A0HYM2TRIV</th>\n",
       "      <th>BAMLCC0A1AAATRIV</th>\n",
       "      <th>DGS1</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WBA</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>0.069088</td>\n",
       "      <td>1.541751</td>\n",
       "      <td>0.915645</td>\n",
       "      <td>0.935161</td>\n",
       "      <td>0.794281</td>\n",
       "      <td>1.692419</td>\n",
       "      <td>2.458548</td>\n",
       "      <td>41.996715</td>\n",
       "      <td>352.547879</td>\n",
       "      <td>1.775484</td>\n",
       "      <td>...</td>\n",
       "      <td>24.940498</td>\n",
       "      <td>0.966422</td>\n",
       "      <td>7.378963</td>\n",
       "      <td>1.252715</td>\n",
       "      <td>22.987969</td>\n",
       "      <td>27.550304</td>\n",
       "      <td>12.984091</td>\n",
       "      <td>39.046941</td>\n",
       "      <td>1.623533</td>\n",
       "      <td>2.482302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.032607</td>\n",
       "      <td>1.495879</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.933710</td>\n",
       "      <td>0.788597</td>\n",
       "      <td>2.045645</td>\n",
       "      <td>2.634194</td>\n",
       "      <td>43.029175</td>\n",
       "      <td>362.683636</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.109538</td>\n",
       "      <td>0.965952</td>\n",
       "      <td>7.352318</td>\n",
       "      <td>1.252347</td>\n",
       "      <td>24.251518</td>\n",
       "      <td>33.238478</td>\n",
       "      <td>14.858189</td>\n",
       "      <td>36.890209</td>\n",
       "      <td>1.620360</td>\n",
       "      <td>2.447742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>-0.003881</td>\n",
       "      <td>1.590695</td>\n",
       "      <td>1.078871</td>\n",
       "      <td>1.096129</td>\n",
       "      <td>0.797332</td>\n",
       "      <td>1.893750</td>\n",
       "      <td>2.481250</td>\n",
       "      <td>43.544771</td>\n",
       "      <td>354.851562</td>\n",
       "      <td>2.472742</td>\n",
       "      <td>...</td>\n",
       "      <td>16.016526</td>\n",
       "      <td>0.968542</td>\n",
       "      <td>7.595334</td>\n",
       "      <td>1.252234</td>\n",
       "      <td>27.052105</td>\n",
       "      <td>37.703203</td>\n",
       "      <td>14.630292</td>\n",
       "      <td>37.523092</td>\n",
       "      <td>1.619811</td>\n",
       "      <td>2.533420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>0.045642</td>\n",
       "      <td>1.544377</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>1.513906</td>\n",
       "      <td>0.793859</td>\n",
       "      <td>1.690484</td>\n",
       "      <td>2.410484</td>\n",
       "      <td>43.206397</td>\n",
       "      <td>363.761045</td>\n",
       "      <td>3.072459</td>\n",
       "      <td>...</td>\n",
       "      <td>16.911974</td>\n",
       "      <td>0.971730</td>\n",
       "      <td>8.632519</td>\n",
       "      <td>1.253729</td>\n",
       "      <td>27.104700</td>\n",
       "      <td>41.275508</td>\n",
       "      <td>15.591040</td>\n",
       "      <td>36.719812</td>\n",
       "      <td>1.632797</td>\n",
       "      <td>2.586150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.010137</td>\n",
       "      <td>1.523840</td>\n",
       "      <td>2.011613</td>\n",
       "      <td>2.047419</td>\n",
       "      <td>0.791116</td>\n",
       "      <td>1.717705</td>\n",
       "      <td>2.453279</td>\n",
       "      <td>44.018290</td>\n",
       "      <td>370.418636</td>\n",
       "      <td>3.337344</td>\n",
       "      <td>...</td>\n",
       "      <td>18.243953</td>\n",
       "      <td>0.970402</td>\n",
       "      <td>8.825318</td>\n",
       "      <td>1.254591</td>\n",
       "      <td>23.588805</td>\n",
       "      <td>44.026221</td>\n",
       "      <td>16.741129</td>\n",
       "      <td>33.769871</td>\n",
       "      <td>1.638542</td>\n",
       "      <td>2.558298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.003958</td>\n",
       "      <td>1.220122</td>\n",
       "      <td>2.388361</td>\n",
       "      <td>2.438525</td>\n",
       "      <td>0.760357</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>1.944921</td>\n",
       "      <td>73.572146</td>\n",
       "      <td>637.862812</td>\n",
       "      <td>1.845000</td>\n",
       "      <td>...</td>\n",
       "      <td>79.716758</td>\n",
       "      <td>1.018707</td>\n",
       "      <td>82.613387</td>\n",
       "      <td>1.310248</td>\n",
       "      <td>117.868538</td>\n",
       "      <td>255.783684</td>\n",
       "      <td>51.443717</td>\n",
       "      <td>109.754493</td>\n",
       "      <td>1.769093</td>\n",
       "      <td>3.600235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-0.032009</td>\n",
       "      <td>1.140147</td>\n",
       "      <td>2.304921</td>\n",
       "      <td>2.354762</td>\n",
       "      <td>0.749156</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>1.834531</td>\n",
       "      <td>73.014092</td>\n",
       "      <td>662.025846</td>\n",
       "      <td>1.575806</td>\n",
       "      <td>...</td>\n",
       "      <td>82.250245</td>\n",
       "      <td>1.019433</td>\n",
       "      <td>84.411047</td>\n",
       "      <td>1.309857</td>\n",
       "      <td>121.248230</td>\n",
       "      <td>269.978145</td>\n",
       "      <td>52.873113</td>\n",
       "      <td>115.861732</td>\n",
       "      <td>1.736154</td>\n",
       "      <td>3.605762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0.208827</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>1.983594</td>\n",
       "      <td>2.026094</td>\n",
       "      <td>0.736517</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>1.755806</td>\n",
       "      <td>71.316802</td>\n",
       "      <td>704.624478</td>\n",
       "      <td>1.067742</td>\n",
       "      <td>...</td>\n",
       "      <td>79.254899</td>\n",
       "      <td>1.019993</td>\n",
       "      <td>93.038666</td>\n",
       "      <td>1.309202</td>\n",
       "      <td>137.445766</td>\n",
       "      <td>282.275764</td>\n",
       "      <td>53.411418</td>\n",
       "      <td>112.660589</td>\n",
       "      <td>1.738538</td>\n",
       "      <td>3.557512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.978977</td>\n",
       "      <td>1.576935</td>\n",
       "      <td>1.607581</td>\n",
       "      <td>0.738111</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>1.572903</td>\n",
       "      <td>74.017057</td>\n",
       "      <td>714.379538</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>...</td>\n",
       "      <td>76.548235</td>\n",
       "      <td>1.020851</td>\n",
       "      <td>92.050876</td>\n",
       "      <td>1.313030</td>\n",
       "      <td>142.459886</td>\n",
       "      <td>304.001915</td>\n",
       "      <td>56.515780</td>\n",
       "      <td>121.245848</td>\n",
       "      <td>1.749870</td>\n",
       "      <td>3.486990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.121361</td>\n",
       "      <td>0.827040</td>\n",
       "      <td>1.081613</td>\n",
       "      <td>1.104032</td>\n",
       "      <td>0.731042</td>\n",
       "      <td>-0.478889</td>\n",
       "      <td>1.483175</td>\n",
       "      <td>75.440865</td>\n",
       "      <td>733.438923</td>\n",
       "      <td>0.134687</td>\n",
       "      <td>...</td>\n",
       "      <td>80.272736</td>\n",
       "      <td>1.021529</td>\n",
       "      <td>91.585849</td>\n",
       "      <td>1.314522</td>\n",
       "      <td>131.167868</td>\n",
       "      <td>333.177687</td>\n",
       "      <td>54.170968</td>\n",
       "      <td>131.581336</td>\n",
       "      <td>1.733090</td>\n",
       "      <td>3.551627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^SP500TR     DGS10      DTB3    DGS3MO  MORTGAGE30US    DFII10  \\\n",
       "Unnamed: 0                                                                   \n",
       "2004-09-30  0.069088  1.541751  0.915645  0.935161      0.794281  1.692419   \n",
       "2004-12-31  0.032607  1.495879  0.916129  0.933710      0.788597  2.045645   \n",
       "2005-03-31 -0.003881  1.590695  1.078871  1.096129      0.797332  1.893750   \n",
       "2005-06-30  0.045642  1.544377  1.488281  1.513906      0.793859  1.690484   \n",
       "2005-09-30  0.010137  1.523840  2.011613  2.047419      0.791116  1.717705   \n",
       "...              ...       ...       ...       ...           ...       ...   \n",
       "2019-12-31 -0.003958  1.220122  2.388361  2.438525      0.760357  0.515873   \n",
       "2020-03-31 -0.032009  1.140147  2.304921  2.354762      0.749156  0.154219   \n",
       "2020-06-30  0.208827  0.980938  1.983594  2.026094      0.736517  0.153387   \n",
       "2020-09-30  0.094300  0.978977  1.576935  1.607581      0.738111 -0.063226   \n",
       "2020-12-31  0.121361  0.827040  1.081613  1.104032      0.731042 -0.478889   \n",
       "\n",
       "              T5YIFR  BAMLHYH0A0HYM2TRIV  BAMLCC0A1AAATRIV      DGS1  ...  \\\n",
       "Unnamed: 0                                                            ...   \n",
       "2004-09-30  2.458548           41.996715        352.547879  1.775484  ...   \n",
       "2004-12-31  2.634194           43.029175        362.683636  2.075000  ...   \n",
       "2005-03-31  2.481250           43.544771        354.851562  2.472742  ...   \n",
       "2005-06-30  2.410484           43.206397        363.761045  3.072459  ...   \n",
       "2005-09-30  2.453279           44.018290        370.418636  3.337344  ...   \n",
       "...              ...                 ...               ...       ...  ...   \n",
       "2019-12-31  1.944921           73.572146        637.862812  1.845000  ...   \n",
       "2020-03-31  1.834531           73.014092        662.025846  1.575806  ...   \n",
       "2020-06-30  1.755806           71.316802        704.624478  1.067742  ...   \n",
       "2020-09-30  1.572903           74.017057        714.379538  0.174286  ...   \n",
       "2020-12-31  1.483175           75.440865        733.438923  0.134687  ...   \n",
       "\n",
       "                  MRK      MSFT        NKE        PG         TRV         UNH  \\\n",
       "Unnamed: 0                                                                     \n",
       "2004-09-30  24.940498  0.966422   7.378963  1.252715   22.987969   27.550304   \n",
       "2004-12-31  24.109538  0.965952   7.352318  1.252347   24.251518   33.238478   \n",
       "2005-03-31  16.016526  0.968542   7.595334  1.252234   27.052105   37.703203   \n",
       "2005-06-30  16.911974  0.971730   8.632519  1.253729   27.104700   41.275508   \n",
       "2005-09-30  18.243953  0.970402   8.825318  1.254591   23.588805   44.026221   \n",
       "...               ...       ...        ...       ...         ...         ...   \n",
       "2019-12-31  79.716758  1.018707  82.613387  1.310248  117.868538  255.783684   \n",
       "2020-03-31  82.250245  1.019433  84.411047  1.309857  121.248230  269.978145   \n",
       "2020-06-30  79.254899  1.019993  93.038666  1.309202  137.445766  282.275764   \n",
       "2020-09-30  76.548235  1.020851  92.050876  1.313030  142.459886  304.001915   \n",
       "2020-12-31  80.272736  1.021529  91.585849  1.314522  131.167868  333.177687   \n",
       "\n",
       "                   VZ         WMT       WBA       DIS  \n",
       "Unnamed: 0                                             \n",
       "2004-09-30  12.984091   39.046941  1.623533  2.482302  \n",
       "2004-12-31  14.858189   36.890209  1.620360  2.447742  \n",
       "2005-03-31  14.630292   37.523092  1.619811  2.533420  \n",
       "2005-06-30  15.591040   36.719812  1.632797  2.586150  \n",
       "2005-09-30  16.741129   33.769871  1.638542  2.558298  \n",
       "...               ...         ...       ...       ...  \n",
       "2019-12-31  51.443717  109.754493  1.769093  3.600235  \n",
       "2020-03-31  52.873113  115.861732  1.736154  3.605762  \n",
       "2020-06-30  53.411418  112.660589  1.738538  3.557512  \n",
       "2020-09-30  56.515780  121.245848  1.749870  3.486990  \n",
       "2020-12-31  54.170968  131.581336  1.733090  3.551627  \n",
       "\n",
       "[66 rows x 91 columns]"
      ]
     },
     "execution_count": 1654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fb84f-111c-44f6-8fcc-7519b387e5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb40926-6979-4f9f-ad09-ed1f93c25a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "id": "d1422b2e-d8e4-43aa-a691-8c54392a6291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null hypothesis can be rejected\n",
      "6.865763215609389\n",
      "The null hypothesis can be rejected\n",
      "6.896546949666965\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.2560705858400435\n",
      "The null hypothesis can be rejected\n",
      "-0.25410510887178017\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.8168452771342554\n",
      "The null hypothesis can be rejected\n",
      "-1.2203262001462745\n",
      "The null hypothesis can be rejected\n",
      "3.980324132809734\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.0330533902639862\n",
      "The null hypothesis can be rejected\n",
      "-1.1348510594870023\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "8.441819888635504\n",
      "The null hypothesis can be rejected\n",
      "1.0871887239135765\n",
      "The null hypothesis can be rejected\n",
      "-0.225351519493807\n",
      "The null hypothesis can be rejected\n",
      "-0.22331262559486822\n",
      "The null hypothesis can be rejected\n",
      "-11.643674081625615\n",
      "The null hypothesis can be rejected\n",
      "-7.872592517879663\n",
      "The null hypothesis can be rejected\n",
      "6.810550509799163\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.8610001927627393\n",
      "The null hypothesis can be rejected\n",
      "0.47387019426883464\n",
      "The null hypothesis can be rejected\n",
      "-1.350128792241651\n",
      "The null hypothesis can be rejected\n",
      "-1.068536116050812\n",
      "The null hypothesis can be rejected\n",
      "-1.5907297978977153\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.1763642319332284\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.1608393629115443\n",
      "The null hypothesis can be rejected\n",
      "-17.292496103544497\n",
      "The null hypothesis can be rejected\n",
      "0.8424543841737614\n",
      "The null hypothesis can be rejected\n",
      "0.6627659332477958\n",
      "The null hypothesis can be rejected\n",
      "0.9814454834302564\n",
      "The null hypothesis can be rejected\n",
      "-1.8518943770701226\n",
      "The null hypothesis can be rejected\n",
      "4.430956496153695\n",
      "The null hypothesis can be rejected\n",
      "7.347405992272229\n",
      "The null hypothesis can be rejected\n",
      "5.375556488149038\n",
      "The null hypothesis can be rejected\n",
      "3.7236366650415897\n",
      "The null hypothesis can be rejected\n",
      "4.622498957737785\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.295897679021274\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "2.994049643817101\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-71.80123292863226\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.2630315430220875\n",
      "The null hypothesis can be rejected\n",
      "8.62589778332678\n",
      "The null hypothesis can be rejected\n",
      "3.6941919528144713\n",
      "The null hypothesis can be rejected\n",
      "3.2126497040172124\n",
      "The null hypothesis can be rejected\n",
      "7.184903442065814\n",
      "The null hypothesis can be rejected\n",
      "6.193200910291322\n",
      "The null hypothesis can be rejected\n",
      "3.980512866916982\n",
      "The null hypothesis can be rejected\n",
      "4.479987948401211\n",
      "The null hypothesis can be rejected\n",
      "10.03254035404625\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.8597491249632236\n",
      "The null hypothesis can be rejected\n",
      "-2.5531656292171774\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.6337017753465424\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.267169095042328\n",
      "The null hypothesis can be rejected\n",
      "4.057632902860579\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "5.168826328875348\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n"
     ]
    }
   ],
   "source": [
    "#skip correlation\n",
    "#Lagged_Differenced_Set_offset = pd.concat([our.result.iloc[:,0].pct_change().shift(-1),differenced_set.iloc[:,0],Lagged_Differenced_Set_offset.iloc[:,1:]],axis=1)\n",
    "#Lagged_Set_offset.index = out.result.index\n",
    "#Lagged_Differenced_Set.dropna(inplace= True)\n",
    "\n",
    "set_ = Lagged_Differenced_Set\n",
    "set_ = pd.concat([differenced_set.iloc[:,0].shift(-1),differenced_set.iloc[:,0],differenced_set.iloc[:,1:]],axis=1)\n",
    "set_.dropna(inplace=True)\n",
    "set_ = set_.tail(-1)\n",
    "transformed, lambdas = transform_boxcox(set_.dropna())\n",
    "\n",
    "#revert_yeo(Lagged_Differenced_Set_offset, transformed, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72722f-fbff-4bff-92b8-26b19888e415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "8cc90237-f851-4afb-86f8-2dca0b41123d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbd = True\n",
    "ic = True\n",
    "\n",
    "# evaluate an elastic net model on the dataset\n",
    "#tsize = .20\n",
    "#train, test = train_test_split(Lagged_Differenced_Set_offset.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "train, test = train_test_split(transformed.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=ic)\n",
    "\n",
    "#train_t, lambdas_t = transform_boxcox(train)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    train_t = train\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_t)\n",
    "\n",
    "#\n",
    "train_s = pd.DataFrame(scaler.transform(train_t))\n",
    "train_s.columns = train.columns\n",
    "train_s.index = train.index  \n",
    "\n",
    "train_t = train_s\n",
    "\n",
    "#test_t = transform_boxcox_l(test, lambdas_t)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    test_t = test\n",
    "\n",
    "test_s = pd.DataFrame(scaler.transform(test_t))\n",
    "test_s.columns = test.columns\n",
    "test_s.index = test.index\n",
    "\n",
    "test_t = test_s\n",
    "\n",
    "y_train = pd.DataFrame(train_t.iloc[:,0])\n",
    "\n",
    "#exclude y\n",
    "\n",
    "X_inter_train = pd.DataFrame(interaction.fit_transform(train_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_t.iloc[:,1:]).columns))\n",
    "\n",
    "    #apply ZCA each time a set of factors are removed (i.e. iteratively)\n",
    " #trf = zca.ZCA().fit(X_inter_train)\n",
    "  #trf = zca.ZCA().fit(X_train)\n",
    "\n",
    " #X_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "  #X_train = pd.DataFrame(trf.transform(X_train))\n",
    " #X_train.columns=X_inter_train.columns\n",
    "  #X_train.columns=X_train.columns\n",
    "  #X_train.index = train.index\n",
    "\n",
    "#X_inter_alt = X_train.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#print(X_inter_alt.head(3))\n",
    "\n",
    "y_test = pd.DataFrame(test_t.iloc[:,0])\n",
    "\n",
    "X_inter_test = pd.DataFrame(interaction.fit_transform(test_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(test_t.iloc[:,1:]).columns))\n",
    "\n",
    " #X_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "  #X_test = pd.DataFrame(trf.transform(X_test))\n",
    "\n",
    " #X_test.columns=X_inter_test.columns\n",
    "  #X_test.columns=X_test.columns\n",
    "  #X_test.index = test.index\n",
    "\n",
    "#X_inter_t_alt = X_test.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#X_inter_t_alt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf46d0-1162-46d6-a166-0461b321e0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "\n",
    " #model = ElasticNetCV(l1_ratio=ratios, alphas=alphas, cv=cv, n_jobs=4, verbose=0, precompute='auto')\n",
    "\n",
    "model = ElasticNet()\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "#search = HalvingRandomSearchCV(model, grid,resource='n_samples',max_resources=10,random_state=0)\n",
    "\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    " #results = search.fit(X_inter_train, y_train)\n",
    "#results = search.fit(X_train, y_train)\n",
    "\n",
    "results = search.fit(X_inter_train, y_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "print(results.best_estimator_)\n",
    "best_model = ElasticNet(alpha=results.best_estimator_.alpha, l1_ratio = results.best_estimator_.l1_ratio)\n",
    "\n",
    "#pd.concat([all_data[Y],all_data_int],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb7965-c50b-4f1e-bd5e-05504a69192f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_inter_train,train_t.iloc[:,0])\n",
    "\n",
    "trainScore = best_model.score(X_inter_train, y_train, sample_weight=None)\n",
    "testScore = best_model.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore)\n",
    "print(testScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb694fa2-0e07-4a01-8648-2d6615a70b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "093a64f9-522d-4761-adf1-f55d566a1b70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b12fd-2b69-4243-909a-6f828aa43b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "0e86999a-16ba-4505-b5ec-843d219ac62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.538462\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367906e7-5aec-4529-8f29-42040e9ac43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "id": "14400790-a56a-4084-8c56-cf73697546e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03847608420351106\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.8648952817620676, pvalue=0.39785994499471344)\n",
      "0.026106343953183363\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.9892221018930833, pvalue=0.3323169495195316)\n"
     ]
    }
   ],
   "source": [
    "#classification transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE \n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#set_ = Lagged_Differenced_Set_offset.copy()\n",
    "#set_ = transformed.copy()\n",
    "#DF_list = list()\n",
    "\n",
    "sets = list()\n",
    "sets.append(transformed.copy())\n",
    "#sets.append(Lagged_Differenced_Set_offset.copy())\n",
    "sets.append(set_.copy())\n",
    "\n",
    "def return_sets(sets):    \n",
    "    \n",
    "    sets_outer = list()\n",
    "    \n",
    "    for i in sets:\n",
    "        \n",
    "        sets_multiple = list()\n",
    "        \n",
    "        set_ = pd.DataFrame()\n",
    "        set_ = i\n",
    "\n",
    "        X, y = set_.iloc[:,1:],  set_.iloc[:,0]\n",
    "        \n",
    "        print(mean(y))\n",
    "\n",
    "        y = pd.DataFrame(np.where(y > mean(y), 1, 0))\n",
    "        y.index = set_.index\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize, shuffle=False)\n",
    "\n",
    "        a = set_.iloc[:,0].loc[X_train.index]\n",
    "        b = set_.iloc[:,0].loc[X_test.index]\n",
    "        plt.hist(a)\n",
    "        plt.show()\n",
    "        plt.hist(b)\n",
    "        plt.show()\n",
    "        print(stats.ttest_ind(a,b, equal_var = False))\n",
    "\n",
    "        one = y_train[y_train==0].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "        two = y_train[y_train==1].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "\n",
    "        train_index = np.append(one.index,two.index)\n",
    "\n",
    "        #destroyed my data\n",
    "        #smote = SVMSMOTE(random_state=42)\n",
    "            #smote = SMOTE()\n",
    "        #Xsm_train, ysm_train = smote.fit_sample(np.array(X_train),np.array(y_train))\n",
    "\n",
    "        Xsm_train = X_train.copy()\n",
    "        ysm_train = y_train.copy()\n",
    "        \n",
    "        #use with optimal lags\n",
    "        #y_test = y_test.loc[y_test.index>y_test.index[maxl]]\n",
    "        #X_test = X_test.loc[X_test.index>X_test.index[maxl]]\n",
    "\n",
    "        scaler = preprocessing.StandardScaler().fit(Xsm_train)\n",
    "\n",
    "        X_train_transformed = pd.DataFrame(scaler.transform(Xsm_train))\n",
    "        X_train_transformed.columns = X_train.columns\n",
    "\n",
    "        X_inter_train = X_train_transformed.copy()\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(interaction.fit_transform(X_train_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_train_transformed).columns))\n",
    "\n",
    "        trf = zca.ZCA().fit(X_inter_train)\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "        X_inter_train.columns=pd.DataFrame(X_inter_train).columns\n",
    "        #X_inter_train.index = X_train.loc[train_index].index\n",
    "\n",
    "        X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "        X_test_transformed.columns = X_test.columns\n",
    "        X_test_transformed.index = X_test.index\n",
    "\n",
    "        X_inter_test = X_test_transformed\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(interaction.fit_transform(X_test_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_test_transformed).columns))\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "\n",
    "        sets_multiple.append(X_inter_train)\n",
    "        sets_multiple.append(y_train)\n",
    "        sets_multiple.append(X_inter_test)\n",
    "        sets_multiple.append(y_test)        \n",
    "    \n",
    "        sets_outer.append(sets_multiple)\n",
    "        \n",
    "    return(sets_outer)\n",
    "\n",
    "values = return_sets(sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568baa66-4a53-4f23-ba8a-c5f9408f1591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "id": "73ec310d-7f86-4154-be9b-11c927a6a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "id": "e560215f-9b7d-4d76-ac61-dbf96d2cfd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49 accuracy with a standard deviation of 0.10\n",
      "0.9090909090909091\n",
      "0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        30\n",
      "           1       1.00      0.80      0.89        25\n",
      "\n",
      "    accuracy                           0.91        55\n",
      "   macro avg       0.93      0.90      0.91        55\n",
      "weighted avg       0.92      0.91      0.91        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[30  0]\n",
      " [ 5 20]]\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "0.47 accuracy with a standard deviation of 0.12\n",
      "0.8545454545454545\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.82        26\n",
      "           1       0.78      1.00      0.88        29\n",
      "\n",
      "    accuracy                           0.85        55\n",
      "   macro avg       0.89      0.85      0.85        55\n",
      "weighted avg       0.89      0.85      0.85        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[18  8]\n",
      " [ 0 29]]\n",
      "[[2 3]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.62      0.56      0.59         9\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.34      0.32      0.33        14\n",
      "weighted avg       0.54      0.50      0.52        14\n",
      "\n",
      "[[2 3 0]\n",
      " [3 5 1]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "#works best\n",
    "#class balanced, no zca\n",
    "from sklearn import svm\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    clf = svm.SVC(kernel='rbf', C=1, random_state=42)\n",
    "\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "    clf = svm.SVC(C=1).fit(X_train, y_train)\n",
    "\n",
    "    train_predict = clf.predict(X_train)\n",
    "    predicteds = clf.predict(X_test)\n",
    "    #predicted.index = y_test.index\n",
    "\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(clf.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predicteds))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predicteds))\n",
    "\n",
    "    predictions_s = arima_adjust(y_train, y_test, train_predict, predicteds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "id": "ec38a51f-ede1-47bb-9af7-ee25b6106160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25944973-ee0b-4b74-be6c-f59463229bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39fe4e-d604-4fa9-ad81-ee7a53a06784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "3909eb8a-645f-47c5-933a-98d61f3d6ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('svc', svm.SVC(kernel='sigmoid', C=1, random_state=42))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)\n",
    "'''\n",
    "#search = cross_val_score(pipe, X_inter_train, y_train.loc[train_index], cv=10)\n",
    "#GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#search.fit(X_digits, y_digits)\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "#print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "d83b6ec4-6148-41ba-9d1b-3765f913ee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "id": "b49b4466-cd31-4f19-85e0-c32db62dbe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "0.9818181818181818\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        30\n",
      "           1       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.98        55\n",
      "   macro avg       0.98      0.98      0.98        55\n",
      "weighted avg       0.98      0.98      0.98        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.56      0.62      0.59         8\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.48      0.48      0.48        14\n",
      "weighted avg       0.49      0.50      0.49        14\n",
      "\n",
      "[[30  0]\n",
      " [ 1 24]]\n",
      "[[2 4]\n",
      " [3 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.56      0.62      0.59         8\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.48      0.48      0.48        14\n",
      "weighted avg       0.49      0.50      0.49        14\n",
      "\n",
      "[[2 4]\n",
      " [3 5]]\n",
      "LogisticRegression()\n",
      "1.0\n",
      "0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29         5\n",
      "           1       0.67      0.89      0.76         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.58      0.54      0.52        14\n",
      "weighted avg       0.61      0.64      0.59        14\n",
      "\n",
      "[[26  0]\n",
      " [ 0 29]]\n",
      "[[1 4]\n",
      " [1 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29         5\n",
      "           1       0.67      0.89      0.76         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.58      0.54      0.52        14\n",
      "weighted avg       0.61      0.64      0.59        14\n",
      "\n",
      "[[1 4]\n",
      " [1 8]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modell = LogisticRegression()\n",
    "    modell.fit(X_train, y_train)\n",
    "    print(modell)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modell.predict(X_train)\n",
    "    predictedl = modell.predict(X_test)\n",
    "\n",
    "    print(modell.score(X_train, y_train))\n",
    "    print(modell.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedl))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedl))\n",
    "    \n",
    "    predictions_l = arima_adjust(y_train, y_test, train_predict, predictedl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "id": "7672895b-f442-45b4-8cb1-3257e8c830a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "0.7272727272727273\n",
      "0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74        30\n",
      "           1       0.68      0.76      0.72        25\n",
      "\n",
      "    accuracy                           0.73        55\n",
      "   macro avg       0.73      0.73      0.73        55\n",
      "weighted avg       0.73      0.73      0.73        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.50      0.43         6\n",
      "           1       0.50      0.38      0.43         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.44      0.44      0.43        14\n",
      "weighted avg       0.45      0.43      0.43        14\n",
      "\n",
      "[[21  9]\n",
      " [ 6 19]]\n",
      "[[3 3]\n",
      " [5 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.57      0.50      0.53         8\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.24      0.21      0.22        14\n",
      "weighted avg       0.50      0.43      0.46        14\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 2 3 1]\n",
      " [1 3 4 0]\n",
      " [0 0 0 0]]\n",
      "GaussianNB()\n",
      "0.6909090909090909\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.46      0.59        26\n",
      "           1       0.65      0.90      0.75        29\n",
      "\n",
      "    accuracy                           0.69        55\n",
      "   macro avg       0.73      0.68      0.67        55\n",
      "weighted avg       0.72      0.69      0.67        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[12 14]\n",
      " [ 3 26]]\n",
      "[[2 3]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[2 3]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeln = GaussianNB()\n",
    "    modeln.fit(X_train, y_train)\n",
    "    print(modeln)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeln.predict(X_train)\n",
    "    predictedn = modeln.predict(X_test)\n",
    "\n",
    "    print(modeln.score(X_train, y_train))\n",
    "    print(modeln.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedn))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedn))\n",
    "    \n",
    "    predictions_n = arima_adjust(y_train, y_test, train_predict, predictedn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "id": "644b63d8-9f6e-453e-b896-0ee262d1242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "1.0\n",
      "0.21428571428571427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.38      0.33      0.35         9\n",
      "\n",
      "    accuracy                           0.21        14\n",
      "   macro avg       0.19      0.17      0.18        14\n",
      "weighted avg       0.24      0.21      0.23        14\n",
      "\n",
      "[[26  0]\n",
      " [ 0 29]]\n",
      "[[0 5]\n",
      " [6 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.38      0.33      0.35         9\n",
      "\n",
      "    accuracy                           0.21        14\n",
      "   macro avg       0.19      0.17      0.18        14\n",
      "weighted avg       0.24      0.21      0.23        14\n",
      "\n",
      "[[0 5]\n",
      " [6 3]]\n",
      "DecisionTreeClassifier()\n",
      "1.0\n",
      "0.35714285714285715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         6\n",
      "           1       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.37      0.38      0.35        14\n",
      "weighted avg       0.37      0.36      0.35        14\n",
      "\n",
      "[[30  0]\n",
      " [ 0 25]]\n",
      "[[3 3]\n",
      " [6 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         6\n",
      "           1       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.37      0.38      0.35        14\n",
      "weighted avg       0.37      0.36      0.35        14\n",
      "\n",
      "[[3 3]\n",
      " [6 2]]\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "#works best with transformed\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in reversed(range(0,len(sets))):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeld = DecisionTreeClassifier()\n",
    "    modeld.fit(X_train, y_train)\n",
    "    print(modeld)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeld.predict(X_train)\n",
    "    predictedd = modeld.predict(X_test)\n",
    "\n",
    "    print(modeld.score(X_train, y_train))\n",
    "    print(modeld.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedd))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedd))\n",
    "        \n",
    "    predictions_d = arima_adjust(y_train, y_test, train_predict, predictedd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "id": "6ce0671f-8931-4f7e-936b-51adcb52dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 8}\n",
      "0.5272727272727272\n",
      "1.0\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         6\n",
      "           1       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.56      0.56      0.56        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[30  0]\n",
      " [ 0 25]]\n",
      "[[3 3]\n",
      " [3 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         6\n",
      "           1       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.56      0.56      0.56        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[3 3]\n",
      " [3 5]]\n",
      "{'n_neighbors': 22}\n",
      "0.5818181818181818\n",
      "1.0\n",
      "0.7142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.69      1.00      0.82         9\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.85      0.60      0.58        14\n",
      "weighted avg       0.80      0.71      0.65        14\n",
      "\n",
      "[[26  0]\n",
      " [ 0 29]]\n",
      "[[1 4]\n",
      " [0 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.69      1.00      0.82         9\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.85      0.60      0.58        14\n",
      "weighted avg       0.80      0.71      0.65        14\n",
      "\n",
      "[[1 4]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "#works best with transformed\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV#create new a knn model\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "    \n",
    "    knn2 = KNeighborsClassifier(metric='euclidean',weights='distance')#create a dictionary of all values we want to test for n_neighbors\n",
    "    param_grid = {'n_neighbors': np.arange(1, 25)}#use gridsearch to test all values for n_neighbors\n",
    "    knn_gscv = GridSearchCV(knn2, param_grid, cv=5)#fit model to data\n",
    "    knn_gscv.fit(X_train, y_train)\n",
    "    #check top performing n_neighbors value\n",
    "    print(knn_gscv.best_params_)\n",
    "    #check mean score for the top performing value of n_neighbors\n",
    "    print(knn_gscv.best_score_)\n",
    "\n",
    "    modelk = KNeighborsClassifier(n_neighbors = knn_gscv.best_params_['n_neighbors'],metric='euclidean',weights='distance')\n",
    "    modelk.fit(X_train,y_train)\n",
    "    train_predict = modelk.predict(X_train)\n",
    "    predictedk = modelk.predict(X_test)\n",
    "    #modelk.score(X_test, y_test)\n",
    "\n",
    "    print(modelk.score(X_train, y_train))\n",
    "    print(modelk.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedk))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedk))\n",
    "    \n",
    "    predictions_k = arima_adjust(y_train, y_test, train_predict, predictedk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43107e46-54bb-4837-a798-af32efaccadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "e55c7caf-0c3b-4911-ba58-8313a7ba85ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-771-d7e137a3e15d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msearch_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresults_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_inter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mysm_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m  \u001b[0;31m#model.fit(X_inter_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Elastic logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = (10 ** np.linspace(-1, 1, 10))/10\n",
    "alphas = np.append(alphas,[10.0, 100.0])\n",
    "\n",
    "model = SGDClassifier(loss=\"log\", penalty=\"elasticnet\")\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "search_l = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "results_l = search_l.fit(X_inter_train, ysm_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results_l.best_score_)\n",
    "print('Config: %s' % results_l.best_params_)\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "print(results_l.best_estimator_)\n",
    "best_model_l = SGDClassifier(alpha=results_l.best_estimator_.alpha, l1_ratio = results_l.best_estimator_.l1_ratio)\n",
    "\n",
    "#calibrator = CalibratedClassifierCV(best_model_l, cv='prefit')\n",
    "#model=calibrator.fit(X_inter_train, y_train)\n",
    "\n",
    "best_model_l.fit(X_inter_train,ysm_train)\n",
    "\n",
    "#sgd = SGDClassifier()\n",
    "\n",
    "#sgd.partial_fit(X_inter_train,y_train, classes=[0,1])\n",
    "\n",
    "print(pd.DataFrame(np.transpose(best_model_l.coef_)).set_index(X_inter_train.columns))\n",
    "\n",
    "trainScore_l = best_model_l.score(X_inter_train, ysm_train, sample_weight=None)\n",
    "testScore_l = best_model_l.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore_l)\n",
    "print(testScore_l)\n",
    "\n",
    "#print(help(KNeighborsClassifier))\n",
    "predictedl = best_model_l.predict(X_inter_test)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b9087-fe22-4d54-b152-a40e48784774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "id": "7015d3fd-f35c-4f6c-b8e9-f66c92514715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.642857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "id": "a6dd1212-7817-4f74-95d6-0493d68c9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            s  k  d  l  n\n",
      "Unnamed: 0               \n",
      "2017-09-30  1  1  0  1  1\n",
      "2017-12-31  1  1  0  1  1\n",
      "2018-03-31  0  1  1  1  1\n",
      "2018-06-30  0  1  0  0  1\n",
      "2018-09-30  1  1  0  1  1\n",
      "2018-12-31  1  1  1  1  0\n",
      "2019-03-31  1  1  0  1  1\n",
      "2019-06-30  1  1  0  1  1\n",
      "2019-09-30  2  1  0  1  0\n",
      "2019-12-31  1  1  1  1  1\n",
      "2020-03-31  0  0  0  0  0\n",
      "2020-06-30  0  1  0  1  0\n",
      "2020-09-30  0  1  1  1  0\n",
      "2020-12-31  1  1  1  1  1\n",
      "[[1 4]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.20      0.22         5\n",
      "           1       0.60      0.67      0.63         9\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.42      0.43      0.43        14\n",
      "weighted avg       0.47      0.50      0.49        14\n",
      "\n",
      "0    0.642857\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#predictedf = pd.concat([pd.DataFrame(predicteds),pd.DataFrame(predictedk),pd.DataFrame(predictedl)],axis=1)\n",
    "predictedf = pd.concat([pd.DataFrame(predictions_s),pd.DataFrame(predictions_k),pd.DataFrame(predictions_d),pd.DataFrame(predictions_l),pd.DataFrame(predictions_n)],axis=1)\n",
    "predictedf.columns = [\"s\",\"k\",\"d\",\"l\",\"n\"]\n",
    "predictedf.index = y_test.index\n",
    "print(predictedf)\n",
    "print(confusion_matrix(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(confusion_matrix(y_test, predictedf.median(axis=1)))\n",
    "print(classification_report(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(classification_report(y_test, predictedf.median(axis=1)))\n",
    "\n",
    "print(mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438843e-110f-404f-b1b1-47bfa41b560b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1662,
   "id": "0e4dfc37-ab80-427f-bc37-edb9a212c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null hypothesis can be rejected\n",
      "7.647058971104165\n",
      "The null hypothesis can be rejected\n",
      "-0.12139720840982086\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.14868039412503942\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.23878868189827293\n",
      "The null hypothesis can be rejected\n",
      "0.01516434729523354\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.2847277093485631\n",
      "The null hypothesis can be rejected\n",
      "-4.421694760735331\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "2.379278265484282\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-4.252299469731882\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-3.8750570260104618\n",
      "The null hypothesis can be rejected\n",
      "-1.477240085595318\n",
      "The null hypothesis can be rejected\n",
      "-1.315225728518115\n",
      "The null hypothesis can be rejected\n",
      "-0.9987736214675152\n",
      "The null hypothesis can be rejected\n",
      "-1.7324607073327576\n",
      "The null hypothesis can be rejected\n",
      "-0.8487769134133378\n",
      "The null hypothesis can be rejected\n",
      "0.1281776304697414\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.9185081117430298\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-4.421694760735331\n",
      "The null hypothesis can be rejected\n",
      "-0.5767439075762518\n",
      "The null hypothesis can be rejected\n",
      "-0.42795074132531136\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.0147949530506908\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.04314234607975888\n",
      "The null hypothesis can be rejected\n",
      "6.379681876399842\n",
      "The null hypothesis can be rejected\n",
      "1.1825414039192585\n",
      "The null hypothesis can be rejected\n",
      "0.019329072245510122\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.6634548740163803\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.4039131599019467\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.7421303146126871\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.20335783324970835\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.8010834349067987\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.8714420624498441\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.2638528728567444\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.4225012072622937\n",
      "The null hypothesis can be rejected\n",
      "-0.33062861855368403\n",
      "The null hypothesis can be rejected\n",
      "-1.0710162934558154\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "67\n",
      "33\n",
      "34\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# multivariate output multi-step 1d cnn example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Lagged_Differenced_Set = (all_data - all_data.shift(-1)).dropna()\n",
    "choice = Lagged_Differenced_Set\n",
    "\n",
    "train, test = train_test_split(choice, test_size=tsize, shuffle=False)\n",
    "\n",
    "transformed_train, lambdas_ = transform_boxcox(train)\n",
    "\n",
    "transformed_test = transform_boxcox_l(test, lambdas_)\n",
    "\n",
    "#train_t, lambdas_t = transform_boxcox(train)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(transformed_train)\n",
    "\n",
    "train_s = pd.DataFrame(scaler.transform(train))\n",
    "test_s = pd.DataFrame(scaler.transform(transformed_test))\n",
    "\n",
    "combined = pd.concat([train_s,test_s],axis=0)\n",
    "combined.index = Lagged_Differenced_Set.index\n",
    "combined.columns = Lagged_Differenced_Set.columns\n",
    "\n",
    "set_ = combined\n",
    "\n",
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out, xcolumns, ycolumns):\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, xcolumns], sequences[end_ix:out_end_ix, ycolumns]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return array(X), array(y)\n",
    "\n",
    "#n_steps_in = int(np.floor(len(train)*.8))\n",
    "print(len(set_))\n",
    "n_steps_in = int(np.round(len(set_)/2))\n",
    "print(len(set_) - n_steps_in)\n",
    "print(n_steps_in)\n",
    "#n_steps_out = int(len(train)-n_steps_in)\n",
    "n_steps_out = 1\n",
    "print(n_steps_out)\n",
    "\n",
    "#ycolumns = range(0,len(transformed.columns))\n",
    "ycolumns = range(0,len(set_.columns[0:1].values))\n",
    "xcolumns = range(1,len(set_.columns[1:]))\n",
    "\n",
    "#trainInner, valid = train_test_split(trainOuter, test_size=0.15, shuffle=False)\n",
    "#trainInner_whitened = pd.DataFrame(trf.transform(trainInner.iloc[:,1:])).set_index(trainInner.index)\n",
    "#valid_whitened = pd.DataFrame(trf.transform(valid.iloc[:,1:])).set_index(valid.index)\n",
    "#test_whitened = pd.DataFrame(trf.transform(test.iloc[:,1:])).set_index(test.index)\n",
    "\n",
    "#trainOuter_whitened=pd.DataFrame(trf.transform(trainOuter.iloc[:,1:])).set_index(trainOuter.index)\n",
    "\n",
    "X, y = split_sequences(np.array(set_), n_steps_in, n_steps_out, xcolumns, ycolumns)\n",
    "\n",
    "#for i in range(len(X)):\n",
    "#    print(X[i], y[i])\n",
    "    \n",
    "#flatten output\n",
    "\n",
    "if len(ycolumns) > 0:\n",
    "    n_output = y.shape[1] * y.shape[2]\n",
    "    y = y.reshape((y.shape[0], n_output))\n",
    "\n",
    "n_features = X.shape[2]\n",
    "\n",
    "# define model\n",
    "modelCNN = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(n_output)\n",
    "])\n",
    "\n",
    "# fit model\n",
    "#model.fit(X, y, epochs=7000, verbose=0)\n",
    "\n",
    "epochs_ = 2000\n",
    "batch_size_ = 25\n",
    "\n",
    "#np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss='mse')\n",
    "modelCNN.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "#X_train_transformed = pd.DataFrame(scaler.transform(X_train))\n",
    "#X_train_transformed.columns = X_train.columns\n",
    "\n",
    "#X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "#X_test_transformed.columns = X_test.columns\n",
    "#X_test_transformed.index = X_test.index\n",
    "\n",
    "    #new_series = pd.DataFrame(ts_train_scaled).append(pd.DataFrame(ts_valid_scaled)).append(pd.DataFrame(ts_test_scaled))\n",
    "\n",
    "    #series_reshaped = np.array([new_series[i:i + (n_steps+n_ahead)].copy() for i in range(len(data) - (n_steps+n_ahead))])  \n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)    \n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "historyCNN = modelCNN.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history6 = model6.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history = model.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1663,
   "id": "d2d1ce87-6c86-4308-8788-b01aa8256fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to apply to test\n",
    "#revert_boxcox(pd.DataFrame(transformed_.iloc[:,0]),pd.DataFrame(lambdas[0]))\n",
    "#Lagged_Differenced_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1664,
   "id": "0b8f7e2d-3603-4ba1-8457-4fd9918498a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "plot_learning_curves(historyCNN.history[\"loss\"], historyCNN.history[\"val_loss\"])\n",
    "plt.show()\n",
    "#plot_learning_curves(history6.history[\"loss\"], history.history[\"val_loss\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1576,
   "id": "799f6d94-9757-4baa-b095-8937fbba5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.403554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.472922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.395263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.648622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.333758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-12.124576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.782852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.403554\n",
       "1  -1.472922\n",
       "2  -2.395263\n",
       "3  -2.648622\n",
       "4  -2.333758\n",
       "5 -12.124576\n",
       "6  25.782852"
      ]
     },
     "execution_count": 1576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "id": "bee4c952-450d-43d4-86c1-2a37673a58d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 1689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(revert_transformed_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1690,
   "id": "c2cbc3da-fa1f-4e57-9d84-f4e5f8872af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.031267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.047498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032469</td>\n",
       "      <td>-0.004005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.035486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234481</td>\n",
       "      <td>0.137470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.110422</td>\n",
       "      <td>0.075139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.091881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  original\n",
       "0   0.032469  0.031267\n",
       "1   0.032469  0.047498\n",
       "2   0.032469 -0.004005\n",
       "3        NaN -0.035486\n",
       "4   0.234481  0.137470\n",
       "5   0.110422  0.075139\n",
       "6   0.032469  0.091881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#multi\n",
    "yhat = modelCNN.predict(X_test, verbose=0)\n",
    "\n",
    "predicted = []\n",
    "original = []\n",
    "if len(ycolumns) > 1:\n",
    "    results = yhat.reshape(len(y_test), int(yhat.shape[1]/X_test.shape[2]), len(transformed.columns))\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(pd.DataFrame(results[i])[0][0])\n",
    "        original.append(pd.DataFrame(y_test[i])[0][0])\n",
    "        #print(pd.DataFrame(results[i])[0][0])\n",
    "        #print(pd.DataFrame(y_test[i])[0][0])\n",
    "else:\n",
    "    results = yhat\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(results[i])\n",
    "        original.append(y_test[i])\n",
    "        #print(pd.DataFrame(results[i]))\n",
    "        #print(pd.DataFrame(y_test[i]))\n",
    "        \n",
    "revert_transformed_predicted = inverse_yeo((scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted)).values,(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted)).values,lambdas_.values[0])\n",
    "revert_transformed_original = inverse_yeo((scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original)).values,(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original)).values,lambdas_.values[0])\n",
    "plt.scatter(revert_transformed_predicted,revert_transformed_original)\n",
    "temp = pd.concat([revert_transformed_predicted,revert_transformed_original],axis=1)\n",
    "temp.columns = [\"predicted\", \"original\"]\n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8229628-eed4-4b76-831d-1de033240347",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(best_model.coef_).set_index(X_inter_train.columns)\n",
    "\n",
    "a_coef = abs(coef)\n",
    "a_coef.sort_values(by=[0],ascending=False,inplace=True)\n",
    "chosen_few = a_coef[a_coef>0].dropna().index.values\n",
    "\n",
    "scaler_ = preprocessing.StandardScaler().fit(transformed)\n",
    "\n",
    "#\n",
    "train_ = pd.DataFrame(scaler_.transform(transformed))\n",
    "train_.columns = transformed.columns\n",
    "train_.index = transformed.index  \n",
    "\n",
    "X_inter_train_ = pd.DataFrame(interaction.fit_transform(train_.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_.iloc[:,1:]).columns))\n",
    "\n",
    "max_pvalue = 1\n",
    "New_Names = X_inter_train.columns\n",
    "X_b = X_inter_train_[chosen_few]\n",
    "while (max_pvalue > .05):\n",
    "        \n",
    "    trf = zca.ZCA().fit(X_b)\n",
    "        \n",
    "    X_b_z = pd.DataFrame(trf.transform(X_b))\n",
    "    X_b_z.columns=pd.DataFrame(X_b).columns\n",
    "    X_b_z.index = train_.index\n",
    "\n",
    "    model_ = sm.OLS(train_.iloc[:,0],sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    #model_ = sm.OLS(pd.DataFrame(pd.concat([train_.iloc[:,0],X_b_z],axis=1),sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    results_ = model_.fit()\n",
    "\n",
    "    set_ = X_b.columns.tolist()\n",
    "    \n",
    "    max_pvalue = max(results_.pvalues[1:])\n",
    "    if (max_pvalue > .05):\n",
    "        print(max_pvalue)\n",
    "        max_pname = (results_.pvalues[1:]).idxmax(axis=1)\n",
    "        set_.remove(max_pname)\n",
    "        New_Names = set_\n",
    "    \n",
    "        X_b = X_inter_train_[New_Names]\n",
    "        X_b.index = X_inter_train_.index\n",
    "\n",
    "#from statsmodels.formula.api import ols\n",
    "#lm = ols(pd.DataFrame(train_.iloc[:,0]) ~ sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip')).fit()\n",
    "#table = sm.stats.anova_lm(model_, type=3)\n",
    "#print(table)\n",
    "print(results_.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e428c-cce9-46e3-b145-754fc9e4c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNaNCols(df_):\n",
    "    for col in df_:        \n",
    "        num_NaNs = df_[col].isnull().sum()\n",
    "        if num_NaNs > 0:\n",
    "            print(f\"Column: {col}\")\n",
    "            print(f\"Number of NaNs: {num_NaNs}\")\n",
    "\n",
    "findNaNCols(X_b_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4e220-4ac2-4945-9e3a-4b8ff1355a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d940860-86d6-4768-81a0-63f9127143a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_plot = Plot.LinearRegressionResidualPlot(X_b_z, pd.DataFrame(train_.iloc[:,0]))\n",
    "lm = linear_plot.fit()\n",
    "summary, diag_res = linear_plot.diagnostic_plots(lm)\n",
    "print(\"Summary of Regression\\n:{}\".format(summary))\n",
    "print(\"Diagnostic Tests of Regression\\n:{}\".format(diag_res))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#sns.pairplot(pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1), hue=Y, height=2);\n",
    "\n",
    "pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1).hist()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_s = sklearn.linear_model.LinearRegression()\n",
    "model_s.fit(X_b_z, pd.DataFrame(train_[Y]))\n",
    "\n",
    "shap.initjs()\n",
    "e = shap.explainers.Linear(model_s, X_b_z)\n",
    "\n",
    "shap_values = e.shap_values(X_b_z)\n",
    "shap.summary_plot(shap_values, X_b_z)\n",
    "shap.plots.heatmap(e(X_b_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b64b8-ca00-46d1-ba16-91f3adb00065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4871c2-4418-491a-8e5c-5776d42e4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "residuals_normalized = lm.get_influence().resid_studentized_internal\n",
    "cooks = lm.get_influence().cooks_distance[0]\n",
    "cooks = np.round(f.pdf(cooks,len(lm.tvalues)+1, len(lm.fittedvalues)-len(lm.tvalues)-1),2)\n",
    "\n",
    "res_std = lm.get_influence().resid_std\n",
    "\n",
    "leverage = lm.get_influence().hat_matrix_diag\n",
    "\n",
    "plt.hist(pd.DataFrame(leverage))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(cooks))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(residuals_normalized))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "testNormal(residuals_normalized)\n",
    "\n",
    "w = res_std\n",
    "x = cooks\n",
    "y = leverage\n",
    "z = residuals_normalized\n",
    "\n",
    "fitted_y = lm.fittedvalues\n",
    "\n",
    "labels_ = fitted_y.index\n",
    "\n",
    "outlier_check = pd.concat([pd.DataFrame(x),pd.DataFrame(y),pd.DataFrame(z),pd.DataFrame(w)],axis=1).set_index(labels_)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres']\n",
    "\n",
    "qq = ProbPlot(residuals_normalized)\n",
    "\n",
    "c_thresh = .1\n",
    "l_thresh = (2*(len(lm.tvalues)-1)/len(lm.fittedvalues))\n",
    "s_thresh = max(qq.theoretical_quantiles)\n",
    "\n",
    "print(\"Outlier threshold's\")\n",
    "print(\"Cooks distance: > .1+\")\n",
    "print(\"Leverage: > \" + str(l_thresh) + \" to \" + str(3 * (len(lm.tvalues)-1)/len(fitted_y)))\n",
    "print(\"Studentized residuals: > \" + str(s_thresh))\n",
    "print()\n",
    "\n",
    "flag = []\n",
    "\n",
    "for i in range(0,len(outlier_check)):\n",
    "    if( (outlier_check.iloc[i][0] >= c_thresh) or (outlier_check.iloc[i][1] >= l_thresh) or (abs(outlier_check.iloc[i][2]) >= s_thresh) ):\n",
    "        print(outlier_check.iloc[i])\n",
    "        print()\n",
    "        flag.append(True)\n",
    "    else:\n",
    "        flag.append(False)\n",
    "\n",
    "outlier_check = pd.concat([outlier_check,pd.DataFrame(flag).set_index(labels_)],axis=1)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres', 'flagged']\n",
    "\n",
    "print(np.flip(np.argsort(cooks), 0))\n",
    "#print(outlier_check)\n",
    "\n",
    "search = outlier_check[outlier_check['flagged']==1].index.to_list()\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in search:\n",
    "    v = outlier_check.index.to_list().index(i)\n",
    "    rows.append(v)\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2b196-7761-4420-a145-a5411053a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_style(row):\n",
    "\n",
    "    color = 'white'\n",
    "    if bool(row.flagged) == True:\n",
    "        color = 'orange'\n",
    "\n",
    "    return ['background-color: %s' % color]*len(row.values)\n",
    "\n",
    "all_data[set(all_data.columns) & set(New_Names)]\n",
    "\n",
    "outlier_check.style.apply(custom_style, axis=1).apply(custom_style, axis=1).background_gradient(cmap ='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da39b86-0ac2-4470-9457-8e999918d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b8430-ac88-4358-88c1-e6c5400fe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = y_train.columns.to_list()\n",
    "df2 = list(set(set(all_data.columns) & set(New_Names)))\n",
    "\n",
    "flattened = [] \n",
    "for sublist in df1,df2: \n",
    "    for val in sublist: \n",
    "        flattened.append(val) \n",
    "\n",
    "all_data.iloc[rows][flattened].style.background_gradient(cmap ='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
