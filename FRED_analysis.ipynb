{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3139d-1ac0-4486-80f0-e54d08259ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "ee726465-0b88-46f7-877f-5aee84616ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import shap\n",
    "import numpy as np\n",
    "import ZCA as zca\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as plt\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython\n",
    "\n",
    "import os\n",
    "os.environ['R_HOME'] = '/mnt/distvol/R/4.0.5/lib64/R/'\n",
    "import rpy2.robjects as R\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import arange\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import seaborn as sns\n",
    "from ModelDiagnostics import Plot\n",
    "from sklearn.cluster import DBSCAN\n",
    "from clustergram import Clustergram\n",
    "import urbangrammar_graphics as ugg\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "\n",
    "import dtale\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "id": "78bf8827-4f34-413b-9a4d-bd6565e33372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001\n",
    "    #print(\"p = {:g}\".format(p))    \n",
    "    if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "        #print(p)\n",
    "        #print(alpha)\n",
    "        print(\"The null hypothesis can be rejected\")\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        #xt, _ = stats.boxcox(x)        \n",
    "        print(_)\n",
    "        xt = pd.DataFrame(xt)\n",
    "        \n",
    "        return _, pd.DataFrame(xt).set_index(x.index)\n",
    "    else:\n",
    "        print(\"The null hypothesis cannot be rejected\")    \n",
    "        return 1, pd.DataFrame(x)\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    power = PowerTransformer(method='yeo-johnson')\n",
    "    power.lambdas_ = lambdas.values\n",
    "    return(power.inverse_transform([data]))\n",
    "    #return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.yeojohnson((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        l, inner_scale = testNormal(data.iloc[:,i])\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def inverse_yeo(og, data_, lambda_):\n",
    "    values = []\n",
    "    for i in range(0,len(og)):\n",
    "        X = og[i]\n",
    "        X_trans = data_[i]\n",
    "        if X >= 0 and lambda_ == 0:\n",
    "            X = exp(X_trans) - 1\n",
    "        elif X >= 0 and lambda_ != 0:\n",
    "            X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
    "        elif X < 0 and lambda_ != 2:\n",
    "            X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
    "        elif X < 0 and lambda_ == 2:\n",
    "            X = 1 - exp(-X_trans)\n",
    "        \n",
    "        values.append(X)\n",
    "    return(pd.DataFrame(values))\n",
    "\n",
    "\n",
    "def revert_yeo (og, data_, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data_.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data_.iloc[:,i]\n",
    "        else:\n",
    "            p#ower = PowerTransformer(method='yeo-johnson')\n",
    "            #power.lambdas_ = lambdas.iloc[i].values\n",
    "            #revert = pd.DataFrame(power.inverse_transform([data.iloc[:,i].values]))\n",
    "            #return inv_boxcox(data, lambdas.values)\n",
    "            revert = pd.DataFrame(inverse_yeo(og.iloc[:,i].values,data_.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data_.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data_.columns\n",
    "    return reverted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "id": "2ec9d431-186e-4171-8a8a-378ab2ab2e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_deltas(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(d)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def get_residuals(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(r)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def arfima_predict(data_, ahead):\n",
    "\n",
    "    R.r('''\n",
    "               f_ <- function(values, ahead) {\n",
    "                        #system(\"which openssl\")\n",
    "                        print(nrow(values))\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x,drop=FALSE]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              #return(r)\n",
    "                              \n",
    "                              pred <- predict(varvefd, ahead)\n",
    "                              #print(ahead)\n",
    "                              #print(pred)\n",
    "                              #print(pred)\n",
    "                              return(as.data.frame(pred)[,1,drop=TRUE])\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f_ = R.globalenv['f_']\n",
    "    d_=R.conversion.rpy2py((r_f_(R.conversion.py2rpy(data_),ahead)))\n",
    "    return(d_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "id": "e43598e7-17dd-4ced-b588-e8870d3df933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "def arima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #arima residual adjusted\n",
    "    \n",
    "    window = 15\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    model = AutoReg(train_resid.values, lags=15)\n",
    "    model_fit = model.fit()\n",
    "    coef = model_fit.params\n",
    "    # walk forward over time steps in test\n",
    "    history = train_resid[len(train_resid)-window:]\n",
    "    history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]    \n",
    "        error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        length = len(history)\n",
    "        lag = [history[i] for i in range(length-window,length)]\n",
    "        pred_error = coef[0]\n",
    "        for d in range(window):\n",
    "            pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        yhat = yhat + pred_error\n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af9904-08a5-4d5f-90f7-1b4c5d4652df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9bb80-d23a-4a60-964b-41dad96d6411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "id": "1235085d-f98a-4b9d-a118-29a6f154af93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom statsmodels.tsa.ar_model import AutoReg\\n\\nresiduals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\\n\\ny_adjusted = predicteds.copy()\\n\\nfor i in range(0,len(y_test)):    \\n    \\n    if i == 0:\\n        forecast_r = arfima_predict(residuals_train.values)\\n        \\n    else:\\n        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\\n        \\n        residuals = pd.concat([residuals_train,residuals_test],axis=0)\\n        \\n        forecast_r = arfima_predict(residuals.values)\\n        \\n    print(forecast_r)\\n    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\\n    #print(adjusted)\\n    \\n    \\n    \\n    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\\n    #ar_s_model = AutoReg(residuals, lags=15)\\n    #model_fit = model.fit()\\n    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\\n\\n    #improved_forecast = forecast + estimated error\\n\\n    #print('Coef=%s' % (model_fit.params))\\n\""
      ]
     },
     "execution_count": 1448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arfima residual adjusted\n",
    "def arfima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #train_resid = get_deltas(y_train)\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    y_adjusted = predicted.copy()\n",
    "\n",
    "    forecast_r = arfima_predict(train_resid.values, len(y_test))  \n",
    "    print(len(forecast_r))\n",
    "    \n",
    "    # walk forward over time steps in test\n",
    "    #history = train_resid[len(train_resid):-1]\n",
    "    #history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]\n",
    "        #error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        #length = len(history)\n",
    "        #lag = [history[i] for i in range(length-window,length)]\n",
    "        #pred_error = coef[0]\n",
    "        #for d in range(window):\n",
    "            #pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        #print(yhat)\n",
    "        #print(pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] )\n",
    "        yhat = yhat + pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] \n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        #history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))\n",
    "\n",
    "'''\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "residuals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\n",
    "\n",
    "y_adjusted = predicteds.copy()\n",
    "\n",
    "for i in range(0,len(y_test)):    \n",
    "    \n",
    "    if i == 0:\n",
    "        forecast_r = arfima_predict(residuals_train.values)\n",
    "        \n",
    "    else:\n",
    "        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\n",
    "        \n",
    "        residuals = pd.concat([residuals_train,residuals_test],axis=0)\n",
    "        \n",
    "        forecast_r = arfima_predict(residuals.values)\n",
    "        \n",
    "    print(forecast_r)\n",
    "    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\n",
    "    #print(adjusted)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\n",
    "    #ar_s_model = AutoReg(residuals, lags=15)\n",
    "    #model_fit = model.fit()\n",
    "    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\n",
    "\n",
    "    #improved_forecast = forecast + estimated error\n",
    "\n",
    "    #print('Coef=%s' % (model_fit.params))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a133da3-b0fd-4741-a0aa-db8cc75f878d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weights(d, num_k):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    \n",
    "    for k in range(1, num_k):\n",
    "        w_k = np.append(w_k, -w_k[-1] * ((d - k + 1)) / k)\n",
    "        \n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def get_weights_floored(d, num_k, floor=1e-3):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$ provided weight above a minimum value\n",
    "    (floor) for the weights to prevent computation of weights for the entire\n",
    "    time series.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "        floor (float): minimum value for the weights for computational efficiency.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    k = 1\n",
    "    \n",
    "    while k < num_k:\n",
    "        w_k_latest = -w_k[-1] * ((d - k + 1)) / k\n",
    "        if abs(w_k_latest) <= floor:\n",
    "            break\n",
    "\n",
    "        w_k = np.append(w_k, w_k_latest)\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def frac_diff(df, d, floor=1e-3):\n",
    "    r\"\"\"Fractionally difference time series via CPU.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe of raw time series values.\n",
    "        d (float): differencing value from 0 to 1 where > 1 has no FD.\n",
    "        floor (float): minimum value of weights, ignoring anything smaller.\n",
    "    \"\"\"\n",
    "    # Get weights window\n",
    "    weights = get_weights_floored(d=d, num_k=len(df), floor=floor)\n",
    "    weights_window_size = len(weights)\n",
    "    \n",
    "    # Reverse weights\n",
    "    weights = weights[::-1]\n",
    "    \n",
    "    # Blank fractionally differenced series to be filled\n",
    "    df_fd = []\n",
    "\n",
    "    # Slide window of time series, to calculated fractionally differenced values\n",
    "    # per window\n",
    "    for idx in range(weights_window_size, df.shape[0]):\n",
    "        # Dot product of weights and original values\n",
    "        # to get fractionally differenced values\n",
    "        date_idx = df.index[idx]\n",
    "        df_fd.append(np.dot(weights.T, df.iloc[idx - weights_window_size:idx]).item())\n",
    "    \n",
    "    # Return FD values and weights\n",
    "    df_fd = pd.DataFrame(df_fd)\n",
    "    \n",
    "    return df_fd, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e53d3-2864-4d69-a45a-ce48217e4fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "d949ef06-ae96-4828-b02b-21a92a11b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxl = 5\n",
    "train_size = .7\n",
    "t_size = 1-train_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "id": "62e6233b-8abf-4f78-83f5-a3e7a2e26fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = pd.read_csv('/mnt/distvol/combined_set.csv')\n",
    "all_data.index = all_data.iloc[:,0]\n",
    "all_data = all_data.iloc[:,1:]\n",
    "\n",
    "filter_ = all_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "ca4d80c7-99c2-4070-b6f4-1b19d28520f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003-06-29\n",
      "2005-04-17\n",
      "2007-02-04\n",
      "2008-11-23\n",
      "2010-09-12\n",
      "2012-07-01\n",
      "2014-04-20\n",
      "2016-02-07\n",
      "2017-11-26\n",
      "2019-09-15\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "id": "8b2b9636-4857-4aaa-b13d-e2077e957c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose Y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0faf97c2c0d418193f2ca420d2516cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Y', options=('DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f3(Y):\n",
    "    \n",
    "    #Y = x\n",
    "    #output_slider_variable.value\n",
    "    internalFilter = filter_.copy()\n",
    "    internalFilter.remove(Y)\n",
    "    all_data_ = pd.concat([all_data[Y],all_data[internalFilter]], axis=1)    \n",
    "    #print(all_data_.describe())\n",
    "    display(all_data_.describe())\n",
    "    #x_ticks = all_data_.index[np.arange(0, len(all_data.index), int(len(internalFilter)/5))]\n",
    "    x_ticks  = []\n",
    "    for index, element in enumerate(all_data_.index):\n",
    "        if index % int(np.round(len(all_data_.index)/10)) == 0:\n",
    "            x_ticks.append(element)\n",
    "    plt.plot(all_data_[Y])\n",
    "    plt.xticks(x_ticks, rotation = 45)\n",
    "    plt.show()        \n",
    "    plt.hist(all_data_[Y], bins='auto')\n",
    "    plt.show()\n",
    "    diff = pd.DataFrame((all_data_[Y].pct_change())).dropna()\n",
    "    plt.hist(diff, bins='auto')\n",
    "    plt.show()\n",
    "    return(all_data_)\n",
    "    \n",
    "out = interactive(f3, Y=filter_)\n",
    "\n",
    "#output_slider_variable.observe(f4, 'value')\n",
    "\n",
    "print(\"choose Y\")\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "id": "4ee2cc18-8baf-4f8a-bcd2-9562b62237fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 02:22:07,108 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:12,387 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,367 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,551 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:15,762 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,589 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,758 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:17,216 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,142 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,361 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,987 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:19,640 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,630 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,887 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,128 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,665 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(out.result, test_size=tsize, shuffle=False)\n",
    "\n",
    "d = get_deltas(train)\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "id": "2d87fad8-9555-4fe1-a82f-18243715d650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 1487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "id": "2ed2b0f5-1e32-4e6a-8e54-ea4dbe225df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "id": "33e1c5c4-9718-4cbb-a820-9fd94e3fc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "from fracdiff import fdiff\n",
    "\n",
    "cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "def getDifferenced(i, data):\n",
    "    #v = d[[i]]\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\n",
    "    #print(i)\n",
    "    a = np.array(data.iloc[:, i])\n",
    "    \n",
    "    return fdiff(a, n=d[i], axis=0)\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "id": "2070d863-3329-4f28-8b4e-a74b5480cc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndifferenced = pd.DataFrame()\\nfor f in range(0,len(futures01)):\\n    value = pd.DataFrame(futures01[f].result())\\n    differenced = pd.concat([differenced,value],axis=1)\\n    \\ndifferenced.columns = train.columns\\ndifferenced.index = train.index\\n'"
      ]
     },
     "execution_count": 1517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "differenced = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, out.result))\n",
    "    #print(value)\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = out.result.columns\n",
    "differenced.index = out.result.index    \n",
    "\n",
    "'''\n",
    "\n",
    "differenced_train = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, train))\n",
    "    #print(value)\n",
    "    differenced_train = pd.concat([differenced_train,value],axis=1)\n",
    "    \n",
    "differenced_train.columns = train.columns\n",
    "differenced_train.index = train.index    \n",
    "\n",
    "differenced_test = pd.DataFrame()\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, test))\n",
    "    differenced_test = pd.concat([differenced_test,value],axis=1)\n",
    "\n",
    "differenced_test.columns = test.columns\n",
    "differenced_test.index = test.index\n",
    "\n",
    "differenced = pd.DataFrame()\n",
    "differenced = pd.concat([differenced_train,differenced_test],axis=0)\n",
    "'''\n",
    "differenced = pd.concat([out.result.iloc[:,0],differenced.iloc[:,1:]],axis=1)\n",
    "\n",
    "#pool01 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "#futures01 = [pool01.submit(getDifferenced, args) for args in (range(0,len(d)))]\n",
    "\n",
    "#wait(futures01, timeout=None, return_when=ALL_COMPLETED)\n",
    "#'''\n",
    "\n",
    "'''\n",
    "differenced = pd.DataFrame()\n",
    "for f in range(0,len(futures01)):\n",
    "    value = pd.DataFrame(futures01[f].result())\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = train.columns\n",
    "differenced.index = train.index\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d32f-b9a1-4196-9d43-1359b65f1c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "f492f94d-cba1-455a-b1d4-157a346f6d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://slurmw01:40000'"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = dtale.show(out.result)\n",
    "d_.open_browser()\n",
    "d_._url  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "4273fdd8-d805-4928-b7dd-bda427cf51fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport concurrent.futures\\nfrom concurrent.futures import wait, ALL_COMPLETED\\nfrom fracdiff import fdiff\\n\\ncores = int(len(os.sched_getaffinity(0)))\\n\\ndef getDifferenced(i):\\n    #v = d[[i]]\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\\n    \\n    a = np.array(out.result.iloc[:, i])\\n    \\n    return fdiff(a, n=d[i], axis=0)\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\\n\\npool01 = concurrent.futures.ProcessPoolExecutor(cores)\\n\\nfutures01 = [pool01.submit(getDifferenced, args) for args in range(0,len(d))]\\n\\nwait(futures01, timeout=None, return_when=ALL_COMPLETED)\\n'"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfa758-3cf3-4410-bfc6-85105b37a19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e2820-110a-4786-9035-98543c301b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for f in range(0,len(futures01)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "        plt.hist(Differenced_Set.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        Differenced_Set.iloc[:,1].plot()\n",
    "        plt.show()\n",
    "        plt.hist(all_data.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        all_data.iloc[:,1].plot()\n",
    "        plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce862ad-f7fc-4f0b-b376-c29d32d01281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b6b7d-d0c5-4077-b822-d79e626067b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "3d49f670-bbdb-42a8-b9e3-e75e1b60e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = out.result.corr()\n",
    "#.abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0016982-6857-424e-868a-da44b16ff66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece4be0-8244-434e-b66e-9c1f39a7c2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "id": "4d4a92b7-e5b3-49ed-b31f-5959f90e8fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "def critical_r(n, alpha = .05 ):\n",
    "    df = n - 2\n",
    "    critical_t = scipy.stats.t.isf(alpha / 2, df)\n",
    "    critical_r = np.sqrt( (critical.t^2) / ( (critical.t^2) + df ) )\n",
    "    return(critical_r)\n",
    "\n",
    "def xcorr(x, y, maxlags=10):\n",
    "    Nx = len(x)\n",
    "    if Nx != len(y):\n",
    "        raise ValueError('x and y must be equal length')\n",
    "\n",
    "    c = np.correlate(x, y, mode=2)\n",
    "\n",
    "    if maxlags is None:\n",
    "        maxlags = Nx - 1\n",
    "\n",
    "    if maxlags >= Nx or maxlags < 1:\n",
    "        raise ValueError('maxlags must be None or strictly positive < %d' % Nx)\n",
    "\n",
    "    c = c[Nx - 1 - maxlags:Nx + maxlags]\n",
    "\n",
    "    return c\n",
    "\n",
    "def getLagged_Set(set_, og):\n",
    "\n",
    "    train, test = train_test_split(set_, test_size=tsize, shuffle=False)\n",
    "    \n",
    "    residuals = pd.DataFrame(np.transpose(get_residuals(train).reshape(len(train.columns),len(train))))\n",
    "    #print(residuals)\n",
    "\n",
    "    residuals.columns = train.columns\n",
    "    residuals.index = train.index\n",
    "\n",
    "    #print(len(train))\n",
    "    #set_.index = all_data.index\n",
    "    \n",
    "    Lagged_Differenced_Set = pd.DataFrame()\n",
    "    Lagged_Set = pd.DataFrame()\n",
    "    lags = []\n",
    "    lagcorrs = []\n",
    "    ogcorrs = []\n",
    "\n",
    "    for f in range(1,len(train.columns)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "\n",
    "        data_1 = residuals.iloc[:,0]\n",
    "        data_2 = residuals.iloc[:,f]\n",
    "\n",
    "        ogc = np.array(pd.concat([data_1 - np.mean(data_1),data_2 - np.mean(data_2)],axis=1).corr())[1,0]    \n",
    "        ogcorrs.append(ogc)\n",
    "\n",
    "        #corr = xcorr(data_1 - np.mean(data_1), data_2 - np.mean(data_2),maxlags=5)\n",
    "\n",
    "        set1 = data_1 - np.mean(data_1)\n",
    "        set2 = data_2 - np.mean(data_2)\n",
    "\n",
    "        corrs_ = []\n",
    "        for i in range(0,maxl):\n",
    "            c = np.array((pd.concat([set1,set2.shift(i)],axis=1).dropna()).corr())[0,1]\n",
    "            corrs_.append(c)\n",
    "\n",
    "        #corr = np.correlate(data_1 - np.mean(data_1), data_2 - np.mean(data_2),mode='full')\n",
    "        #plt.plot(corr)\n",
    "        #plt.show()\n",
    "\n",
    "        #lag = corr.argmax() - (len(data_1) - 1)\n",
    "        lag = abs(pd.Series(corrs_)).idxmax()\n",
    "\n",
    "        #print(corr)\n",
    "        lagc = np.array(pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1).corr())[1,0]\n",
    "\n",
    "        #print(lag)\n",
    "\n",
    "        #print(ogc)\n",
    "        #print(lagc)\n",
    "\n",
    "        #print(lag)\n",
    "        #plt.plot(data_1, 'r*')\n",
    "        #plt.plot(data_2, 'b*')\n",
    "\n",
    "        lag_merged = pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1)\n",
    "\n",
    "        #x_ticks = all_data.index[np.arange(0, len(all_data.index), 5)]\n",
    "        #plt.xticks(x_ticks, rotation = 45)    \n",
    "        #plt.show()\n",
    "\n",
    "        #plt.scatter(data_2.shift(lag),data_1)\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_acf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_pacf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #y = data_1\n",
    "        #X = data_2\n",
    "        #reg = LinearRegression().fit(X, y)\n",
    "\n",
    "        #print(reg.score(X, y),reg.coef_,reg.intercept_)\n",
    "\n",
    "        #model = sm.OLS(y,X)\n",
    "        #results = model.fit()\n",
    "        #print(results.summary())\n",
    "\n",
    "        #Lagged_Differenced_Set = pd.concat([Lagged_Differenced_Set,data_2.shift(lag)],axis=1)\n",
    "        #TrainO_Lagged_Set = pd.concat([TrainO_Lagged_Set,all_data.iloc[:,f].shift(lag)],axis=1)\n",
    "        #if lag>0:\n",
    "            #lag = 0\n",
    "\n",
    "        Lagged_Set = pd.concat([Lagged_Set,og.iloc[:,f].shift(lag)],axis=1)\n",
    "\n",
    "        lagcorrs.append(lagc)\n",
    "\n",
    "        lags.append(lag)\n",
    "\n",
    "    Lagged_Set.index = set_.index\n",
    "    #stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(lagcorrs),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    \n",
    "    #print(Lagged_Set)\n",
    "    #return stats, pd.concat([data_1,Lagged_Set],axis=1),  pd.concat([data_1,Lagged_Differenced_Set],axis=1)\n",
    "    return stats, pd.concat([set_.iloc[:,0],Lagged_Set],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "id": "23eb26a0-bb46-4fd9-b9b8-2de6a3a7f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['^SP500TR', 'DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10',\n",
       "       'T5YIFR', 'BAMLHYH0A0HYM2TRIV', 'BAMLCC0A1AAATRIV', 'DGS1',\n",
       "       'BAMLCC0A4BBBTRIV', 'IC4WSA', 'WILLMICROCAPPR', 'WILLLRGCAPVAL',\n",
       "       'T5YIE', 'WTB3MS', 'WGS3MO', 'TWEXB', 'DEXCHUS', 'DEXUSUK', 'TEDRATE',\n",
       "       'VIXCLS', 'NFCI', 'BAA10Y', 'BAMLC0A0CM', 'BAMLH0A3HYC', 'DCOILBRENTEU',\n",
       "       'DCOILWTICO', 'DFF', 'DGS1MO', 'DGS30', 'DGS5', 'ICSA', 'M1', 'STLFSI2',\n",
       "       'T10Y2Y', 'T10Y3M', 'TREAST', 'QQQ', 'DIA', 'IYR', 'EWG', 'EWU', 'EWJ',\n",
       "       'EZU', 'EWZ', 'ILF', 'EWW', 'LQD', 'SHY', 'IEF', 'TLT', 'ETH', 'BCH',\n",
       "       'LTC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLK', 'XLU',\n",
       "       'MMM', 'AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'GS',\n",
       "       'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE',\n",
       "       'PG', 'TRV', 'UNH', 'VZ', 'WMT', 'WBA', 'DIS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "id": "3e80173c-962f-4b0e-b170-8186d5f9b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lagged_Set = pd.DataFrame()\n",
    "Lagged_Differenced_Set = pd.DataFrame()\n",
    "\n",
    "#'''\n",
    "#Lagged_Differenced_Set_offset = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),out.result.iloc[:,1:].pct_change()],axis=1)\n",
    "differenced_set = out.result.pct_change()\n",
    "differenced_set = differenced_set.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "ls_stats, Lagged_Differenced_Set= getLagged_Set(differenced_set, out.result)\n",
    "lso_stats, Lagged_Differenced_Set_offset= getLagged_Set(pd.concat([differenced_set.iloc[:,0].shift(-1),differenced_set.iloc[:,1:]],axis=1), out.result)\n",
    "#add in last period of y\n",
    "Lagged_Differenced_Set_offset = pd.concat([Lagged_Differenced_Set_offset.iloc[:,0],differenced_set.iloc[:,0],Lagged_Differenced_Set_offset.iloc[:,1:]],axis=1)\n",
    "#Lagged_Set_offset.index = out.result.index\n",
    "Lagged_Differenced_Set.dropna(inplace= True)\n",
    "#Lagged_Set_offset.columns = out.result.columns\n",
    "\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "\n",
    "#Lagged_Differenced_Set.dropna(inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "57b19b33-dfd6-4233-8e3c-4f266a9ce8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "2003-09-30    0.060820\n",
       "2003-12-31    0.076878\n",
       "2004-03-31   -0.004395\n",
       "2004-06-30   -0.012870\n",
       "2004-09-30    0.057999\n",
       "2004-12-31    0.029813\n",
       "2005-03-31   -0.003927\n",
       "2005-06-30    0.040415\n",
       "2005-09-30    0.009843\n",
       "2005-12-31    0.048335\n",
       "Name: ^SP500TR, dtype: float64"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e943c-2c5b-4cc8-86ca-87a1dab05a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "id": "29c83e18-ed0b-446d-89a3-86ea42e5672c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "^SP500TR       0\n",
       "AXP            0\n",
       "MMM            0\n",
       "XLU            0\n",
       "XLK            0\n",
       "              ..\n",
       "BAMLH0A3HYC    0\n",
       "BAMLC0A0CM     0\n",
       "BAA10Y         0\n",
       "ICSA           0\n",
       "DIS            0\n",
       "Length: 92, dtype: int64"
      ]
     },
     "execution_count": 1695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "temp = pd.DataFrame()\n",
    "temp = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),Lagged_Set_offset.iloc[:,1:].pct_change()],axis=1).copy()\n",
    "Lagged_Differenced_Set_offset = pd.DataFrame()\n",
    "Lagged_Differenced_Set_offset = temp.copy()\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "Lagged_Differenced_Set_offset\n",
    "Lagged_Differenced_Set_offset = Lagged_Differenced_Set_offset.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "#Lagged_Differenced_Set_offset.fillna(0)\n",
    "#preprocessing.StandardScaler().fit(Lagged_Differenced_Set_offset)\n",
    "'''\n",
    "np.sum(Lagged_Differenced_Set_offset.isin([np.inf, -np.inf, np.NaN])).sort_values(kind=\"quicksort\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "id": "8cfbc252-b567-48e9-86f9-9e57df0ac45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0  0         0\n",
      "0          DGS10  0  0.293900\n",
      "1           DTB3  1 -0.003070\n",
      "2         DGS3MO  0  0.112961\n",
      "3   MORTGAGE30US  0  0.080523\n",
      "4         DFII10  0  0.052994\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.544979\n",
      "86            VZ  0  0.511754\n",
      "87           WMT  0  0.407511\n",
      "88           WBA  0  0.457171\n",
      "89           DIS  0  0.730196\n",
      "\n",
      "[90 rows x 3 columns]\n",
      "               0  0         0\n",
      "0          DGS10  3 -0.042244\n",
      "1           DTB3  3 -0.089426\n",
      "2         DGS3MO  3 -0.088654\n",
      "3   MORTGAGE30US  3 -0.145695\n",
      "4         DFII10  2  0.041021\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.273665\n",
      "86            VZ  3  0.080712\n",
      "87           WMT  1 -0.086052\n",
      "88           WBA  3  0.151340\n",
      "89           DIS  1 -0.092398\n",
      "\n",
      "[90 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ls_stats)\n",
    "print(lso_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "id": "53aa28e7-3712-466f-96fd-7bbf115714ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SP500TR</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>DTB3</th>\n",
       "      <th>DGS3MO</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>DFII10</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>BAMLHYH0A0HYM2TRIV</th>\n",
       "      <th>BAMLCC0A1AAATRIV</th>\n",
       "      <th>DGS1</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WBA</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>0.069088</td>\n",
       "      <td>1.541751</td>\n",
       "      <td>0.915645</td>\n",
       "      <td>0.935161</td>\n",
       "      <td>0.794281</td>\n",
       "      <td>1.692419</td>\n",
       "      <td>2.458548</td>\n",
       "      <td>41.996715</td>\n",
       "      <td>352.547879</td>\n",
       "      <td>1.775484</td>\n",
       "      <td>...</td>\n",
       "      <td>24.940498</td>\n",
       "      <td>0.966422</td>\n",
       "      <td>7.378963</td>\n",
       "      <td>1.252715</td>\n",
       "      <td>22.987969</td>\n",
       "      <td>27.550304</td>\n",
       "      <td>12.984091</td>\n",
       "      <td>39.046941</td>\n",
       "      <td>1.623533</td>\n",
       "      <td>2.482302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.032607</td>\n",
       "      <td>1.495879</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.933710</td>\n",
       "      <td>0.788597</td>\n",
       "      <td>2.045645</td>\n",
       "      <td>2.634194</td>\n",
       "      <td>43.029175</td>\n",
       "      <td>362.683636</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.109538</td>\n",
       "      <td>0.965952</td>\n",
       "      <td>7.352318</td>\n",
       "      <td>1.252347</td>\n",
       "      <td>24.251518</td>\n",
       "      <td>33.238478</td>\n",
       "      <td>14.858189</td>\n",
       "      <td>36.890209</td>\n",
       "      <td>1.620360</td>\n",
       "      <td>2.447742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>-0.003881</td>\n",
       "      <td>1.590695</td>\n",
       "      <td>1.078871</td>\n",
       "      <td>1.096129</td>\n",
       "      <td>0.797332</td>\n",
       "      <td>1.893750</td>\n",
       "      <td>2.481250</td>\n",
       "      <td>43.544771</td>\n",
       "      <td>354.851562</td>\n",
       "      <td>2.472742</td>\n",
       "      <td>...</td>\n",
       "      <td>16.016526</td>\n",
       "      <td>0.968542</td>\n",
       "      <td>7.595334</td>\n",
       "      <td>1.252234</td>\n",
       "      <td>27.052105</td>\n",
       "      <td>37.703203</td>\n",
       "      <td>14.630292</td>\n",
       "      <td>37.523092</td>\n",
       "      <td>1.619811</td>\n",
       "      <td>2.533420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>0.045642</td>\n",
       "      <td>1.544377</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>1.513906</td>\n",
       "      <td>0.793859</td>\n",
       "      <td>1.690484</td>\n",
       "      <td>2.410484</td>\n",
       "      <td>43.206397</td>\n",
       "      <td>363.761045</td>\n",
       "      <td>3.072459</td>\n",
       "      <td>...</td>\n",
       "      <td>16.911974</td>\n",
       "      <td>0.971730</td>\n",
       "      <td>8.632519</td>\n",
       "      <td>1.253729</td>\n",
       "      <td>27.104700</td>\n",
       "      <td>41.275508</td>\n",
       "      <td>15.591040</td>\n",
       "      <td>36.719812</td>\n",
       "      <td>1.632797</td>\n",
       "      <td>2.586150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.010137</td>\n",
       "      <td>1.523840</td>\n",
       "      <td>2.011613</td>\n",
       "      <td>2.047419</td>\n",
       "      <td>0.791116</td>\n",
       "      <td>1.717705</td>\n",
       "      <td>2.453279</td>\n",
       "      <td>44.018290</td>\n",
       "      <td>370.418636</td>\n",
       "      <td>3.337344</td>\n",
       "      <td>...</td>\n",
       "      <td>18.243953</td>\n",
       "      <td>0.970402</td>\n",
       "      <td>8.825318</td>\n",
       "      <td>1.254591</td>\n",
       "      <td>23.588805</td>\n",
       "      <td>44.026221</td>\n",
       "      <td>16.741129</td>\n",
       "      <td>33.769871</td>\n",
       "      <td>1.638542</td>\n",
       "      <td>2.558298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.003958</td>\n",
       "      <td>1.220122</td>\n",
       "      <td>2.388361</td>\n",
       "      <td>2.438525</td>\n",
       "      <td>0.760357</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>1.944921</td>\n",
       "      <td>73.572146</td>\n",
       "      <td>637.862812</td>\n",
       "      <td>1.845000</td>\n",
       "      <td>...</td>\n",
       "      <td>79.716758</td>\n",
       "      <td>1.018707</td>\n",
       "      <td>82.613387</td>\n",
       "      <td>1.310248</td>\n",
       "      <td>117.868538</td>\n",
       "      <td>255.783684</td>\n",
       "      <td>51.443717</td>\n",
       "      <td>109.754493</td>\n",
       "      <td>1.769093</td>\n",
       "      <td>3.600235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-0.032009</td>\n",
       "      <td>1.140147</td>\n",
       "      <td>2.304921</td>\n",
       "      <td>2.354762</td>\n",
       "      <td>0.749156</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>1.834531</td>\n",
       "      <td>73.014092</td>\n",
       "      <td>662.025846</td>\n",
       "      <td>1.575806</td>\n",
       "      <td>...</td>\n",
       "      <td>82.250245</td>\n",
       "      <td>1.019433</td>\n",
       "      <td>84.411047</td>\n",
       "      <td>1.309857</td>\n",
       "      <td>121.248230</td>\n",
       "      <td>269.978145</td>\n",
       "      <td>52.873113</td>\n",
       "      <td>115.861732</td>\n",
       "      <td>1.736154</td>\n",
       "      <td>3.605762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0.208827</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>1.983594</td>\n",
       "      <td>2.026094</td>\n",
       "      <td>0.736517</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>1.755806</td>\n",
       "      <td>71.316802</td>\n",
       "      <td>704.624478</td>\n",
       "      <td>1.067742</td>\n",
       "      <td>...</td>\n",
       "      <td>79.254899</td>\n",
       "      <td>1.019993</td>\n",
       "      <td>93.038666</td>\n",
       "      <td>1.309202</td>\n",
       "      <td>137.445766</td>\n",
       "      <td>282.275764</td>\n",
       "      <td>53.411418</td>\n",
       "      <td>112.660589</td>\n",
       "      <td>1.738538</td>\n",
       "      <td>3.557512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.978977</td>\n",
       "      <td>1.576935</td>\n",
       "      <td>1.607581</td>\n",
       "      <td>0.738111</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>1.572903</td>\n",
       "      <td>74.017057</td>\n",
       "      <td>714.379538</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>...</td>\n",
       "      <td>76.548235</td>\n",
       "      <td>1.020851</td>\n",
       "      <td>92.050876</td>\n",
       "      <td>1.313030</td>\n",
       "      <td>142.459886</td>\n",
       "      <td>304.001915</td>\n",
       "      <td>56.515780</td>\n",
       "      <td>121.245848</td>\n",
       "      <td>1.749870</td>\n",
       "      <td>3.486990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.121361</td>\n",
       "      <td>0.827040</td>\n",
       "      <td>1.081613</td>\n",
       "      <td>1.104032</td>\n",
       "      <td>0.731042</td>\n",
       "      <td>-0.478889</td>\n",
       "      <td>1.483175</td>\n",
       "      <td>75.440865</td>\n",
       "      <td>733.438923</td>\n",
       "      <td>0.134687</td>\n",
       "      <td>...</td>\n",
       "      <td>80.272736</td>\n",
       "      <td>1.021529</td>\n",
       "      <td>91.585849</td>\n",
       "      <td>1.314522</td>\n",
       "      <td>131.167868</td>\n",
       "      <td>333.177687</td>\n",
       "      <td>54.170968</td>\n",
       "      <td>131.581336</td>\n",
       "      <td>1.733090</td>\n",
       "      <td>3.551627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^SP500TR     DGS10      DTB3    DGS3MO  MORTGAGE30US    DFII10  \\\n",
       "Unnamed: 0                                                                   \n",
       "2004-09-30  0.069088  1.541751  0.915645  0.935161      0.794281  1.692419   \n",
       "2004-12-31  0.032607  1.495879  0.916129  0.933710      0.788597  2.045645   \n",
       "2005-03-31 -0.003881  1.590695  1.078871  1.096129      0.797332  1.893750   \n",
       "2005-06-30  0.045642  1.544377  1.488281  1.513906      0.793859  1.690484   \n",
       "2005-09-30  0.010137  1.523840  2.011613  2.047419      0.791116  1.717705   \n",
       "...              ...       ...       ...       ...           ...       ...   \n",
       "2019-12-31 -0.003958  1.220122  2.388361  2.438525      0.760357  0.515873   \n",
       "2020-03-31 -0.032009  1.140147  2.304921  2.354762      0.749156  0.154219   \n",
       "2020-06-30  0.208827  0.980938  1.983594  2.026094      0.736517  0.153387   \n",
       "2020-09-30  0.094300  0.978977  1.576935  1.607581      0.738111 -0.063226   \n",
       "2020-12-31  0.121361  0.827040  1.081613  1.104032      0.731042 -0.478889   \n",
       "\n",
       "              T5YIFR  BAMLHYH0A0HYM2TRIV  BAMLCC0A1AAATRIV      DGS1  ...  \\\n",
       "Unnamed: 0                                                            ...   \n",
       "2004-09-30  2.458548           41.996715        352.547879  1.775484  ...   \n",
       "2004-12-31  2.634194           43.029175        362.683636  2.075000  ...   \n",
       "2005-03-31  2.481250           43.544771        354.851562  2.472742  ...   \n",
       "2005-06-30  2.410484           43.206397        363.761045  3.072459  ...   \n",
       "2005-09-30  2.453279           44.018290        370.418636  3.337344  ...   \n",
       "...              ...                 ...               ...       ...  ...   \n",
       "2019-12-31  1.944921           73.572146        637.862812  1.845000  ...   \n",
       "2020-03-31  1.834531           73.014092        662.025846  1.575806  ...   \n",
       "2020-06-30  1.755806           71.316802        704.624478  1.067742  ...   \n",
       "2020-09-30  1.572903           74.017057        714.379538  0.174286  ...   \n",
       "2020-12-31  1.483175           75.440865        733.438923  0.134687  ...   \n",
       "\n",
       "                  MRK      MSFT        NKE        PG         TRV         UNH  \\\n",
       "Unnamed: 0                                                                     \n",
       "2004-09-30  24.940498  0.966422   7.378963  1.252715   22.987969   27.550304   \n",
       "2004-12-31  24.109538  0.965952   7.352318  1.252347   24.251518   33.238478   \n",
       "2005-03-31  16.016526  0.968542   7.595334  1.252234   27.052105   37.703203   \n",
       "2005-06-30  16.911974  0.971730   8.632519  1.253729   27.104700   41.275508   \n",
       "2005-09-30  18.243953  0.970402   8.825318  1.254591   23.588805   44.026221   \n",
       "...               ...       ...        ...       ...         ...         ...   \n",
       "2019-12-31  79.716758  1.018707  82.613387  1.310248  117.868538  255.783684   \n",
       "2020-03-31  82.250245  1.019433  84.411047  1.309857  121.248230  269.978145   \n",
       "2020-06-30  79.254899  1.019993  93.038666  1.309202  137.445766  282.275764   \n",
       "2020-09-30  76.548235  1.020851  92.050876  1.313030  142.459886  304.001915   \n",
       "2020-12-31  80.272736  1.021529  91.585849  1.314522  131.167868  333.177687   \n",
       "\n",
       "                   VZ         WMT       WBA       DIS  \n",
       "Unnamed: 0                                             \n",
       "2004-09-30  12.984091   39.046941  1.623533  2.482302  \n",
       "2004-12-31  14.858189   36.890209  1.620360  2.447742  \n",
       "2005-03-31  14.630292   37.523092  1.619811  2.533420  \n",
       "2005-06-30  15.591040   36.719812  1.632797  2.586150  \n",
       "2005-09-30  16.741129   33.769871  1.638542  2.558298  \n",
       "...               ...         ...       ...       ...  \n",
       "2019-12-31  51.443717  109.754493  1.769093  3.600235  \n",
       "2020-03-31  52.873113  115.861732  1.736154  3.605762  \n",
       "2020-06-30  53.411418  112.660589  1.738538  3.557512  \n",
       "2020-09-30  56.515780  121.245848  1.749870  3.486990  \n",
       "2020-12-31  54.170968  131.581336  1.733090  3.551627  \n",
       "\n",
       "[66 rows x 91 columns]"
      ]
     },
     "execution_count": 1654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fb84f-111c-44f6-8fcc-7519b387e5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb40926-6979-4f9f-ad09-ed1f93c25a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "id": "d1422b2e-d8e4-43aa-a691-8c54392a6291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null hypothesis can be rejected\n",
      "6.865763215609389\n",
      "The null hypothesis can be rejected\n",
      "6.896546949666965\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.2560705858400435\n",
      "The null hypothesis can be rejected\n",
      "-0.25410510887178017\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.8168452771342554\n",
      "The null hypothesis can be rejected\n",
      "-1.2203262001462745\n",
      "The null hypothesis can be rejected\n",
      "3.980324132809734\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.0330533902639862\n",
      "The null hypothesis can be rejected\n",
      "-1.1348510594870023\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "8.441819888635504\n",
      "The null hypothesis can be rejected\n",
      "1.0871887239135765\n",
      "The null hypothesis can be rejected\n",
      "-0.225351519493807\n",
      "The null hypothesis can be rejected\n",
      "-0.22331262559486822\n",
      "The null hypothesis can be rejected\n",
      "-11.643674081625615\n",
      "The null hypothesis can be rejected\n",
      "-7.872592517879663\n",
      "The null hypothesis can be rejected\n",
      "6.810550509799163\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.8610001927627393\n",
      "The null hypothesis can be rejected\n",
      "0.47387019426883464\n",
      "The null hypothesis can be rejected\n",
      "-1.350128792241651\n",
      "The null hypothesis can be rejected\n",
      "-1.068536116050812\n",
      "The null hypothesis can be rejected\n",
      "-1.5907297978977153\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.1763642319332284\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.1608393629115443\n",
      "The null hypothesis can be rejected\n",
      "-17.292496103544497\n",
      "The null hypothesis can be rejected\n",
      "0.8424543841737614\n",
      "The null hypothesis can be rejected\n",
      "0.6627659332477958\n",
      "The null hypothesis can be rejected\n",
      "0.9814454834302564\n",
      "The null hypothesis can be rejected\n",
      "-1.8518943770701226\n",
      "The null hypothesis can be rejected\n",
      "4.430956496153695\n",
      "The null hypothesis can be rejected\n",
      "7.347405992272229\n",
      "The null hypothesis can be rejected\n",
      "5.375556488149038\n",
      "The null hypothesis can be rejected\n",
      "3.7236366650415897\n",
      "The null hypothesis can be rejected\n",
      "4.622498957737785\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.295897679021274\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "2.994049643817101\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-71.80123292863226\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.2630315430220875\n",
      "The null hypothesis can be rejected\n",
      "8.62589778332678\n",
      "The null hypothesis can be rejected\n",
      "3.6941919528144713\n",
      "The null hypothesis can be rejected\n",
      "3.2126497040172124\n",
      "The null hypothesis can be rejected\n",
      "7.184903442065814\n",
      "The null hypothesis can be rejected\n",
      "6.193200910291322\n",
      "The null hypothesis can be rejected\n",
      "3.980512866916982\n",
      "The null hypothesis can be rejected\n",
      "4.479987948401211\n",
      "The null hypothesis can be rejected\n",
      "10.03254035404625\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.8597491249632236\n",
      "The null hypothesis can be rejected\n",
      "-2.5531656292171774\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.6337017753465424\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.267169095042328\n",
      "The null hypothesis can be rejected\n",
      "4.057632902860579\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "5.168826328875348\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n"
     ]
    }
   ],
   "source": [
    "#skip correlation\n",
    "#Lagged_Differenced_Set_offset = pd.concat([our.result.iloc[:,0].pct_change().shift(-1),differenced_set.iloc[:,0],Lagged_Differenced_Set_offset.iloc[:,1:]],axis=1)\n",
    "#Lagged_Set_offset.index = out.result.index\n",
    "#Lagged_Differenced_Set.dropna(inplace= True)\n",
    "\n",
    "set_ = Lagged_Differenced_Set\n",
    "set_ = pd.concat([differenced_set.iloc[:,0].shift(-1),differenced_set.iloc[:,0],differenced_set.iloc[:,1:]],axis=1)\n",
    "set_.dropna(inplace=True)\n",
    "set_ = set_.tail(-1)\n",
    "transformed, lambdas = transform_boxcox(set_.dropna())\n",
    "\n",
    "#revert_yeo(Lagged_Differenced_Set_offset, transformed, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72722f-fbff-4bff-92b8-26b19888e415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "8cc90237-f851-4afb-86f8-2dca0b41123d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbd = True\n",
    "ic = True\n",
    "\n",
    "# evaluate an elastic net model on the dataset\n",
    "#tsize = .20\n",
    "#train, test = train_test_split(Lagged_Differenced_Set_offset.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "train, test = train_test_split(transformed.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=ic)\n",
    "\n",
    "#train_t, lambdas_t = transform_boxcox(train)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    train_t = train\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_t)\n",
    "\n",
    "#\n",
    "train_s = pd.DataFrame(scaler.transform(train_t))\n",
    "train_s.columns = train.columns\n",
    "train_s.index = train.index  \n",
    "\n",
    "train_t = train_s\n",
    "\n",
    "#test_t = transform_boxcox_l(test, lambdas_t)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    test_t = test\n",
    "\n",
    "test_s = pd.DataFrame(scaler.transform(test_t))\n",
    "test_s.columns = test.columns\n",
    "test_s.index = test.index\n",
    "\n",
    "test_t = test_s\n",
    "\n",
    "y_train = pd.DataFrame(train_t.iloc[:,0])\n",
    "\n",
    "#exclude y\n",
    "\n",
    "X_inter_train = pd.DataFrame(interaction.fit_transform(train_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_t.iloc[:,1:]).columns))\n",
    "\n",
    "    #apply ZCA each time a set of factors are removed (i.e. iteratively)\n",
    " #trf = zca.ZCA().fit(X_inter_train)\n",
    "  #trf = zca.ZCA().fit(X_train)\n",
    "\n",
    " #X_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "  #X_train = pd.DataFrame(trf.transform(X_train))\n",
    " #X_train.columns=X_inter_train.columns\n",
    "  #X_train.columns=X_train.columns\n",
    "  #X_train.index = train.index\n",
    "\n",
    "#X_inter_alt = X_train.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#print(X_inter_alt.head(3))\n",
    "\n",
    "y_test = pd.DataFrame(test_t.iloc[:,0])\n",
    "\n",
    "X_inter_test = pd.DataFrame(interaction.fit_transform(test_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(test_t.iloc[:,1:]).columns))\n",
    "\n",
    " #X_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "  #X_test = pd.DataFrame(trf.transform(X_test))\n",
    "\n",
    " #X_test.columns=X_inter_test.columns\n",
    "  #X_test.columns=X_test.columns\n",
    "  #X_test.index = test.index\n",
    "\n",
    "#X_inter_t_alt = X_test.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#X_inter_t_alt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf46d0-1162-46d6-a166-0461b321e0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "\n",
    " #model = ElasticNetCV(l1_ratio=ratios, alphas=alphas, cv=cv, n_jobs=4, verbose=0, precompute='auto')\n",
    "\n",
    "model = ElasticNet()\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "#search = HalvingRandomSearchCV(model, grid,resource='n_samples',max_resources=10,random_state=0)\n",
    "\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    " #results = search.fit(X_inter_train, y_train)\n",
    "#results = search.fit(X_train, y_train)\n",
    "\n",
    "results = search.fit(X_inter_train, y_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "print(results.best_estimator_)\n",
    "best_model = ElasticNet(alpha=results.best_estimator_.alpha, l1_ratio = results.best_estimator_.l1_ratio)\n",
    "\n",
    "#pd.concat([all_data[Y],all_data_int],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb7965-c50b-4f1e-bd5e-05504a69192f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_inter_train,train_t.iloc[:,0])\n",
    "\n",
    "trainScore = best_model.score(X_inter_train, y_train, sample_weight=None)\n",
    "testScore = best_model.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore)\n",
    "print(testScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb694fa2-0e07-4a01-8648-2d6615a70b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "093a64f9-522d-4761-adf1-f55d566a1b70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b12fd-2b69-4243-909a-6f828aa43b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "0e86999a-16ba-4505-b5ec-843d219ac62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.538462\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367906e7-5aec-4529-8f29-42040e9ac43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "id": "14400790-a56a-4084-8c56-cf73697546e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03847608420351106\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.8648952817620676, pvalue=0.39785994499471344)\n",
      "0.026106343953183363\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.9892221018930833, pvalue=0.3323169495195316)\n"
     ]
    }
   ],
   "source": [
    "#classification transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE \n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#set_ = Lagged_Differenced_Set_offset.copy()\n",
    "#set_ = transformed.copy()\n",
    "#DF_list = list()\n",
    "\n",
    "sets = list()\n",
    "sets.append(transformed.copy())\n",
    "#sets.append(Lagged_Differenced_Set_offset.copy())\n",
    "sets.append(set_.copy())\n",
    "\n",
    "def return_sets(sets):    \n",
    "    \n",
    "    sets_outer = list()\n",
    "    \n",
    "    for i in sets:\n",
    "        \n",
    "        sets_multiple = list()\n",
    "        \n",
    "        set_ = pd.DataFrame()\n",
    "        set_ = i\n",
    "\n",
    "        X, y = set_.iloc[:,1:],  set_.iloc[:,0]\n",
    "        \n",
    "        print(mean(y))\n",
    "\n",
    "        y = pd.DataFrame(np.where(y > mean(y), 1, 0))\n",
    "        y.index = set_.index\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize, shuffle=False)\n",
    "\n",
    "        a = set_.iloc[:,0].loc[X_train.index]\n",
    "        b = set_.iloc[:,0].loc[X_test.index]\n",
    "        plt.hist(a)\n",
    "        plt.show()\n",
    "        plt.hist(b)\n",
    "        plt.show()\n",
    "        print(stats.ttest_ind(a,b, equal_var = False))\n",
    "\n",
    "        one = y_train[y_train==0].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "        two = y_train[y_train==1].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "\n",
    "        train_index = np.append(one.index,two.index)\n",
    "\n",
    "        #destroyed my data\n",
    "        #smote = SVMSMOTE(random_state=42)\n",
    "            #smote = SMOTE()\n",
    "        #Xsm_train, ysm_train = smote.fit_sample(np.array(X_train),np.array(y_train))\n",
    "\n",
    "        Xsm_train = X_train.copy()\n",
    "        ysm_train = y_train.copy()\n",
    "        \n",
    "        #use with optimal lags\n",
    "        #y_test = y_test.loc[y_test.index>y_test.index[maxl]]\n",
    "        #X_test = X_test.loc[X_test.index>X_test.index[maxl]]\n",
    "\n",
    "        scaler = preprocessing.StandardScaler().fit(Xsm_train)\n",
    "\n",
    "        X_train_transformed = pd.DataFrame(scaler.transform(Xsm_train))\n",
    "        X_train_transformed.columns = X_train.columns\n",
    "\n",
    "        X_inter_train = X_train_transformed.copy()\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(interaction.fit_transform(X_train_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_train_transformed).columns))\n",
    "\n",
    "        trf = zca.ZCA().fit(X_inter_train)\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "        X_inter_train.columns=pd.DataFrame(X_inter_train).columns\n",
    "        #X_inter_train.index = X_train.loc[train_index].index\n",
    "\n",
    "        X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "        X_test_transformed.columns = X_test.columns\n",
    "        X_test_transformed.index = X_test.index\n",
    "\n",
    "        X_inter_test = X_test_transformed\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(interaction.fit_transform(X_test_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_test_transformed).columns))\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "\n",
    "        sets_multiple.append(X_inter_train)\n",
    "        sets_multiple.append(y_train)\n",
    "        sets_multiple.append(X_inter_test)\n",
    "        sets_multiple.append(y_test)        \n",
    "    \n",
    "        sets_outer.append(sets_multiple)\n",
    "        \n",
    "    return(sets_outer)\n",
    "\n",
    "values = return_sets(sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568baa66-4a53-4f23-ba8a-c5f9408f1591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "id": "73ec310d-7f86-4154-be9b-11c927a6a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "id": "e560215f-9b7d-4d76-ac61-dbf96d2cfd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49 accuracy with a standard deviation of 0.10\n",
      "0.9090909090909091\n",
      "0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        30\n",
      "           1       1.00      0.80      0.89        25\n",
      "\n",
      "    accuracy                           0.91        55\n",
      "   macro avg       0.93      0.90      0.91        55\n",
      "weighted avg       0.92      0.91      0.91        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[30  0]\n",
      " [ 5 20]]\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "0.47 accuracy with a standard deviation of 0.12\n",
      "0.8545454545454545\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.82        26\n",
      "           1       0.78      1.00      0.88        29\n",
      "\n",
      "    accuracy                           0.85        55\n",
      "   macro avg       0.89      0.85      0.85        55\n",
      "weighted avg       0.89      0.85      0.85        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[18  8]\n",
      " [ 0 29]]\n",
      "[[2 3]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.62      0.56      0.59         9\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.34      0.32      0.33        14\n",
      "weighted avg       0.54      0.50      0.52        14\n",
      "\n",
      "[[2 3 0]\n",
      " [3 5 1]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "#works best\n",
    "#class balanced, no zca\n",
    "from sklearn import svm\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    clf = svm.SVC(kernel='rbf', C=1, random_state=42)\n",
    "\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "    clf = svm.SVC(C=1).fit(X_train, y_train)\n",
    "\n",
    "    train_predict = clf.predict(X_train)\n",
    "    predicteds = clf.predict(X_test)\n",
    "    #predicted.index = y_test.index\n",
    "\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(clf.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predicteds))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predicteds))\n",
    "\n",
    "    predictions_s = arima_adjust(y_train, y_test, train_predict, predicteds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "id": "ec38a51f-ede1-47bb-9af7-ee25b6106160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25944973-ee0b-4b74-be6c-f59463229bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39fe4e-d604-4fa9-ad81-ee7a53a06784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "3909eb8a-645f-47c5-933a-98d61f3d6ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('svc', svm.SVC(kernel='sigmoid', C=1, random_state=42))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)\n",
    "'''\n",
    "#search = cross_val_score(pipe, X_inter_train, y_train.loc[train_index], cv=10)\n",
    "#GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#search.fit(X_digits, y_digits)\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "#print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "d83b6ec4-6148-41ba-9d1b-3765f913ee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "id": "b49b4466-cd31-4f19-85e0-c32db62dbe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "0.9818181818181818\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        30\n",
      "           1       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.98        55\n",
      "   macro avg       0.98      0.98      0.98        55\n",
      "weighted avg       0.98      0.98      0.98        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.56      0.62      0.59         8\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.48      0.48      0.48        14\n",
      "weighted avg       0.49      0.50      0.49        14\n",
      "\n",
      "[[30  0]\n",
      " [ 1 24]]\n",
      "[[2 4]\n",
      " [3 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.56      0.62      0.59         8\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.48      0.48      0.48        14\n",
      "weighted avg       0.49      0.50      0.49        14\n",
      "\n",
      "[[2 4]\n",
      " [3 5]]\n",
      "LogisticRegression()\n",
      "1.0\n",
      "0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29         5\n",
      "           1       0.67      0.89      0.76         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.58      0.54      0.52        14\n",
      "weighted avg       0.61      0.64      0.59        14\n",
      "\n",
      "[[26  0]\n",
      " [ 0 29]]\n",
      "[[1 4]\n",
      " [1 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29         5\n",
      "           1       0.67      0.89      0.76         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.58      0.54      0.52        14\n",
      "weighted avg       0.61      0.64      0.59        14\n",
      "\n",
      "[[1 4]\n",
      " [1 8]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modell = LogisticRegression()\n",
    "    modell.fit(X_train, y_train)\n",
    "    print(modell)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modell.predict(X_train)\n",
    "    predictedl = modell.predict(X_test)\n",
    "\n",
    "    print(modell.score(X_train, y_train))\n",
    "    print(modell.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedl))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedl))\n",
    "    \n",
    "    predictions_l = arima_adjust(y_train, y_test, train_predict, predictedl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "id": "7672895b-f442-45b4-8cb1-3257e8c830a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "0.7272727272727273\n",
      "0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74        30\n",
      "           1       0.68      0.76      0.72        25\n",
      "\n",
      "    accuracy                           0.73        55\n",
      "   macro avg       0.73      0.73      0.73        55\n",
      "weighted avg       0.73      0.73      0.73        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.50      0.43         6\n",
      "           1       0.50      0.38      0.43         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.44      0.44      0.43        14\n",
      "weighted avg       0.45      0.43      0.43        14\n",
      "\n",
      "[[21  9]\n",
      " [ 6 19]]\n",
      "[[3 3]\n",
      " [5 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.57      0.50      0.53         8\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.24      0.21      0.22        14\n",
      "weighted avg       0.50      0.43      0.46        14\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 2 3 1]\n",
      " [1 3 4 0]\n",
      " [0 0 0 0]]\n",
      "GaussianNB()\n",
      "0.6909090909090909\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.46      0.59        26\n",
      "           1       0.65      0.90      0.75        29\n",
      "\n",
      "    accuracy                           0.69        55\n",
      "   macro avg       0.73      0.68      0.67        55\n",
      "weighted avg       0.72      0.69      0.67        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[12 14]\n",
      " [ 3 26]]\n",
      "[[2 3]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[2 3]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeln = GaussianNB()\n",
    "    modeln.fit(X_train, y_train)\n",
    "    print(modeln)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeln.predict(X_train)\n",
    "    predictedn = modeln.predict(X_test)\n",
    "\n",
    "    print(modeln.score(X_train, y_train))\n",
    "    print(modeln.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedn))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedn))\n",
    "    \n",
    "    predictions_n = arima_adjust(y_train, y_test, train_predict, predictedn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "id": "644b63d8-9f6e-453e-b896-0ee262d1242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "1.0\n",
      "0.21428571428571427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.38      0.33      0.35         9\n",
      "\n",
      "    accuracy                           0.21        14\n",
      "   macro avg       0.19      0.17      0.18        14\n",
      "weighted avg       0.24      0.21      0.23        14\n",
      "\n",
      "[[26  0]\n",
      " [ 0 29]]\n",
      "[[0 5]\n",
      " [6 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.38      0.33      0.35         9\n",
      "\n",
      "    accuracy                           0.21        14\n",
      "   macro avg       0.19      0.17      0.18        14\n",
      "weighted avg       0.24      0.21      0.23        14\n",
      "\n",
      "[[0 5]\n",
      " [6 3]]\n",
      "DecisionTreeClassifier()\n",
      "1.0\n",
      "0.35714285714285715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         6\n",
      "           1       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.37      0.38      0.35        14\n",
      "weighted avg       0.37      0.36      0.35        14\n",
      "\n",
      "[[30  0]\n",
      " [ 0 25]]\n",
      "[[3 3]\n",
      " [6 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         6\n",
      "           1       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.37      0.38      0.35        14\n",
      "weighted avg       0.37      0.36      0.35        14\n",
      "\n",
      "[[3 3]\n",
      " [6 2]]\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "#works best with transformed\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in reversed(range(0,len(sets))):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeld = DecisionTreeClassifier()\n",
    "    modeld.fit(X_train, y_train)\n",
    "    print(modeld)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeld.predict(X_train)\n",
    "    predictedd = modeld.predict(X_test)\n",
    "\n",
    "    print(modeld.score(X_train, y_train))\n",
    "    print(modeld.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedd))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedd))\n",
    "        \n",
    "    predictions_d = arima_adjust(y_train, y_test, train_predict, predictedd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "id": "6ce0671f-8931-4f7e-936b-51adcb52dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 8}\n",
      "0.5272727272727272\n",
      "1.0\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         6\n",
      "           1       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.56      0.56      0.56        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[30  0]\n",
      " [ 0 25]]\n",
      "[[3 3]\n",
      " [3 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         6\n",
      "           1       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.56      0.56      0.56        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[3 3]\n",
      " [3 5]]\n",
      "{'n_neighbors': 22}\n",
      "0.5818181818181818\n",
      "1.0\n",
      "0.7142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.69      1.00      0.82         9\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.85      0.60      0.58        14\n",
      "weighted avg       0.80      0.71      0.65        14\n",
      "\n",
      "[[26  0]\n",
      " [ 0 29]]\n",
      "[[1 4]\n",
      " [0 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.69      1.00      0.82         9\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.85      0.60      0.58        14\n",
      "weighted avg       0.80      0.71      0.65        14\n",
      "\n",
      "[[1 4]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "#works best with transformed\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV#create new a knn model\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "    \n",
    "    knn2 = KNeighborsClassifier(metric='euclidean',weights='distance')#create a dictionary of all values we want to test for n_neighbors\n",
    "    param_grid = {'n_neighbors': np.arange(1, 25)}#use gridsearch to test all values for n_neighbors\n",
    "    knn_gscv = GridSearchCV(knn2, param_grid, cv=5)#fit model to data\n",
    "    knn_gscv.fit(X_train, y_train)\n",
    "    #check top performing n_neighbors value\n",
    "    print(knn_gscv.best_params_)\n",
    "    #check mean score for the top performing value of n_neighbors\n",
    "    print(knn_gscv.best_score_)\n",
    "\n",
    "    modelk = KNeighborsClassifier(n_neighbors = knn_gscv.best_params_['n_neighbors'],metric='euclidean',weights='distance')\n",
    "    modelk.fit(X_train,y_train)\n",
    "    train_predict = modelk.predict(X_train)\n",
    "    predictedk = modelk.predict(X_test)\n",
    "    #modelk.score(X_test, y_test)\n",
    "\n",
    "    print(modelk.score(X_train, y_train))\n",
    "    print(modelk.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedk))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedk))\n",
    "    \n",
    "    predictions_k = arima_adjust(y_train, y_test, train_predict, predictedk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43107e46-54bb-4837-a798-af32efaccadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "e55c7caf-0c3b-4911-ba58-8313a7ba85ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-771-d7e137a3e15d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msearch_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresults_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_inter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mysm_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m  \u001b[0;31m#model.fit(X_inter_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Elastic logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = (10 ** np.linspace(-1, 1, 10))/10\n",
    "alphas = np.append(alphas,[10.0, 100.0])\n",
    "\n",
    "model = SGDClassifier(loss=\"log\", penalty=\"elasticnet\")\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "search_l = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "results_l = search_l.fit(X_inter_train, ysm_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results_l.best_score_)\n",
    "print('Config: %s' % results_l.best_params_)\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "print(results_l.best_estimator_)\n",
    "best_model_l = SGDClassifier(alpha=results_l.best_estimator_.alpha, l1_ratio = results_l.best_estimator_.l1_ratio)\n",
    "\n",
    "#calibrator = CalibratedClassifierCV(best_model_l, cv='prefit')\n",
    "#model=calibrator.fit(X_inter_train, y_train)\n",
    "\n",
    "best_model_l.fit(X_inter_train,ysm_train)\n",
    "\n",
    "#sgd = SGDClassifier()\n",
    "\n",
    "#sgd.partial_fit(X_inter_train,y_train, classes=[0,1])\n",
    "\n",
    "print(pd.DataFrame(np.transpose(best_model_l.coef_)).set_index(X_inter_train.columns))\n",
    "\n",
    "trainScore_l = best_model_l.score(X_inter_train, ysm_train, sample_weight=None)\n",
    "testScore_l = best_model_l.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore_l)\n",
    "print(testScore_l)\n",
    "\n",
    "#print(help(KNeighborsClassifier))\n",
    "predictedl = best_model_l.predict(X_inter_test)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b9087-fe22-4d54-b152-a40e48784774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "id": "7015d3fd-f35c-4f6c-b8e9-f66c92514715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.642857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "id": "a6dd1212-7817-4f74-95d6-0493d68c9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            s  k  d  l  n\n",
      "Unnamed: 0               \n",
      "2017-09-30  1  1  0  1  1\n",
      "2017-12-31  1  1  0  1  1\n",
      "2018-03-31  0  1  1  1  1\n",
      "2018-06-30  0  1  0  0  1\n",
      "2018-09-30  1  1  0  1  1\n",
      "2018-12-31  1  1  1  1  0\n",
      "2019-03-31  1  1  0  1  1\n",
      "2019-06-30  1  1  0  1  1\n",
      "2019-09-30  2  1  0  1  0\n",
      "2019-12-31  1  1  1  1  1\n",
      "2020-03-31  0  0  0  0  0\n",
      "2020-06-30  0  1  0  1  0\n",
      "2020-09-30  0  1  1  1  0\n",
      "2020-12-31  1  1  1  1  1\n",
      "[[1 4]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.20      0.22         5\n",
      "           1       0.60      0.67      0.63         9\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.42      0.43      0.43        14\n",
      "weighted avg       0.47      0.50      0.49        14\n",
      "\n",
      "0    0.642857\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#predictedf = pd.concat([pd.DataFrame(predicteds),pd.DataFrame(predictedk),pd.DataFrame(predictedl)],axis=1)\n",
    "predictedf = pd.concat([pd.DataFrame(predictions_s),pd.DataFrame(predictions_k),pd.DataFrame(predictions_d),pd.DataFrame(predictions_l),pd.DataFrame(predictions_n)],axis=1)\n",
    "predictedf.columns = [\"s\",\"k\",\"d\",\"l\",\"n\"]\n",
    "predictedf.index = y_test.index\n",
    "print(predictedf)\n",
    "print(confusion_matrix(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(confusion_matrix(y_test, predictedf.median(axis=1)))\n",
    "print(classification_report(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(classification_report(y_test, predictedf.median(axis=1)))\n",
    "\n",
    "print(mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438843e-110f-404f-b1b1-47bfa41b560b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "id": "0e4dfc37-ab80-427f-bc37-edb9a212c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null hypothesis can be rejected\n",
      "7.646373750137569\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.40514623443399356\n",
      "The null hypothesis can be rejected\n",
      "-0.40483634918469846\n",
      "The null hypothesis can be rejected\n",
      "-3.6470536818264154\n",
      "The null hypothesis can be rejected\n",
      "1.259503803215001\n",
      "The null hypothesis can be rejected\n",
      "-1.136520328738504\n",
      "The null hypothesis can be rejected\n",
      "4.136040961331319\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.195112413151037\n",
      "The null hypothesis can be rejected\n",
      "-5.428905651858575\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "8.40983838078041\n",
      "The null hypothesis can be rejected\n",
      "1.105154218129704\n",
      "The null hypothesis can be rejected\n",
      "-0.3866451441114222\n",
      "The null hypothesis can be rejected\n",
      "-0.385879251752391\n",
      "The null hypothesis can be rejected\n",
      "-13.236135358775554\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "6.8612669842356695\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.6069916960392927\n",
      "The null hypothesis can be rejected\n",
      "0.4753535130059253\n",
      "The null hypothesis can be rejected\n",
      "-1.3322502715493079\n",
      "The null hypothesis can be rejected\n",
      "-1.2688183891496545\n",
      "The null hypothesis can be rejected\n",
      "-1.7501678387215072\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.5319681441702234\n",
      "The null hypothesis can be rejected\n",
      "-0.2802518523984959\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.34345571037416905\n",
      "The null hypothesis can be rejected\n",
      "-6.743570324962083\n",
      "The null hypothesis can be rejected\n",
      "-22.179017205125312\n",
      "The null hypothesis can be rejected\n",
      "0.8440491226492548\n",
      "The null hypothesis can be rejected\n",
      "0.6573188363341986\n",
      "The null hypothesis can be rejected\n",
      "1.6960498518713947\n",
      "The null hypothesis can be rejected\n",
      "-0.41573858764941946\n",
      "The null hypothesis can be rejected\n",
      "5.257626930766483\n",
      "The null hypothesis can be rejected\n",
      "7.77728744444702\n",
      "The null hypothesis can be rejected\n",
      "5.428027363915695\n",
      "The null hypothesis can be rejected\n",
      "4.830834575910595\n",
      "The null hypothesis can be rejected\n",
      "4.628320789459902\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.718584547128605\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-77.4540604477489\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.004515545834275\n",
      "The null hypothesis can be rejected\n",
      "9.375545618317162\n",
      "The null hypothesis can be rejected\n",
      "4.08333730067389\n",
      "The null hypothesis can be rejected\n",
      "3.059059883280719\n",
      "The null hypothesis can be rejected\n",
      "7.052758871394548\n",
      "The null hypothesis can be rejected\n",
      "7.265905205010742\n",
      "The null hypothesis can be rejected\n",
      "4.466090260871639\n",
      "The null hypothesis can be rejected\n",
      "5.424809591407335\n",
      "The null hypothesis can be rejected\n",
      "9.305064711543547\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.7364966026744422\n",
      "The null hypothesis can be rejected\n",
      "-2.8331379469993236\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "5.239188981827869\n",
      "The null hypothesis can be rejected\n",
      "4.333808329382541\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.878469875759412\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "71\n",
      "35\n",
      "36\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# multivariate output multi-step 1d cnn example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Lagged_Differenced_Set = (all_data - all_data.shift(-1)).dropna()\n",
    "choice = differenced_set\n",
    "\n",
    "train, test = train_test_split(choice, test_size=tsize, shuffle=False)\n",
    "\n",
    "transformed_train, lambdas_ = transform_boxcox(train)\n",
    "transformed_test = transform_boxcox_l(test, lambdas_)\n",
    "scaler = preprocessing.StandardScaler().fit(transformed_train)\n",
    "train_s = pd.DataFrame(scaler.transform(transformed_train))\n",
    "test_s = pd.DataFrame(scaler.transform(transformed_test))\n",
    "\n",
    "#scaler = preprocessing.StandardScaler().fit(train)\n",
    "#train_s = pd.DataFrame(scaler.transform(train))\n",
    "#test_s = pd.DataFrame(scaler.transform(test))\n",
    "\n",
    "combined = pd.concat([train_s,test_s],axis=0)\n",
    "combined.index = choice.index\n",
    "combined.columns = choice.columns\n",
    "\n",
    "set_ = combined\n",
    "\n",
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out, xcolumns, ycolumns):\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, xcolumns], sequences[end_ix:out_end_ix, ycolumns]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return array(X), array(y)\n",
    "\n",
    "#n_steps_in = int(np.floor(len(train)*.8))\n",
    "print(len(set_))\n",
    "n_steps_in = int(np.round(len(set_)/2))\n",
    "print(len(set_) - n_steps_in)\n",
    "print(n_steps_in)\n",
    "#n_steps_out = int(len(train)-n_steps_in)\n",
    "n_steps_out = 1\n",
    "print(n_steps_out)\n",
    "\n",
    "#ycolumns = range(0,len(transformed.columns))\n",
    "ycolumns = range(0,len(set_.columns[0:1].values))\n",
    "xcolumns = range(1,len(set_.columns[1:]))\n",
    "\n",
    "#trainInner, valid = train_test_split(trainOuter, test_size=0.15, shuffle=False)\n",
    "#trainInner_whitened = pd.DataFrame(trf.transform(trainInner.iloc[:,1:])).set_index(trainInner.index)\n",
    "#valid_whitened = pd.DataFrame(trf.transform(valid.iloc[:,1:])).set_index(valid.index)\n",
    "#test_whitened = pd.DataFrame(trf.transform(test.iloc[:,1:])).set_index(test.index)\n",
    "\n",
    "#trainOuter_whitened=pd.DataFrame(trf.transform(trainOuter.iloc[:,1:])).set_index(trainOuter.index)\n",
    "\n",
    "X, y = split_sequences(np.array(set_), n_steps_in, n_steps_out, xcolumns, ycolumns)\n",
    "\n",
    "#for i in range(len(X)):\n",
    "#    print(X[i], y[i])\n",
    "    \n",
    "#flatten output\n",
    "\n",
    "if len(ycolumns) > 0:\n",
    "    n_output = y.shape[1] * y.shape[2]\n",
    "    y = y.reshape((y.shape[0], n_output))\n",
    "\n",
    "n_features = X.shape[2]\n",
    "\n",
    "# define model\n",
    "modelCNN = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(n_output)\n",
    "])\n",
    "\n",
    "# fit model\n",
    "#model.fit(X, y, epochs=7000, verbose=0)\n",
    "\n",
    "epochs_ = 2000\n",
    "batch_size_ = 25\n",
    "\n",
    "#np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss='mse')\n",
    "modelCNN.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "#X_train_transformed = pd.DataFrame(scaler.transform(X_train))\n",
    "#X_train_transformed.columns = X_train.columns\n",
    "\n",
    "#X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "#X_test_transformed.columns = X_test.columns\n",
    "#X_test_transformed.index = X_test.index\n",
    "\n",
    "    #new_series = pd.DataFrame(ts_train_scaled).append(pd.DataFrame(ts_valid_scaled)).append(pd.DataFrame(ts_test_scaled))\n",
    "\n",
    "    #series_reshaped = np.array([new_series[i:i + (n_steps+n_ahead)].copy() for i in range(len(data) - (n_steps+n_ahead))])  \n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)    \n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "historyCNN = modelCNN.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history6 = model6.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history = model.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1663,
   "id": "d2d1ce87-6c86-4308-8788-b01aa8256fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to apply to test\n",
    "#revert_boxcox(pd.DataFrame(transformed_.iloc[:,0]),pd.DataFrame(lambdas[0]))\n",
    "#Lagged_Differenced_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "id": "0b8f7e2d-3603-4ba1-8457-4fd9918498a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "plot_learning_curves(historyCNN.history[\"loss\"], historyCNN.history[\"val_loss\"])\n",
    "plt.show()\n",
    "#plot_learning_curves(history6.history[\"loss\"], history.history[\"val_loss\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1733,
   "id": "799f6d94-9757-4baa-b095-8937fbba5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.90033141],\n",
       "       [4.21896173],\n",
       "       [4.19081743],\n",
       "       [3.94246046],\n",
       "       [4.87044704],\n",
       "       [5.44739564],\n",
       "       [6.20591252]])"
      ]
     },
     "execution_count": 1733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "id": "bee4c952-450d-43d4-86c1-2a37673a58d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 1689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(revert_transformed_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5ad28-e151-4ccf-915f-a9797fa263cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "id": "c2cbc3da-fa1f-4e57-9d84-f4e5f8872af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050150</td>\n",
       "      <td>0.034715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.053954</td>\n",
       "      <td>0.055703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.053768</td>\n",
       "      <td>-0.003952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048064</td>\n",
       "      <td>-0.031652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044903</td>\n",
       "      <td>0.219392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.039673</td>\n",
       "      <td>0.096799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.038080</td>\n",
       "      <td>0.125342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  original\n",
       "0   0.050150  0.034715\n",
       "1   0.053954  0.055703\n",
       "2   0.053768 -0.003952\n",
       "3   0.048064 -0.031652\n",
       "4   0.044903  0.219392\n",
       "5   0.039673  0.096799\n",
       "6   0.038080  0.125342"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAS8UlEQVR4nO3df6zdd33f8eer105y2w4cyJ2EnRibNrVmxoTbS7L1B2NiwwlbEy9LpTB1ChJVhNZM2xDeYnUSNFSirTeBqmaFqDAxOhrSzLOsTtUdaunUf0hzjQPGpHc4hhJfo5EmGMa4I7bz3h/na3N8c517ru899xx//HxIRz7n8/18v+d17z3ndY+/3+89J1WFJKldPzTqAJKk4bLoJalxFr0kNc6il6TGWfSS1LgNow6w2A033FDbtm0bdQxJuqIcPnz4r6pqaqllY1f027ZtY3Z2dtQxJOmKkuQvL7XMXTeS1DiLXpIaZ9FLUuMseklqnEUvSY0bu7NupNU4eGSe/TNznDq9wOZNk+zdvYM9u7aMOpY0Uha9mnHwyDz7Dhxl4cw5AOZPL7DvwFEAy15XNXfdqBn7Z+YulPx5C2fOsX9mbkSJpPFg0asZp04vrGhculpY9GrG5k2TKxqXrhYWvZqxd/cOJjdOXDQ2uXGCvbt3jCiRNB48GKtmnD/g6lk30sUsejVlz64tFru0iLtuJKlxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklq3EBFn+S2JHNJjid5YInl70ny5SRfTPLHSV7bt+zeJF/pLveuZXhJ0vKWLfokE8BDwO3ATuAdSXYumnYEmK6qvwU8Bvxmt+6rgPcBtwK3AO9Lcv3axZckLWeQV/S3AMer6kRVvQA8AtzZP6GqPltV3+tufg64sbu+G/hMVT1fVd8CPgPctjbRJUmDGKTotwDP9N0+2Y1dyruAP7rMdSVJa2xN3+smyS8C08DfXeF69wH3AWzdunUtI0nSVW+QV/TzwE19t2/sxi6S5O8DvwLcUVXfX8m6VfVwVU1X1fTU1NSg2SVJAxik6J8Abk6yPck1wD3Aof4JSXYBH6VX8t/sWzQDvC3J9d1B2Ld1Y5KkdbLsrpuqOpvkfnoFPQF8vKqOJXkQmK2qQ8B+4EeBP0gC8PWquqOqnk/yAXq/LAAerKrnh/KVSJKWlKoadYaLTE9P1+zs7KhjSNIVJcnhqppeapl/GStJjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMGKvoktyWZS3I8yQNLLH9zks8nOZvk7kXLziV5srscWqvgkqTBbFhuQpIJ4CHgHwAngSeSHKqqL/dN+zrwTuC9S2xioareuPqokqTLsWzRA7cAx6vqBECSR4A7gQtFX1Vf65a9OISMkqRVGGTXzRbgmb7bJ7uxQV2XZDbJ55LsWWpCkvu6ObPPPvvsCjYtSVrOehyMfW1VTQP/FPhwkh9bPKGqHq6q6aqanpqaWodIknT1GKTo54Gb+m7f2I0NpKrmu39PAH8K7FpBPknSKg1S9E8ANyfZnuQa4B5goLNnklyf5Nru+g3Az9C3b1+SNHzLFn1VnQXuB2aAp4BHq+pYkgeT3AGQ5E1JTgK/AHw0ybFu9b8BzCb5AvBZ4NcXna0jSRqyVNWoM1xkenq6ZmdnRx1Dkq4oSQ53x0Nfwr+MlaTGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktS4QT545Ipw8Mg8+2fmOHV6gc2bJtm7ewd7dq3kbfMlqU1NFP3BI/PsO3CUhTPnAJg/vcC+A0cBLHtJV70mdt3sn5m7UPLnLZw5x/6ZuRElkqTx0UTRnzq9sKJxSbqaNFH0mzdNrmhckq4mTRT93t07mNw4cdHY5MYJ9u7eMaJEkjQ+mjgYe/6Aq2fdSNJLNVH00Ct7i12SXqqJXTeSpEuz6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMYNVPRJbksyl+R4kgeWWP7mJJ9PcjbJ3YuW3ZvkK93l3rUKLkkazLJFn2QCeAi4HdgJvCPJzkXTvg68E/jUonVfBbwPuBW4BXhfkutXH1uSNKhBXtHfAhyvqhNV9QLwCHBn/4Sq+lpVfRF4cdG6u4HPVNXzVfUt4DPAbWuQW5I0oEHej34L8Ezf7ZP0XqEPYql1X/Km8UnuA+4D2Lp164CbHg8Hj8z7gSeSxtpYHIytqoerarqqpqempkYdZ2AHj8yz78BR5k8vUMD86QX2HTjKwSPzo44mSRcMUvTzwE19t2/sxgaxmnXH3v6ZORbOnLtobOHMOfbPzI0okSS91CBF/wRwc5LtSa4B7gEODbj9GeBtSa7vDsK+rRtrwqnTCysal6RRWLboq+oscD+9gn4KeLSqjiV5MMkdAEnelOQk8AvAR5Mc69Z9HvgAvV8WTwAPdmNN2LxpckXjkjQKqapRZ7jI9PR0zc7OjjrGQM7vo+/ffTO5cYIP3vUGD8hKWldJDlfV9FLLBjnrRpdwvsw960bSOLPoV2nPri0Wu6SxNhanV0qShseil6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxG0YdQJKudgePzLN/Zo5TpxfYvGmSvbt3sGfXljXbvkUvSSN08Mg8+w4cZeHMOQDmTy+w78BRgDUre3fdSNII7Z+Zu1Dy5y2cOcf+mbk1uw+LXpJG6NTphRWNX46Bij7JbUnmkhxP8sASy69N8ulu+eNJtnXj25IsJHmyu3xkzZJLUgM2b5pc0fjlWLbok0wADwG3AzuBdyTZuWjau4BvVdWPAx8CfqNv2dNV9cbu8u41yi1JTdi7eweTGycuGpvcOMHe3TvW7D4GeUV/C3C8qk5U1QvAI8Cdi+bcCXyiu/4Y8NYkWbOUktSoPbu28MG73sCWTZME2LJpkg/e9YZ1P+tmC/BM3+2TwK2XmlNVZ5N8G3h1t2x7kiPAd4B/V1V/trrIktSWPbu2rGmxLzbs0yu/AWytqueS/BRwMMnrq+o7/ZOS3AfcB7B169YhR5Kkq8sgu27mgZv6bt/YjS05J8kG4JXAc1X1/ap6DqCqDgNPAz+x+A6q6uGqmq6q6ampqZV/FZKkSxqk6J8Abk6yPck1wD3AoUVzDgH3dtfvBv6kqirJVHcwlySvA24GTqxNdEnSIJbdddPtc78fmAEmgI9X1bEkDwKzVXUI+BjwySTHgefp/TIAeDPwYJIzwIvAu6vq+WF8IZKkpaWqRp3hItPT0zU7OzvqGJJ0RUlyuKqml1rmX8ZKUuMseklqnEUvSY2z6CWpcb4fvaShGvaHamh5Fr2koVmPD9XQ8tx1I2lo1uNDNbQ8i17S0KzHh2poeRa9pKFZjw/V0PIseklDsx4fqqHleTBW0tCcP+DqWTejZdFLGqphf6iGlueuG0lqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGmfRS1LjLHpJapxFL0mNs+glqXEWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWqcRS9JjbPoJalxAxV9ktuSzCU5nuSBJZZfm+TT3fLHk2zrW7avG59LsnsNs0uSBrBs0SeZAB4Cbgd2Au9IsnPRtHcB36qqHwc+BPxGt+5O4B7g9cBtwH/stidJWieDvKK/BTheVSeq6gXgEeDORXPuBD7RXX8MeGuSdOOPVNX3q+qrwPFue5KkdbJhgDlbgGf6bp8Ebr3UnKo6m+TbwKu78c8tWnfL4jtIch9wH8DWrVsHzS5JV6SDR+bZPzPHqdMLbN40yd7dO9iz6yXVuGbG4mBsVT1cVdNVNT01NTXqOJI0NAePzLPvwFHmTy9QwPzpBfYdOMrBI/NDu89Bin4euKnv9o3d2JJzkmwAXgk8N+C6knTV2D8zx8KZcxeNLZw5x/6ZuaHd5yBF/wRwc5LtSa6hd3D10KI5h4B7u+t3A39SVdWN39OdlbMduBn487WJLklXnlOnF1Y0vhaW3Uff7XO/H5gBJoCPV9WxJA8Cs1V1CPgY8Mkkx4Hn6f0yoJv3KPBl4Czwy1V1bsk7kqSrwOZNk8wvUeqbN00O7T7Te+E9Pqanp2t2dnbUMSRpKM7vo+/ffTO5cYIP3vWGVR2QTXK4qqaXWjbIWTeSpDVyvszX86wbi16S1tmeXVuGWuyLjcXplZKk4bHoJalxFr0kNc6il6TGWfSS1DiLXpIaZ9FLUuMseklqnEUvSY2z6CWpcRa9JDXOopekxln0ktQ4i16SGufbFEtXuINH5tf1vc115bHopSvY4k8rmj+9wL4DRwEse13grhvpCrZ/Zu6ij6QDWDhzjv0zcyNKpHFk0UtXsFNLfMj0y43r6mTRS1ewzZsmVzSuq5NFL13B9u7eweTGiYvGJjdOsHf3jhEl0jjyYKx0BTt/wNWzbvRyLHrpCrdn1xaLXS/LXTeS1DiLXpIaZ9FLUuMseklqnEUvSY1LVY06w0WSPAv85WWsegPwV2scZy2May4Y32zjmgvGN5u5Vm5cs11urtdW1dRSC8au6C9Xktmqmh51jsXGNReMb7ZxzQXjm81cKzeu2YaRy103ktQ4i16SGtdS0T886gCXMK65YHyzjWsuGN9s5lq5cc225rma2UcvSVpaS6/oJUlLsOglqXFjW/RJbksyl+R4kgeWWH5tkk93yx9Psq0bvyXJk93lC0n+cd86/zrJsSRfSvL7Sa5br1x9y7cm+W6S9w66zVHkSnJTks8m+XL3PfuXl5NrGNn6xieSHEnyh+OSK8mmJI8l+YskTyX5O2OSa9WP/dVkS7ItyULfc/Mjfev8VJKj3Tq/lSSjzpXkh5P89+7neCzJr6800zByLVr3UJIvDRSkqsbuAkwATwOvA64BvgDsXDTnnwMf6a7fA3y6u/7DwIbu+muAb9J7O+YtwFeByW7Zo8A71ytX3/LHgD8A3jvoNkeU6zXAT3bX/xrwv1aaa1jZ+sbfA3wK+MNxyQV8Avil7vo1wKZR51qLx/4aPC+3AV+6xHb/HPjbQIA/Am4fdS56PfL3+n6OfzYOufrWu6t77F9yTv9lXF/R3wIcr6oTVfUC8Ahw56I5d9J7UkHvgf3WJKmq71XV2W78OqD/aPMGYDLJBno/yFPrlQsgyR56T7hjK9zmuueqqm9U1ee76/8HeIpeYazUML5nJLkR+IfA715GpqHkSvJK4M3AxwCq6oWqOj3qXJ3VPvZXnW0pSV4DvKKqPle9BvvPwJ5R5+p65LPd9ReAzwM3jjoXQJIfpfci59cGDTKuRb8FeKbv9kleWjIX5nTF/m3g1QBJbk1yDDgKvLuqzlbVPPDvga8D3wC+XVX/Y71ydT+cfwv86mVscxS5Luj+O7kLeHyFuYaZ7cPAvwFevIxMw8q1HXgW+E/dLqXfTfIjo861Ro/9VWXrlm3vvi//M8nP9c0/ucw2R5HrgiSbgJ8H/nhMcn0A+A/A9wYNMq5FvypV9XhVvR54E7AvyXVJrqf323M7sBn4kSS/uI6x3g98qKq+u473OYj38zK5uvL4r8C/qqrvrGcwLpEtyT8CvllVh9c5z3nvZ+nv2QbgJ4HfqapdwP8FLuuYy1rmGoPHPvR+wWztvi/vAT6V5BXrnGEpL5ur+x/Q7wO/VVUnRp0ryRuBH6uq/7aSjY3rRwnOAzf13b6xG1tqzsnuh/FK4Ln+CVX1VJLvAn+T3oP8q1X1LECSA8BPA7+3TrluBe5O8pvAJuDFJP8PODzANtc9V1X9dpKN9Er+v1TVgRVmGlo2eq+C7kjydnq7516R5PeqaiXlNYxcjwEnq+r8/3weY+VFP4xc/5vVP/ZXla3bLfN9gKo6nORp4Ce6+f27RNb18f8yuWa79R4GvlJVH15hpmHlehMwneRr9Pr7ryf506p6y8smWcnBhfW6dF/ACXrlfP4gxusXzfllLj6I8Wh3fTs/OBj7Wnr7Im+g9yQ4Rm//ZOjtF/sX65Vr0Zz384MDZctuc0S5Qm9/6YdH9bO8VLZF42/h8g7GDiUXvYN2O/qW7R91rrV47K/B83IKmOiuv45ewb2qu734YOzbxyTXr9F7ofND6/3Yf7lcfetuY8CDsZf9BB72BXg7vTM9ngZ+pRt7ELiju34dvTMLjncPlNd14/+se1A/Se8Ayp6+bf4q8BfAl4BPAteuV65F27jwJLzUNkedC/hZegeyv9h9L59c6RNwmN+zvvG3cBlFP8Sf5RvpvRr8InAQuH5Mcq36sb/K5+U/4eLn5c/3bXO6y/U08Nt0f7E/ylz0Xn0XvZMQnuwuvzTqXIu2vY0Bi963QJCkxjV5MFaS9AMWvSQ1zqKXpMZZ9JLUOItekhpn0UtS4yx6SWrc/wco/c6b7gSuTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#multi\n",
    "yhat = modelCNN.predict(X_test, verbose=0)\n",
    "\n",
    "predicted = []\n",
    "original = []\n",
    "if len(ycolumns) > 1:\n",
    "    results = yhat.reshape(len(y_test), int(yhat.shape[1]/X_test.shape[2]), len(choice.columns))\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(pd.DataFrame(results[i])[0][0])\n",
    "        original.append(pd.DataFrame(y_test[i])[0][0])\n",
    "        #print(pd.DataFrame(results[i])[0][0])\n",
    "        #print(pd.DataFrame(y_test[i])[0][0])\n",
    "else:\n",
    "    results = yhat\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(results[i])\n",
    "        original.append(y_test[i])\n",
    "        #print(pd.DataFrame(results[i]))\n",
    "        #print(pd.DataFrame(y_test[i]))\n",
    "        \n",
    "#revert_transformed_predicted = inverse_yeo((scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted)).values,(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted)).values,lambdas_.values[0])\n",
    "#revert_transformed_original = inverse_yeo((scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original)).values,(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original)).values,lambdas_.values[0])\n",
    "revert_transformed_predicted = (scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted))\n",
    "revert_transformed_original = (scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original))\n",
    "\n",
    "plt.scatter(revert_transformed_predicted,revert_transformed_original)\n",
    "temp = pd.concat([revert_transformed_predicted,revert_transformed_original],axis=1)\n",
    "temp.columns = [\"predicted\", \"original\"]\n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8229628-eed4-4b76-831d-1de033240347",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(best_model.coef_).set_index(X_inter_train.columns)\n",
    "\n",
    "a_coef = abs(coef)\n",
    "a_coef.sort_values(by=[0],ascending=False,inplace=True)\n",
    "chosen_few = a_coef[a_coef>0].dropna().index.values\n",
    "\n",
    "scaler_ = preprocessing.StandardScaler().fit(transformed)\n",
    "\n",
    "#\n",
    "train_ = pd.DataFrame(scaler_.transform(transformed))\n",
    "train_.columns = transformed.columns\n",
    "train_.index = transformed.index  \n",
    "\n",
    "X_inter_train_ = pd.DataFrame(interaction.fit_transform(train_.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_.iloc[:,1:]).columns))\n",
    "\n",
    "max_pvalue = 1\n",
    "New_Names = X_inter_train.columns\n",
    "X_b = X_inter_train_[chosen_few]\n",
    "while (max_pvalue > .05):\n",
    "        \n",
    "    trf = zca.ZCA().fit(X_b)\n",
    "        \n",
    "    X_b_z = pd.DataFrame(trf.transform(X_b))\n",
    "    X_b_z.columns=pd.DataFrame(X_b).columns\n",
    "    X_b_z.index = train_.index\n",
    "\n",
    "    model_ = sm.OLS(train_.iloc[:,0],sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    #model_ = sm.OLS(pd.DataFrame(pd.concat([train_.iloc[:,0],X_b_z],axis=1),sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    results_ = model_.fit()\n",
    "\n",
    "    set_ = X_b.columns.tolist()\n",
    "    \n",
    "    max_pvalue = max(results_.pvalues[1:])\n",
    "    if (max_pvalue > .05):\n",
    "        print(max_pvalue)\n",
    "        max_pname = (results_.pvalues[1:]).idxmax(axis=1)\n",
    "        set_.remove(max_pname)\n",
    "        New_Names = set_\n",
    "    \n",
    "        X_b = X_inter_train_[New_Names]\n",
    "        X_b.index = X_inter_train_.index\n",
    "\n",
    "#from statsmodels.formula.api import ols\n",
    "#lm = ols(pd.DataFrame(train_.iloc[:,0]) ~ sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip')).fit()\n",
    "#table = sm.stats.anova_lm(model_, type=3)\n",
    "#print(table)\n",
    "print(results_.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e428c-cce9-46e3-b145-754fc9e4c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNaNCols(df_):\n",
    "    for col in df_:        \n",
    "        num_NaNs = df_[col].isnull().sum()\n",
    "        if num_NaNs > 0:\n",
    "            print(f\"Column: {col}\")\n",
    "            print(f\"Number of NaNs: {num_NaNs}\")\n",
    "\n",
    "findNaNCols(X_b_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4e220-4ac2-4945-9e3a-4b8ff1355a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d940860-86d6-4768-81a0-63f9127143a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_plot = Plot.LinearRegressionResidualPlot(X_b_z, pd.DataFrame(train_.iloc[:,0]))\n",
    "lm = linear_plot.fit()\n",
    "summary, diag_res = linear_plot.diagnostic_plots(lm)\n",
    "print(\"Summary of Regression\\n:{}\".format(summary))\n",
    "print(\"Diagnostic Tests of Regression\\n:{}\".format(diag_res))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#sns.pairplot(pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1), hue=Y, height=2);\n",
    "\n",
    "pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1).hist()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_s = sklearn.linear_model.LinearRegression()\n",
    "model_s.fit(X_b_z, pd.DataFrame(train_[Y]))\n",
    "\n",
    "shap.initjs()\n",
    "e = shap.explainers.Linear(model_s, X_b_z)\n",
    "\n",
    "shap_values = e.shap_values(X_b_z)\n",
    "shap.summary_plot(shap_values, X_b_z)\n",
    "shap.plots.heatmap(e(X_b_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b64b8-ca00-46d1-ba16-91f3adb00065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4871c2-4418-491a-8e5c-5776d42e4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "residuals_normalized = lm.get_influence().resid_studentized_internal\n",
    "cooks = lm.get_influence().cooks_distance[0]\n",
    "cooks = np.round(f.pdf(cooks,len(lm.tvalues)+1, len(lm.fittedvalues)-len(lm.tvalues)-1),2)\n",
    "\n",
    "res_std = lm.get_influence().resid_std\n",
    "\n",
    "leverage = lm.get_influence().hat_matrix_diag\n",
    "\n",
    "plt.hist(pd.DataFrame(leverage))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(cooks))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(residuals_normalized))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "testNormal(residuals_normalized)\n",
    "\n",
    "w = res_std\n",
    "x = cooks\n",
    "y = leverage\n",
    "z = residuals_normalized\n",
    "\n",
    "fitted_y = lm.fittedvalues\n",
    "\n",
    "labels_ = fitted_y.index\n",
    "\n",
    "outlier_check = pd.concat([pd.DataFrame(x),pd.DataFrame(y),pd.DataFrame(z),pd.DataFrame(w)],axis=1).set_index(labels_)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres']\n",
    "\n",
    "qq = ProbPlot(residuals_normalized)\n",
    "\n",
    "c_thresh = .1\n",
    "l_thresh = (2*(len(lm.tvalues)-1)/len(lm.fittedvalues))\n",
    "s_thresh = max(qq.theoretical_quantiles)\n",
    "\n",
    "print(\"Outlier threshold's\")\n",
    "print(\"Cooks distance: > .1+\")\n",
    "print(\"Leverage: > \" + str(l_thresh) + \" to \" + str(3 * (len(lm.tvalues)-1)/len(fitted_y)))\n",
    "print(\"Studentized residuals: > \" + str(s_thresh))\n",
    "print()\n",
    "\n",
    "flag = []\n",
    "\n",
    "for i in range(0,len(outlier_check)):\n",
    "    if( (outlier_check.iloc[i][0] >= c_thresh) or (outlier_check.iloc[i][1] >= l_thresh) or (abs(outlier_check.iloc[i][2]) >= s_thresh) ):\n",
    "        print(outlier_check.iloc[i])\n",
    "        print()\n",
    "        flag.append(True)\n",
    "    else:\n",
    "        flag.append(False)\n",
    "\n",
    "outlier_check = pd.concat([outlier_check,pd.DataFrame(flag).set_index(labels_)],axis=1)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres', 'flagged']\n",
    "\n",
    "print(np.flip(np.argsort(cooks), 0))\n",
    "#print(outlier_check)\n",
    "\n",
    "search = outlier_check[outlier_check['flagged']==1].index.to_list()\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in search:\n",
    "    v = outlier_check.index.to_list().index(i)\n",
    "    rows.append(v)\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2b196-7761-4420-a145-a5411053a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_style(row):\n",
    "\n",
    "    color = 'white'\n",
    "    if bool(row.flagged) == True:\n",
    "        color = 'orange'\n",
    "\n",
    "    return ['background-color: %s' % color]*len(row.values)\n",
    "\n",
    "all_data[set(all_data.columns) & set(New_Names)]\n",
    "\n",
    "outlier_check.style.apply(custom_style, axis=1).apply(custom_style, axis=1).background_gradient(cmap ='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da39b86-0ac2-4470-9457-8e999918d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b8430-ac88-4358-88c1-e6c5400fe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = y_train.columns.to_list()\n",
    "df2 = list(set(set(all_data.columns) & set(New_Names)))\n",
    "\n",
    "flattened = [] \n",
    "for sublist in df1,df2: \n",
    "    for val in sublist: \n",
    "        flattened.append(val) \n",
    "\n",
    "all_data.iloc[rows][flattened].style.background_gradient(cmap ='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
