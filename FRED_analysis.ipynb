{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3139d-1ac0-4486-80f0-e54d08259ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "ee726465-0b88-46f7-877f-5aee84616ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import shap\n",
    "import numpy as np\n",
    "import ZCA as zca\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as plt\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython\n",
    "\n",
    "import os\n",
    "os.environ['R_HOME'] = '/mnt/distvol/R/4.0.5/lib64/R/'\n",
    "import rpy2.robjects as R\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import arange\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import seaborn as sns\n",
    "from ModelDiagnostics import Plot\n",
    "from sklearn.cluster import DBSCAN\n",
    "from clustergram import Clustergram\n",
    "import urbangrammar_graphics as ugg\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "\n",
    "import dtale\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "id": "78bf8827-4f34-413b-9a4d-bd6565e33372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001\n",
    "    #print(\"p = {:g}\".format(p))    \n",
    "    if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "        #print(p)\n",
    "        #print(alpha)\n",
    "        print(\"The null hypothesis can be rejected\")\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        #xt, _ = stats.boxcox(x)        \n",
    "        print(_)\n",
    "        xt = pd.DataFrame(xt)\n",
    "        \n",
    "        return _, pd.DataFrame(xt).set_index(x.index)\n",
    "    else:\n",
    "        print(\"The null hypothesis cannot be rejected\")    \n",
    "        return 1, pd.DataFrame(x)\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    power = PowerTransformer(method='yeo-johnson')\n",
    "    power.lambdas_ = lambdas.values\n",
    "    return(power.inverse_transform([data]))\n",
    "    #return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.yeojohnson((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        l, inner_scale = testNormal(data.iloc[:,i])\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def inverse_yeo(og, data_, lambda_):\n",
    "    values = []\n",
    "    for i in range(0,len(og)):\n",
    "        X = og[i]\n",
    "        X_trans = data_[i]\n",
    "        if X >= 0 and lambda_ == 0:\n",
    "            X = exp(X_trans) - 1\n",
    "        elif X >= 0 and lambda_ != 0:\n",
    "            X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
    "        elif X < 0 and lambda_ != 2:\n",
    "            X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
    "        elif X < 0 and lambda_ == 2:\n",
    "            X = 1 - exp(-X_trans)\n",
    "        \n",
    "        values.append(X)\n",
    "    return(pd.DataFrame(values))\n",
    "\n",
    "\n",
    "def revert_yeo (og, data_, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data_.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data_.iloc[:,i]\n",
    "        else:\n",
    "            p#ower = PowerTransformer(method='yeo-johnson')\n",
    "            #power.lambdas_ = lambdas.iloc[i].values\n",
    "            #revert = pd.DataFrame(power.inverse_transform([data.iloc[:,i].values]))\n",
    "            #return inv_boxcox(data, lambdas.values)\n",
    "            revert = pd.DataFrame(inverse_yeo(og.iloc[:,i].values,data_.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data_.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data_.columns\n",
    "    return reverted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "id": "2ec9d431-186e-4171-8a8a-378ab2ab2e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_deltas(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(d)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def get_residuals(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(r)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def arfima_predict(data_, ahead):\n",
    "\n",
    "    R.r('''\n",
    "               f_ <- function(values, ahead) {\n",
    "                        #system(\"which openssl\")\n",
    "                        print(nrow(values))\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x,drop=FALSE]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              #return(r)\n",
    "                              \n",
    "                              pred <- predict(varvefd, ahead)\n",
    "                              #print(ahead)\n",
    "                              #print(pred)\n",
    "                              #print(pred)\n",
    "                              return(as.data.frame(pred)[,1,drop=TRUE])\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f_ = R.globalenv['f_']\n",
    "    d_=R.conversion.rpy2py((r_f_(R.conversion.py2rpy(data_),ahead)))\n",
    "    return(d_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "id": "e43598e7-17dd-4ced-b588-e8870d3df933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "def arima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #arima residual adjusted\n",
    "    \n",
    "    window = 15\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    model = AutoReg(train_resid.values, lags=15)\n",
    "    model_fit = model.fit()\n",
    "    coef = model_fit.params\n",
    "    # walk forward over time steps in test\n",
    "    history = train_resid[len(train_resid)-window:]\n",
    "    history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]    \n",
    "        error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        length = len(history)\n",
    "        lag = [history[i] for i in range(length-window,length)]\n",
    "        pred_error = coef[0]\n",
    "        for d in range(window):\n",
    "            pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        yhat = yhat + pred_error\n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af9904-08a5-4d5f-90f7-1b4c5d4652df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9bb80-d23a-4a60-964b-41dad96d6411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "id": "1235085d-f98a-4b9d-a118-29a6f154af93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom statsmodels.tsa.ar_model import AutoReg\\n\\nresiduals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\\n\\ny_adjusted = predicteds.copy()\\n\\nfor i in range(0,len(y_test)):    \\n    \\n    if i == 0:\\n        forecast_r = arfima_predict(residuals_train.values)\\n        \\n    else:\\n        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\\n        \\n        residuals = pd.concat([residuals_train,residuals_test],axis=0)\\n        \\n        forecast_r = arfima_predict(residuals.values)\\n        \\n    print(forecast_r)\\n    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\\n    #print(adjusted)\\n    \\n    \\n    \\n    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\\n    #ar_s_model = AutoReg(residuals, lags=15)\\n    #model_fit = model.fit()\\n    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\\n\\n    #improved_forecast = forecast + estimated error\\n\\n    #print('Coef=%s' % (model_fit.params))\\n\""
      ]
     },
     "execution_count": 1448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arfima residual adjusted\n",
    "def arfima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #train_resid = get_deltas(y_train)\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    y_adjusted = predicted.copy()\n",
    "\n",
    "    forecast_r = arfima_predict(train_resid.values, len(y_test))  \n",
    "    print(len(forecast_r))\n",
    "    \n",
    "    # walk forward over time steps in test\n",
    "    #history = train_resid[len(train_resid):-1]\n",
    "    #history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]\n",
    "        #error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        #length = len(history)\n",
    "        #lag = [history[i] for i in range(length-window,length)]\n",
    "        #pred_error = coef[0]\n",
    "        #for d in range(window):\n",
    "            #pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        #print(yhat)\n",
    "        #print(pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] )\n",
    "        yhat = yhat + pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] \n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        #history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))\n",
    "\n",
    "'''\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "residuals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\n",
    "\n",
    "y_adjusted = predicteds.copy()\n",
    "\n",
    "for i in range(0,len(y_test)):    \n",
    "    \n",
    "    if i == 0:\n",
    "        forecast_r = arfima_predict(residuals_train.values)\n",
    "        \n",
    "    else:\n",
    "        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\n",
    "        \n",
    "        residuals = pd.concat([residuals_train,residuals_test],axis=0)\n",
    "        \n",
    "        forecast_r = arfima_predict(residuals.values)\n",
    "        \n",
    "    print(forecast_r)\n",
    "    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\n",
    "    #print(adjusted)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\n",
    "    #ar_s_model = AutoReg(residuals, lags=15)\n",
    "    #model_fit = model.fit()\n",
    "    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\n",
    "\n",
    "    #improved_forecast = forecast + estimated error\n",
    "\n",
    "    #print('Coef=%s' % (model_fit.params))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a133da3-b0fd-4741-a0aa-db8cc75f878d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weights(d, num_k):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    \n",
    "    for k in range(1, num_k):\n",
    "        w_k = np.append(w_k, -w_k[-1] * ((d - k + 1)) / k)\n",
    "        \n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def get_weights_floored(d, num_k, floor=1e-3):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$ provided weight above a minimum value\n",
    "    (floor) for the weights to prevent computation of weights for the entire\n",
    "    time series.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "        floor (float): minimum value for the weights for computational efficiency.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    k = 1\n",
    "    \n",
    "    while k < num_k:\n",
    "        w_k_latest = -w_k[-1] * ((d - k + 1)) / k\n",
    "        if abs(w_k_latest) <= floor:\n",
    "            break\n",
    "\n",
    "        w_k = np.append(w_k, w_k_latest)\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def frac_diff(df, d, floor=1e-3):\n",
    "    r\"\"\"Fractionally difference time series via CPU.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe of raw time series values.\n",
    "        d (float): differencing value from 0 to 1 where > 1 has no FD.\n",
    "        floor (float): minimum value of weights, ignoring anything smaller.\n",
    "    \"\"\"\n",
    "    # Get weights window\n",
    "    weights = get_weights_floored(d=d, num_k=len(df), floor=floor)\n",
    "    weights_window_size = len(weights)\n",
    "    \n",
    "    # Reverse weights\n",
    "    weights = weights[::-1]\n",
    "    \n",
    "    # Blank fractionally differenced series to be filled\n",
    "    df_fd = []\n",
    "\n",
    "    # Slide window of time series, to calculated fractionally differenced values\n",
    "    # per window\n",
    "    for idx in range(weights_window_size, df.shape[0]):\n",
    "        # Dot product of weights and original values\n",
    "        # to get fractionally differenced values\n",
    "        date_idx = df.index[idx]\n",
    "        df_fd.append(np.dot(weights.T, df.iloc[idx - weights_window_size:idx]).item())\n",
    "    \n",
    "    # Return FD values and weights\n",
    "    df_fd = pd.DataFrame(df_fd)\n",
    "    \n",
    "    return df_fd, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e53d3-2864-4d69-a45a-ce48217e4fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "d949ef06-ae96-4828-b02b-21a92a11b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxl = 5\n",
    "train_size = .7\n",
    "t_size = 1-train_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "id": "62e6233b-8abf-4f78-83f5-a3e7a2e26fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = pd.read_csv('/mnt/distvol/combined_set.csv')\n",
    "all_data.index = all_data.iloc[:,0]\n",
    "all_data = all_data.iloc[:,1:]\n",
    "\n",
    "filter_ = all_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "ca4d80c7-99c2-4070-b6f4-1b19d28520f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003-06-29\n",
      "2005-04-17\n",
      "2007-02-04\n",
      "2008-11-23\n",
      "2010-09-12\n",
      "2012-07-01\n",
      "2014-04-20\n",
      "2016-02-07\n",
      "2017-11-26\n",
      "2019-09-15\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "id": "8b2b9636-4857-4aaa-b13d-e2077e957c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose Y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0faf97c2c0d418193f2ca420d2516cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Y', options=('DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f3(Y):\n",
    "    \n",
    "    #Y = x\n",
    "    #output_slider_variable.value\n",
    "    internalFilter = filter_.copy()\n",
    "    internalFilter.remove(Y)\n",
    "    all_data_ = pd.concat([all_data[Y],all_data[internalFilter]], axis=1)    \n",
    "    #print(all_data_.describe())\n",
    "    display(all_data_.describe())\n",
    "    #x_ticks = all_data_.index[np.arange(0, len(all_data.index), int(len(internalFilter)/5))]\n",
    "    x_ticks  = []\n",
    "    for index, element in enumerate(all_data_.index):\n",
    "        if index % int(np.round(len(all_data_.index)/10)) == 0:\n",
    "            x_ticks.append(element)\n",
    "    plt.plot(all_data_[Y])\n",
    "    plt.xticks(x_ticks, rotation = 45)\n",
    "    plt.show()        \n",
    "    plt.hist(all_data_[Y], bins='auto')\n",
    "    plt.show()\n",
    "    diff = pd.DataFrame((all_data_[Y].pct_change())).dropna()\n",
    "    plt.hist(diff, bins='auto')\n",
    "    plt.show()\n",
    "    return(all_data_)\n",
    "    \n",
    "out = interactive(f3, Y=filter_)\n",
    "\n",
    "#output_slider_variable.observe(f4, 'value')\n",
    "\n",
    "print(\"choose Y\")\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "id": "4ee2cc18-8baf-4f8a-bcd2-9562b62237fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 02:22:07,108 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:12,387 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,367 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,551 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:15,762 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,589 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,758 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:17,216 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,142 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,361 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,987 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:19,640 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,630 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,887 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,128 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,665 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(out.result, test_size=tsize, shuffle=False)\n",
    "\n",
    "d = get_deltas(train)\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "id": "2d87fad8-9555-4fe1-a82f-18243715d650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 1487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "id": "2ed2b0f5-1e32-4e6a-8e54-ea4dbe225df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "id": "33e1c5c4-9718-4cbb-a820-9fd94e3fc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "from fracdiff import fdiff\n",
    "\n",
    "cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "def getDifferenced(i, data):\n",
    "    #v = d[[i]]\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\n",
    "    #print(i)\n",
    "    a = np.array(data.iloc[:, i])\n",
    "    \n",
    "    return fdiff(a, n=d[i], axis=0)\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "id": "2070d863-3329-4f28-8b4e-a74b5480cc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndifferenced = pd.DataFrame()\\nfor f in range(0,len(futures01)):\\n    value = pd.DataFrame(futures01[f].result())\\n    differenced = pd.concat([differenced,value],axis=1)\\n    \\ndifferenced.columns = train.columns\\ndifferenced.index = train.index\\n'"
      ]
     },
     "execution_count": 1517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "differenced = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, out.result))\n",
    "    #print(value)\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = out.result.columns\n",
    "differenced.index = out.result.index    \n",
    "\n",
    "'''\n",
    "\n",
    "differenced_train = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, train))\n",
    "    #print(value)\n",
    "    differenced_train = pd.concat([differenced_train,value],axis=1)\n",
    "    \n",
    "differenced_train.columns = train.columns\n",
    "differenced_train.index = train.index    \n",
    "\n",
    "differenced_test = pd.DataFrame()\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, test))\n",
    "    differenced_test = pd.concat([differenced_test,value],axis=1)\n",
    "\n",
    "differenced_test.columns = test.columns\n",
    "differenced_test.index = test.index\n",
    "\n",
    "differenced = pd.DataFrame()\n",
    "differenced = pd.concat([differenced_train,differenced_test],axis=0)\n",
    "'''\n",
    "differenced = pd.concat([out.result.iloc[:,0],differenced.iloc[:,1:]],axis=1)\n",
    "\n",
    "#pool01 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "#futures01 = [pool01.submit(getDifferenced, args) for args in (range(0,len(d)))]\n",
    "\n",
    "#wait(futures01, timeout=None, return_when=ALL_COMPLETED)\n",
    "#'''\n",
    "\n",
    "'''\n",
    "differenced = pd.DataFrame()\n",
    "for f in range(0,len(futures01)):\n",
    "    value = pd.DataFrame(futures01[f].result())\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = train.columns\n",
    "differenced.index = train.index\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d32f-b9a1-4196-9d43-1359b65f1c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "f492f94d-cba1-455a-b1d4-157a346f6d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://slurmw01:40000'"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = dtale.show(out.result)\n",
    "d_.open_browser()\n",
    "d_._url  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "4273fdd8-d805-4928-b7dd-bda427cf51fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport concurrent.futures\\nfrom concurrent.futures import wait, ALL_COMPLETED\\nfrom fracdiff import fdiff\\n\\ncores = int(len(os.sched_getaffinity(0)))\\n\\ndef getDifferenced(i):\\n    #v = d[[i]]\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\\n    \\n    a = np.array(out.result.iloc[:, i])\\n    \\n    return fdiff(a, n=d[i], axis=0)\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\\n\\npool01 = concurrent.futures.ProcessPoolExecutor(cores)\\n\\nfutures01 = [pool01.submit(getDifferenced, args) for args in range(0,len(d))]\\n\\nwait(futures01, timeout=None, return_when=ALL_COMPLETED)\\n'"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfa758-3cf3-4410-bfc6-85105b37a19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e2820-110a-4786-9035-98543c301b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for f in range(0,len(futures01)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "        plt.hist(Differenced_Set.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        Differenced_Set.iloc[:,1].plot()\n",
    "        plt.show()\n",
    "        plt.hist(all_data.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        all_data.iloc[:,1].plot()\n",
    "        plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce862ad-f7fc-4f0b-b376-c29d32d01281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b6b7d-d0c5-4077-b822-d79e626067b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "3d49f670-bbdb-42a8-b9e3-e75e1b60e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = out.result.corr()\n",
    "#.abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0016982-6857-424e-868a-da44b16ff66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece4be0-8244-434e-b66e-9c1f39a7c2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "id": "4d4a92b7-e5b3-49ed-b31f-5959f90e8fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "def critical_r(n, alpha = .05 ):\n",
    "    df = n - 2\n",
    "    critical_t = scipy.stats.t.isf(alpha / 2, df)\n",
    "    critical_r = np.sqrt( (critical.t^2) / ( (critical.t^2) + df ) )\n",
    "    return(critical_r)\n",
    "\n",
    "def xcorr(x, y, maxlags=10):\n",
    "    Nx = len(x)\n",
    "    if Nx != len(y):\n",
    "        raise ValueError('x and y must be equal length')\n",
    "\n",
    "    c = np.correlate(x, y, mode=2)\n",
    "\n",
    "    if maxlags is None:\n",
    "        maxlags = Nx - 1\n",
    "\n",
    "    if maxlags >= Nx or maxlags < 1:\n",
    "        raise ValueError('maxlags must be None or strictly positive < %d' % Nx)\n",
    "\n",
    "    c = c[Nx - 1 - maxlags:Nx + maxlags]\n",
    "\n",
    "    return c\n",
    "\n",
    "def getLagged_Set(set_, og):\n",
    "\n",
    "    train, test = train_test_split(set_, test_size=tsize, shuffle=False)\n",
    "    \n",
    "    residuals = pd.DataFrame(np.transpose(get_residuals(train).reshape(len(train.columns),len(train))))\n",
    "    #print(residuals)\n",
    "\n",
    "    residuals.columns = train.columns\n",
    "    residuals.index = train.index\n",
    "\n",
    "    #print(len(train))\n",
    "    #set_.index = all_data.index\n",
    "    \n",
    "    Lagged_Differenced_Set = pd.DataFrame()\n",
    "    Lagged_Set = pd.DataFrame()\n",
    "    lags = []\n",
    "    lagcorrs = []\n",
    "    ogcorrs = []\n",
    "\n",
    "    for f in range(1,len(train.columns)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "\n",
    "        data_1 = residuals.iloc[:,0]\n",
    "        data_2 = residuals.iloc[:,f]\n",
    "\n",
    "        ogc = np.array(pd.concat([data_1 - np.mean(data_1),data_2 - np.mean(data_2)],axis=1).corr())[1,0]    \n",
    "        ogcorrs.append(ogc)\n",
    "\n",
    "        #corr = xcorr(data_1 - np.mean(data_1), data_2 - np.mean(data_2),maxlags=5)\n",
    "\n",
    "        set1 = data_1 - np.mean(data_1)\n",
    "        set2 = data_2 - np.mean(data_2)\n",
    "\n",
    "        corrs_ = []\n",
    "        for i in range(0,maxl):\n",
    "            c = np.array((pd.concat([set1,set2.shift(i)],axis=1).dropna()).corr())[0,1]\n",
    "            corrs_.append(c)\n",
    "\n",
    "        #corr = np.correlate(data_1 - np.mean(data_1), data_2 - np.mean(data_2),mode='full')\n",
    "        #plt.plot(corr)\n",
    "        #plt.show()\n",
    "\n",
    "        #lag = corr.argmax() - (len(data_1) - 1)\n",
    "        lag = abs(pd.Series(corrs_)).idxmax()\n",
    "\n",
    "        #print(corr)\n",
    "        lagc = np.array(pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1).corr())[1,0]\n",
    "\n",
    "        #print(lag)\n",
    "\n",
    "        #print(ogc)\n",
    "        #print(lagc)\n",
    "\n",
    "        #print(lag)\n",
    "        #plt.plot(data_1, 'r*')\n",
    "        #plt.plot(data_2, 'b*')\n",
    "\n",
    "        lag_merged = pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1)\n",
    "\n",
    "        #x_ticks = all_data.index[np.arange(0, len(all_data.index), 5)]\n",
    "        #plt.xticks(x_ticks, rotation = 45)    \n",
    "        #plt.show()\n",
    "\n",
    "        #plt.scatter(data_2.shift(lag),data_1)\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_acf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_pacf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #y = data_1\n",
    "        #X = data_2\n",
    "        #reg = LinearRegression().fit(X, y)\n",
    "\n",
    "        #print(reg.score(X, y),reg.coef_,reg.intercept_)\n",
    "\n",
    "        #model = sm.OLS(y,X)\n",
    "        #results = model.fit()\n",
    "        #print(results.summary())\n",
    "\n",
    "        #Lagged_Differenced_Set = pd.concat([Lagged_Differenced_Set,data_2.shift(lag)],axis=1)\n",
    "        #TrainO_Lagged_Set = pd.concat([TrainO_Lagged_Set,all_data.iloc[:,f].shift(lag)],axis=1)\n",
    "        #if lag>0:\n",
    "            #lag = 0\n",
    "\n",
    "        Lagged_Set = pd.concat([Lagged_Set,og.iloc[:,f].shift(lag)],axis=1)\n",
    "\n",
    "        lagcorrs.append(lagc)\n",
    "\n",
    "        lags.append(lag)\n",
    "\n",
    "    Lagged_Set.index = set_.index\n",
    "    #stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(lagcorrs),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    \n",
    "    #print(Lagged_Set)\n",
    "    #return stats, pd.concat([data_1,Lagged_Set],axis=1),  pd.concat([data_1,Lagged_Differenced_Set],axis=1)\n",
    "    return stats, pd.concat([set_.iloc[:,0],Lagged_Set],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "id": "23eb26a0-bb46-4fd9-b9b8-2de6a3a7f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['^SP500TR', 'DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10',\n",
       "       'T5YIFR', 'BAMLHYH0A0HYM2TRIV', 'BAMLCC0A1AAATRIV', 'DGS1',\n",
       "       'BAMLCC0A4BBBTRIV', 'IC4WSA', 'WILLMICROCAPPR', 'WILLLRGCAPVAL',\n",
       "       'T5YIE', 'WTB3MS', 'WGS3MO', 'TWEXB', 'DEXCHUS', 'DEXUSUK', 'TEDRATE',\n",
       "       'VIXCLS', 'NFCI', 'BAA10Y', 'BAMLC0A0CM', 'BAMLH0A3HYC', 'DCOILBRENTEU',\n",
       "       'DCOILWTICO', 'DFF', 'DGS1MO', 'DGS30', 'DGS5', 'ICSA', 'M1', 'STLFSI2',\n",
       "       'T10Y2Y', 'T10Y3M', 'TREAST', 'QQQ', 'DIA', 'IYR', 'EWG', 'EWU', 'EWJ',\n",
       "       'EZU', 'EWZ', 'ILF', 'EWW', 'LQD', 'SHY', 'IEF', 'TLT', 'ETH', 'BCH',\n",
       "       'LTC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLK', 'XLU',\n",
       "       'MMM', 'AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'GS',\n",
       "       'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE',\n",
       "       'PG', 'TRV', 'UNH', 'VZ', 'WMT', 'WBA', 'DIS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "id": "3e80173c-962f-4b0e-b170-8186d5f9b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lagged_Set = pd.DataFrame()\n",
    "Lagged_Differenced_Set = pd.DataFrame()\n",
    "\n",
    "#'''\n",
    "#Lagged_Differenced_Set_offset = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),out.result.iloc[:,1:].pct_change()],axis=1)\n",
    "differenced_set = out.result.pct_change()\n",
    "differenced_set = differenced_set.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "ls_stats, Lagged_Differenced_Set= getLagged_Set(differenced_set, out.result)\n",
    "lso_stats, Lagged_Differenced_Set_offset= getLagged_Set(pd.concat([differenced_set.iloc[:,0].shift(-1),differenced_set.iloc[:,1:]],axis=1), out.result)\n",
    "#add in last period of y\n",
    "Lagged_Differenced_Set_offset = pd.concat([Lagged_Differenced_Set_offset.iloc[:,0],differenced_set.iloc[:,0],Lagged_Differenced_Set_offset.iloc[:,1:]],axis=1)\n",
    "#Lagged_Set_offset.index = out.result.index\n",
    "Lagged_Differenced_Set.dropna(inplace= True)\n",
    "#Lagged_Set_offset.columns = out.result.columns\n",
    "\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "\n",
    "#Lagged_Differenced_Set.dropna(inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "57b19b33-dfd6-4233-8e3c-4f266a9ce8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "2003-09-30    0.060820\n",
       "2003-12-31    0.076878\n",
       "2004-03-31   -0.004395\n",
       "2004-06-30   -0.012870\n",
       "2004-09-30    0.057999\n",
       "2004-12-31    0.029813\n",
       "2005-03-31   -0.003927\n",
       "2005-06-30    0.040415\n",
       "2005-09-30    0.009843\n",
       "2005-12-31    0.048335\n",
       "Name: ^SP500TR, dtype: float64"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e943c-2c5b-4cc8-86ca-87a1dab05a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "id": "29c83e18-ed0b-446d-89a3-86ea42e5672c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "^SP500TR       0\n",
       "AXP            0\n",
       "MMM            0\n",
       "XLU            0\n",
       "XLK            0\n",
       "              ..\n",
       "BAMLH0A3HYC    0\n",
       "BAMLC0A0CM     0\n",
       "BAA10Y         0\n",
       "ICSA           0\n",
       "DIS            0\n",
       "Length: 92, dtype: int64"
      ]
     },
     "execution_count": 1695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "temp = pd.DataFrame()\n",
    "temp = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),Lagged_Set_offset.iloc[:,1:].pct_change()],axis=1).copy()\n",
    "Lagged_Differenced_Set_offset = pd.DataFrame()\n",
    "Lagged_Differenced_Set_offset = temp.copy()\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "Lagged_Differenced_Set_offset\n",
    "Lagged_Differenced_Set_offset = Lagged_Differenced_Set_offset.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "#Lagged_Differenced_Set_offset.fillna(0)\n",
    "#preprocessing.StandardScaler().fit(Lagged_Differenced_Set_offset)\n",
    "'''\n",
    "np.sum(Lagged_Differenced_Set_offset.isin([np.inf, -np.inf, np.NaN])).sort_values(kind=\"quicksort\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "id": "8cfbc252-b567-48e9-86f9-9e57df0ac45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0  0         0\n",
      "0          DGS10  0  0.293900\n",
      "1           DTB3  1 -0.003070\n",
      "2         DGS3MO  0  0.112961\n",
      "3   MORTGAGE30US  0  0.080523\n",
      "4         DFII10  0  0.052994\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.544979\n",
      "86            VZ  0  0.511754\n",
      "87           WMT  0  0.407511\n",
      "88           WBA  0  0.457171\n",
      "89           DIS  0  0.730196\n",
      "\n",
      "[90 rows x 3 columns]\n",
      "               0  0         0\n",
      "0          DGS10  3 -0.042244\n",
      "1           DTB3  3 -0.089426\n",
      "2         DGS3MO  3 -0.088654\n",
      "3   MORTGAGE30US  3 -0.145695\n",
      "4         DFII10  2  0.041021\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.273665\n",
      "86            VZ  3  0.080712\n",
      "87           WMT  1 -0.086052\n",
      "88           WBA  3  0.151340\n",
      "89           DIS  1 -0.092398\n",
      "\n",
      "[90 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ls_stats)\n",
    "print(lso_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "id": "53aa28e7-3712-466f-96fd-7bbf115714ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SP500TR</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>DTB3</th>\n",
       "      <th>DGS3MO</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>DFII10</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>BAMLHYH0A0HYM2TRIV</th>\n",
       "      <th>BAMLCC0A1AAATRIV</th>\n",
       "      <th>DGS1</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WBA</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>0.069088</td>\n",
       "      <td>1.541751</td>\n",
       "      <td>0.915645</td>\n",
       "      <td>0.935161</td>\n",
       "      <td>0.794281</td>\n",
       "      <td>1.692419</td>\n",
       "      <td>2.458548</td>\n",
       "      <td>41.996715</td>\n",
       "      <td>352.547879</td>\n",
       "      <td>1.775484</td>\n",
       "      <td>...</td>\n",
       "      <td>24.940498</td>\n",
       "      <td>0.966422</td>\n",
       "      <td>7.378963</td>\n",
       "      <td>1.252715</td>\n",
       "      <td>22.987969</td>\n",
       "      <td>27.550304</td>\n",
       "      <td>12.984091</td>\n",
       "      <td>39.046941</td>\n",
       "      <td>1.623533</td>\n",
       "      <td>2.482302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.032607</td>\n",
       "      <td>1.495879</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.933710</td>\n",
       "      <td>0.788597</td>\n",
       "      <td>2.045645</td>\n",
       "      <td>2.634194</td>\n",
       "      <td>43.029175</td>\n",
       "      <td>362.683636</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.109538</td>\n",
       "      <td>0.965952</td>\n",
       "      <td>7.352318</td>\n",
       "      <td>1.252347</td>\n",
       "      <td>24.251518</td>\n",
       "      <td>33.238478</td>\n",
       "      <td>14.858189</td>\n",
       "      <td>36.890209</td>\n",
       "      <td>1.620360</td>\n",
       "      <td>2.447742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>-0.003881</td>\n",
       "      <td>1.590695</td>\n",
       "      <td>1.078871</td>\n",
       "      <td>1.096129</td>\n",
       "      <td>0.797332</td>\n",
       "      <td>1.893750</td>\n",
       "      <td>2.481250</td>\n",
       "      <td>43.544771</td>\n",
       "      <td>354.851562</td>\n",
       "      <td>2.472742</td>\n",
       "      <td>...</td>\n",
       "      <td>16.016526</td>\n",
       "      <td>0.968542</td>\n",
       "      <td>7.595334</td>\n",
       "      <td>1.252234</td>\n",
       "      <td>27.052105</td>\n",
       "      <td>37.703203</td>\n",
       "      <td>14.630292</td>\n",
       "      <td>37.523092</td>\n",
       "      <td>1.619811</td>\n",
       "      <td>2.533420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>0.045642</td>\n",
       "      <td>1.544377</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>1.513906</td>\n",
       "      <td>0.793859</td>\n",
       "      <td>1.690484</td>\n",
       "      <td>2.410484</td>\n",
       "      <td>43.206397</td>\n",
       "      <td>363.761045</td>\n",
       "      <td>3.072459</td>\n",
       "      <td>...</td>\n",
       "      <td>16.911974</td>\n",
       "      <td>0.971730</td>\n",
       "      <td>8.632519</td>\n",
       "      <td>1.253729</td>\n",
       "      <td>27.104700</td>\n",
       "      <td>41.275508</td>\n",
       "      <td>15.591040</td>\n",
       "      <td>36.719812</td>\n",
       "      <td>1.632797</td>\n",
       "      <td>2.586150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.010137</td>\n",
       "      <td>1.523840</td>\n",
       "      <td>2.011613</td>\n",
       "      <td>2.047419</td>\n",
       "      <td>0.791116</td>\n",
       "      <td>1.717705</td>\n",
       "      <td>2.453279</td>\n",
       "      <td>44.018290</td>\n",
       "      <td>370.418636</td>\n",
       "      <td>3.337344</td>\n",
       "      <td>...</td>\n",
       "      <td>18.243953</td>\n",
       "      <td>0.970402</td>\n",
       "      <td>8.825318</td>\n",
       "      <td>1.254591</td>\n",
       "      <td>23.588805</td>\n",
       "      <td>44.026221</td>\n",
       "      <td>16.741129</td>\n",
       "      <td>33.769871</td>\n",
       "      <td>1.638542</td>\n",
       "      <td>2.558298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.003958</td>\n",
       "      <td>1.220122</td>\n",
       "      <td>2.388361</td>\n",
       "      <td>2.438525</td>\n",
       "      <td>0.760357</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>1.944921</td>\n",
       "      <td>73.572146</td>\n",
       "      <td>637.862812</td>\n",
       "      <td>1.845000</td>\n",
       "      <td>...</td>\n",
       "      <td>79.716758</td>\n",
       "      <td>1.018707</td>\n",
       "      <td>82.613387</td>\n",
       "      <td>1.310248</td>\n",
       "      <td>117.868538</td>\n",
       "      <td>255.783684</td>\n",
       "      <td>51.443717</td>\n",
       "      <td>109.754493</td>\n",
       "      <td>1.769093</td>\n",
       "      <td>3.600235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-0.032009</td>\n",
       "      <td>1.140147</td>\n",
       "      <td>2.304921</td>\n",
       "      <td>2.354762</td>\n",
       "      <td>0.749156</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>1.834531</td>\n",
       "      <td>73.014092</td>\n",
       "      <td>662.025846</td>\n",
       "      <td>1.575806</td>\n",
       "      <td>...</td>\n",
       "      <td>82.250245</td>\n",
       "      <td>1.019433</td>\n",
       "      <td>84.411047</td>\n",
       "      <td>1.309857</td>\n",
       "      <td>121.248230</td>\n",
       "      <td>269.978145</td>\n",
       "      <td>52.873113</td>\n",
       "      <td>115.861732</td>\n",
       "      <td>1.736154</td>\n",
       "      <td>3.605762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0.208827</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>1.983594</td>\n",
       "      <td>2.026094</td>\n",
       "      <td>0.736517</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>1.755806</td>\n",
       "      <td>71.316802</td>\n",
       "      <td>704.624478</td>\n",
       "      <td>1.067742</td>\n",
       "      <td>...</td>\n",
       "      <td>79.254899</td>\n",
       "      <td>1.019993</td>\n",
       "      <td>93.038666</td>\n",
       "      <td>1.309202</td>\n",
       "      <td>137.445766</td>\n",
       "      <td>282.275764</td>\n",
       "      <td>53.411418</td>\n",
       "      <td>112.660589</td>\n",
       "      <td>1.738538</td>\n",
       "      <td>3.557512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.978977</td>\n",
       "      <td>1.576935</td>\n",
       "      <td>1.607581</td>\n",
       "      <td>0.738111</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>1.572903</td>\n",
       "      <td>74.017057</td>\n",
       "      <td>714.379538</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>...</td>\n",
       "      <td>76.548235</td>\n",
       "      <td>1.020851</td>\n",
       "      <td>92.050876</td>\n",
       "      <td>1.313030</td>\n",
       "      <td>142.459886</td>\n",
       "      <td>304.001915</td>\n",
       "      <td>56.515780</td>\n",
       "      <td>121.245848</td>\n",
       "      <td>1.749870</td>\n",
       "      <td>3.486990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.121361</td>\n",
       "      <td>0.827040</td>\n",
       "      <td>1.081613</td>\n",
       "      <td>1.104032</td>\n",
       "      <td>0.731042</td>\n",
       "      <td>-0.478889</td>\n",
       "      <td>1.483175</td>\n",
       "      <td>75.440865</td>\n",
       "      <td>733.438923</td>\n",
       "      <td>0.134687</td>\n",
       "      <td>...</td>\n",
       "      <td>80.272736</td>\n",
       "      <td>1.021529</td>\n",
       "      <td>91.585849</td>\n",
       "      <td>1.314522</td>\n",
       "      <td>131.167868</td>\n",
       "      <td>333.177687</td>\n",
       "      <td>54.170968</td>\n",
       "      <td>131.581336</td>\n",
       "      <td>1.733090</td>\n",
       "      <td>3.551627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^SP500TR     DGS10      DTB3    DGS3MO  MORTGAGE30US    DFII10  \\\n",
       "Unnamed: 0                                                                   \n",
       "2004-09-30  0.069088  1.541751  0.915645  0.935161      0.794281  1.692419   \n",
       "2004-12-31  0.032607  1.495879  0.916129  0.933710      0.788597  2.045645   \n",
       "2005-03-31 -0.003881  1.590695  1.078871  1.096129      0.797332  1.893750   \n",
       "2005-06-30  0.045642  1.544377  1.488281  1.513906      0.793859  1.690484   \n",
       "2005-09-30  0.010137  1.523840  2.011613  2.047419      0.791116  1.717705   \n",
       "...              ...       ...       ...       ...           ...       ...   \n",
       "2019-12-31 -0.003958  1.220122  2.388361  2.438525      0.760357  0.515873   \n",
       "2020-03-31 -0.032009  1.140147  2.304921  2.354762      0.749156  0.154219   \n",
       "2020-06-30  0.208827  0.980938  1.983594  2.026094      0.736517  0.153387   \n",
       "2020-09-30  0.094300  0.978977  1.576935  1.607581      0.738111 -0.063226   \n",
       "2020-12-31  0.121361  0.827040  1.081613  1.104032      0.731042 -0.478889   \n",
       "\n",
       "              T5YIFR  BAMLHYH0A0HYM2TRIV  BAMLCC0A1AAATRIV      DGS1  ...  \\\n",
       "Unnamed: 0                                                            ...   \n",
       "2004-09-30  2.458548           41.996715        352.547879  1.775484  ...   \n",
       "2004-12-31  2.634194           43.029175        362.683636  2.075000  ...   \n",
       "2005-03-31  2.481250           43.544771        354.851562  2.472742  ...   \n",
       "2005-06-30  2.410484           43.206397        363.761045  3.072459  ...   \n",
       "2005-09-30  2.453279           44.018290        370.418636  3.337344  ...   \n",
       "...              ...                 ...               ...       ...  ...   \n",
       "2019-12-31  1.944921           73.572146        637.862812  1.845000  ...   \n",
       "2020-03-31  1.834531           73.014092        662.025846  1.575806  ...   \n",
       "2020-06-30  1.755806           71.316802        704.624478  1.067742  ...   \n",
       "2020-09-30  1.572903           74.017057        714.379538  0.174286  ...   \n",
       "2020-12-31  1.483175           75.440865        733.438923  0.134687  ...   \n",
       "\n",
       "                  MRK      MSFT        NKE        PG         TRV         UNH  \\\n",
       "Unnamed: 0                                                                     \n",
       "2004-09-30  24.940498  0.966422   7.378963  1.252715   22.987969   27.550304   \n",
       "2004-12-31  24.109538  0.965952   7.352318  1.252347   24.251518   33.238478   \n",
       "2005-03-31  16.016526  0.968542   7.595334  1.252234   27.052105   37.703203   \n",
       "2005-06-30  16.911974  0.971730   8.632519  1.253729   27.104700   41.275508   \n",
       "2005-09-30  18.243953  0.970402   8.825318  1.254591   23.588805   44.026221   \n",
       "...               ...       ...        ...       ...         ...         ...   \n",
       "2019-12-31  79.716758  1.018707  82.613387  1.310248  117.868538  255.783684   \n",
       "2020-03-31  82.250245  1.019433  84.411047  1.309857  121.248230  269.978145   \n",
       "2020-06-30  79.254899  1.019993  93.038666  1.309202  137.445766  282.275764   \n",
       "2020-09-30  76.548235  1.020851  92.050876  1.313030  142.459886  304.001915   \n",
       "2020-12-31  80.272736  1.021529  91.585849  1.314522  131.167868  333.177687   \n",
       "\n",
       "                   VZ         WMT       WBA       DIS  \n",
       "Unnamed: 0                                             \n",
       "2004-09-30  12.984091   39.046941  1.623533  2.482302  \n",
       "2004-12-31  14.858189   36.890209  1.620360  2.447742  \n",
       "2005-03-31  14.630292   37.523092  1.619811  2.533420  \n",
       "2005-06-30  15.591040   36.719812  1.632797  2.586150  \n",
       "2005-09-30  16.741129   33.769871  1.638542  2.558298  \n",
       "...               ...         ...       ...       ...  \n",
       "2019-12-31  51.443717  109.754493  1.769093  3.600235  \n",
       "2020-03-31  52.873113  115.861732  1.736154  3.605762  \n",
       "2020-06-30  53.411418  112.660589  1.738538  3.557512  \n",
       "2020-09-30  56.515780  121.245848  1.749870  3.486990  \n",
       "2020-12-31  54.170968  131.581336  1.733090  3.551627  \n",
       "\n",
       "[66 rows x 91 columns]"
      ]
     },
     "execution_count": 1654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fb84f-111c-44f6-8fcc-7519b387e5c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb40926-6979-4f9f-ad09-ed1f93c25a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "id": "d1422b2e-d8e4-43aa-a691-8c54392a6291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null hypothesis can be rejected\n",
      "6.865763215609389\n",
      "The null hypothesis can be rejected\n",
      "6.896546949666965\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.2560705858400435\n",
      "The null hypothesis can be rejected\n",
      "-0.25410510887178017\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.8168452771342554\n",
      "The null hypothesis can be rejected\n",
      "-1.2203262001462745\n",
      "The null hypothesis can be rejected\n",
      "3.980324132809734\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.0330533902639862\n",
      "The null hypothesis can be rejected\n",
      "-1.1348510594870023\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "8.441819888635504\n",
      "The null hypothesis can be rejected\n",
      "1.0871887239135765\n",
      "The null hypothesis can be rejected\n",
      "-0.225351519493807\n",
      "The null hypothesis can be rejected\n",
      "-0.22331262559486822\n",
      "The null hypothesis can be rejected\n",
      "-11.643674081625615\n",
      "The null hypothesis can be rejected\n",
      "-7.872592517879663\n",
      "The null hypothesis can be rejected\n",
      "6.810550509799163\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.8610001927627393\n",
      "The null hypothesis can be rejected\n",
      "0.47387019426883464\n",
      "The null hypothesis can be rejected\n",
      "-1.350128792241651\n",
      "The null hypothesis can be rejected\n",
      "-1.068536116050812\n",
      "The null hypothesis can be rejected\n",
      "-1.5907297978977153\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.1763642319332284\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.1608393629115443\n",
      "The null hypothesis can be rejected\n",
      "-17.292496103544497\n",
      "The null hypothesis can be rejected\n",
      "0.8424543841737614\n",
      "The null hypothesis can be rejected\n",
      "0.6627659332477958\n",
      "The null hypothesis can be rejected\n",
      "0.9814454834302564\n",
      "The null hypothesis can be rejected\n",
      "-1.8518943770701226\n",
      "The null hypothesis can be rejected\n",
      "4.430956496153695\n",
      "The null hypothesis can be rejected\n",
      "7.347405992272229\n",
      "The null hypothesis can be rejected\n",
      "5.375556488149038\n",
      "The null hypothesis can be rejected\n",
      "3.7236366650415897\n",
      "The null hypothesis can be rejected\n",
      "4.622498957737785\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.295897679021274\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "2.994049643817101\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-71.80123292863226\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.2630315430220875\n",
      "The null hypothesis can be rejected\n",
      "8.62589778332678\n",
      "The null hypothesis can be rejected\n",
      "3.6941919528144713\n",
      "The null hypothesis can be rejected\n",
      "3.2126497040172124\n",
      "The null hypothesis can be rejected\n",
      "7.184903442065814\n",
      "The null hypothesis can be rejected\n",
      "6.193200910291322\n",
      "The null hypothesis can be rejected\n",
      "3.980512866916982\n",
      "The null hypothesis can be rejected\n",
      "4.479987948401211\n",
      "The null hypothesis can be rejected\n",
      "10.03254035404625\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.8597491249632236\n",
      "The null hypothesis can be rejected\n",
      "-2.5531656292171774\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.6337017753465424\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.267169095042328\n",
      "The null hypothesis can be rejected\n",
      "4.057632902860579\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "5.168826328875348\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n"
     ]
    }
   ],
   "source": [
    "#skip correlation\n",
    "#Lagged_Differenced_Set_offset = pd.concat([our.result.iloc[:,0].pct_change().shift(-1),differenced_set.iloc[:,0],Lagged_Differenced_Set_offset.iloc[:,1:]],axis=1)\n",
    "#Lagged_Set_offset.index = out.result.index\n",
    "#Lagged_Differenced_Set.dropna(inplace= True)\n",
    "\n",
    "set_ = Lagged_Differenced_Set\n",
    "set_ = pd.concat([differenced_set.iloc[:,0].shift(-1),differenced_set.iloc[:,0],differenced_set.iloc[:,1:]],axis=1)\n",
    "set_.dropna(inplace=True)\n",
    "set_ = set_.tail(-1)\n",
    "transformed, lambdas = transform_boxcox(set_.dropna())\n",
    "\n",
    "#revert_yeo(Lagged_Differenced_Set_offset, transformed, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72722f-fbff-4bff-92b8-26b19888e415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "8cc90237-f851-4afb-86f8-2dca0b41123d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbd = True\n",
    "ic = True\n",
    "\n",
    "# evaluate an elastic net model on the dataset\n",
    "#tsize = .20\n",
    "#train, test = train_test_split(Lagged_Differenced_Set_offset.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "train, test = train_test_split(transformed.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=ic)\n",
    "\n",
    "#train_t, lambdas_t = transform_boxcox(train)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    train_t = train\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_t)\n",
    "\n",
    "#\n",
    "train_s = pd.DataFrame(scaler.transform(train_t))\n",
    "train_s.columns = train.columns\n",
    "train_s.index = train.index  \n",
    "\n",
    "train_t = train_s\n",
    "\n",
    "#test_t = transform_boxcox_l(test, lambdas_t)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    test_t = test\n",
    "\n",
    "test_s = pd.DataFrame(scaler.transform(test_t))\n",
    "test_s.columns = test.columns\n",
    "test_s.index = test.index\n",
    "\n",
    "test_t = test_s\n",
    "\n",
    "y_train = pd.DataFrame(train_t.iloc[:,0])\n",
    "\n",
    "#exclude y\n",
    "\n",
    "X_inter_train = pd.DataFrame(interaction.fit_transform(train_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_t.iloc[:,1:]).columns))\n",
    "\n",
    "    #apply ZCA each time a set of factors are removed (i.e. iteratively)\n",
    " #trf = zca.ZCA().fit(X_inter_train)\n",
    "  #trf = zca.ZCA().fit(X_train)\n",
    "\n",
    " #X_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "  #X_train = pd.DataFrame(trf.transform(X_train))\n",
    " #X_train.columns=X_inter_train.columns\n",
    "  #X_train.columns=X_train.columns\n",
    "  #X_train.index = train.index\n",
    "\n",
    "#X_inter_alt = X_train.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#print(X_inter_alt.head(3))\n",
    "\n",
    "y_test = pd.DataFrame(test_t.iloc[:,0])\n",
    "\n",
    "X_inter_test = pd.DataFrame(interaction.fit_transform(test_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(test_t.iloc[:,1:]).columns))\n",
    "\n",
    " #X_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "  #X_test = pd.DataFrame(trf.transform(X_test))\n",
    "\n",
    " #X_test.columns=X_inter_test.columns\n",
    "  #X_test.columns=X_test.columns\n",
    "  #X_test.index = test.index\n",
    "\n",
    "#X_inter_t_alt = X_test.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#X_inter_t_alt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf46d0-1162-46d6-a166-0461b321e0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "\n",
    " #model = ElasticNetCV(l1_ratio=ratios, alphas=alphas, cv=cv, n_jobs=4, verbose=0, precompute='auto')\n",
    "\n",
    "model = ElasticNet()\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "#search = HalvingRandomSearchCV(model, grid,resource='n_samples',max_resources=10,random_state=0)\n",
    "\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    " #results = search.fit(X_inter_train, y_train)\n",
    "#results = search.fit(X_train, y_train)\n",
    "\n",
    "results = search.fit(X_inter_train, y_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "print(results.best_estimator_)\n",
    "best_model = ElasticNet(alpha=results.best_estimator_.alpha, l1_ratio = results.best_estimator_.l1_ratio)\n",
    "\n",
    "#pd.concat([all_data[Y],all_data_int],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb7965-c50b-4f1e-bd5e-05504a69192f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_inter_train,train_t.iloc[:,0])\n",
    "\n",
    "trainScore = best_model.score(X_inter_train, y_train, sample_weight=None)\n",
    "testScore = best_model.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore)\n",
    "print(testScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb694fa2-0e07-4a01-8648-2d6615a70b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "093a64f9-522d-4761-adf1-f55d566a1b70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b12fd-2b69-4243-909a-6f828aa43b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "0e86999a-16ba-4505-b5ec-843d219ac62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.538462\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367906e7-5aec-4529-8f29-42040e9ac43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "id": "14400790-a56a-4084-8c56-cf73697546e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03847608420351106\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.8648952817620676, pvalue=0.39785994499471344)\n",
      "0.026106343953183363\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.9892221018930833, pvalue=0.3323169495195316)\n"
     ]
    }
   ],
   "source": [
    "#classification transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE \n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#set_ = Lagged_Differenced_Set_offset.copy()\n",
    "#set_ = transformed.copy()\n",
    "#DF_list = list()\n",
    "\n",
    "sets = list()\n",
    "sets.append(transformed.copy())\n",
    "#sets.append(Lagged_Differenced_Set_offset.copy())\n",
    "sets.append(set_.copy())\n",
    "\n",
    "def return_sets(sets):    \n",
    "    \n",
    "    sets_outer = list()\n",
    "    \n",
    "    for i in sets:\n",
    "        \n",
    "        sets_multiple = list()\n",
    "        \n",
    "        set_ = pd.DataFrame()\n",
    "        set_ = i\n",
    "\n",
    "        X, y = set_.iloc[:,1:],  set_.iloc[:,0]\n",
    "        \n",
    "        print(mean(y))\n",
    "\n",
    "        y = pd.DataFrame(np.where(y > mean(y), 1, 0))\n",
    "        y.index = set_.index\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize, shuffle=False)\n",
    "\n",
    "        a = set_.iloc[:,0].loc[X_train.index]\n",
    "        b = set_.iloc[:,0].loc[X_test.index]\n",
    "        plt.hist(a)\n",
    "        plt.show()\n",
    "        plt.hist(b)\n",
    "        plt.show()\n",
    "        print(stats.ttest_ind(a,b, equal_var = False))\n",
    "\n",
    "        one = y_train[y_train==0].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "        two = y_train[y_train==1].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "\n",
    "        train_index = np.append(one.index,two.index)\n",
    "\n",
    "        #destroyed my data\n",
    "        #smote = SVMSMOTE(random_state=42)\n",
    "            #smote = SMOTE()\n",
    "        #Xsm_train, ysm_train = smote.fit_sample(np.array(X_train),np.array(y_train))\n",
    "\n",
    "        Xsm_train = X_train.copy()\n",
    "        ysm_train = y_train.copy()\n",
    "        \n",
    "        #use with optimal lags\n",
    "        #y_test = y_test.loc[y_test.index>y_test.index[maxl]]\n",
    "        #X_test = X_test.loc[X_test.index>X_test.index[maxl]]\n",
    "\n",
    "        scaler = preprocessing.StandardScaler().fit(Xsm_train)\n",
    "\n",
    "        X_train_transformed = pd.DataFrame(scaler.transform(Xsm_train))\n",
    "        X_train_transformed.columns = X_train.columns\n",
    "\n",
    "        X_inter_train = X_train_transformed.copy()\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(interaction.fit_transform(X_train_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_train_transformed).columns))\n",
    "\n",
    "        trf = zca.ZCA().fit(X_inter_train)\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "        X_inter_train.columns=pd.DataFrame(X_inter_train).columns\n",
    "        #X_inter_train.index = X_train.loc[train_index].index\n",
    "\n",
    "        X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "        X_test_transformed.columns = X_test.columns\n",
    "        X_test_transformed.index = X_test.index\n",
    "\n",
    "        X_inter_test = X_test_transformed\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(interaction.fit_transform(X_test_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_test_transformed).columns))\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "\n",
    "        sets_multiple.append(X_inter_train)\n",
    "        sets_multiple.append(y_train)\n",
    "        sets_multiple.append(X_inter_test)\n",
    "        sets_multiple.append(y_test)        \n",
    "    \n",
    "        sets_outer.append(sets_multiple)\n",
    "        \n",
    "    return(sets_outer)\n",
    "\n",
    "values = return_sets(sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568baa66-4a53-4f23-ba8a-c5f9408f1591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "id": "73ec310d-7f86-4154-be9b-11c927a6a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "id": "e560215f-9b7d-4d76-ac61-dbf96d2cfd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49 accuracy with a standard deviation of 0.10\n",
      "0.9090909090909091\n",
      "0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        30\n",
      "           1       1.00      0.80      0.89        25\n",
      "\n",
      "    accuracy                           0.91        55\n",
      "   macro avg       0.93      0.90      0.91        55\n",
      "weighted avg       0.92      0.91      0.91        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[30  0]\n",
      " [ 5 20]]\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "0.47 accuracy with a standard deviation of 0.12\n",
      "0.8545454545454545\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.82        26\n",
      "           1       0.78      1.00      0.88        29\n",
      "\n",
      "    accuracy                           0.85        55\n",
      "   macro avg       0.89      0.85      0.85        55\n",
      "weighted avg       0.89      0.85      0.85        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[18  8]\n",
      " [ 0 29]]\n",
      "[[2 3]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.62      0.56      0.59         9\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.34      0.32      0.33        14\n",
      "weighted avg       0.54      0.50      0.52        14\n",
      "\n",
      "[[2 3 0]\n",
      " [3 5 1]\n",
      " [0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "#works best\n",
    "#class balanced, no zca\n",
    "from sklearn import svm\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    clf = svm.SVC(kernel='rbf', C=1, random_state=42)\n",
    "\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "    clf = svm.SVC(C=1).fit(X_train, y_train)\n",
    "\n",
    "    train_predict = clf.predict(X_train)\n",
    "    predicteds = clf.predict(X_test)\n",
    "    #predicted.index = y_test.index\n",
    "\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(clf.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predicteds))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predicteds))\n",
    "\n",
    "    predictions_s = arima_adjust(y_train, y_test, train_predict, predicteds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "id": "ec38a51f-ede1-47bb-9af7-ee25b6106160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25944973-ee0b-4b74-be6c-f59463229bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39fe4e-d604-4fa9-ad81-ee7a53a06784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "3909eb8a-645f-47c5-933a-98d61f3d6ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('svc', svm.SVC(kernel='sigmoid', C=1, random_state=42))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)\n",
    "'''\n",
    "#search = cross_val_score(pipe, X_inter_train, y_train.loc[train_index], cv=10)\n",
    "#GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#search.fit(X_digits, y_digits)\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "#print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "d83b6ec4-6148-41ba-9d1b-3765f913ee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "id": "b49b4466-cd31-4f19-85e0-c32db62dbe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "0.9818181818181818\n",
      "0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        30\n",
      "           1       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.98        55\n",
      "   macro avg       0.98      0.98      0.98        55\n",
      "weighted avg       0.98      0.98      0.98        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.56      0.62      0.59         8\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.48      0.48      0.48        14\n",
      "weighted avg       0.49      0.50      0.49        14\n",
      "\n",
      "[[30  0]\n",
      " [ 1 24]]\n",
      "[[2 4]\n",
      " [3 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.56      0.62      0.59         8\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.48      0.48      0.48        14\n",
      "weighted avg       0.49      0.50      0.49        14\n",
      "\n",
      "[[2 4]\n",
      " [3 5]]\n",
      "LogisticRegression()\n",
      "1.0\n",
      "0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29         5\n",
      "           1       0.67      0.89      0.76         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.58      0.54      0.52        14\n",
      "weighted avg       0.61      0.64      0.59        14\n",
      "\n",
      "[[26  0]\n",
      " [ 0 29]]\n",
      "[[1 4]\n",
      " [1 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.20      0.29         5\n",
      "           1       0.67      0.89      0.76         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.58      0.54      0.52        14\n",
      "weighted avg       0.61      0.64      0.59        14\n",
      "\n",
      "[[1 4]\n",
      " [1 8]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modell = LogisticRegression()\n",
    "    modell.fit(X_train, y_train)\n",
    "    print(modell)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modell.predict(X_train)\n",
    "    predictedl = modell.predict(X_test)\n",
    "\n",
    "    print(modell.score(X_train, y_train))\n",
    "    print(modell.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedl))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedl))\n",
    "    \n",
    "    predictions_l = arima_adjust(y_train, y_test, train_predict, predictedl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "id": "7672895b-f442-45b4-8cb1-3257e8c830a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "0.7272727272727273\n",
      "0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.70      0.74        30\n",
      "           1       0.68      0.76      0.72        25\n",
      "\n",
      "    accuracy                           0.73        55\n",
      "   macro avg       0.73      0.73      0.73        55\n",
      "weighted avg       0.73      0.73      0.73        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.50      0.43         6\n",
      "           1       0.50      0.38      0.43         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.44      0.44      0.43        14\n",
      "weighted avg       0.45      0.43      0.43        14\n",
      "\n",
      "[[21  9]\n",
      " [ 6 19]]\n",
      "[[3 3]\n",
      " [5 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           0       0.40      0.33      0.36         6\n",
      "           1       0.57      0.50      0.53         8\n",
      "           2       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.24      0.21      0.22        14\n",
      "weighted avg       0.50      0.43      0.46        14\n",
      "\n",
      "[[0 0 0 0]\n",
      " [0 2 3 1]\n",
      " [1 3 4 0]\n",
      " [0 0 0 0]]\n",
      "GaussianNB()\n",
      "0.6909090909090909\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.46      0.59        26\n",
      "           1       0.65      0.90      0.75        29\n",
      "\n",
      "    accuracy                           0.69        55\n",
      "   macro avg       0.73      0.68      0.67        55\n",
      "weighted avg       0.72      0.69      0.67        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[12 14]\n",
      " [ 3 26]]\n",
      "[[2 3]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.40      0.40         5\n",
      "           1       0.67      0.67      0.67         9\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.53      0.53      0.53        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[2 3]\n",
      " [3 6]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeln = GaussianNB()\n",
    "    modeln.fit(X_train, y_train)\n",
    "    print(modeln)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeln.predict(X_train)\n",
    "    predictedn = modeln.predict(X_test)\n",
    "\n",
    "    print(modeln.score(X_train, y_train))\n",
    "    print(modeln.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedn))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedn))\n",
    "    \n",
    "    predictions_n = arima_adjust(y_train, y_test, train_predict, predictedn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "id": "644b63d8-9f6e-453e-b896-0ee262d1242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "1.0\n",
      "0.21428571428571427\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.38      0.33      0.35         9\n",
      "\n",
      "    accuracy                           0.21        14\n",
      "   macro avg       0.19      0.17      0.18        14\n",
      "weighted avg       0.24      0.21      0.23        14\n",
      "\n",
      "[[26  0]\n",
      " [ 0 29]]\n",
      "[[0 5]\n",
      " [6 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.38      0.33      0.35         9\n",
      "\n",
      "    accuracy                           0.21        14\n",
      "   macro avg       0.19      0.17      0.18        14\n",
      "weighted avg       0.24      0.21      0.23        14\n",
      "\n",
      "[[0 5]\n",
      " [6 3]]\n",
      "DecisionTreeClassifier()\n",
      "1.0\n",
      "0.35714285714285715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         6\n",
      "           1       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.37      0.38      0.35        14\n",
      "weighted avg       0.37      0.36      0.35        14\n",
      "\n",
      "[[30  0]\n",
      " [ 0 25]]\n",
      "[[3 3]\n",
      " [6 2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.50      0.40         6\n",
      "           1       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.37      0.38      0.35        14\n",
      "weighted avg       0.37      0.36      0.35        14\n",
      "\n",
      "[[3 3]\n",
      " [6 2]]\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "#works best with transformed\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in reversed(range(0,len(sets))):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeld = DecisionTreeClassifier()\n",
    "    modeld.fit(X_train, y_train)\n",
    "    print(modeld)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeld.predict(X_train)\n",
    "    predictedd = modeld.predict(X_test)\n",
    "\n",
    "    print(modeld.score(X_train, y_train))\n",
    "    print(modeld.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedd))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedd))\n",
    "        \n",
    "    predictions_d = arima_adjust(y_train, y_test, train_predict, predictedd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "id": "6ce0671f-8931-4f7e-936b-51adcb52dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 8}\n",
      "0.5272727272727272\n",
      "1.0\n",
      "0.5714285714285714\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         6\n",
      "           1       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.56      0.56      0.56        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[30  0]\n",
      " [ 0 25]]\n",
      "[[3 3]\n",
      " [3 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         6\n",
      "           1       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.56      0.56      0.56        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n",
      "[[3 3]\n",
      " [3 5]]\n",
      "{'n_neighbors': 22}\n",
      "0.5818181818181818\n",
      "1.0\n",
      "0.7142857142857143\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        26\n",
      "           1       1.00      1.00      1.00        29\n",
      "\n",
      "    accuracy                           1.00        55\n",
      "   macro avg       1.00      1.00      1.00        55\n",
      "weighted avg       1.00      1.00      1.00        55\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.69      1.00      0.82         9\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.85      0.60      0.58        14\n",
      "weighted avg       0.80      0.71      0.65        14\n",
      "\n",
      "[[26  0]\n",
      " [ 0 29]]\n",
      "[[1 4]\n",
      " [0 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.20      0.33         5\n",
      "           1       0.69      1.00      0.82         9\n",
      "\n",
      "    accuracy                           0.71        14\n",
      "   macro avg       0.85      0.60      0.58        14\n",
      "weighted avg       0.80      0.71      0.65        14\n",
      "\n",
      "[[1 4]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "#works best with transformed\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV#create new a knn model\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "    \n",
    "    knn2 = KNeighborsClassifier(metric='euclidean',weights='distance')#create a dictionary of all values we want to test for n_neighbors\n",
    "    param_grid = {'n_neighbors': np.arange(1, 25)}#use gridsearch to test all values for n_neighbors\n",
    "    knn_gscv = GridSearchCV(knn2, param_grid, cv=5)#fit model to data\n",
    "    knn_gscv.fit(X_train, y_train)\n",
    "    #check top performing n_neighbors value\n",
    "    print(knn_gscv.best_params_)\n",
    "    #check mean score for the top performing value of n_neighbors\n",
    "    print(knn_gscv.best_score_)\n",
    "\n",
    "    modelk = KNeighborsClassifier(n_neighbors = knn_gscv.best_params_['n_neighbors'],metric='euclidean',weights='distance')\n",
    "    modelk.fit(X_train,y_train)\n",
    "    train_predict = modelk.predict(X_train)\n",
    "    predictedk = modelk.predict(X_test)\n",
    "    #modelk.score(X_test, y_test)\n",
    "\n",
    "    print(modelk.score(X_train, y_train))\n",
    "    print(modelk.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_train,train_predict))\n",
    "    print(metrics.classification_report(y_test,predictedk))\n",
    "    print(metrics.confusion_matrix(y_train,train_predict))\n",
    "    print(metrics.confusion_matrix(y_test,predictedk))\n",
    "    \n",
    "    predictions_k = arima_adjust(y_train, y_test, train_predict, predictedk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43107e46-54bb-4837-a798-af32efaccadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "e55c7caf-0c3b-4911-ba58-8313a7ba85ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-771-d7e137a3e15d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msearch_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresults_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_inter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mysm_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m  \u001b[0;31m#model.fit(X_inter_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Elastic logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = (10 ** np.linspace(-1, 1, 10))/10\n",
    "alphas = np.append(alphas,[10.0, 100.0])\n",
    "\n",
    "model = SGDClassifier(loss=\"log\", penalty=\"elasticnet\")\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "search_l = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "results_l = search_l.fit(X_inter_train, ysm_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results_l.best_score_)\n",
    "print('Config: %s' % results_l.best_params_)\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "print(results_l.best_estimator_)\n",
    "best_model_l = SGDClassifier(alpha=results_l.best_estimator_.alpha, l1_ratio = results_l.best_estimator_.l1_ratio)\n",
    "\n",
    "#calibrator = CalibratedClassifierCV(best_model_l, cv='prefit')\n",
    "#model=calibrator.fit(X_inter_train, y_train)\n",
    "\n",
    "best_model_l.fit(X_inter_train,ysm_train)\n",
    "\n",
    "#sgd = SGDClassifier()\n",
    "\n",
    "#sgd.partial_fit(X_inter_train,y_train, classes=[0,1])\n",
    "\n",
    "print(pd.DataFrame(np.transpose(best_model_l.coef_)).set_index(X_inter_train.columns))\n",
    "\n",
    "trainScore_l = best_model_l.score(X_inter_train, ysm_train, sample_weight=None)\n",
    "testScore_l = best_model_l.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore_l)\n",
    "print(testScore_l)\n",
    "\n",
    "#print(help(KNeighborsClassifier))\n",
    "predictedl = best_model_l.predict(X_inter_test)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b9087-fe22-4d54-b152-a40e48784774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "id": "7015d3fd-f35c-4f6c-b8e9-f66c92514715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.642857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "id": "a6dd1212-7817-4f74-95d6-0493d68c9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            s  k  d  l  n\n",
      "Unnamed: 0               \n",
      "2017-09-30  1  1  0  1  1\n",
      "2017-12-31  1  1  0  1  1\n",
      "2018-03-31  0  1  1  1  1\n",
      "2018-06-30  0  1  0  0  1\n",
      "2018-09-30  1  1  0  1  1\n",
      "2018-12-31  1  1  1  1  0\n",
      "2019-03-31  1  1  0  1  1\n",
      "2019-06-30  1  1  0  1  1\n",
      "2019-09-30  2  1  0  1  0\n",
      "2019-12-31  1  1  1  1  1\n",
      "2020-03-31  0  0  0  0  0\n",
      "2020-06-30  0  1  0  1  0\n",
      "2020-09-30  0  1  1  1  0\n",
      "2020-12-31  1  1  1  1  1\n",
      "[[1 4]\n",
      " [3 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.20      0.22         5\n",
      "           1       0.60      0.67      0.63         9\n",
      "\n",
      "    accuracy                           0.50        14\n",
      "   macro avg       0.42      0.43      0.43        14\n",
      "weighted avg       0.47      0.50      0.49        14\n",
      "\n",
      "0    0.642857\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#predictedf = pd.concat([pd.DataFrame(predicteds),pd.DataFrame(predictedk),pd.DataFrame(predictedl)],axis=1)\n",
    "predictedf = pd.concat([pd.DataFrame(predictions_s),pd.DataFrame(predictions_k),pd.DataFrame(predictions_d),pd.DataFrame(predictions_l),pd.DataFrame(predictions_n)],axis=1)\n",
    "predictedf.columns = [\"s\",\"k\",\"d\",\"l\",\"n\"]\n",
    "predictedf.index = y_test.index\n",
    "print(predictedf)\n",
    "print(confusion_matrix(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(confusion_matrix(y_test, predictedf.median(axis=1)))\n",
    "print(classification_report(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(classification_report(y_test, predictedf.median(axis=1)))\n",
    "\n",
    "print(mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438843e-110f-404f-b1b1-47bfa41b560b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "id": "0e4dfc37-ab80-427f-bc37-edb9a212c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "7.646373750137569\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.40514623443399356\n",
      "The null hypothesis can be rejected\n",
      "-0.40483634918469846\n",
      "The null hypothesis can be rejected\n",
      "-3.6470536818264154\n",
      "The null hypothesis can be rejected\n",
      "1.259503803215001\n",
      "The null hypothesis can be rejected\n",
      "-1.136520328738504\n",
      "The null hypothesis can be rejected\n",
      "4.136040961331319\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "3.195112413151037\n",
      "The null hypothesis can be rejected\n",
      "-5.428905651858575\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "8.40983838078041\n",
      "The null hypothesis can be rejected\n",
      "1.105154218129704\n",
      "The null hypothesis can be rejected\n",
      "-0.3866451441114222\n",
      "The null hypothesis can be rejected\n",
      "-0.385879251752391\n",
      "The null hypothesis can be rejected\n",
      "-13.236135358775554\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "6.8612669842356695\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.6069916960392927\n",
      "The null hypothesis can be rejected\n",
      "0.4753535130059253\n",
      "The null hypothesis can be rejected\n",
      "-1.3322502715493079\n",
      "The null hypothesis can be rejected\n",
      "-1.2688183891496545\n",
      "The null hypothesis can be rejected\n",
      "-1.7501678387215072\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.5319681441702234\n",
      "The null hypothesis can be rejected\n",
      "-0.2802518523984959\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.34345571037416905\n",
      "The null hypothesis can be rejected\n",
      "-6.743570324962083\n",
      "The null hypothesis can be rejected\n",
      "-22.179017205125312\n",
      "The null hypothesis can be rejected\n",
      "0.8440491226492548\n",
      "The null hypothesis can be rejected\n",
      "0.6573188363341986\n",
      "The null hypothesis can be rejected\n",
      "1.6960498518713947\n",
      "The null hypothesis can be rejected\n",
      "-0.41573858764941946\n",
      "The null hypothesis can be rejected\n",
      "5.257626930766483\n",
      "The null hypothesis can be rejected\n",
      "7.77728744444702\n",
      "The null hypothesis can be rejected\n",
      "5.428027363915695\n",
      "The null hypothesis can be rejected\n",
      "4.830834575910595\n",
      "The null hypothesis can be rejected\n",
      "4.628320789459902\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.718584547128605\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-77.4540604477489\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.004515545834275\n",
      "The null hypothesis can be rejected\n",
      "9.375545618317162\n",
      "The null hypothesis can be rejected\n",
      "4.08333730067389\n",
      "The null hypothesis can be rejected\n",
      "3.059059883280719\n",
      "The null hypothesis can be rejected\n",
      "7.052758871394548\n",
      "The null hypothesis can be rejected\n",
      "7.265905205010742\n",
      "The null hypothesis can be rejected\n",
      "4.466090260871639\n",
      "The null hypothesis can be rejected\n",
      "5.424809591407335\n",
      "The null hypothesis can be rejected\n",
      "9.305064711543547\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.7364966026744422\n",
      "The null hypothesis can be rejected\n",
      "-2.8331379469993236\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "5.239188981827869\n",
      "The null hypothesis can be rejected\n",
      "4.333808329382541\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "4.878469875759412\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "71\n",
      "35\n",
      "36\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# multivariate output multi-step 1d cnn example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Lagged_Differenced_Set = (all_data - all_data.shift(-1)).dropna()\n",
    "choice = pd.concat([out.result.iloc[:,0],differenced_set],axis=1)\n",
    "\n",
    "train, test = train_test_split(choice, test_size=tsize, shuffle=False)\n",
    "\n",
    "transformed_train, lambdas_ = transform_boxcox(train)\n",
    "transformed_test = transform_boxcox_l(test, lambdas_)\n",
    "scaler = preprocessing.StandardScaler().fit(transformed_train)\n",
    "train_s = pd.DataFrame(scaler.transform(transformed_train))\n",
    "test_s = pd.DataFrame(scaler.transform(transformed_test))\n",
    "\n",
    "#scaler = preprocessing.StandardScaler().fit(train)\n",
    "#train_s = pd.DataFrame(scaler.transform(train))\n",
    "#test_s = pd.DataFrame(scaler.transform(test))\n",
    "\n",
    "combined = pd.concat([train_s,test_s],axis=0)\n",
    "combined.index = choice.index\n",
    "combined.columns = choice.columns\n",
    "\n",
    "set_ = combined\n",
    "\n",
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out, xcolumns, ycolumns):\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, xcolumns], sequences[end_ix:out_end_ix, ycolumns]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return array(X), array(y)\n",
    "\n",
    "#n_steps_in = int(np.floor(len(train)*.8))\n",
    "print(len(set_))\n",
    "n_steps_in = int(np.round(len(set_)/2))\n",
    "print(len(set_) - n_steps_in)\n",
    "print(n_steps_in)\n",
    "#n_steps_out = int(len(train)-n_steps_in)\n",
    "n_steps_out = 1\n",
    "print(n_steps_out)\n",
    "\n",
    "#ycolumns = range(0,len(transformed.columns))\n",
    "ycolumns = range(0,len(set_.columns[0:1].values))\n",
    "xcolumns = range(1,len(set_.columns[1:]))\n",
    "\n",
    "#trainInner, valid = train_test_split(trainOuter, test_size=0.15, shuffle=False)\n",
    "#trainInner_whitened = pd.DataFrame(trf.transform(trainInner.iloc[:,1:])).set_index(trainInner.index)\n",
    "#valid_whitened = pd.DataFrame(trf.transform(valid.iloc[:,1:])).set_index(valid.index)\n",
    "#test_whitened = pd.DataFrame(trf.transform(test.iloc[:,1:])).set_index(test.index)\n",
    "\n",
    "#trainOuter_whitened=pd.DataFrame(trf.transform(trainOuter.iloc[:,1:])).set_index(trainOuter.index)\n",
    "\n",
    "X, y = split_sequences(np.array(set_), n_steps_in, n_steps_out, xcolumns, ycolumns)\n",
    "\n",
    "#for i in range(len(X)):\n",
    "#    print(X[i], y[i])\n",
    "    \n",
    "#flatten output\n",
    "\n",
    "if len(ycolumns) > 0:\n",
    "    n_output = y.shape[1] * y.shape[2]\n",
    "    y = y.reshape((y.shape[0], n_output))\n",
    "\n",
    "n_features = X.shape[2]\n",
    "\n",
    "# define model\n",
    "modelCNN = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(n_output)\n",
    "])\n",
    "\n",
    "# fit model\n",
    "#model.fit(X, y, epochs=7000, verbose=0)\n",
    "\n",
    "epochs_ = 2000\n",
    "batch_size_ = 25\n",
    "\n",
    "#np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss='mse')\n",
    "modelCNN.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "#X_train_transformed = pd.DataFrame(scaler.transform(X_train))\n",
    "#X_train_transformed.columns = X_train.columns\n",
    "\n",
    "#X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "#X_test_transformed.columns = X_test.columns\n",
    "#X_test_transformed.index = X_test.index\n",
    "\n",
    "    #new_series = pd.DataFrame(ts_train_scaled).append(pd.DataFrame(ts_valid_scaled)).append(pd.DataFrame(ts_test_scaled))\n",
    "\n",
    "    #series_reshaped = np.array([new_series[i:i + (n_steps+n_ahead)].copy() for i in range(len(data) - (n_steps+n_ahead))])  \n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)    \n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "historyCNN = modelCNN.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history6 = model6.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history = model.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1663,
   "id": "d2d1ce87-6c86-4308-8788-b01aa8256fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to apply to test\n",
    "#revert_boxcox(pd.DataFrame(transformed_.iloc[:,0]),pd.DataFrame(lambdas[0]))\n",
    "#Lagged_Differenced_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "id": "0b8f7e2d-3603-4ba1-8457-4fd9918498a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "plot_learning_curves(historyCNN.history[\"loss\"], historyCNN.history[\"val_loss\"])\n",
    "plt.show()\n",
    "#plot_learning_curves(history6.history[\"loss\"], history.history[\"val_loss\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1733,
   "id": "799f6d94-9757-4baa-b095-8937fbba5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.90033141],\n",
       "       [4.21896173],\n",
       "       [4.19081743],\n",
       "       [3.94246046],\n",
       "       [4.87044704],\n",
       "       [5.44739564],\n",
       "       [6.20591252]])"
      ]
     },
     "execution_count": 1733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "id": "bee4c952-450d-43d4-86c1-2a37673a58d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 1689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(revert_transformed_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5ad28-e151-4ccf-915f-a9797fa263cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1756,
   "id": "c2cbc3da-fa1f-4e57-9d84-f4e5f8872af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3528.655493</td>\n",
       "      <td>5954.886383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3357.692867</td>\n",
       "      <td>6237.729370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3413.494694</td>\n",
       "      <td>6212.746133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3503.918338</td>\n",
       "      <td>5992.283660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3454.663392</td>\n",
       "      <td>6816.042351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3398.949078</td>\n",
       "      <td>7328.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3274.655788</td>\n",
       "      <td>8001.513472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     predicted     original\n",
       "0  3528.655493  5954.886383\n",
       "1  3357.692867  6237.729370\n",
       "2  3413.494694  6212.746133\n",
       "3  3503.918338  5992.283660\n",
       "4  3454.663392  6816.042351\n",
       "5  3398.949078  7328.190300\n",
       "6  3274.655788  8001.513472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#multi\n",
    "yhat = modelCNN.predict(X_test, verbose=0)\n",
    "\n",
    "predicted = []\n",
    "original = []\n",
    "if len(ycolumns) > 1:\n",
    "    results = yhat.reshape(len(y_test), int(yhat.shape[1]/X_test.shape[2]), len(choice.columns))\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(pd.DataFrame(results[i])[0][0])\n",
    "        original.append(pd.DataFrame(y_test[i])[0][0])\n",
    "        #print(pd.DataFrame(results[i])[0][0])\n",
    "        #print(pd.DataFrame(y_test[i])[0][0])\n",
    "else:\n",
    "    results = yhat\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(results[i])\n",
    "        original.append(y_test[i])\n",
    "        #print(pd.DataFrame(results[i]))\n",
    "        #print(pd.DataFrame(y_test[i]))\n",
    "        \n",
    "#revert_transformed_predicted = inverse_yeo((scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted)).values,(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted)).values,lambdas_.values[0])\n",
    "#revert_transformed_original = inverse_yeo((scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original)).values,(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original)).values,lambdas_.values[0])\n",
    "revert_transformed_predicted = (scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted))\n",
    "revert_transformed_original = (scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original))\n",
    "\n",
    "plt.scatter(revert_transformed_predicted,revert_transformed_original)\n",
    "temp = pd.concat([revert_transformed_predicted,revert_transformed_original],axis=1)\n",
    "temp.columns = [\"predicted\", \"original\"]\n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8229628-eed4-4b76-831d-1de033240347",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(best_model.coef_).set_index(X_inter_train.columns)\n",
    "\n",
    "a_coef = abs(coef)\n",
    "a_coef.sort_values(by=[0],ascending=False,inplace=True)\n",
    "chosen_few = a_coef[a_coef>0].dropna().index.values\n",
    "\n",
    "scaler_ = preprocessing.StandardScaler().fit(transformed)\n",
    "\n",
    "#\n",
    "train_ = pd.DataFrame(scaler_.transform(transformed))\n",
    "train_.columns = transformed.columns\n",
    "train_.index = transformed.index  \n",
    "\n",
    "X_inter_train_ = pd.DataFrame(interaction.fit_transform(train_.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_.iloc[:,1:]).columns))\n",
    "\n",
    "max_pvalue = 1\n",
    "New_Names = X_inter_train.columns\n",
    "X_b = X_inter_train_[chosen_few]\n",
    "while (max_pvalue > .05):\n",
    "        \n",
    "    trf = zca.ZCA().fit(X_b)\n",
    "        \n",
    "    X_b_z = pd.DataFrame(trf.transform(X_b))\n",
    "    X_b_z.columns=pd.DataFrame(X_b).columns\n",
    "    X_b_z.index = train_.index\n",
    "\n",
    "    model_ = sm.OLS(train_.iloc[:,0],sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    #model_ = sm.OLS(pd.DataFrame(pd.concat([train_.iloc[:,0],X_b_z],axis=1),sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    results_ = model_.fit()\n",
    "\n",
    "    set_ = X_b.columns.tolist()\n",
    "    \n",
    "    max_pvalue = max(results_.pvalues[1:])\n",
    "    if (max_pvalue > .05):\n",
    "        print(max_pvalue)\n",
    "        max_pname = (results_.pvalues[1:]).idxmax(axis=1)\n",
    "        set_.remove(max_pname)\n",
    "        New_Names = set_\n",
    "    \n",
    "        X_b = X_inter_train_[New_Names]\n",
    "        X_b.index = X_inter_train_.index\n",
    "\n",
    "#from statsmodels.formula.api import ols\n",
    "#lm = ols(pd.DataFrame(train_.iloc[:,0]) ~ sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip')).fit()\n",
    "#table = sm.stats.anova_lm(model_, type=3)\n",
    "#print(table)\n",
    "print(results_.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e428c-cce9-46e3-b145-754fc9e4c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNaNCols(df_):\n",
    "    for col in df_:        \n",
    "        num_NaNs = df_[col].isnull().sum()\n",
    "        if num_NaNs > 0:\n",
    "            print(f\"Column: {col}\")\n",
    "            print(f\"Number of NaNs: {num_NaNs}\")\n",
    "\n",
    "findNaNCols(X_b_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4e220-4ac2-4945-9e3a-4b8ff1355a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d940860-86d6-4768-81a0-63f9127143a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_plot = Plot.LinearRegressionResidualPlot(X_b_z, pd.DataFrame(train_.iloc[:,0]))\n",
    "lm = linear_plot.fit()\n",
    "summary, diag_res = linear_plot.diagnostic_plots(lm)\n",
    "print(\"Summary of Regression\\n:{}\".format(summary))\n",
    "print(\"Diagnostic Tests of Regression\\n:{}\".format(diag_res))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#sns.pairplot(pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1), hue=Y, height=2);\n",
    "\n",
    "pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1).hist()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_s = sklearn.linear_model.LinearRegression()\n",
    "model_s.fit(X_b_z, pd.DataFrame(train_[Y]))\n",
    "\n",
    "shap.initjs()\n",
    "e = shap.explainers.Linear(model_s, X_b_z)\n",
    "\n",
    "shap_values = e.shap_values(X_b_z)\n",
    "shap.summary_plot(shap_values, X_b_z)\n",
    "shap.plots.heatmap(e(X_b_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b64b8-ca00-46d1-ba16-91f3adb00065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4871c2-4418-491a-8e5c-5776d42e4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "residuals_normalized = lm.get_influence().resid_studentized_internal\n",
    "cooks = lm.get_influence().cooks_distance[0]\n",
    "cooks = np.round(f.pdf(cooks,len(lm.tvalues)+1, len(lm.fittedvalues)-len(lm.tvalues)-1),2)\n",
    "\n",
    "res_std = lm.get_influence().resid_std\n",
    "\n",
    "leverage = lm.get_influence().hat_matrix_diag\n",
    "\n",
    "plt.hist(pd.DataFrame(leverage))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(cooks))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(residuals_normalized))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "testNormal(residuals_normalized)\n",
    "\n",
    "w = res_std\n",
    "x = cooks\n",
    "y = leverage\n",
    "z = residuals_normalized\n",
    "\n",
    "fitted_y = lm.fittedvalues\n",
    "\n",
    "labels_ = fitted_y.index\n",
    "\n",
    "outlier_check = pd.concat([pd.DataFrame(x),pd.DataFrame(y),pd.DataFrame(z),pd.DataFrame(w)],axis=1).set_index(labels_)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres']\n",
    "\n",
    "qq = ProbPlot(residuals_normalized)\n",
    "\n",
    "c_thresh = .1\n",
    "l_thresh = (2*(len(lm.tvalues)-1)/len(lm.fittedvalues))\n",
    "s_thresh = max(qq.theoretical_quantiles)\n",
    "\n",
    "print(\"Outlier threshold's\")\n",
    "print(\"Cooks distance: > .1+\")\n",
    "print(\"Leverage: > \" + str(l_thresh) + \" to \" + str(3 * (len(lm.tvalues)-1)/len(fitted_y)))\n",
    "print(\"Studentized residuals: > \" + str(s_thresh))\n",
    "print()\n",
    "\n",
    "flag = []\n",
    "\n",
    "for i in range(0,len(outlier_check)):\n",
    "    if( (outlier_check.iloc[i][0] >= c_thresh) or (outlier_check.iloc[i][1] >= l_thresh) or (abs(outlier_check.iloc[i][2]) >= s_thresh) ):\n",
    "        print(outlier_check.iloc[i])\n",
    "        print()\n",
    "        flag.append(True)\n",
    "    else:\n",
    "        flag.append(False)\n",
    "\n",
    "outlier_check = pd.concat([outlier_check,pd.DataFrame(flag).set_index(labels_)],axis=1)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres', 'flagged']\n",
    "\n",
    "print(np.flip(np.argsort(cooks), 0))\n",
    "#print(outlier_check)\n",
    "\n",
    "search = outlier_check[outlier_check['flagged']==1].index.to_list()\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in search:\n",
    "    v = outlier_check.index.to_list().index(i)\n",
    "    rows.append(v)\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2b196-7761-4420-a145-a5411053a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_style(row):\n",
    "\n",
    "    color = 'white'\n",
    "    if bool(row.flagged) == True:\n",
    "        color = 'orange'\n",
    "\n",
    "    return ['background-color: %s' % color]*len(row.values)\n",
    "\n",
    "all_data[set(all_data.columns) & set(New_Names)]\n",
    "\n",
    "outlier_check.style.apply(custom_style, axis=1).apply(custom_style, axis=1).background_gradient(cmap ='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da39b86-0ac2-4470-9457-8e999918d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b8430-ac88-4358-88c1-e6c5400fe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = y_train.columns.to_list()\n",
    "df2 = list(set(set(all_data.columns) & set(New_Names)))\n",
    "\n",
    "flattened = [] \n",
    "for sublist in df1,df2: \n",
    "    for val in sublist: \n",
    "        flattened.append(val) \n",
    "\n",
    "all_data.iloc[rows][flattened].style.background_gradient(cmap ='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
