{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3139d-1ac0-4486-80f0-e54d08259ed1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "ee726465-0b88-46f7-877f-5aee84616ef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy\n",
    "import shap\n",
    "import numpy as np\n",
    "import ZCA as zca\n",
    "import statsmodels.api as sm\n",
    "import matplotlib as plt\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import *\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import IPython\n",
    "\n",
    "import os\n",
    "os.environ['R_HOME'] = '/mnt/distvol/R/4.0.5/lib64/R/'\n",
    "import rpy2.robjects as R\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import arange\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import shap\n",
    "from sklearn.linear_model import ElasticNet\n",
    "import seaborn as sns\n",
    "from ModelDiagnostics import Plot\n",
    "from sklearn.cluster import DBSCAN\n",
    "from clustergram import Clustergram\n",
    "import urbangrammar_graphics as ugg\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox, inv_boxcox\n",
    "from scipy.stats import f\n",
    "\n",
    "import dtale\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "id": "78bf8827-4f34-413b-9a4d-bd6565e33372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "def testNormal (x):    \n",
    "    \n",
    "    k2, p = stats.normaltest(x)\n",
    "    alpha = .001\n",
    "    #print(\"p = {:g}\".format(p))    \n",
    "    if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "        #print(p)\n",
    "        #print(alpha)\n",
    "        print(\"The null hypothesis can be rejected\")\n",
    "        xt, _ = stats.yeojohnson(x)\n",
    "        #xt, _ = stats.boxcox(x)        \n",
    "        print(_)\n",
    "        xt = pd.DataFrame(xt)\n",
    "        \n",
    "        return _, pd.DataFrame(xt).set_index(x.index)\n",
    "    else:\n",
    "        print(\"The null hypothesis cannot be rejected\")    \n",
    "        return 1, pd.DataFrame(x)\n",
    "\n",
    "def inverse_boxcox (data, lambdas):\n",
    "    power = PowerTransformer(method='yeo-johnson')\n",
    "    power.lambdas_ = lambdas.values\n",
    "    return(power.inverse_transform([data]))\n",
    "    #return inv_boxcox(data, lambdas.values)\n",
    "    \n",
    "def transform_boxcox_l(data, l_):\n",
    "    transformed = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        #print(i)\n",
    "        if l_.iloc[i].values == 1:\n",
    "            inner_scale = data.iloc[:,i]            \n",
    "        else:\n",
    "            inner_scale = pd.DataFrame(stats.yeojohnson((data.iloc[:,i]), lmbda=l_.iloc[i].values))\n",
    "            \n",
    "        inner_scale.index = data.index\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed\n",
    "\n",
    "def transform_boxcox (data):\n",
    "    transformed = pd.DataFrame()\n",
    "    transformed_lambdas = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data.columns)):\n",
    "        l, inner_scale = testNormal(data.iloc[:,i])\n",
    "        inner_scale.set_index(data.index)\n",
    "\n",
    "        transformed_lambdas = pd.concat([transformed_lambdas,pd.DataFrame(pd.Series(l))],axis=0)\n",
    "        transformed = pd.concat([transformed,inner_scale],axis=1)\n",
    "        \n",
    "    transformed.columns = data.columns\n",
    "    return transformed, transformed_lambdas\n",
    "\n",
    "def inverse_yeo(og, data_, lambda_):\n",
    "    values = []\n",
    "    for i in range(0,len(og)):\n",
    "        X = og[i]\n",
    "        X_trans = data_[i]\n",
    "        if X >= 0 and lambda_ == 0:\n",
    "            X = exp(X_trans) - 1\n",
    "        elif X >= 0 and lambda_ != 0:\n",
    "            X = (X_trans * lambda_ + 1) ** (1 / lambda_) - 1\n",
    "        elif X < 0 and lambda_ != 2:\n",
    "            X = 1 - (-(2 - lambda_) * X_trans + 1) ** (1 / (2 - lambda_))\n",
    "        elif X < 0 and lambda_ == 2:\n",
    "            X = 1 - exp(-X_trans)\n",
    "        \n",
    "        values.append(X)\n",
    "    return(pd.DataFrame(values))\n",
    "\n",
    "\n",
    "def revert_yeo (og, data_, lambdas):\n",
    "    reverted = pd.DataFrame()\n",
    "\n",
    "    for i in range(0,len(data_.columns)):        \n",
    "        if lambdas.iloc[i].values == 1 :\n",
    "            revert = data_.iloc[:,i]\n",
    "        else:\n",
    "            p#ower = PowerTransformer(method='yeo-johnson')\n",
    "            #power.lambdas_ = lambdas.iloc[i].values\n",
    "            #revert = pd.DataFrame(power.inverse_transform([data.iloc[:,i].values]))\n",
    "            #return inv_boxcox(data, lambdas.values)\n",
    "            revert = pd.DataFrame(inverse_yeo(og.iloc[:,i].values,data_.iloc[:,i].values, lambdas.iloc[i].values))            \n",
    "        revert.index = data_.index\n",
    "        reverted = pd.concat([reverted,revert],axis=1)\n",
    "        \n",
    "    reverted.columns = data_.columns\n",
    "    return reverted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "id": "2ec9d431-186e-4171-8a8a-378ab2ab2e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_deltas(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(d)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def get_residuals(data):\n",
    "\n",
    "    R.r('''\n",
    "               f <- function(values) {\n",
    "                        #system(\"which openssl\")\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              return(r)\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f = R.globalenv['f']\n",
    "    d=R.conversion.rpy2py((r_f(R.conversion.py2rpy(data.dropna()))))\n",
    "    return(d)\n",
    "\n",
    "def arfima_predict(data_, ahead):\n",
    "\n",
    "    R.r('''\n",
    "               f_ <- function(values, ahead) {\n",
    "                        #system(\"which openssl\")\n",
    "                        print(nrow(values))\n",
    "\n",
    "                        library(snpEnrichment)\n",
    "                        library(arfima)\n",
    "                        library(parallel)\n",
    "                        library(forecast)                    \n",
    "\n",
    "                        dset <- lapply(1:ncol(values),function(x)\n",
    "                        {\n",
    "                            column = values[,x,drop=FALSE]\n",
    "\n",
    "\n",
    "                            #tryCatch(invisible(capture.output(suppressMessages(suppressWarnings(\n",
    "                            #{\n",
    "                              varvefd = arfima(column)\n",
    "                              d = summary(varvefd)$coef[[1]][1]\n",
    "                              \n",
    "                              #return(d)\n",
    "                              r = residuals(varvefd, reg = TRUE)\n",
    "                              #print(r)\n",
    "                              #return(r)\n",
    "                              \n",
    "                              pred <- predict(varvefd, ahead)\n",
    "                              #print(ahead)\n",
    "                              #print(pred)\n",
    "                              #print(pred)\n",
    "                              return(as.data.frame(pred)[,1,drop=TRUE])\n",
    "                            #}\n",
    "                           #)\n",
    "                           #))),\n",
    "                            #error=function(e)\n",
    "                              #{\n",
    "                                #d = 1\n",
    "                                #return(d)\n",
    "                              #})\n",
    "\n",
    "                        })    \n",
    "\n",
    "                        unlist(dset)\n",
    "\n",
    "                }\n",
    "                ''')\n",
    "\n",
    "    r_f_ = R.globalenv['f_']\n",
    "    d_=R.conversion.rpy2py((r_f_(R.conversion.py2rpy(data_),ahead)))\n",
    "    return(d_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1446,
   "id": "e43598e7-17dd-4ced-b588-e8870d3df933",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "def arima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #arima residual adjusted\n",
    "    \n",
    "    window = 15\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    model = AutoReg(train_resid.values, lags=15)\n",
    "    model_fit = model.fit()\n",
    "    coef = model_fit.params\n",
    "    # walk forward over time steps in test\n",
    "    history = train_resid[len(train_resid)-window:]\n",
    "    history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]    \n",
    "        error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        length = len(history)\n",
    "        lag = [history[i] for i in range(length-window,length)]\n",
    "        pred_error = coef[0]\n",
    "        for d in range(window):\n",
    "            pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        yhat = yhat + pred_error\n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af9904-08a5-4d5f-90f7-1b4c5d4652df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb9bb80-d23a-4a60-964b-41dad96d6411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1448,
   "id": "1235085d-f98a-4b9d-a118-29a6f154af93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom statsmodels.tsa.ar_model import AutoReg\\n\\nresiduals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\\n\\ny_adjusted = predicteds.copy()\\n\\nfor i in range(0,len(y_test)):    \\n    \\n    if i == 0:\\n        forecast_r = arfima_predict(residuals_train.values)\\n        \\n    else:\\n        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\\n        \\n        residuals = pd.concat([residuals_train,residuals_test],axis=0)\\n        \\n        forecast_r = arfima_predict(residuals.values)\\n        \\n    print(forecast_r)\\n    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\\n    #print(adjusted)\\n    \\n    \\n    \\n    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\\n    #ar_s_model = AutoReg(residuals, lags=15)\\n    #model_fit = model.fit()\\n    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\\n\\n    #improved_forecast = forecast + estimated error\\n\\n    #print('Coef=%s' % (model_fit.params))\\n\""
      ]
     },
     "execution_count": 1448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#arfima residual adjusted\n",
    "def arfima_adjust(y_train, y_test, train_predicted, test_predicted):\n",
    "    \n",
    "    #train_resid = get_deltas(y_train)\n",
    "    train_resid = y_train - pd.DataFrame(train_predicted).set_index(y_train.index)\n",
    "\n",
    "    y_adjusted = predicted.copy()\n",
    "\n",
    "    forecast_r = arfima_predict(train_resid.values, len(y_test))  \n",
    "    print(len(forecast_r))\n",
    "    \n",
    "    # walk forward over time steps in test\n",
    "    #history = train_resid[len(train_resid):-1]\n",
    "    #history = [history.loc[history.index[i]] for i in range(len(history))]\n",
    "    predictions = list()\n",
    "    for t in range(len(y_test)):\n",
    "        # persistence\n",
    "        yhat = pd.DataFrame(test_predicted).set_index(y_test.index).loc[y_test.index[t]]\n",
    "        #error = y_test.loc[y_test.index[t]] - yhat\n",
    "        # predict error\n",
    "        #length = len(history)\n",
    "        #lag = [history[i] for i in range(length-window,length)]\n",
    "        #pred_error = coef[0]\n",
    "        #for d in range(window):\n",
    "            #pred_error += coef[d+1] * lag[window-d-1]\n",
    "        # correct the prediction\n",
    "        #print(yhat)\n",
    "        #print(pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] )\n",
    "        yhat = yhat + pd.DataFrame(forecast_r).set_index(y_test.index).loc[y_test.index[t]] \n",
    "        #print(yhat)\n",
    "        predictions.append(np.round(yhat,0).astype(int))\n",
    "        #history.append(error)\n",
    "        #print('predicted=%f, expected=%f' % ((np.round(yhat,0)), y_test.loc[y_test.index[t]]))\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictions))\n",
    "    print(metrics.confusion_matrix(y_test,predictions))\n",
    "    \n",
    "    return(pd.DataFrame(predictions).set_index(y_test.index))\n",
    "\n",
    "'''\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "residuals_train = y_train - pd.DataFrame(clf.predict(X_train)).set_index(y_train.index)\n",
    "\n",
    "y_adjusted = predicteds.copy()\n",
    "\n",
    "for i in range(0,len(y_test)):    \n",
    "    \n",
    "    if i == 0:\n",
    "        forecast_r = arfima_predict(residuals_train.values)\n",
    "        \n",
    "    else:\n",
    "        residuals_test = y_test.loc[y_test.index[0:i]] - pd.DataFrame(predicteds).set_index(y_test.index).loc[y_test.index[0:i]]\n",
    "        \n",
    "        residuals = pd.concat([residuals_train,residuals_test],axis=0)\n",
    "        \n",
    "        forecast_r = arfima_predict(residuals.values)\n",
    "        \n",
    "    print(forecast_r)\n",
    "    adjusted = pd.DataFrame(y_adjusted).set_index(y_test.index).loc[y_test.index[i]]\n",
    "    #print(adjusted)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #y_test.loc[0:i]-pd.DataFrame(predicteds).set_index(y_test.loc[0:i].index)\n",
    "    #ar_s_model = AutoReg(residuals, lags=15)\n",
    "    #model_fit = model.fit()\n",
    "    #plt.plot(np.round(arfima_predict(residuals.values, len(y_test)),0))\n",
    "\n",
    "    #improved_forecast = forecast + estimated error\n",
    "\n",
    "    #print('Coef=%s' % (model_fit.params))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a133da3-b0fd-4741-a0aa-db8cc75f878d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weights(d, num_k):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    \n",
    "    for k in range(1, num_k):\n",
    "        w_k = np.append(w_k, -w_k[-1] * ((d - k + 1)) / k)\n",
    "        \n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def get_weights_floored(d, num_k, floor=1e-3):\n",
    "    r\"\"\"Calculate weights ($w$) for each lag ($k$) through\n",
    "    $w_k = -w_{k-1} \\frac{d - k + 1}{k}$ provided weight above a minimum value\n",
    "    (floor) for the weights to prevent computation of weights for the entire\n",
    "    time series.\n",
    "    \n",
    "    Args:\n",
    "        d (int): differencing value.\n",
    "        num_k (int): number of lags (typically length of timeseries) to calculate w.\n",
    "        floor (float): minimum value for the weights for computational efficiency.\n",
    "    \"\"\"\n",
    "    w_k = np.array([1])\n",
    "    k = 1\n",
    "    \n",
    "    while k < num_k:\n",
    "        w_k_latest = -w_k[-1] * ((d - k + 1)) / k\n",
    "        if abs(w_k_latest) <= floor:\n",
    "            break\n",
    "\n",
    "        w_k = np.append(w_k, w_k_latest)\n",
    "        \n",
    "        k += 1\n",
    "\n",
    "    w_k = w_k.reshape(-1, 1) \n",
    "    \n",
    "    return w_k\n",
    "\n",
    "def frac_diff(df, d, floor=1e-3):\n",
    "    r\"\"\"Fractionally difference time series via CPU.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe of raw time series values.\n",
    "        d (float): differencing value from 0 to 1 where > 1 has no FD.\n",
    "        floor (float): minimum value of weights, ignoring anything smaller.\n",
    "    \"\"\"\n",
    "    # Get weights window\n",
    "    weights = get_weights_floored(d=d, num_k=len(df), floor=floor)\n",
    "    weights_window_size = len(weights)\n",
    "    \n",
    "    # Reverse weights\n",
    "    weights = weights[::-1]\n",
    "    \n",
    "    # Blank fractionally differenced series to be filled\n",
    "    df_fd = []\n",
    "\n",
    "    # Slide window of time series, to calculated fractionally differenced values\n",
    "    # per window\n",
    "    for idx in range(weights_window_size, df.shape[0]):\n",
    "        # Dot product of weights and original values\n",
    "        # to get fractionally differenced values\n",
    "        date_idx = df.index[idx]\n",
    "        df_fd.append(np.dot(weights.T, df.iloc[idx - weights_window_size:idx]).item())\n",
    "    \n",
    "    # Return FD values and weights\n",
    "    df_fd = pd.DataFrame(df_fd)\n",
    "    \n",
    "    return df_fd, weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222e53d3-2864-4d69-a45a-ce48217e4fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "d949ef06-ae96-4828-b02b-21a92a11b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxl = 5\n",
    "train_size = .7\n",
    "t_size = 1-train_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1512,
   "id": "62e6233b-8abf-4f78-83f5-a3e7a2e26fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_data = pd.read_csv('/mnt/distvol/combined_set.csv')\n",
    "all_data.index = all_data.iloc[:,0]\n",
    "all_data = all_data.iloc[:,1:]\n",
    "\n",
    "filter_ = all_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "id": "ca4d80c7-99c2-4070-b6f4-1b19d28520f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2003-06-29\n",
      "2005-04-17\n",
      "2007-02-04\n",
      "2008-11-23\n",
      "2010-09-12\n",
      "2012-07-01\n",
      "2014-04-20\n",
      "2016-02-07\n",
      "2017-11-26\n",
      "2019-09-15\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1513,
   "id": "8b2b9636-4857-4aaa-b13d-e2077e957c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose Y\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0faf97c2c0d418193f2ca420d2516cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Y', options=('DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10', â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f3(Y):\n",
    "    \n",
    "    #Y = x\n",
    "    #output_slider_variable.value\n",
    "    internalFilter = filter_.copy()\n",
    "    internalFilter.remove(Y)\n",
    "    all_data_ = pd.concat([all_data[Y],all_data[internalFilter]], axis=1)    \n",
    "    #print(all_data_.describe())\n",
    "    display(all_data_.describe())\n",
    "    #x_ticks = all_data_.index[np.arange(0, len(all_data.index), int(len(internalFilter)/5))]\n",
    "    x_ticks  = []\n",
    "    for index, element in enumerate(all_data_.index):\n",
    "        if index % int(np.round(len(all_data_.index)/10)) == 0:\n",
    "            x_ticks.append(element)\n",
    "    plt.plot(all_data_[Y])\n",
    "    plt.xticks(x_ticks, rotation = 45)\n",
    "    plt.show()        \n",
    "    plt.hist(all_data_[Y], bins='auto')\n",
    "    plt.show()\n",
    "    diff = pd.DataFrame((all_data_[Y].pct_change())).dropna()\n",
    "    plt.hist(diff, bins='auto')\n",
    "    plt.show()\n",
    "    return(all_data_)\n",
    "    \n",
    "out = interactive(f3, Y=filter_)\n",
    "\n",
    "#output_slider_variable.observe(f4, 'value')\n",
    "\n",
    "print(\"choose Y\")\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1514,
   "id": "4ee2cc18-8baf-4f8a-bcd2-9562b62237fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-26 02:22:07,108 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:12,387 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,367 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:13,551 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:15,762 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,589 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:16,758 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:17,216 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,142 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,361 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:18,987 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:19,640 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,630 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:20,887 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,128 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n",
      "2021-05-26 02:22:22,665 - WARNING  - R[write to console]: Error in stats::arima(x = x, order = order, seasonal = seasonal, include.mean = include.mean,  : \n",
      "  non-stationary AR part from CSS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(out.result, test_size=tsize, shuffle=False)\n",
    "\n",
    "d = get_deltas(train)\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n",
    "#differenced = pd.DataFrame(np.transpose(d.reshape(len(out.result.columns),len(out.result))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1487,
   "id": "2d87fad8-9555-4fe1-a82f-18243715d650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 1487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1489,
   "id": "2ed2b0f5-1e32-4e6a-8e54-ea4dbe225df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1516,
   "id": "33e1c5c4-9718-4cbb-a820-9fd94e3fc482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "from fracdiff import fdiff\n",
    "\n",
    "cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "def getDifferenced(i, data):\n",
    "    #v = d[[i]]\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\n",
    "    #print(i)\n",
    "    a = np.array(data.iloc[:, i])\n",
    "    \n",
    "    return fdiff(a, n=d[i], axis=0)\n",
    "    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1517,
   "id": "2070d863-3329-4f28-8b4e-a74b5480cc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndifferenced = pd.DataFrame()\\nfor f in range(0,len(futures01)):\\n    value = pd.DataFrame(futures01[f].result())\\n    differenced = pd.concat([differenced,value],axis=1)\\n    \\ndifferenced.columns = train.columns\\ndifferenced.index = train.index\\n'"
      ]
     },
     "execution_count": 1517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "differenced = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, out.result))\n",
    "    #print(value)\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = out.result.columns\n",
    "differenced.index = out.result.index    \n",
    "\n",
    "'''\n",
    "\n",
    "differenced_train = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, train))\n",
    "    #print(value)\n",
    "    differenced_train = pd.concat([differenced_train,value],axis=1)\n",
    "    \n",
    "differenced_train.columns = train.columns\n",
    "differenced_train.index = train.index    \n",
    "\n",
    "differenced_test = pd.DataFrame()\n",
    "for i in range(0,len(d)):\n",
    "    value = pd.DataFrame(getDifferenced(i, test))\n",
    "    differenced_test = pd.concat([differenced_test,value],axis=1)\n",
    "\n",
    "differenced_test.columns = test.columns\n",
    "differenced_test.index = test.index\n",
    "\n",
    "differenced = pd.DataFrame()\n",
    "differenced = pd.concat([differenced_train,differenced_test],axis=0)\n",
    "'''\n",
    "differenced = pd.concat([out.result.iloc[:,0],differenced.iloc[:,1:]],axis=1)\n",
    "\n",
    "#pool01 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "#futures01 = [pool01.submit(getDifferenced, args) for args in (range(0,len(d)))]\n",
    "\n",
    "#wait(futures01, timeout=None, return_when=ALL_COMPLETED)\n",
    "#'''\n",
    "\n",
    "'''\n",
    "differenced = pd.DataFrame()\n",
    "for f in range(0,len(futures01)):\n",
    "    value = pd.DataFrame(futures01[f].result())\n",
    "    differenced = pd.concat([differenced,value],axis=1)\n",
    "    \n",
    "differenced.columns = train.columns\n",
    "differenced.index = train.index\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc2d32f-b9a1-4196-9d43-1359b65f1c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "f492f94d-cba1-455a-b1d4-157a346f6d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://slurmw01:40000'"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_ = dtale.show(out.result)\n",
    "d_.open_browser()\n",
    "d_._url  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "4273fdd8-d805-4928-b7dd-bda427cf51fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport concurrent.futures\\nfrom concurrent.futures import wait, ALL_COMPLETED\\nfrom fracdiff import fdiff\\n\\ncores = int(len(os.sched_getaffinity(0)))\\n\\ndef getDifferenced(i):\\n    #v = d[[i]]\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i], d=d[[i]], floor=5e-5)\\n    \\n    a = np.array(out.result.iloc[:, i])\\n    \\n    return fdiff(a, n=d[i], axis=0)\\n    #gquant_gpu, weights = frac_diff(all_data.iloc[:, i]), d=v, floor=5e-5)\\n\\npool01 = concurrent.futures.ProcessPoolExecutor(cores)\\n\\nfutures01 = [pool01.submit(getDifferenced, args) for args in range(0,len(d))]\\n\\nwait(futures01, timeout=None, return_when=ALL_COMPLETED)\\n'"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfa758-3cf3-4410-bfc6-85105b37a19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0e2820-110a-4786-9035-98543c301b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    for f in range(0,len(futures01)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "        plt.hist(Differenced_Set.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        Differenced_Set.iloc[:,1].plot()\n",
    "        plt.show()\n",
    "        plt.hist(all_data.iloc[:,f], bins='auto')  # arguments are passed to np.histogram\n",
    "        plt.show()\n",
    "        all_data.iloc[:,1].plot()\n",
    "        plt.show()    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce862ad-f7fc-4f0b-b376-c29d32d01281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b6b7d-d0c5-4077-b822-d79e626067b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 929,
   "id": "3d49f670-bbdb-42a8-b9e3-e75e1b60e830",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = out.result.corr()\n",
    "#.abs()\n",
    "s = c.unstack()\n",
    "so = s.sort_values(kind=\"quicksort\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0016982-6857-424e-868a-da44b16ff66b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ece4be0-8244-434e-b66e-9c1f39a7c2c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "id": "4d4a92b7-e5b3-49ed-b31f-5959f90e8fca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "def critical_r(n, alpha = .05 ):\n",
    "    df = n - 2\n",
    "    critical_t = scipy.stats.t.isf(alpha / 2, df)\n",
    "    critical_r = np.sqrt( (critical.t^2) / ( (critical.t^2) + df ) )\n",
    "    return(critical_r)\n",
    "\n",
    "def xcorr(x, y, maxlags=10):\n",
    "    Nx = len(x)\n",
    "    if Nx != len(y):\n",
    "        raise ValueError('x and y must be equal length')\n",
    "\n",
    "    c = np.correlate(x, y, mode=2)\n",
    "\n",
    "    if maxlags is None:\n",
    "        maxlags = Nx - 1\n",
    "\n",
    "    if maxlags >= Nx or maxlags < 1:\n",
    "        raise ValueError('maxlags must be None or strictly positive < %d' % Nx)\n",
    "\n",
    "    c = c[Nx - 1 - maxlags:Nx + maxlags]\n",
    "\n",
    "    return c\n",
    "\n",
    "def getLagged_Set(set_, og):\n",
    "\n",
    "    train, test = train_test_split(set_, test_size=tsize, shuffle=False)\n",
    "    \n",
    "    residuals = pd.DataFrame(np.transpose(get_residuals(train).reshape(len(train.columns),len(train))))\n",
    "    #print(residuals)\n",
    "\n",
    "    residuals.columns = train.columns\n",
    "    residuals.index = train.index\n",
    "\n",
    "    #print(len(train))\n",
    "    #set_.index = all_data.index\n",
    "    \n",
    "    Lagged_Differenced_Set = pd.DataFrame()\n",
    "    Lagged_Set = pd.DataFrame()\n",
    "    lags = []\n",
    "    lagcorrs = []\n",
    "    ogcorrs = []\n",
    "\n",
    "    for f in range(1,len(train.columns)):\n",
    "        #print(f)\n",
    "        #print(len(futures01[f].result()))\n",
    "\n",
    "        data_1 = residuals.iloc[:,0]\n",
    "        data_2 = residuals.iloc[:,f]\n",
    "\n",
    "        ogc = np.array(pd.concat([data_1 - np.mean(data_1),data_2 - np.mean(data_2)],axis=1).corr())[1,0]    \n",
    "        ogcorrs.append(ogc)\n",
    "\n",
    "        #corr = xcorr(data_1 - np.mean(data_1), data_2 - np.mean(data_2),maxlags=5)\n",
    "\n",
    "        set1 = data_1 - np.mean(data_1)\n",
    "        set2 = data_2 - np.mean(data_2)\n",
    "\n",
    "        corrs_ = []\n",
    "        for i in range(0,maxl):\n",
    "            c = np.array((pd.concat([set1,set2.shift(i)],axis=1).dropna()).corr())[0,1]\n",
    "            corrs_.append(c)\n",
    "\n",
    "        #corr = np.correlate(data_1 - np.mean(data_1), data_2 - np.mean(data_2),mode='full')\n",
    "        #plt.plot(corr)\n",
    "        #plt.show()\n",
    "\n",
    "        #lag = corr.argmax() - (len(data_1) - 1)\n",
    "        lag = abs(pd.Series(corrs_)).idxmax()\n",
    "\n",
    "        #print(corr)\n",
    "        lagc = np.array(pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1).corr())[1,0]\n",
    "\n",
    "        #print(lag)\n",
    "\n",
    "        #print(ogc)\n",
    "        #print(lagc)\n",
    "\n",
    "        #print(lag)\n",
    "        #plt.plot(data_1, 'r*')\n",
    "        #plt.plot(data_2, 'b*')\n",
    "\n",
    "        lag_merged = pd.concat([data_1 - np.mean(data_1),(data_2 - np.mean(data_2)).shift(lag)],axis=1)\n",
    "\n",
    "        #x_ticks = all_data.index[np.arange(0, len(all_data.index), 5)]\n",
    "        #plt.xticks(x_ticks, rotation = 45)    \n",
    "        #plt.show()\n",
    "\n",
    "        #plt.scatter(data_2.shift(lag),data_1)\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_acf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #plot_pacf(data_2.shift(lag))\n",
    "        #plt.show()\n",
    "\n",
    "        #y = data_1\n",
    "        #X = data_2\n",
    "        #reg = LinearRegression().fit(X, y)\n",
    "\n",
    "        #print(reg.score(X, y),reg.coef_,reg.intercept_)\n",
    "\n",
    "        #model = sm.OLS(y,X)\n",
    "        #results = model.fit()\n",
    "        #print(results.summary())\n",
    "\n",
    "        #Lagged_Differenced_Set = pd.concat([Lagged_Differenced_Set,data_2.shift(lag)],axis=1)\n",
    "        #TrainO_Lagged_Set = pd.concat([TrainO_Lagged_Set,all_data.iloc[:,f].shift(lag)],axis=1)\n",
    "        #if lag>0:\n",
    "            #lag = 0\n",
    "\n",
    "        Lagged_Set = pd.concat([Lagged_Set,og.iloc[:,f].shift(lag)],axis=1)\n",
    "\n",
    "        lagcorrs.append(lagc)\n",
    "\n",
    "        lags.append(lag)\n",
    "\n",
    "    Lagged_Set.index = set_.index\n",
    "    #stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(lagcorrs),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    stats = pd.concat([pd.DataFrame(set_.columns[1:]),pd.DataFrame(lags),pd.DataFrame(ogcorrs)],axis=1)\n",
    "    \n",
    "    #print(Lagged_Set)\n",
    "    #return stats, pd.concat([data_1,Lagged_Set],axis=1),  pd.concat([data_1,Lagged_Differenced_Set],axis=1)\n",
    "    return stats, pd.concat([set_.iloc[:,0],Lagged_Set],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "id": "23eb26a0-bb46-4fd9-b9b8-2de6a3a7f875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['^SP500TR', 'DGS10', 'DTB3', 'DGS3MO', 'MORTGAGE30US', 'DFII10',\n",
       "       'T5YIFR', 'BAMLHYH0A0HYM2TRIV', 'BAMLCC0A1AAATRIV', 'DGS1',\n",
       "       'BAMLCC0A4BBBTRIV', 'IC4WSA', 'WILLMICROCAPPR', 'WILLLRGCAPVAL',\n",
       "       'T5YIE', 'WTB3MS', 'WGS3MO', 'TWEXB', 'DEXCHUS', 'DEXUSUK', 'TEDRATE',\n",
       "       'VIXCLS', 'NFCI', 'BAA10Y', 'BAMLC0A0CM', 'BAMLH0A3HYC', 'DCOILBRENTEU',\n",
       "       'DCOILWTICO', 'DFF', 'DGS1MO', 'DGS30', 'DGS5', 'ICSA', 'M1', 'STLFSI2',\n",
       "       'T10Y2Y', 'T10Y3M', 'TREAST', 'QQQ', 'DIA', 'IYR', 'EWG', 'EWU', 'EWJ',\n",
       "       'EZU', 'EWZ', 'ILF', 'EWW', 'LQD', 'SHY', 'IEF', 'TLT', 'ETH', 'BCH',\n",
       "       'LTC', 'XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLK', 'XLU',\n",
       "       'MMM', 'AXP', 'AMGN', 'AAPL', 'BA', 'CAT', 'CVX', 'CSCO', 'KO', 'GS',\n",
       "       'HD', 'HON', 'IBM', 'INTC', 'JNJ', 'JPM', 'MCD', 'MRK', 'MSFT', 'NKE',\n",
       "       'PG', 'TRV', 'UNH', 'VZ', 'WMT', 'WBA', 'DIS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1560,
   "id": "3e80173c-962f-4b0e-b170-8186d5f9b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lagged_Set = pd.DataFrame()\n",
    "Lagged_Differenced_Set = pd.DataFrame()\n",
    "\n",
    "#'''\n",
    "#Lagged_Differenced_Set_offset = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),out.result.iloc[:,1:].pct_change()],axis=1)\n",
    "differenced_set = out.result.pct_change()\n",
    "differenced_set = differenced_set.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "ls_stats, Lagged_Differenced_Set= getLagged_Set(differenced_set, out.result)\n",
    "lso_stats, Lagged_Differenced_Set_offset= getLagged_Set(pd.concat([differenced_set.iloc[:,0].shift(-1),differenced_set.iloc[:,1:]],axis=1), out.result)\n",
    "\n",
    "#Lagged_Set_offset.index = out.result.index\n",
    "Lagged_Differenced_Set.dropna(inplace= True)\n",
    "#Lagged_Set_offset.columns = out.result.columns\n",
    "\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "\n",
    "#Lagged_Differenced_Set.dropna(inplace= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "id": "57b19b33-dfd6-4233-8e3c-4f266a9ce8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0\n",
       "2003-09-30    0.060820\n",
       "2003-12-31    0.076878\n",
       "2004-03-31   -0.004395\n",
       "2004-06-30   -0.012870\n",
       "2004-09-30    0.057999\n",
       "2004-12-31    0.029813\n",
       "2005-03-31   -0.003927\n",
       "2005-06-30    0.040415\n",
       "2005-09-30    0.009843\n",
       "2005-12-31    0.048335\n",
       "Name: ^SP500TR, dtype: float64"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541e943c-2c5b-4cc8-86ca-87a1dab05a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "id": "29c83e18-ed0b-446d-89a3-86ea42e5672c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "^SP500TR        0\n",
       "AXP             0\n",
       "MMM             0\n",
       "XLU             0\n",
       "XLK             0\n",
       "               ..\n",
       "DCOILBRENTEU    0\n",
       "BAMLH0A3HYC     0\n",
       "BAMLC0A0CM      0\n",
       "NFCI            0\n",
       "DIS             0\n",
       "Length: 91, dtype: int64"
      ]
     },
     "execution_count": 1535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "temp = pd.DataFrame()\n",
    "temp = pd.concat([out.result.iloc[:,0].pct_change().shift(-1),Lagged_Set_offset.iloc[:,1:].pct_change()],axis=1).copy()\n",
    "Lagged_Differenced_Set_offset = pd.DataFrame()\n",
    "Lagged_Differenced_Set_offset = temp.copy()\n",
    "Lagged_Differenced_Set_offset.dropna(inplace= True)\n",
    "Lagged_Differenced_Set_offset\n",
    "Lagged_Differenced_Set_offset = Lagged_Differenced_Set_offset.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "#Lagged_Differenced_Set_offset.fillna(0)\n",
    "#preprocessing.StandardScaler().fit(Lagged_Differenced_Set_offset)\n",
    "'''\n",
    "np.sum(Lagged_Differenced_Set_offset.isin([np.inf, -np.inf, np.NaN])).sort_values(kind=\"quicksort\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "id": "8cfbc252-b567-48e9-86f9-9e57df0ac45c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0  0         0\n",
      "0          DGS10  0  0.293900\n",
      "1           DTB3  1 -0.003070\n",
      "2         DGS3MO  0  0.112961\n",
      "3   MORTGAGE30US  0  0.080523\n",
      "4         DFII10  0  0.052994\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.544979\n",
      "86            VZ  0  0.511754\n",
      "87           WMT  0  0.407511\n",
      "88           WBA  0  0.457171\n",
      "89           DIS  0  0.730196\n",
      "\n",
      "[90 rows x 3 columns]\n",
      "               0  0         0\n",
      "0          DGS10  3 -0.042244\n",
      "1           DTB3  3 -0.089426\n",
      "2         DGS3MO  3 -0.088654\n",
      "3   MORTGAGE30US  3 -0.145695\n",
      "4         DFII10  2  0.041021\n",
      "..           ... ..       ...\n",
      "85           UNH  0  0.273665\n",
      "86            VZ  3  0.080712\n",
      "87           WMT  1 -0.086052\n",
      "88           WBA  3  0.151340\n",
      "89           DIS  1 -0.092398\n",
      "\n",
      "[90 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(ls_stats)\n",
    "print(lso_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "id": "53aa28e7-3712-466f-96fd-7bbf115714ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SP500TR</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>DTB3</th>\n",
       "      <th>DGS3MO</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>DFII10</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>BAMLHYH0A0HYM2TRIV</th>\n",
       "      <th>BAMLCC0A1AAATRIV</th>\n",
       "      <th>DGS1</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WBA</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>0.069088</td>\n",
       "      <td>1.541751</td>\n",
       "      <td>0.915645</td>\n",
       "      <td>0.935161</td>\n",
       "      <td>0.794281</td>\n",
       "      <td>1.692419</td>\n",
       "      <td>2.458548</td>\n",
       "      <td>41.996715</td>\n",
       "      <td>352.547879</td>\n",
       "      <td>1.775484</td>\n",
       "      <td>...</td>\n",
       "      <td>24.940498</td>\n",
       "      <td>0.966422</td>\n",
       "      <td>7.378963</td>\n",
       "      <td>1.252715</td>\n",
       "      <td>22.987969</td>\n",
       "      <td>27.550304</td>\n",
       "      <td>12.984091</td>\n",
       "      <td>39.046941</td>\n",
       "      <td>1.623533</td>\n",
       "      <td>2.482302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.032607</td>\n",
       "      <td>1.495879</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.933710</td>\n",
       "      <td>0.788597</td>\n",
       "      <td>2.045645</td>\n",
       "      <td>2.634194</td>\n",
       "      <td>43.029175</td>\n",
       "      <td>362.683636</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.109538</td>\n",
       "      <td>0.965952</td>\n",
       "      <td>7.352318</td>\n",
       "      <td>1.252347</td>\n",
       "      <td>24.251518</td>\n",
       "      <td>33.238478</td>\n",
       "      <td>14.858189</td>\n",
       "      <td>36.890209</td>\n",
       "      <td>1.620360</td>\n",
       "      <td>2.447742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>-0.003881</td>\n",
       "      <td>1.590695</td>\n",
       "      <td>1.078871</td>\n",
       "      <td>1.096129</td>\n",
       "      <td>0.797332</td>\n",
       "      <td>1.893750</td>\n",
       "      <td>2.481250</td>\n",
       "      <td>43.544771</td>\n",
       "      <td>354.851562</td>\n",
       "      <td>2.472742</td>\n",
       "      <td>...</td>\n",
       "      <td>16.016526</td>\n",
       "      <td>0.968542</td>\n",
       "      <td>7.595334</td>\n",
       "      <td>1.252234</td>\n",
       "      <td>27.052105</td>\n",
       "      <td>37.703203</td>\n",
       "      <td>14.630292</td>\n",
       "      <td>37.523092</td>\n",
       "      <td>1.619811</td>\n",
       "      <td>2.533420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>0.045642</td>\n",
       "      <td>1.544377</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>1.513906</td>\n",
       "      <td>0.793859</td>\n",
       "      <td>1.690484</td>\n",
       "      <td>2.410484</td>\n",
       "      <td>43.206397</td>\n",
       "      <td>363.761045</td>\n",
       "      <td>3.072459</td>\n",
       "      <td>...</td>\n",
       "      <td>16.911974</td>\n",
       "      <td>0.971730</td>\n",
       "      <td>8.632519</td>\n",
       "      <td>1.253729</td>\n",
       "      <td>27.104700</td>\n",
       "      <td>41.275508</td>\n",
       "      <td>15.591040</td>\n",
       "      <td>36.719812</td>\n",
       "      <td>1.632797</td>\n",
       "      <td>2.586150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.010137</td>\n",
       "      <td>1.523840</td>\n",
       "      <td>2.011613</td>\n",
       "      <td>2.047419</td>\n",
       "      <td>0.791116</td>\n",
       "      <td>1.717705</td>\n",
       "      <td>2.453279</td>\n",
       "      <td>44.018290</td>\n",
       "      <td>370.418636</td>\n",
       "      <td>3.337344</td>\n",
       "      <td>...</td>\n",
       "      <td>18.243953</td>\n",
       "      <td>0.970402</td>\n",
       "      <td>8.825318</td>\n",
       "      <td>1.254591</td>\n",
       "      <td>23.588805</td>\n",
       "      <td>44.026221</td>\n",
       "      <td>16.741129</td>\n",
       "      <td>33.769871</td>\n",
       "      <td>1.638542</td>\n",
       "      <td>2.558298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.003958</td>\n",
       "      <td>1.220122</td>\n",
       "      <td>2.388361</td>\n",
       "      <td>2.438525</td>\n",
       "      <td>0.760357</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>1.944921</td>\n",
       "      <td>73.572146</td>\n",
       "      <td>637.862812</td>\n",
       "      <td>1.845000</td>\n",
       "      <td>...</td>\n",
       "      <td>79.716758</td>\n",
       "      <td>1.018707</td>\n",
       "      <td>82.613387</td>\n",
       "      <td>1.310248</td>\n",
       "      <td>117.868538</td>\n",
       "      <td>255.783684</td>\n",
       "      <td>51.443717</td>\n",
       "      <td>109.754493</td>\n",
       "      <td>1.769093</td>\n",
       "      <td>3.600235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-0.032009</td>\n",
       "      <td>1.140147</td>\n",
       "      <td>2.304921</td>\n",
       "      <td>2.354762</td>\n",
       "      <td>0.749156</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>1.834531</td>\n",
       "      <td>73.014092</td>\n",
       "      <td>662.025846</td>\n",
       "      <td>1.575806</td>\n",
       "      <td>...</td>\n",
       "      <td>82.250245</td>\n",
       "      <td>1.019433</td>\n",
       "      <td>84.411047</td>\n",
       "      <td>1.309857</td>\n",
       "      <td>121.248230</td>\n",
       "      <td>269.978145</td>\n",
       "      <td>52.873113</td>\n",
       "      <td>115.861732</td>\n",
       "      <td>1.736154</td>\n",
       "      <td>3.605762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0.208827</td>\n",
       "      <td>0.980938</td>\n",
       "      <td>1.983594</td>\n",
       "      <td>2.026094</td>\n",
       "      <td>0.736517</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>1.755806</td>\n",
       "      <td>71.316802</td>\n",
       "      <td>704.624478</td>\n",
       "      <td>1.067742</td>\n",
       "      <td>...</td>\n",
       "      <td>79.254899</td>\n",
       "      <td>1.019993</td>\n",
       "      <td>93.038666</td>\n",
       "      <td>1.309202</td>\n",
       "      <td>137.445766</td>\n",
       "      <td>282.275764</td>\n",
       "      <td>53.411418</td>\n",
       "      <td>112.660589</td>\n",
       "      <td>1.738538</td>\n",
       "      <td>3.557512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.094300</td>\n",
       "      <td>0.978977</td>\n",
       "      <td>1.576935</td>\n",
       "      <td>1.607581</td>\n",
       "      <td>0.738111</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>1.572903</td>\n",
       "      <td>74.017057</td>\n",
       "      <td>714.379538</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>...</td>\n",
       "      <td>76.548235</td>\n",
       "      <td>1.020851</td>\n",
       "      <td>92.050876</td>\n",
       "      <td>1.313030</td>\n",
       "      <td>142.459886</td>\n",
       "      <td>304.001915</td>\n",
       "      <td>56.515780</td>\n",
       "      <td>121.245848</td>\n",
       "      <td>1.749870</td>\n",
       "      <td>3.486990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.121361</td>\n",
       "      <td>0.827040</td>\n",
       "      <td>1.081613</td>\n",
       "      <td>1.104032</td>\n",
       "      <td>0.731042</td>\n",
       "      <td>-0.478889</td>\n",
       "      <td>1.483175</td>\n",
       "      <td>75.440865</td>\n",
       "      <td>733.438923</td>\n",
       "      <td>0.134687</td>\n",
       "      <td>...</td>\n",
       "      <td>80.272736</td>\n",
       "      <td>1.021529</td>\n",
       "      <td>91.585849</td>\n",
       "      <td>1.314522</td>\n",
       "      <td>131.167868</td>\n",
       "      <td>333.177687</td>\n",
       "      <td>54.170968</td>\n",
       "      <td>131.581336</td>\n",
       "      <td>1.733090</td>\n",
       "      <td>3.551627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^SP500TR     DGS10      DTB3    DGS3MO  MORTGAGE30US    DFII10  \\\n",
       "Unnamed: 0                                                                   \n",
       "2004-09-30  0.069088  1.541751  0.915645  0.935161      0.794281  1.692419   \n",
       "2004-12-31  0.032607  1.495879  0.916129  0.933710      0.788597  2.045645   \n",
       "2005-03-31 -0.003881  1.590695  1.078871  1.096129      0.797332  1.893750   \n",
       "2005-06-30  0.045642  1.544377  1.488281  1.513906      0.793859  1.690484   \n",
       "2005-09-30  0.010137  1.523840  2.011613  2.047419      0.791116  1.717705   \n",
       "...              ...       ...       ...       ...           ...       ...   \n",
       "2019-12-31 -0.003958  1.220122  2.388361  2.438525      0.760357  0.515873   \n",
       "2020-03-31 -0.032009  1.140147  2.304921  2.354762      0.749156  0.154219   \n",
       "2020-06-30  0.208827  0.980938  1.983594  2.026094      0.736517  0.153387   \n",
       "2020-09-30  0.094300  0.978977  1.576935  1.607581      0.738111 -0.063226   \n",
       "2020-12-31  0.121361  0.827040  1.081613  1.104032      0.731042 -0.478889   \n",
       "\n",
       "              T5YIFR  BAMLHYH0A0HYM2TRIV  BAMLCC0A1AAATRIV      DGS1  ...  \\\n",
       "Unnamed: 0                                                            ...   \n",
       "2004-09-30  2.458548           41.996715        352.547879  1.775484  ...   \n",
       "2004-12-31  2.634194           43.029175        362.683636  2.075000  ...   \n",
       "2005-03-31  2.481250           43.544771        354.851562  2.472742  ...   \n",
       "2005-06-30  2.410484           43.206397        363.761045  3.072459  ...   \n",
       "2005-09-30  2.453279           44.018290        370.418636  3.337344  ...   \n",
       "...              ...                 ...               ...       ...  ...   \n",
       "2019-12-31  1.944921           73.572146        637.862812  1.845000  ...   \n",
       "2020-03-31  1.834531           73.014092        662.025846  1.575806  ...   \n",
       "2020-06-30  1.755806           71.316802        704.624478  1.067742  ...   \n",
       "2020-09-30  1.572903           74.017057        714.379538  0.174286  ...   \n",
       "2020-12-31  1.483175           75.440865        733.438923  0.134687  ...   \n",
       "\n",
       "                  MRK      MSFT        NKE        PG         TRV         UNH  \\\n",
       "Unnamed: 0                                                                     \n",
       "2004-09-30  24.940498  0.966422   7.378963  1.252715   22.987969   27.550304   \n",
       "2004-12-31  24.109538  0.965952   7.352318  1.252347   24.251518   33.238478   \n",
       "2005-03-31  16.016526  0.968542   7.595334  1.252234   27.052105   37.703203   \n",
       "2005-06-30  16.911974  0.971730   8.632519  1.253729   27.104700   41.275508   \n",
       "2005-09-30  18.243953  0.970402   8.825318  1.254591   23.588805   44.026221   \n",
       "...               ...       ...        ...       ...         ...         ...   \n",
       "2019-12-31  79.716758  1.018707  82.613387  1.310248  117.868538  255.783684   \n",
       "2020-03-31  82.250245  1.019433  84.411047  1.309857  121.248230  269.978145   \n",
       "2020-06-30  79.254899  1.019993  93.038666  1.309202  137.445766  282.275764   \n",
       "2020-09-30  76.548235  1.020851  92.050876  1.313030  142.459886  304.001915   \n",
       "2020-12-31  80.272736  1.021529  91.585849  1.314522  131.167868  333.177687   \n",
       "\n",
       "                   VZ         WMT       WBA       DIS  \n",
       "Unnamed: 0                                             \n",
       "2004-09-30  12.984091   39.046941  1.623533  2.482302  \n",
       "2004-12-31  14.858189   36.890209  1.620360  2.447742  \n",
       "2005-03-31  14.630292   37.523092  1.619811  2.533420  \n",
       "2005-06-30  15.591040   36.719812  1.632797  2.586150  \n",
       "2005-09-30  16.741129   33.769871  1.638542  2.558298  \n",
       "...               ...         ...       ...       ...  \n",
       "2019-12-31  51.443717  109.754493  1.769093  3.600235  \n",
       "2020-03-31  52.873113  115.861732  1.736154  3.605762  \n",
       "2020-06-30  53.411418  112.660589  1.738538  3.557512  \n",
       "2020-09-30  56.515780  121.245848  1.749870  3.486990  \n",
       "2020-12-31  54.170968  131.581336  1.733090  3.551627  \n",
       "\n",
       "[66 rows x 91 columns]"
      ]
     },
     "execution_count": 1654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fb84f-111c-44f6-8fcc-7519b387e5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed, lambdas = transform_boxcox(Lagged_Differenced_Set_offset.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1658,
   "id": "abb40926-6979-4f9f-ad09-ed1f93c25a80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>^SP500TR</th>\n",
       "      <th>DGS10</th>\n",
       "      <th>DTB3</th>\n",
       "      <th>DGS3MO</th>\n",
       "      <th>MORTGAGE30US</th>\n",
       "      <th>DFII10</th>\n",
       "      <th>T5YIFR</th>\n",
       "      <th>BAMLHYH0A0HYM2TRIV</th>\n",
       "      <th>BAMLCC0A1AAATRIV</th>\n",
       "      <th>DGS1</th>\n",
       "      <th>...</th>\n",
       "      <th>MRK</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>NKE</th>\n",
       "      <th>PG</th>\n",
       "      <th>TRV</th>\n",
       "      <th>UNH</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WMT</th>\n",
       "      <th>WBA</th>\n",
       "      <th>DIS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-09-30</th>\n",
       "      <td>0.057999</td>\n",
       "      <td>4.285161</td>\n",
       "      <td>0.915645</td>\n",
       "      <td>0.935161</td>\n",
       "      <td>5.919286</td>\n",
       "      <td>1.692419</td>\n",
       "      <td>2.458548</td>\n",
       "      <td>471.486567</td>\n",
       "      <td>352.547879</td>\n",
       "      <td>1.775484</td>\n",
       "      <td>...</td>\n",
       "      <td>24.940498</td>\n",
       "      <td>17.041861</td>\n",
       "      <td>7.378963</td>\n",
       "      <td>34.063519</td>\n",
       "      <td>22.987969</td>\n",
       "      <td>27.550304</td>\n",
       "      <td>12.984091</td>\n",
       "      <td>39.046941</td>\n",
       "      <td>24.984413</td>\n",
       "      <td>19.556695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-12-31</th>\n",
       "      <td>0.029813</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>0.933710</td>\n",
       "      <td>5.597500</td>\n",
       "      <td>2.045645</td>\n",
       "      <td>2.634194</td>\n",
       "      <td>493.799545</td>\n",
       "      <td>362.683636</td>\n",
       "      <td>2.075000</td>\n",
       "      <td>...</td>\n",
       "      <td>24.109538</td>\n",
       "      <td>16.901527</td>\n",
       "      <td>7.352318</td>\n",
       "      <td>33.884191</td>\n",
       "      <td>24.251518</td>\n",
       "      <td>33.238478</td>\n",
       "      <td>14.858189</td>\n",
       "      <td>36.890209</td>\n",
       "      <td>24.579924</td>\n",
       "      <td>18.519040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-03-31</th>\n",
       "      <td>-0.003927</td>\n",
       "      <td>4.597097</td>\n",
       "      <td>1.078871</td>\n",
       "      <td>1.096129</td>\n",
       "      <td>6.106154</td>\n",
       "      <td>1.893750</td>\n",
       "      <td>2.481250</td>\n",
       "      <td>505.133968</td>\n",
       "      <td>354.851562</td>\n",
       "      <td>2.472742</td>\n",
       "      <td>...</td>\n",
       "      <td>16.016526</td>\n",
       "      <td>17.702574</td>\n",
       "      <td>7.595334</td>\n",
       "      <td>33.829297</td>\n",
       "      <td>27.052105</td>\n",
       "      <td>37.703203</td>\n",
       "      <td>14.630292</td>\n",
       "      <td>37.523092</td>\n",
       "      <td>24.510839</td>\n",
       "      <td>21.208334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-06-30</th>\n",
       "      <td>0.040415</td>\n",
       "      <td>4.301406</td>\n",
       "      <td>1.488281</td>\n",
       "      <td>1.513906</td>\n",
       "      <td>5.894286</td>\n",
       "      <td>1.690484</td>\n",
       "      <td>2.410484</td>\n",
       "      <td>497.681061</td>\n",
       "      <td>363.761045</td>\n",
       "      <td>3.072459</td>\n",
       "      <td>...</td>\n",
       "      <td>16.911974</td>\n",
       "      <td>18.790922</td>\n",
       "      <td>8.632519</td>\n",
       "      <td>34.566107</td>\n",
       "      <td>27.104700</td>\n",
       "      <td>41.275508</td>\n",
       "      <td>15.591040</td>\n",
       "      <td>36.719812</td>\n",
       "      <td>26.221627</td>\n",
       "      <td>23.071799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-09-30</th>\n",
       "      <td>0.009843</td>\n",
       "      <td>4.175806</td>\n",
       "      <td>2.011613</td>\n",
       "      <td>2.047419</td>\n",
       "      <td>5.736154</td>\n",
       "      <td>1.717705</td>\n",
       "      <td>2.453279</td>\n",
       "      <td>515.655821</td>\n",
       "      <td>370.418636</td>\n",
       "      <td>3.337344</td>\n",
       "      <td>...</td>\n",
       "      <td>18.243953</td>\n",
       "      <td>18.322877</td>\n",
       "      <td>8.825318</td>\n",
       "      <td>35.003092</td>\n",
       "      <td>23.588805</td>\n",
       "      <td>44.026221</td>\n",
       "      <td>16.741129</td>\n",
       "      <td>33.769871</td>\n",
       "      <td>27.033593</td>\n",
       "      <td>22.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>-0.004005</td>\n",
       "      <td>2.652951</td>\n",
       "      <td>2.388361</td>\n",
       "      <td>2.438525</td>\n",
       "      <td>4.373846</td>\n",
       "      <td>0.515873</td>\n",
       "      <td>1.944921</td>\n",
       "      <td>1384.913846</td>\n",
       "      <td>637.862812</td>\n",
       "      <td>1.845000</td>\n",
       "      <td>...</td>\n",
       "      <td>79.716758</td>\n",
       "      <td>123.989471</td>\n",
       "      <td>82.613387</td>\n",
       "      <td>117.793996</td>\n",
       "      <td>117.868538</td>\n",
       "      <td>255.783684</td>\n",
       "      <td>51.443717</td>\n",
       "      <td>109.754493</td>\n",
       "      <td>62.453910</td>\n",
       "      <td>137.410347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-31</th>\n",
       "      <td>-0.035486</td>\n",
       "      <td>2.338889</td>\n",
       "      <td>2.304921</td>\n",
       "      <td>2.354762</td>\n",
       "      <td>4.010769</td>\n",
       "      <td>0.154219</td>\n",
       "      <td>1.834531</td>\n",
       "      <td>1364.631385</td>\n",
       "      <td>662.025846</td>\n",
       "      <td>1.575806</td>\n",
       "      <td>...</td>\n",
       "      <td>82.250245</td>\n",
       "      <td>134.769845</td>\n",
       "      <td>84.411047</td>\n",
       "      <td>116.213096</td>\n",
       "      <td>121.248230</td>\n",
       "      <td>269.978145</td>\n",
       "      <td>52.873113</td>\n",
       "      <td>115.861732</td>\n",
       "      <td>48.962003</td>\n",
       "      <td>138.907687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-30</th>\n",
       "      <td>0.137470</td>\n",
       "      <td>1.797969</td>\n",
       "      <td>1.983594</td>\n",
       "      <td>2.026094</td>\n",
       "      <td>3.658462</td>\n",
       "      <td>0.153387</td>\n",
       "      <td>1.755806</td>\n",
       "      <td>1303.857231</td>\n",
       "      <td>704.624478</td>\n",
       "      <td>1.067742</td>\n",
       "      <td>...</td>\n",
       "      <td>79.254899</td>\n",
       "      <td>144.430752</td>\n",
       "      <td>93.038666</td>\n",
       "      <td>113.641568</td>\n",
       "      <td>137.445766</td>\n",
       "      <td>282.275764</td>\n",
       "      <td>53.411418</td>\n",
       "      <td>112.660589</td>\n",
       "      <td>49.787525</td>\n",
       "      <td>126.429677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-30</th>\n",
       "      <td>0.075139</td>\n",
       "      <td>1.791935</td>\n",
       "      <td>1.576935</td>\n",
       "      <td>1.607581</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>-0.063226</td>\n",
       "      <td>1.572903</td>\n",
       "      <td>1401.190606</td>\n",
       "      <td>714.379538</td>\n",
       "      <td>0.174286</td>\n",
       "      <td>...</td>\n",
       "      <td>76.548235</td>\n",
       "      <td>162.182739</td>\n",
       "      <td>92.050876</td>\n",
       "      <td>130.226242</td>\n",
       "      <td>142.459886</td>\n",
       "      <td>304.001915</td>\n",
       "      <td>56.515780</td>\n",
       "      <td>121.245848</td>\n",
       "      <td>54.004437</td>\n",
       "      <td>110.398254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>0.091881</td>\n",
       "      <td>1.365000</td>\n",
       "      <td>1.081613</td>\n",
       "      <td>1.104032</td>\n",
       "      <td>3.521538</td>\n",
       "      <td>-0.478889</td>\n",
       "      <td>1.483175</td>\n",
       "      <td>1453.914697</td>\n",
       "      <td>733.438923</td>\n",
       "      <td>0.134687</td>\n",
       "      <td>...</td>\n",
       "      <td>80.272736</td>\n",
       "      <td>179.525844</td>\n",
       "      <td>91.585849</td>\n",
       "      <td>137.858893</td>\n",
       "      <td>131.167868</td>\n",
       "      <td>333.177687</td>\n",
       "      <td>54.170968</td>\n",
       "      <td>131.581336</td>\n",
       "      <td>47.930033</td>\n",
       "      <td>124.996250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ^SP500TR     DGS10      DTB3    DGS3MO  MORTGAGE30US    DFII10  \\\n",
       "Unnamed: 0                                                                   \n",
       "2004-09-30  0.057999  4.285161  0.915645  0.935161      5.919286  1.692419   \n",
       "2004-12-31  0.029813  4.010000  0.916129  0.933710      5.597500  2.045645   \n",
       "2005-03-31 -0.003927  4.597097  1.078871  1.096129      6.106154  1.893750   \n",
       "2005-06-30  0.040415  4.301406  1.488281  1.513906      5.894286  1.690484   \n",
       "2005-09-30  0.009843  4.175806  2.011613  2.047419      5.736154  1.717705   \n",
       "...              ...       ...       ...       ...           ...       ...   \n",
       "2019-12-31 -0.004005  2.652951  2.388361  2.438525      4.373846  0.515873   \n",
       "2020-03-31 -0.035486  2.338889  2.304921  2.354762      4.010769  0.154219   \n",
       "2020-06-30  0.137470  1.797969  1.983594  2.026094      3.658462  0.153387   \n",
       "2020-09-30  0.075139  1.791935  1.576935  1.607581      3.700000 -0.063226   \n",
       "2020-12-31  0.091881  1.365000  1.081613  1.104032      3.521538 -0.478889   \n",
       "\n",
       "              T5YIFR  BAMLHYH0A0HYM2TRIV  BAMLCC0A1AAATRIV      DGS1  ...  \\\n",
       "Unnamed: 0                                                            ...   \n",
       "2004-09-30  2.458548          471.486567        352.547879  1.775484  ...   \n",
       "2004-12-31  2.634194          493.799545        362.683636  2.075000  ...   \n",
       "2005-03-31  2.481250          505.133968        354.851562  2.472742  ...   \n",
       "2005-06-30  2.410484          497.681061        363.761045  3.072459  ...   \n",
       "2005-09-30  2.453279          515.655821        370.418636  3.337344  ...   \n",
       "...              ...                 ...               ...       ...  ...   \n",
       "2019-12-31  1.944921         1384.913846        637.862812  1.845000  ...   \n",
       "2020-03-31  1.834531         1364.631385        662.025846  1.575806  ...   \n",
       "2020-06-30  1.755806         1303.857231        704.624478  1.067742  ...   \n",
       "2020-09-30  1.572903         1401.190606        714.379538  0.174286  ...   \n",
       "2020-12-31  1.483175         1453.914697        733.438923  0.134687  ...   \n",
       "\n",
       "                  MRK        MSFT        NKE          PG         TRV  \\\n",
       "Unnamed: 0                                                             \n",
       "2004-09-30  24.940498   17.041861   7.378963   34.063519   22.987969   \n",
       "2004-12-31  24.109538   16.901527   7.352318   33.884191   24.251518   \n",
       "2005-03-31  16.016526   17.702574   7.595334   33.829297   27.052105   \n",
       "2005-06-30  16.911974   18.790922   8.632519   34.566107   27.104700   \n",
       "2005-09-30  18.243953   18.322877   8.825318   35.003092   23.588805   \n",
       "...               ...         ...        ...         ...         ...   \n",
       "2019-12-31  79.716758  123.989471  82.613387  117.793996  117.868538   \n",
       "2020-03-31  82.250245  134.769845  84.411047  116.213096  121.248230   \n",
       "2020-06-30  79.254899  144.430752  93.038666  113.641568  137.445766   \n",
       "2020-09-30  76.548235  162.182739  92.050876  130.226242  142.459886   \n",
       "2020-12-31  80.272736  179.525844  91.585849  137.858893  131.167868   \n",
       "\n",
       "                   UNH         VZ         WMT        WBA         DIS  \n",
       "Unnamed: 0                                                            \n",
       "2004-09-30   27.550304  12.984091   39.046941  24.984413   19.556695  \n",
       "2004-12-31   33.238478  14.858189   36.890209  24.579924   18.519040  \n",
       "2005-03-31   37.703203  14.630292   37.523092  24.510839   21.208334  \n",
       "2005-06-30   41.275508  15.591040   36.719812  26.221627   23.071799  \n",
       "2005-09-30   44.026221  16.741129   33.769871  27.033593   22.066300  \n",
       "...                ...        ...         ...        ...         ...  \n",
       "2019-12-31  255.783684  51.443717  109.754493  62.453910  137.410347  \n",
       "2020-03-31  269.978145  52.873113  115.861732  48.962003  138.907687  \n",
       "2020-06-30  282.275764  53.411418  112.660589  49.787525  126.429677  \n",
       "2020-09-30  304.001915  56.515780  121.245848  54.004437  110.398254  \n",
       "2020-12-31  333.177687  54.170968  131.581336  47.930033  124.996250  \n",
       "\n",
       "[66 rows x 91 columns]"
      ]
     },
     "execution_count": 1658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "revert_yeo(Lagged_Differenced_Set_offset, transformed, lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1422b2e-d8e4-43aa-a691-8c54392a6291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c72722f-fbff-4bff-92b8-26b19888e415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "8cc90237-f851-4afb-86f8-2dca0b41123d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cbd = True\n",
    "ic = True\n",
    "\n",
    "# evaluate an elastic net model on the dataset\n",
    "#tsize = .20\n",
    "#train, test = train_test_split(Lagged_Differenced_Set_offset.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "train, test = train_test_split(transformed.iloc[:,0:], test_size=tsize, shuffle=False)\n",
    "\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=ic)\n",
    "\n",
    "#train_t, lambdas_t = transform_boxcox(train)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    train_t = train\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(train_t)\n",
    "\n",
    "#\n",
    "train_s = pd.DataFrame(scaler.transform(train_t))\n",
    "train_s.columns = train.columns\n",
    "train_s.index = train.index  \n",
    "\n",
    "train_t = train_s\n",
    "\n",
    "#test_t = transform_boxcox_l(test, lambdas_t)\n",
    "\n",
    "#disabled boxcox\n",
    "if cbd:\n",
    "    test_t = test\n",
    "\n",
    "test_s = pd.DataFrame(scaler.transform(test_t))\n",
    "test_s.columns = test.columns\n",
    "test_s.index = test.index\n",
    "\n",
    "test_t = test_s\n",
    "\n",
    "y_train = pd.DataFrame(train_t.iloc[:,0])\n",
    "\n",
    "#exclude y\n",
    "\n",
    "X_inter_train = pd.DataFrame(interaction.fit_transform(train_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_t.iloc[:,1:]).columns))\n",
    "\n",
    "    #apply ZCA each time a set of factors are removed (i.e. iteratively)\n",
    " #trf = zca.ZCA().fit(X_inter_train)\n",
    "  #trf = zca.ZCA().fit(X_train)\n",
    "\n",
    " #X_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "  #X_train = pd.DataFrame(trf.transform(X_train))\n",
    " #X_train.columns=X_inter_train.columns\n",
    "  #X_train.columns=X_train.columns\n",
    "  #X_train.index = train.index\n",
    "\n",
    "#X_inter_alt = X_train.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#print(X_inter_alt.head(3))\n",
    "\n",
    "y_test = pd.DataFrame(test_t.iloc[:,0])\n",
    "\n",
    "X_inter_test = pd.DataFrame(interaction.fit_transform(test_t.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(test_t.iloc[:,1:]).columns))\n",
    "\n",
    " #X_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "  #X_test = pd.DataFrame(trf.transform(X_test))\n",
    "\n",
    " #X_test.columns=X_inter_test.columns\n",
    "  #X_test.columns=X_test.columns\n",
    "  #X_test.index = test.index\n",
    "\n",
    "#X_inter_t_alt = X_test.iloc[:, np.array(range(0,len(all_data.iloc[:,2:].columns)))]\n",
    "#X_inter_t_alt.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcf46d0-1162-46d6-a166-0461b321e0c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "\n",
    " #model = ElasticNetCV(l1_ratio=ratios, alphas=alphas, cv=cv, n_jobs=4, verbose=0, precompute='auto')\n",
    "\n",
    "model = ElasticNet()\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "#search = HalvingRandomSearchCV(model, grid,resource='n_samples',max_resources=10,random_state=0)\n",
    "\n",
    "search = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    " #results = search.fit(X_inter_train, y_train)\n",
    "#results = search.fit(X_train, y_train)\n",
    "\n",
    "results = search.fit(X_inter_train, y_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results.best_score_)\n",
    "print('Config: %s' % results.best_params_)\n",
    "\n",
    "print(results.best_estimator_)\n",
    "best_model = ElasticNet(alpha=results.best_estimator_.alpha, l1_ratio = results.best_estimator_.l1_ratio)\n",
    "\n",
    "#pd.concat([all_data[Y],all_data_int],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebb7965-c50b-4f1e-bd5e-05504a69192f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_inter_train,train_t.iloc[:,0])\n",
    "\n",
    "trainScore = best_model.score(X_inter_train, y_train, sample_weight=None)\n",
    "testScore = best_model.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore)\n",
    "print(testScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb694fa2-0e07-4a01-8648-2d6615a70b84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "093a64f9-522d-4761-adf1-f55d566a1b70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b12fd-2b69-4243-909a-6f828aa43b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "id": "0e86999a-16ba-4505-b5ec-843d219ac62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.538462\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367906e7-5aec-4529-8f29-42040e9ac43d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1552,
   "id": "14400790-a56a-4084-8c56-cf73697546e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03928334382719691\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.8323698710372744, pvalue=0.4152951008847169)\n",
      "0.026389773294391506\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-0.9656230696732769, pvalue=0.34336454282654105)\n"
     ]
    }
   ],
   "source": [
    "#classification transforms\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_score\n",
    "interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import random\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import SVMSMOTE \n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#set_ = Lagged_Differenced_Set_offset.copy()\n",
    "#set_ = transformed.copy()\n",
    "#DF_list = list()\n",
    "\n",
    "sets = list()\n",
    "sets.append(transformed.copy())\n",
    "sets.append(Lagged_Differenced_Set_offset.copy())\n",
    "\n",
    "def return_sets(sets):    \n",
    "    \n",
    "    sets_outer = list()\n",
    "    \n",
    "    for i in sets:\n",
    "        \n",
    "        sets_multiple = list()\n",
    "        \n",
    "        set_ = pd.DataFrame()\n",
    "        set_ = i\n",
    "\n",
    "        X, y = set_.iloc[:,1:],  set_.iloc[:,0]\n",
    "        \n",
    "        print(mean(y))\n",
    "\n",
    "        y = pd.DataFrame(np.where(y > mean(y), 1, 0))\n",
    "        y.index = set_.index\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=tsize, shuffle=False)\n",
    "\n",
    "        a = set_.iloc[:,0].loc[X_train.index]\n",
    "        b = set_.iloc[:,0].loc[X_test.index]\n",
    "        plt.hist(a)\n",
    "        plt.show()\n",
    "        plt.hist(b)\n",
    "        plt.show()\n",
    "        print(stats.ttest_ind(a,b, equal_var = False))\n",
    "\n",
    "        one = y_train[y_train==0].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "        two = y_train[y_train==1].dropna().sample(int(len(X_train)*2), replace=True, random_state=1)\n",
    "\n",
    "        train_index = np.append(one.index,two.index)\n",
    "\n",
    "        #destroyed my data\n",
    "        #smote = SVMSMOTE(random_state=42)\n",
    "            #smote = SMOTE()\n",
    "        #Xsm_train, ysm_train = smote.fit_sample(np.array(X_train),np.array(y_train))\n",
    "\n",
    "        Xsm_train = X_train.copy()\n",
    "        ysm_train = y_train.copy()\n",
    "        \n",
    "        #use with optimal lags\n",
    "        #y_test = y_test.loc[y_test.index>y_test.index[maxl]]\n",
    "        #X_test = X_test.loc[X_test.index>X_test.index[maxl]]\n",
    "\n",
    "        scaler = preprocessing.StandardScaler().fit(Xsm_train)\n",
    "\n",
    "        X_train_transformed = pd.DataFrame(scaler.transform(Xsm_train))\n",
    "        X_train_transformed.columns = X_train.columns\n",
    "\n",
    "        X_inter_train = X_train_transformed.copy()\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(interaction.fit_transform(X_train_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_train_transformed).columns))\n",
    "\n",
    "        trf = zca.ZCA().fit(X_inter_train)\n",
    "\n",
    "        #X_inter_train = pd.DataFrame(trf.transform(X_inter_train))\n",
    "        X_inter_train.columns=pd.DataFrame(X_inter_train).columns\n",
    "        #X_inter_train.index = X_train.loc[train_index].index\n",
    "\n",
    "        X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "        X_test_transformed.columns = X_test.columns\n",
    "        X_test_transformed.index = X_test.index\n",
    "\n",
    "        X_inter_test = X_test_transformed\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(interaction.fit_transform(X_test_transformed), columns=interaction.get_feature_names(input_features=pd.DataFrame(X_test_transformed).columns))\n",
    "\n",
    "        #X_inter_test = pd.DataFrame(trf.transform(X_inter_test))\n",
    "\n",
    "        sets_multiple.append(X_inter_train)\n",
    "        sets_multiple.append(y_train)\n",
    "        sets_multiple.append(X_inter_test)\n",
    "        sets_multiple.append(y_test)        \n",
    "    \n",
    "        sets_outer.append(sets_multiple)\n",
    "        \n",
    "    return(sets_outer)\n",
    "\n",
    "values = return_sets(sets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568baa66-4a53-4f23-ba8a-c5f9408f1591",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "id": "73ec310d-7f86-4154-be9b-11c927a6a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1553,
   "id": "e560215f-9b7d-4d76-ac61-dbf96d2cfd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.52 accuracy with a standard deviation of 0.12\n",
      "0.42857142857142855\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "0.46 accuracy with a standard deviation of 0.20\n",
      "0.6428571428571429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "#works best\n",
    "#class balanced, no zca\n",
    "from sklearn import svm\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    clf = svm.SVC(kernel='rbf', C=1, random_state=42)\n",
    "\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "\n",
    "    print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "\n",
    "    clf = svm.SVC(C=1).fit(X_train, y_train)\n",
    "\n",
    "    train_predict = clf.predict(X_train)\n",
    "    predicteds = clf.predict(X_test)\n",
    "    #predicted.index = y_test.index\n",
    "\n",
    "    print(clf.score(X_test, y_test))\n",
    "\n",
    "    #clf.predict(X_test)\n",
    "    #print(predicteds)\n",
    "    print(metrics.classification_report(y_test,predicteds))\n",
    "    print(metrics.confusion_matrix(y_test,predicteds))\n",
    "\n",
    "    predictions_s = arfima_adjust(y_train, y_test, train_predict, predicteds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "id": "ec38a51f-ede1-47bb-9af7-ee25b6106160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25944973-ee0b-4b74-be6c-f59463229bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c39fe4e-d604-4fa9-ad81-ee7a53a06784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "id": "3909eb8a-645f-47c5-933a-98d61f3d6ab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9285714285714286"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('scaler', StandardScaler()),('svc', svm.SVC(kernel='sigmoid', C=1, random_state=42))])\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_test, y_test)\n",
    "'''\n",
    "#search = cross_val_score(pipe, X_inter_train, y_train.loc[train_index], cv=10)\n",
    "#GridSearchCV(pipe, param_grid, n_jobs=-1)\n",
    "#search.fit(X_digits, y_digits)\n",
    "#print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "#print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "d83b6ec4-6148-41ba-9d1b-3765f913ee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0]"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1554,
   "id": "b49b4466-cd31-4f19-85e0-c32db62dbe01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "LogisticRegression()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#Logistic1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modell = LogisticRegression()\n",
    "    modell.fit(X_train, y_train)\n",
    "    print(modell)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modell.predict(X_train)\n",
    "    predictedl = modell.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictedl))\n",
    "    print(metrics.confusion_matrix(y_test,predictedl))\n",
    "    \n",
    "    predictions_l = arfima_adjust(y_train, y_test, train_predict, predictedl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1555,
   "id": "7672895b-f442-45b4-8cb1-3257e8c830a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67         6\n",
      "           1       0.80      0.50      0.62         8\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.68      0.67      0.64        14\n",
      "weighted avg       0.70      0.64      0.64        14\n",
      "\n",
      "[[5 1]\n",
      " [4 4]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67         6\n",
      "           1       0.80      0.50      0.62         8\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.68      0.67      0.64        14\n",
      "weighted avg       0.70      0.64      0.64        14\n",
      "\n",
      "[[5 1]\n",
      " [4 4]]\n",
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "[1] 52\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeln = GaussianNB()\n",
    "    modeln.fit(X_train, y_train)\n",
    "    print(modeln)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeln.predict(X_train)\n",
    "    predictedn = modeln.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictedn))\n",
    "    print(metrics.confusion_matrix(y_test,predictedn))\n",
    "    \n",
    "    predictions_n = arfima_adjust(y_train, y_test, train_predict, predictedn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1556,
   "id": "644b63d8-9f6e-453e-b896-0ee262d1242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "DecisionTreeClassifier()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53         5\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.18      0.50      0.26        14\n",
      "weighted avg       0.13      0.36      0.19        14\n",
      "\n",
      "[[5 0]\n",
      " [9 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53         5\n",
      "           1       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.36        14\n",
      "   macro avg       0.18      0.50      0.26        14\n",
      "weighted avg       0.13      0.36      0.19        14\n",
      "\n",
      "[[5 0]\n",
      " [9 0]]\n"
     ]
    }
   ],
   "source": [
    "#DecisionTreeClassifier\n",
    "#works best with transformed\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "\n",
    "    modeld = DecisionTreeClassifier()\n",
    "    modeld.fit(X_train, y_train)\n",
    "    print(modeld)\n",
    "\n",
    "    #expected = y_test\n",
    "    train_predict = modeld.predict(X_train)\n",
    "    predictedd = modeld.predict(X_test)\n",
    "\n",
    "    print(metrics.classification_report(y_test,predictedd))\n",
    "    print(metrics.confusion_matrix(y_test,predictedd))\n",
    "        \n",
    "    predictions_d = arima_adjust(y_train, y_test, train_predict, predictedd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1557,
   "id": "6ce0671f-8931-4f7e-936b-51adcb52dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 14}\n",
      "0.5381818181818182\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      1.00      0.60         6\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.43        14\n",
      "   macro avg       0.21      0.50      0.30        14\n",
      "weighted avg       0.18      0.43      0.26        14\n",
      "\n",
      "[[6 0]\n",
      " [8 0]]\n",
      "{'n_neighbors': 1}\n",
      "0.5327272727272728\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n",
      "[[0 5]\n",
      " [0 9]]\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "#works best with transformed\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV#create new a knn model\n",
    "\n",
    "for i in range(0,len(sets)):\n",
    "    \n",
    "    X_train = values[i][0]\n",
    "    y_train = values[i][1]\n",
    "    X_test = values[i][2]\n",
    "    y_test = values[i][3]\n",
    "    \n",
    "    knn2 = KNeighborsClassifier(metric='euclidean',weights='distance')#create a dictionary of all values we want to test for n_neighbors\n",
    "    param_grid = {'n_neighbors': np.arange(1, 25)}#use gridsearch to test all values for n_neighbors\n",
    "    knn_gscv = GridSearchCV(knn2, param_grid, cv=5)#fit model to data\n",
    "    knn_gscv.fit(X_train, y_train)\n",
    "    #check top performing n_neighbors value\n",
    "    print(knn_gscv.best_params_)\n",
    "    #check mean score for the top performing value of n_neighbors\n",
    "    print(knn_gscv.best_score_)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors = knn_gscv.best_params_['n_neighbors'],metric='euclidean',weights='distance')\n",
    "    knn.fit(X_train,y_train)\n",
    "    train_predict = knn.predict(X_train)\n",
    "    predictedk = knn.predict(X_test)\n",
    "    knn.score(X_test, y_test)\n",
    "\n",
    "    print(confusion_matrix(y_test, predictedk))\n",
    "    print(classification_report(y_test, predictedk))\n",
    "    \n",
    "    predictions_k = arima_adjust(y_train, y_test, train_predict, predictedk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43107e46-54bb-4837-a798-af32efaccadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "e55c7caf-0c3b-4911-ba58-8313a7ba85ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-771-d7e137a3e15d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msearch_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mresults_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_inter_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mysm_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m  \u001b[0;31m#model.fit(X_inter_train, y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/distvol/Python-3.9.4/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "#Elastic logistic\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1)\n",
    "# define model\n",
    "ratios = arange(0, 1, 0.01)\n",
    "alphas = (10 ** np.linspace(-1, 1, 10))/10\n",
    "alphas = np.append(alphas,[10.0, 100.0])\n",
    "\n",
    "model = SGDClassifier(loss=\"log\", penalty=\"elasticnet\")\n",
    "grid = dict()\n",
    "# fit model\n",
    "\n",
    "grid['alpha'] = alphas\n",
    "grid['l1_ratio'] = ratios\n",
    "\n",
    "search_l = GridSearchCV(model, grid, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "\n",
    "results_l = search_l.fit(X_inter_train, ysm_train)\n",
    "\n",
    " #model.fit(X_inter_train, y_train)\n",
    "# summarize chosen configuration\n",
    "\n",
    "print('MAE: %.3f' % results_l.best_score_)\n",
    "print('Config: %s' % results_l.best_params_)\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "print(results_l.best_estimator_)\n",
    "best_model_l = SGDClassifier(alpha=results_l.best_estimator_.alpha, l1_ratio = results_l.best_estimator_.l1_ratio)\n",
    "\n",
    "#calibrator = CalibratedClassifierCV(best_model_l, cv='prefit')\n",
    "#model=calibrator.fit(X_inter_train, y_train)\n",
    "\n",
    "best_model_l.fit(X_inter_train,ysm_train)\n",
    "\n",
    "#sgd = SGDClassifier()\n",
    "\n",
    "#sgd.partial_fit(X_inter_train,y_train, classes=[0,1])\n",
    "\n",
    "print(pd.DataFrame(np.transpose(best_model_l.coef_)).set_index(X_inter_train.columns))\n",
    "\n",
    "trainScore_l = best_model_l.score(X_inter_train, ysm_train, sample_weight=None)\n",
    "testScore_l = best_model_l.score(X_inter_test, y_test, sample_weight=None)\n",
    "print(trainScore_l)\n",
    "print(testScore_l)\n",
    "\n",
    "#print(help(KNeighborsClassifier))\n",
    "predictedl = best_model_l.predict(X_inter_test)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b9087-fe22-4d54-b152-a40e48784774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1559,
   "id": "7015d3fd-f35c-4f6c-b8e9-f66c92514715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.642857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 1559,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1558,
   "id": "a6dd1212-7817-4f74-95d6-0493d68c9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            s  k  d  l  n\n",
      "Unnamed: 0               \n",
      "2017-09-30  1  1  0  1  1\n",
      "2017-12-31  1  1  0  1  1\n",
      "2018-03-31  1  1  0  1  1\n",
      "2018-06-30  1  1  0  1  1\n",
      "2018-09-30  1  1  0  1  1\n",
      "2018-12-31  1  1  0  1  1\n",
      "2019-03-31  1  1  0  1  1\n",
      "2019-06-30  1  1  0  1  1\n",
      "2019-09-30  1  1  0  1  1\n",
      "2019-12-31  1  1  0  1  1\n",
      "2020-03-31  1  1  0  1  1\n",
      "2020-06-30  1  1  0  1  1\n",
      "2020-09-30  1  1  0  1  1\n",
      "2020-12-31  1  1  0  1  1\n",
      "[[0 5]\n",
      " [0 9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.64      1.00      0.78         9\n",
      "\n",
      "    accuracy                           0.64        14\n",
      "   macro avg       0.32      0.50      0.39        14\n",
      "weighted avg       0.41      0.64      0.50        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from matplotlib import pyplot\n",
    "\n",
    "#predictedf = pd.concat([pd.DataFrame(predicteds),pd.DataFrame(predictedk),pd.DataFrame(predictedl)],axis=1)\n",
    "predictedf = pd.concat([pd.DataFrame(predictions_s),pd.DataFrame(predictions_k),pd.DataFrame(predictions_d),pd.DataFrame(predictions_l),pd.DataFrame(predictions_n)],axis=1)\n",
    "predictedf.columns = [\"s\",\"k\",\"d\",\"l\",\"n\"]\n",
    "predictedf.index = y_test.index\n",
    "print(predictedf)\n",
    "print(confusion_matrix(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(confusion_matrix(y_test, predictedf.median(axis=1)))\n",
    "print(classification_report(y_test, predictedf.mode(axis=1).iloc[:,0]))\n",
    "#print(classification_report(y_test, predictedf.median(axis=1)))\n",
    "\n",
    "print(mean(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438843e-110f-404f-b1b1-47bfa41b560b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1662,
   "id": "0e4dfc37-ab80-427f-bc37-edb9a212c4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The null hypothesis can be rejected\n",
      "7.647058971104165\n",
      "The null hypothesis can be rejected\n",
      "-0.12139720840982086\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.14868039412503942\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.23878868189827293\n",
      "The null hypothesis can be rejected\n",
      "0.01516434729523354\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.2847277093485631\n",
      "The null hypothesis can be rejected\n",
      "-4.421694760735331\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "2.379278265484282\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-4.252299469731882\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-3.8750570260104618\n",
      "The null hypothesis can be rejected\n",
      "-1.477240085595318\n",
      "The null hypothesis can be rejected\n",
      "-1.315225728518115\n",
      "The null hypothesis can be rejected\n",
      "-0.9987736214675152\n",
      "The null hypothesis can be rejected\n",
      "-1.7324607073327576\n",
      "The null hypothesis can be rejected\n",
      "-0.8487769134133378\n",
      "The null hypothesis can be rejected\n",
      "0.1281776304697414\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.9185081117430298\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-4.421694760735331\n",
      "The null hypothesis can be rejected\n",
      "-0.5767439075762518\n",
      "The null hypothesis can be rejected\n",
      "-0.42795074132531136\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.0147949530506908\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.04314234607975888\n",
      "The null hypothesis can be rejected\n",
      "6.379681876399842\n",
      "The null hypothesis can be rejected\n",
      "1.1825414039192585\n",
      "The null hypothesis can be rejected\n",
      "0.019329072245510122\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.6634548740163803\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.4039131599019467\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.7421303146126871\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.20335783324970835\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "0.8010834349067987\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.8714420624498441\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-1.2638528728567444\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis can be rejected\n",
      "-0.4225012072622937\n",
      "The null hypothesis can be rejected\n",
      "-0.33062861855368403\n",
      "The null hypothesis can be rejected\n",
      "-1.0710162934558154\n",
      "The null hypothesis cannot be rejected\n",
      "The null hypothesis cannot be rejected\n",
      "67\n",
      "33\n",
      "34\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# multivariate output multi-step 1d cnn example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "from keras.optimizers import SGD\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Lagged_Differenced_Set = (all_data - all_data.shift(-1)).dropna()\n",
    "choice = Lagged_Differenced_Set\n",
    "\n",
    "train, test = train_test_split(choice, test_size=tsize, shuffle=False)\n",
    "\n",
    "transformed_train, lambdas_ = transform_boxcox(train)\n",
    "\n",
    "transformed_test = transform_boxcox_l(test, lambdas_)\n",
    "\n",
    "#train_t, lambdas_t = transform_boxcox(train)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(transformed_train)\n",
    "\n",
    "train_s = pd.DataFrame(scaler.transform(train))\n",
    "test_s = pd.DataFrame(scaler.transform(transformed_test))\n",
    "\n",
    "combined = pd.concat([train_s,test_s],axis=0)\n",
    "combined.index = Lagged_Differenced_Set.index\n",
    "combined.columns = Lagged_Differenced_Set.columns\n",
    "\n",
    "set_ = combined\n",
    "\n",
    "def plot_learning_curves(loss, val_loss):\n",
    "    plt.plot(np.arange(len(loss)) + 0.5, loss, \"b.\", label=\"Training loss\")\n",
    "    plt.plot(np.arange(len(val_loss)) + 1, val_loss, \"r-\", label=\"Validation loss\")\n",
    "    plt.gca().xaxis.set_major_locator(mpl.ticker.MaxNLocator(integer=True))\n",
    "    plt.legend(fontsize=14)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out, xcolumns, ycolumns):\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, xcolumns], sequences[end_ix:out_end_ix, ycolumns]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return array(X), array(y)\n",
    "\n",
    "#n_steps_in = int(np.floor(len(train)*.8))\n",
    "print(len(set_))\n",
    "n_steps_in = int(np.round(len(set_)/2))\n",
    "print(len(set_) - n_steps_in)\n",
    "print(n_steps_in)\n",
    "#n_steps_out = int(len(train)-n_steps_in)\n",
    "n_steps_out = 1\n",
    "print(n_steps_out)\n",
    "\n",
    "#ycolumns = range(0,len(transformed.columns))\n",
    "ycolumns = range(0,len(set_.columns[0:1].values))\n",
    "xcolumns = range(1,len(set_.columns[1:]))\n",
    "\n",
    "#trainInner, valid = train_test_split(trainOuter, test_size=0.15, shuffle=False)\n",
    "#trainInner_whitened = pd.DataFrame(trf.transform(trainInner.iloc[:,1:])).set_index(trainInner.index)\n",
    "#valid_whitened = pd.DataFrame(trf.transform(valid.iloc[:,1:])).set_index(valid.index)\n",
    "#test_whitened = pd.DataFrame(trf.transform(test.iloc[:,1:])).set_index(test.index)\n",
    "\n",
    "#trainOuter_whitened=pd.DataFrame(trf.transform(trainOuter.iloc[:,1:])).set_index(trainOuter.index)\n",
    "\n",
    "X, y = split_sequences(np.array(set_), n_steps_in, n_steps_out, xcolumns, ycolumns)\n",
    "\n",
    "#for i in range(len(X)):\n",
    "#    print(X[i], y[i])\n",
    "    \n",
    "#flatten output\n",
    "\n",
    "if len(ycolumns) > 0:\n",
    "    n_output = y.shape[1] * y.shape[2]\n",
    "    y = y.reshape((y.shape[0], n_output))\n",
    "\n",
    "n_features = X.shape[2]\n",
    "\n",
    "# define model\n",
    "modelCNN = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(n_steps_in, n_features)),\n",
    "    keras.layers.MaxPooling1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(50, activation='relu'),\n",
    "    keras.layers.Dense(n_output)\n",
    "])\n",
    "\n",
    "# fit model\n",
    "#model.fit(X, y, epochs=7000, verbose=0)\n",
    "\n",
    "epochs_ = 2000\n",
    "batch_size_ = 25\n",
    "\n",
    "#np.random.seed(42)\n",
    "#tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "#model.compile(optimizer='adam', loss='mse')\n",
    "modelCNN.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "#X_train_transformed = pd.DataFrame(scaler.transform(X_train))\n",
    "#X_train_transformed.columns = X_train.columns\n",
    "\n",
    "#X_test_transformed = pd.DataFrame(scaler.transform(X_test))\n",
    "#X_test_transformed.columns = X_test.columns\n",
    "#X_test_transformed.index = X_test.index\n",
    "\n",
    "    #new_series = pd.DataFrame(ts_train_scaled).append(pd.DataFrame(ts_valid_scaled)).append(pd.DataFrame(ts_test_scaled))\n",
    "\n",
    "    #series_reshaped = np.array([new_series[i:i + (n_steps+n_ahead)].copy() for i in range(len(data) - (n_steps+n_ahead))])  \n",
    "    \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train,\n",
    "                                                    test_size=tsize,\n",
    "                                                    shuffle = False)\n",
    "                                                    #random_state=42)    \n",
    "\n",
    "#model6.compile(loss=\"MAPE\", optimizer=\"rmsprop\",metrics=['MAPE'])\n",
    "historyCNN = modelCNN.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history6 = model6.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,validation_data=(X_valid, y_valid), verbose=0)\n",
    "#history = model.fit(X_train, y_train, epochs=epochs_,batch_size=batch_size_,verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1663,
   "id": "d2d1ce87-6c86-4308-8788-b01aa8256fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to apply to test\n",
    "#revert_boxcox(pd.DataFrame(transformed_.iloc[:,0]),pd.DataFrame(lambdas[0]))\n",
    "#Lagged_Differenced_Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1664,
   "id": "0b8f7e2d-3603-4ba1-8457-4fd9918498a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "plot_learning_curves(historyCNN.history[\"loss\"], historyCNN.history[\"val_loss\"])\n",
    "plt.show()\n",
    "#plot_learning_curves(history6.history[\"loss\"], history.history[\"val_loss\"])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1576,
   "id": "799f6d94-9757-4baa-b095-8937fbba5857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.403554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.472922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.395263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.648622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.333758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-12.124576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.782852</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0   0.403554\n",
       "1  -1.472922\n",
       "2  -2.395263\n",
       "3  -2.648622\n",
       "4  -2.333758\n",
       "5 -12.124576\n",
       "6  25.782852"
      ]
     },
     "execution_count": 1576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "id": "bee4c952-450d-43d4-86c1-2a37673a58d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 1689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(revert_transformed_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1690,
   "id": "c2cbc3da-fa1f-4e57-9d84-f4e5f8872af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.031267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.047498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.032469</td>\n",
       "      <td>-0.004005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.035486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.234481</td>\n",
       "      <td>0.137470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.110422</td>\n",
       "      <td>0.075139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.032469</td>\n",
       "      <td>0.091881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted  original\n",
       "0   0.032469  0.031267\n",
       "1   0.032469  0.047498\n",
       "2   0.032469 -0.004005\n",
       "3        NaN -0.035486\n",
       "4   0.234481  0.137470\n",
       "5   0.110422  0.075139\n",
       "6   0.032469  0.091881"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#multi\n",
    "yhat = modelCNN.predict(X_test, verbose=0)\n",
    "\n",
    "predicted = []\n",
    "original = []\n",
    "if len(ycolumns) > 1:\n",
    "    results = yhat.reshape(len(y_test), int(yhat.shape[1]/X_test.shape[2]), len(transformed.columns))\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(pd.DataFrame(results[i])[0][0])\n",
    "        original.append(pd.DataFrame(y_test[i])[0][0])\n",
    "        #print(pd.DataFrame(results[i])[0][0])\n",
    "        #print(pd.DataFrame(y_test[i])[0][0])\n",
    "else:\n",
    "    results = yhat\n",
    "    for i in range(0,len(results)):\n",
    "        predicted.append(results[i])\n",
    "        original.append(y_test[i])\n",
    "        #print(pd.DataFrame(results[i]))\n",
    "        #print(pd.DataFrame(y_test[i]))\n",
    "        \n",
    "revert_transformed_predicted = inverse_yeo((scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted)).values,(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(predicted)).values,lambdas_.values[0])\n",
    "revert_transformed_original = inverse_yeo((scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original)).values,(scaler.mean_[0]+scaler.scale_[0]*pd.DataFrame(original)).values,lambdas_.values[0])\n",
    "plt.scatter(revert_transformed_predicted,revert_transformed_original)\n",
    "temp = pd.concat([revert_transformed_predicted,revert_transformed_original],axis=1)\n",
    "temp.columns = [\"predicted\", \"original\"]\n",
    "display(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8229628-eed4-4b76-831d-1de033240347",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef = pd.DataFrame(best_model.coef_).set_index(X_inter_train.columns)\n",
    "\n",
    "a_coef = abs(coef)\n",
    "a_coef.sort_values(by=[0],ascending=False,inplace=True)\n",
    "chosen_few = a_coef[a_coef>0].dropna().index.values\n",
    "\n",
    "scaler_ = preprocessing.StandardScaler().fit(transformed)\n",
    "\n",
    "#\n",
    "train_ = pd.DataFrame(scaler_.transform(transformed))\n",
    "train_.columns = transformed.columns\n",
    "train_.index = transformed.index  \n",
    "\n",
    "X_inter_train_ = pd.DataFrame(interaction.fit_transform(train_.iloc[:,1:]), columns=interaction.get_feature_names(input_features=pd.DataFrame(train_.iloc[:,1:]).columns))\n",
    "\n",
    "max_pvalue = 1\n",
    "New_Names = X_inter_train.columns\n",
    "X_b = X_inter_train_[chosen_few]\n",
    "while (max_pvalue > .05):\n",
    "        \n",
    "    trf = zca.ZCA().fit(X_b)\n",
    "        \n",
    "    X_b_z = pd.DataFrame(trf.transform(X_b))\n",
    "    X_b_z.columns=pd.DataFrame(X_b).columns\n",
    "    X_b_z.index = train_.index\n",
    "\n",
    "    model_ = sm.OLS(train_.iloc[:,0],sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    #model_ = sm.OLS(pd.DataFrame(pd.concat([train_.iloc[:,0],X_b_z],axis=1),sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip'))        \n",
    "    results_ = model_.fit()\n",
    "\n",
    "    set_ = X_b.columns.tolist()\n",
    "    \n",
    "    max_pvalue = max(results_.pvalues[1:])\n",
    "    if (max_pvalue > .05):\n",
    "        print(max_pvalue)\n",
    "        max_pname = (results_.pvalues[1:]).idxmax(axis=1)\n",
    "        set_.remove(max_pname)\n",
    "        New_Names = set_\n",
    "    \n",
    "        X_b = X_inter_train_[New_Names]\n",
    "        X_b.index = X_inter_train_.index\n",
    "\n",
    "#from statsmodels.formula.api import ols\n",
    "#lm = ols(pd.DataFrame(train_.iloc[:,0]) ~ sm.tools.tools.add_constant(X_b_z, prepend=True, has_constant='skip')).fit()\n",
    "#table = sm.stats.anova_lm(model_, type=3)\n",
    "#print(table)\n",
    "print(results_.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e428c-cce9-46e3-b145-754fc9e4c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNaNCols(df_):\n",
    "    for col in df_:        \n",
    "        num_NaNs = df_[col].isnull().sum()\n",
    "        if num_NaNs > 0:\n",
    "            print(f\"Column: {col}\")\n",
    "            print(f\"Number of NaNs: {num_NaNs}\")\n",
    "\n",
    "findNaNCols(X_b_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d4e220-4ac2-4945-9e3a-4b8ff1355a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d940860-86d6-4768-81a0-63f9127143a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "linear_plot = Plot.LinearRegressionResidualPlot(X_b_z, pd.DataFrame(train_.iloc[:,0]))\n",
    "lm = linear_plot.fit()\n",
    "summary, diag_res = linear_plot.diagnostic_plots(lm)\n",
    "print(\"Summary of Regression\\n:{}\".format(summary))\n",
    "print(\"Diagnostic Tests of Regression\\n:{}\".format(diag_res))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#sns.pairplot(pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1), hue=Y, height=2);\n",
    "\n",
    "pd.concat([pd.DataFrame(train[Y]),X_b_z],axis=1).hist()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "model_s = sklearn.linear_model.LinearRegression()\n",
    "model_s.fit(X_b_z, pd.DataFrame(train_[Y]))\n",
    "\n",
    "shap.initjs()\n",
    "e = shap.explainers.Linear(model_s, X_b_z)\n",
    "\n",
    "shap_values = e.shap_values(X_b_z)\n",
    "shap.summary_plot(shap_values, X_b_z)\n",
    "shap.plots.heatmap(e(X_b_z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b64b8-ca00-46d1-ba16-91f3adb00065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4871c2-4418-491a-8e5c-5776d42e4381",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f\n",
    "\n",
    "from statsmodels.graphics.gofplots import ProbPlot\n",
    "residuals_normalized = lm.get_influence().resid_studentized_internal\n",
    "cooks = lm.get_influence().cooks_distance[0]\n",
    "cooks = np.round(f.pdf(cooks,len(lm.tvalues)+1, len(lm.fittedvalues)-len(lm.tvalues)-1),2)\n",
    "\n",
    "res_std = lm.get_influence().resid_std\n",
    "\n",
    "leverage = lm.get_influence().hat_matrix_diag\n",
    "\n",
    "plt.hist(pd.DataFrame(leverage))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(cooks))\n",
    "plt.show()\n",
    "\n",
    "plt.hist(pd.DataFrame(residuals_normalized))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "testNormal(residuals_normalized)\n",
    "\n",
    "w = res_std\n",
    "x = cooks\n",
    "y = leverage\n",
    "z = residuals_normalized\n",
    "\n",
    "fitted_y = lm.fittedvalues\n",
    "\n",
    "labels_ = fitted_y.index\n",
    "\n",
    "outlier_check = pd.concat([pd.DataFrame(x),pd.DataFrame(y),pd.DataFrame(z),pd.DataFrame(w)],axis=1).set_index(labels_)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres']\n",
    "\n",
    "qq = ProbPlot(residuals_normalized)\n",
    "\n",
    "c_thresh = .1\n",
    "l_thresh = (2*(len(lm.tvalues)-1)/len(lm.fittedvalues))\n",
    "s_thresh = max(qq.theoretical_quantiles)\n",
    "\n",
    "print(\"Outlier threshold's\")\n",
    "print(\"Cooks distance: > .1+\")\n",
    "print(\"Leverage: > \" + str(l_thresh) + \" to \" + str(3 * (len(lm.tvalues)-1)/len(fitted_y)))\n",
    "print(\"Studentized residuals: > \" + str(s_thresh))\n",
    "print()\n",
    "\n",
    "flag = []\n",
    "\n",
    "for i in range(0,len(outlier_check)):\n",
    "    if( (outlier_check.iloc[i][0] >= c_thresh) or (outlier_check.iloc[i][1] >= l_thresh) or (abs(outlier_check.iloc[i][2]) >= s_thresh) ):\n",
    "        print(outlier_check.iloc[i])\n",
    "        print()\n",
    "        flag.append(True)\n",
    "    else:\n",
    "        flag.append(False)\n",
    "\n",
    "outlier_check = pd.concat([outlier_check,pd.DataFrame(flag).set_index(labels_)],axis=1)\n",
    "\n",
    "outlier_check.columns =  ['cooks', 'leverage', 'tsres', 'sres', 'flagged']\n",
    "\n",
    "print(np.flip(np.argsort(cooks), 0))\n",
    "#print(outlier_check)\n",
    "\n",
    "search = outlier_check[outlier_check['flagged']==1].index.to_list()\n",
    "\n",
    "rows = []\n",
    "\n",
    "for i in search:\n",
    "    v = outlier_check.index.to_list().index(i)\n",
    "    rows.append(v)\n",
    "\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b2b196-7761-4420-a145-a5411053a625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_style(row):\n",
    "\n",
    "    color = 'white'\n",
    "    if bool(row.flagged) == True:\n",
    "        color = 'orange'\n",
    "\n",
    "    return ['background-color: %s' % color]*len(row.values)\n",
    "\n",
    "all_data[set(all_data.columns) & set(New_Names)]\n",
    "\n",
    "outlier_check.style.apply(custom_style, axis=1).apply(custom_style, axis=1).background_gradient(cmap ='viridis')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da39b86-0ac2-4470-9457-8e999918d47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b8430-ac88-4358-88c1-e6c5400fe7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = y_train.columns.to_list()\n",
    "df2 = list(set(set(all_data.columns) & set(New_Names)))\n",
    "\n",
    "flattened = [] \n",
    "for sublist in df1,df2: \n",
    "    for val in sublist: \n",
    "        flattened.append(val) \n",
    "\n",
    "all_data.iloc[rows][flattened].style.background_gradient(cmap ='viridis')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
