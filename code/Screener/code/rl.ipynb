{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c3bc4-4773-48d2-912e-9b90e2f94d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Any\n",
    "import random\n",
    "from pdb import set_trace as stop\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(\n",
    "    agent,\n",
    "    env,\n",
    "    n_episodes: int,\n",
    "    epsilon: float\n",
    ") -> Tuple[Any, List, List]:\n",
    "    \"\"\"\n",
    "    Trains and agent and returns 3 things:\n",
    "    - agent object\n",
    "    - timesteps_per_episode\n",
    "    - penalties_per_episode\n",
    "    \"\"\"\n",
    "    # For plotting metrics\n",
    "    timesteps_per_episode = []\n",
    "    penalties_per_episode = []\n",
    "\n",
    "    for i in tqdm(range(0, n_episodes)):\n",
    "\n",
    "        state = env.reset()\n",
    "\n",
    "        epochs, penalties, reward, = 0, 0, 0\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                # Explore action space\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Exploit learned values\n",
    "                action = agent.get_action(state)\n",
    "\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            agent.update_parameters(state, action, reward, next_state)\n",
    "\n",
    "            if reward == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            state = next_state\n",
    "            epochs += 1\n",
    "\n",
    "        timesteps_per_episode.append(epochs)\n",
    "        penalties_per_episode.append(penalties)\n",
    "\n",
    "    return agent, timesteps_per_episode, penalties_per_episode\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    agent,\n",
    "    env,\n",
    "    n_episodes: int,\n",
    "    epsilon: float,\n",
    "    initial_state: int = None\n",
    ") -> Tuple[List, List]:\n",
    "    \"\"\"\n",
    "    Tests agent performance in random `n_episodes`.\n",
    "    It returns:\n",
    "    - timesteps_per_episode\n",
    "    - penalties_per_episode\n",
    "    \"\"\"\n",
    "    # For plotting metrics\n",
    "    timesteps_per_episode = []\n",
    "    penalties_per_episode = []\n",
    "    frames_per_episode = []\n",
    "\n",
    "    for i in tqdm(range(0, n_episodes)):\n",
    "\n",
    "        if initial_state:\n",
    "            # init the environment at 'initial_state'\n",
    "            state = initial_state\n",
    "            env.s = initial_state\n",
    "        else:\n",
    "            # random starting state\n",
    "            state = env.reset()\n",
    "\n",
    "        epochs, penalties, reward, = 0, 0, 0\n",
    "        frames = []\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "\n",
    "            if random.uniform(0, 1) < epsilon:\n",
    "                # Explore action space\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Exploit learned values\n",
    "                action = agent.get_action(state)\n",
    "\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "\n",
    "            frames.append({\n",
    "                'frame': env.render(mode='ansi'),\n",
    "                'state': state,\n",
    "                'action': action,\n",
    "                'reward': reward\n",
    "            })\n",
    "\n",
    "            if reward == -10:\n",
    "                penalties += 1\n",
    "\n",
    "            state = next_state\n",
    "            epochs += 1\n",
    "\n",
    "        timesteps_per_episode.append(epochs)\n",
    "        penalties_per_episode.append(penalties)\n",
    "        frames_per_episode.append(frames)\n",
    "\n",
    "    return timesteps_per_episode, penalties_per_episode, frames_per_episode\n",
    "\n",
    "\n",
    "def train_many_runs(\n",
    "    agent,\n",
    "    env,\n",
    "    n_episodes: int,\n",
    "    epsilon: float,\n",
    "    n_runs: int,\n",
    ") -> Tuple[List, List]:\n",
    "    \"\"\"\n",
    "    Calls 'train' many times, stores results and averages them out.\n",
    "    \"\"\"\n",
    "    timesteps = np.zeros(shape=(n_runs, n_episodes))\n",
    "    penalties = np.zeros(shape=(n_runs, n_episodes))\n",
    "\n",
    "    for i in range(0, n_runs):\n",
    "\n",
    "        agent.reset()\n",
    "\n",
    "        _, timesteps[i, :], penalties[i, :] = train(\n",
    "            agent, env, n_episodes, epsilon\n",
    "        )\n",
    "    timesteps = np.mean(timesteps, axis=0).tolist()\n",
    "    penalties = np.mean(penalties, axis=0).tolist()\n",
    "\n",
    "    return timesteps, penalties\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    import gym\n",
    "    from src.q_agent import QAgent\n",
    "\n",
    "    env = gym.make(\"Taxi-v3\").env\n",
    "    alpha = 0.1\n",
    "    gamma = 0.6\n",
    "    agent = QAgent(env, alpha, gamma)\n",
    "\n",
    "    agent, _, _ = train(\n",
    "        agent, env, n_episodes=10000, epsilon=0.10)\n",
    "\n",
    "    timesteps_per_episode, penalties_per_episode, _ = evaluate(\n",
    "        agent, env, n_episodes=100, epsilon=0.05\n",
    "    )\n",
    "\n",
    "    print(f'Avg steps to complete ride: {np.array(timesteps_per_episode).mean()}')\n",
    "    print(f'Avg penalties to complete ride: {np.array(penalties_per_episode).mean()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b919d4-e908-46ef-b2a1-c9cad8dd2bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
