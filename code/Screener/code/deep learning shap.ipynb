{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5faeea76-db3a-4dc1-958c-1ea9e71c1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load package\n",
    "#https://towardsdatascience.com/deep-learning-model-interpretation-using-shap-a21786e91d16\n",
    "import shap\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "import ssl\n",
    "# load build-in dataset\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "# reshape and normalize data\n",
    "x_train = x_train.reshape(50000, 32, 32, 3).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 32, 32, 3).astype(\"float32\") / 255\n",
    "y_train = y_train.reshape(50000,)\n",
    "y_test = y_test.reshape(10000,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb71cf9-3e56-4066-a101-f7fca0da4bfd",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# compile the model\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[0;32m     19\u001b[0m       loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(),\n\u001b[0;32m     20\u001b[0m       optimizer\u001b[38;5;241m=\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(),\n\u001b[0;32m     21\u001b[0m       metrics\u001b[38;5;241m=\u001b[39m[tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mSparseCategoricalAccuracy()]\n\u001b[0;32m     22\u001b[0m   )\n\u001b[1;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    }
   ],
   "source": [
    "# define the model architecture\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "x = keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Conv2D(128, (3, 3), activation='relu')(inputs)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Conv2D(64, (3, 3), activation='relu')(inputs)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
    "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "x = keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = keras.layers.Dense(10, activation='softmax')(x)\n",
    "# inputs and outputs\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"test_for_shap\")\n",
    "# compile the model\n",
    "model.compile(\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "      optimizer=keras.optimizers.Adam(),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "  )\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33829e3-1a9d-4bd8-ae3d-0f470deff791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class label list\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "# example image for each class\n",
    "images_dict = dict()\n",
    "for i, l in enumerate(y_train):\n",
    "  if len(images_dict)==10:\n",
    "    break\n",
    "  if l not in images_dict.keys():\n",
    "    images_dict[l] = x_train[i].reshape((32, 32,3))\n",
    "images_dict = dict(sorted(images_dict.items()))\n",
    "    \n",
    "# example image for each class for test set\n",
    "x_test_dict = dict()\n",
    "for i, l in enumerate(y_test):\n",
    "  if len(x_test_dict)==10:\n",
    "    break\n",
    "  if l not in x_test_dict.keys():\n",
    "    x_test_dict[l] = x_test[i]\n",
    "# order by class\n",
    "x_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\n",
    "x_test_each_class = np.asarray(x_test_each_class)\n",
    "# Compute predictions\n",
    "predictions = model.predict(x_test_each_class)\n",
    "predicted_class = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b26856-aee5-45e2-ba94-bc58abfde6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot actual and predicted class\n",
    "def plot_actual_predicted(images, pred_classes):\n",
    "  fig, axes = plt.subplots(1, 11, figsize=(16, 15))\n",
    "  axes = axes.flatten()\n",
    "  \n",
    "  # plot\n",
    "  ax = axes[0]\n",
    "  dummy_array = np.array([[[0, 0, 0, 0]]], dtype='uint8')\n",
    "  ax.set_title(\"Base reference\")\n",
    "  ax.set_axis_off()\n",
    "  ax.imshow(dummy_array, interpolation='nearest')\n",
    "  # plot image\n",
    "  for k,v in images.items():\n",
    "    ax = axes[k+1]\n",
    "    ax.imshow(v, cmap=plt.cm.binary)\n",
    "    ax.set_title(f\"True: %s \\nPredict: %s\" % (class_names[k], class_names[pred_classes[k]]))\n",
    "    ax.set_axis_off()\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaf18cd-cd53-4105-ad7d-2407b1e2bc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select backgroud for shap\n",
    "background = x_train[np.random.choice(x_train.shape[0], 1000, replace=False)]\n",
    "# DeepExplainer to explain predictions of the model\n",
    "explainer = shap.DeepExplainer(model, background)\n",
    "# compute shap values\n",
    "shap_values = explainer.shap_values(x_test_each_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e7f5b-9ed1-451f-b702-e2d635fac423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot SHAP values\n",
    "plot_actual_predicted(images_dict, predicted_class)\n",
    "print()\n",
    "shap.image_plot(shap_values, x_test_each_class * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83013b0-c5e0-48c7-bdc7-c433cf135b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import package\n",
    "import shap\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import os\n",
    "# load data\n",
    "os.chdir('/titanic/')\n",
    "train_data = pd.read_csv('./train.csv', index_col=0)\n",
    "test_data = pd.read_csv('./test.csv', index_col=0)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e857223-0c9b-45b4-a8c8-115813f126cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(df):\n",
    "    df = df.drop(columns=['Name', 'Ticket', 'Cabin'])\n",
    "    \n",
    "    # fill na\n",
    "    df[['Age']] = df[['Age']].fillna(value=df[['Age']].mean())\n",
    "    df[['Embarked']] = df[['Embarked']].fillna(value=df['Embarked'].value_counts().idxmax())\n",
    "    df[['Fare']] = df[['Fare']].fillna(value=df[['Fare']].mean())\n",
    "    \n",
    "    # categorical features into numeric\n",
    "    df['Sex'] = df['Sex'].map( {'female': 1, 'male': 0} ).astype(int)\n",
    "    \n",
    "    # one-hot encoding\n",
    "    embarked_one_hot = pd.get_dummies(df['Embarked'], prefix='Embarked')\n",
    "    df = df.drop('Embarked', axis=1)\n",
    "    df = df.join(embarked_one_hot)\n",
    "    \n",
    "    return df\n",
    "# train data processing\n",
    "train_data = data_preprocessing(train_data)\n",
    "train_data.isnull().sum()\n",
    "# create data for training\n",
    "x_train = train_data.drop(['Survived'], axis=1).values\n",
    "# Check test data\n",
    "test_data.isnull().sum()\n",
    "# scale\n",
    "scale = StandardScaler()\n",
    "x_train = scale.fit_transform(x_train)\n",
    "# prepare y_train\n",
    "y_train = train_data['Survived'].values\n",
    "test_data = data_preprocessing(test_data)\n",
    "x_test = test_data.values.astype(float)\n",
    "# scaling\n",
    "x_test = scale.transform(x_test)\n",
    "# Check test data\n",
    "test_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1465bb-fc3e-4e8b-8a83-17ac447c990f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build mlp\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "# compile model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "# fit model\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4724f4a6-ee5c-4a73-af7b-0514487b0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHAP values\n",
    "explainer = shap.DeepExplainer(model, x_train)\n",
    "shap_values = explainer.shap_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a27026-c6b4-4ee6-ac31-8171539eade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0], plot_type = 'bar', feature_names = test_data.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
