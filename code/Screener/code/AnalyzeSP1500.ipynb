{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9d05a-a1d5-4f4c-a68f-884d49aeb201",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2d4bb-dcca-41bb-9c62-081bb5f88e02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b7a6d5-288f-435a-8cb8-e7513a912d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ade43c-b6c3-4b09-8331-8cfeea94eeef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from vevestaX import vevesta as v\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from matplotlib.dates import DateFormatter\n",
    "from pandas.io.formats.style import Styler\n",
    "from pivottablejs import pivot_ui\n",
    "from pmdarima.arima import auto_arima\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from random import random\n",
    "\n",
    "import re\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib as mp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "import pickle\n",
    "import rpy2\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import statsmodels\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import time\n",
    "from clustergram import Clustergram\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.vq import vq\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import scale\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from scipy.stats import f as f_\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from IPython.display import HTML as html_print\n",
    "from IPython.display import display\n",
    "\n",
    "# univariate bidirectional lstm example\n",
    "from numpy import array\n",
    "\n",
    "\"\"\"\n",
    "from tensorflow.keras.layers import Input, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "\"\"\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "gpus = tf.config.list_logical_devices('GPU')\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "import pandas as pd\n",
    "from rpy2.robjects import pandas2ri\n",
    "from prophet import Prophet\n",
    "from multi_prophet.multi_prophet import MultiProphet\n",
    "\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ec93b6-a52b-4aac-afe8-4b405ac9d9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2120b7c8-6f66-4e05-94c3-cf6a5baa5460",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# split a univariate sequence\n",
    "def split_sequence(sequence, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif end_ix > len(sequence)-1:\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f54772-8e5b-4d1c-b5c7-46b644c45beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dates(ds):\n",
    "    date = pd.to_datetime(ds)\n",
    "    return(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f7e3d-658b-42c3-a2c5-2ffb792b37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_vertical_headers(df):\n",
    "    \"\"\"Display a dataframe with vertical column headers\"\"\"\n",
    "    styles = [dict(selector=\"th\", props=[('width', '40px')]),\n",
    "              dict(selector=\"th.col_heading\",\n",
    "                   props=[(\"writing-mode\", \"vertical-rl\"),\n",
    "                          ('transform', 'rotateZ(180deg)'), \n",
    "                          ('height', '290px'),\n",
    "                          ('vertical-align', 'top')])]\n",
    "    return (df.fillna('').style.set_table_styles(styles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37e766-4331-4821-99bd-0680ffdf3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not sys.warnoptions:\n",
    "#    import warnings\n",
    "#    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "wd = os.getcwd()\n",
    "\n",
    "if (os.defpath==\".;C:\\\\bin\"):\n",
    "    os.environ['R_HOME'] = 'C:/Users/User/Documents/R/R-4.1.2'\n",
    "    os.environ['R_LIBS'] = 'C:/Users/User/Documents/R/R-4.1.2/library'\n",
    "    from OLS_LR_DiagnosticPlots.ModelDiagnostics import Plot\n",
    "else:\n",
    "    os.environ['R_HOME'] = '/mnt/distvol/R/4.0.5/lib64/R/'\n",
    "\n",
    "pandas2ri.activate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955f43d-9872-4b22-8b0b-686d51bbacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#robjects.ro['version']\n",
    "\n",
    "base = importr('base')\n",
    "#grdevices = importr('grDevices')\n",
    "print(base._libPaths())\n",
    "\n",
    "timetk = importr('timetk')\n",
    "magrittr = importr('magrittr')\n",
    "dplyr = importr('dplyr')\n",
    "tidyverse = importr('tidyverse')\n",
    "nbclust = importr('NbClust')\n",
    "grdevices = importr('grDevices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df587e-2842-43ff-b29d-8132fb0d798e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b479a-a439-4905-9d5b-758e15b99163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccb3eb-f028-43da-aa35-2afd62c7fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "si = ['03-31','06-30','09-30','12-31']\n",
    "\n",
    "#future_commodities_n_w_index_pvt_w_Fred = pd.read_csv('..\\\\data\\\\processed\\\\'+end.strftime('%Y-%m-%d')+'_future_commodities_n_w_index_pvt_w_Fred.csv')\n",
    "#[start,end,prices_df, sp1500_index_df, sp500, sp600, sp400, market_data, completed_fred_pvt, completed_bonds, completed_bonds_pvt, sectors, indexes, screener_sorted, dict_sectors, dict_indexes, dict_sectors_reverse, invert_dict_indexes, list_sector_n_indexes, list_stocks] = pickle.load(open('..\\\\data\\\\interim\\\\data_object.pkl', 'rb'))\n",
    "[start,end,prices_df, sp1500_index_df, sp500, sp600, sp400, market_data, completed_fred_pvt, completed_bonds, completed_bonds_pvt, sectors, indexes, screener_sorted, dict_sectors, dict_indexes, dict_sectors_reverse, invert_dict_indexes, list_sector_n_indexes, list_stocks,future_commodities_n_w_index_pvt_w_Fred] = pickle.load(open('..\\\\data\\\\interim\\\\data_object.pkl', 'rb'))\n",
    "\n",
    "fred_friendly_names = ['Consumer Loans','Copper','Iron and Steel','Gold','Unemployment','Market volatility','Commercial-Industrial Loans','Average Weekly Hours','Credit to Income','Consumer Confidence','Oil Prices','Inflation','Housing Prices','Interest Rates','10 Year to 3 Month','Recession Indicator','OECD Leading Indicator','Coincident Index','Index: Industrial Production','Mfr Orders Excl AC','Personal Expenditures',]\n",
    "fred_names = ['CONSUMER','WPUSI019011','WPU101','GVZCLS','UNRATE','VIXCLS','BUSLOANS','AWHAETP','UMCSENT','TDSP','DCOILWTICO','CPIAUCSL','CSUSHPINSA','FEDFUNDS','T10Y3M','USREC','USALOLITONOSTSAM','USPHCI','INDPRO','NEWORDER','PCE']\n",
    "\n",
    "dict_fred = dict(zip(*[fred_names,fred_friendly_names]))\n",
    "\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "nyse_dates = nyse.schedule(start_date=start, end_date=end)\n",
    "\n",
    "fundamentals_quarterlies = pickle.load(open('..\\\\data\\\\interim\\\\fundamental.pkl', 'rb'))\n",
    "fundamental_entries = [e[0] for e in fundamentals_quarterlies]\n",
    "\n",
    "sectors.columns = ['Symbol']\n",
    "indexes.columns = ['Symbol']\n",
    "\n",
    "newDates = pd.date_range((end+ dt.timedelta(7)).strftime('%Y-%m-%d'), (end + dt.timedelta(92)).strftime('%Y-%m-%d'), freq='W-'+nyse_dates.index[-1].strftime('%a')).map(lambda t: t.strftime('%Y-%m-%d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d9d190-7107-42e0-99a8-6f2e0eb24b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp_df = prices_df[['Open','High','Low','Close','Adj Close','Volume','Symbol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3126cc-dcc4-4cb0-8003-6b19eff20b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47b5ce-1bf7-404e-9bfd-e7af76417251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed_fred_pvt_df = completed_fred_pvt.asfreq('D').reindex(nyse_dates.index).interpolate(method='time')\n",
    "completed_fred_pvt_df = completed_fred_pvt\n",
    "\n",
    "temp_new = completed_fred_pvt.asfreq('D').interpolate(method='time',limit_area='inside').reindex(nyse_dates.index)\n",
    "temp_dates = pd.date_range(completed_fred_pvt.index[0].strftime('%Y-%m-%d'), completed_fred_pvt.index[-1].strftime('%Y-%m-%d'), freq='D').map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "nyse_inbetween_temp_dates = nyse_dates.index[(nyse_dates.index >= temp_dates[0]) & (nyse_dates.index <= temp_dates[-1])]\n",
    "temp_new = temp_new.reindex(nyse_inbetween_temp_dates)\n",
    "\n",
    "completed_fred_pvt_df = temp_new\n",
    "completed_fred_pvt_df.columns = [name[1] for name in completed_fred_pvt_df.columns]\n",
    "\n",
    "np.array(completed_fred_pvt_df.index.map(lambda t: t.strftime('%Y-%m-%d')))[np.arange(0,len(completed_fred_pvt_df.index),int(len(completed_fred_pvt_df.index)/10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d68f4-e6ea-41dd-8b87-4fd29cb22e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_ahead = 13\n",
    "\n",
    "cv_inner = TimeSeriesSplit(n_splits=10,test_size=n_ahead)\n",
    "cv_outer = TimeSeriesSplit(n_splits=11,test_size=n_ahead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75f256-bd00-463f-b5bf-36d429b1e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cstr(s, color='black'):\n",
    "    return \"<text style=color:{}>{}</text>\".format(color, s)\n",
    "\n",
    "def print_color(t):\n",
    "    print(t)\n",
    "    display(html_print(' '.join([cstr(ti, color=ci) for ti,ci in t])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc38bd-0235-4486-b957-a7674fefc307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findknee(xdata):\n",
    "    rate_of_change=(xdata[0]-xdata[-1])/(len(xdata)-1)\n",
    "    #print(rate_of_change)\n",
    "    delta = xdata-xdata[-1]\n",
    "    deltas = []\n",
    "    deltas.append(delta[0])\n",
    "    for d in range(1,len(xdata)):\n",
    "        deltas.append(deltas[d-1]-rate_of_change)\n",
    "    #print(deltas)\n",
    "    for d in range(0,len(xdata)):\n",
    "        deltas[d]=delta[d]-deltas[d]\n",
    "    return(np.round(np.abs(deltas)))\n",
    "\n",
    "def deriveANOVA(clf, df):\n",
    "\n",
    "    labels = clf.labels_\n",
    "    clusters = clf.n_clusters\n",
    "    centers = clf.cluster_centers_\n",
    "        \n",
    "    within_ss = []\n",
    "\n",
    "    for n in range(0,clusters):\n",
    "      #WSS means the sum of distances between the points and the corresponding centroids for each cluster\n",
    "      data = df[labels==(n)]\n",
    "      within_ss.append(((data - centers[n])**2).sum(1).sum())\n",
    "\n",
    "    WSS = total_within_ss = np.sum(within_ss)\n",
    "\n",
    "    print('wss',total_within_ss)\n",
    "\n",
    "    #sum of ((deviation from variable means) squared)\n",
    "    tot_ss = np.sum(np.sum((df-df.mean())**2))\n",
    "    print('tot_ss',tot_ss)\n",
    "\n",
    "    cluster_BSS = []\n",
    "    for n in range(0,clusters):\n",
    "      #sum((variable/column means cluster - variable/column means data)^2)*len(cluster members)\n",
    "      BSS = np.sum((df[labels==(n)].mean()-np.array(np.mean(df)))**2)*len(df[labels==(n)])\n",
    "      cluster_BSS.append(BSS)\n",
    "\n",
    "    BSS = np.sum(cluster_BSS)\n",
    "    print('bss',BSS)\n",
    "    \n",
    "    return(tot_ss, BSS, within_ss)\n",
    "\n",
    "def findOptimalK_ANOVA(df, mink=2, maxk=6, init_min=2, init_max=5):\n",
    "\n",
    "    tss = []\n",
    "    bss = []\n",
    "    wss = []\n",
    "\n",
    "    for k in range(mink,maxk):\n",
    "        print(k)\n",
    "\n",
    "        print(max(init_min,k+1))\n",
    "        size_min_ = max(init_min,k+1)\n",
    "        size_max_ = max(np.ceil(len(df)/k),init_max)\n",
    "        if(size_min_>size_max_):\n",
    "            break\n",
    "        else:\n",
    "            clf = KMeansConstrained(n_clusters=k, size_min=size_min_, size_max=size_max_, init='k-means++', n_init=100, max_iter=100, tol=0.0001, verbose=False, random_state=int(time.time()), copy_x=True, n_jobs=4)\n",
    "            clf.fit_predict(np.array(df))\n",
    "\n",
    "            tot_ss, BSS, within_ss = deriveANOVA(clf, df)\n",
    "\n",
    "            wss.append(within_ss)\n",
    "            tss.append(tot_ss)\n",
    "            bss.append(BSS)\n",
    "\n",
    "    return(tss, bss, wss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed1442-0c89-43a1-ab60-ba829fa4b086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4c743-7f04-4405-b0a4-a20d02cd34b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_to_int(dateobj):\n",
    "    total = int(dateobj.strftime('%S'))\n",
    "    total += int(dateobj.strftime('%M')) * 60\n",
    "    total += int(dateobj.strftime('%H')) * 60 * 60\n",
    "    total += (int(dateobj.strftime('%j')) - 1) * 60 * 60 * 24\n",
    "    total += (int(dateobj.strftime('%Y')) - 1970) * 60 * 60 * 24 * 365\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca18dd-3ef1-4b3d-ae25-688131622be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_cells(val, color_if_true, color_if_false, threshold_):\n",
    "    color = color_if_true if val >= threshold_ else color_if_false\n",
    "    return 'background-color: {}'.format(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e93ff1-1957-4260-b7f6-a013c5cfb763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7dc96-9214-40de-be05-b8ddb0fa4180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbfcad-ace0-4f5e-a474-cdf2d25e01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_fb_test_error(npa):\n",
    "    n_ahead = 13\n",
    "\n",
    "    subset_train = npa[0]\n",
    "    subset_test = npa[1]\n",
    "\n",
    "    base_model = Prophet()\n",
    "\n",
    "    prophet_df_base = subset_train['Adj Close'].reset_index()#data.reset_index()\n",
    "    prophet_df_base.columns = ['ds','y']\n",
    "    prophet_df_base['y'] = np.log(prophet_df_base['y'])\n",
    "\n",
    "    base_model.fit(prophet_df_base)\n",
    "\n",
    "    future_base = base_model.make_future_dataframe(periods = n_ahead,freq='W-'+subset_train.index[-1].strftime('%a'))\n",
    "\n",
    "    forecast_base = base_model.predict(future_base).set_index('ds')[['yhat','yhat_lower','yhat_upper']]\n",
    "    df_pred_base = np.exp(forecast_base)\n",
    "\n",
    "    rmse_ = mean_squared_error(subset_test['Adj Close'].tail(n_ahead), df_pred_base['yhat'].tail(n_ahead), squared=True)\n",
    "    return([[subset_test['Adj Close'].tail(n_ahead)],[df_pred_base['yhat'].tail(n_ahead)],rmse_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ee731-6770-4f82-b064-0050b2944473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "symbol_ = 'BA'\n",
    "\n",
    "if(str(symbol_)=='None'):\n",
    "    run=False\n",
    "else:\n",
    "    run=True\n",
    "\n",
    "if(run):\n",
    "    client = Client('192.168.3.100:8786')\n",
    "    #client = Client(n_workers=4,threads_per_worker=1)\n",
    "\n",
    "    s = symbol_\n",
    "    msize = 2\n",
    "    date_form = DateFormatter(\"%Y-%m-%d\")\n",
    "\n",
    "    metrics_df_ = pd.DataFrame(pd.DataFrame(screener_sorted.loc[s]).T[['volume_factor','Adj Close','adf','hurst']])\n",
    "    subset=prices_df[prices_df['Symbol']==s]\n",
    "    \n",
    "    y = subset['Adj Close']\n",
    "    data = subset[['Adj Close']].asfreq('D').interpolate().asfreq('W-'+subset.index[-1].strftime('%a'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027b0ca-06f8-4679-b42f-59adcbe223f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deacbc06-9e40-4e44-b3c5-96ad4dc72c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0bf8bd-a49c-4bc5-891a-daabca660927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cdcbb8-de81-4ff4-b20c-cca4d39a3406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2018ca9e-d18c-42d8-82cf-80ab94d78891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c9e9d-0487-400a-a083-bf3e4d492e58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14951c47-6bc8-4f40-b5e4-b790334db91d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9752c0-c023-4c4c-a400-358b576bf3c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e700f0e0-60b1-4f32-8ac2-fe908bc6f5f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13ba380-237c-4328-b85b-4f0ad13594da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaed78c-4b4c-4a7c-b390-99b4ace54fa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797e0773-6602-45c9-9aae-99218a8fc282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee7dda-a400-4239-a768-1fa96d044ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7f37b-05c3-4c51-a2e3-e7c1e24f0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_(symbols):    \n",
    "\n",
    "    #symbols = ['ITOS']\n",
    "    decision_metrics_df = pd.DataFrame()\n",
    "    \n",
    "    forecast_winners_df = pd.DataFrame()\n",
    "\n",
    "    for symbol_ in symbols:\n",
    "\n",
    "        print(symbol_)\n",
    "        if(str(symbol_)=='None'):\n",
    "            run=False\n",
    "        else:\n",
    "            run=True\n",
    "\n",
    "        if(run):\n",
    "            client = Client('192.168.3.100:8786')\n",
    "            #client = Client(n_workers=4,threads_per_worker=1)\n",
    "\n",
    "            s = symbol_\n",
    "            msize = 2\n",
    "            date_form = DateFormatter(\"%Y-%m-%d\")\n",
    "\n",
    "            metrics_df_ = pd.DataFrame(pd.DataFrame(screener_sorted.loc[s]).T)#[['volume_factor','Adj Close','adf','hurst']])\n",
    "            subset=prices_df[prices_df['Symbol']==s]\n",
    "\n",
    "            #if less than 2 years of data.\n",
    "            print(len(subset))\n",
    "            process = True;\n",
    "            if(len(subset)<512):\n",
    "                process=False\n",
    "            \n",
    "            if(process):\n",
    "\n",
    "                dates = []\n",
    "                for t in subset.index.values:\n",
    "                    d = pd.Timestamp(t).strftime('%Y-%m-%d')\n",
    "                    dates.append(d)\n",
    "                    dto = datetime.strptime(d, '%Y-%m-%d').date()\n",
    "\n",
    "                old_ordinal = [datetime.strptime(i, '%Y-%m-%d').toordinal() for i in dates]\n",
    "                new_ordinal = old_ordinal + md.date2num(np.datetime64('0000-12-31'))\n",
    "                x = new_ordinal    \n",
    "\n",
    "                lookup_index_ = []\n",
    "\n",
    "                labels = list()\n",
    "                print(\"symbol:\",s)\n",
    "\n",
    "                symbol_sector = screener_sorted.loc[symbol_]['Sector Symbol']\n",
    "\n",
    "                print(\"sector:\",dict_sectors_reverse[symbol_sector])\n",
    "                symbol_index = screener_sorted.loc[s]['Index Symbol']\n",
    "\n",
    "                try:\n",
    "                    matched_index_name = indexes.iloc[np.where(indexes['Symbol'].values==s)].index[0]\n",
    "                except:\n",
    "                    try:\n",
    "                        matched_index_name = screener_sorted.loc[s]['Index Symbol']\n",
    "                    except:\n",
    "                        matched_index_name = \"error\"\n",
    "\n",
    "                print(\"Index:\",dict_indexes[matched_index_name])\n",
    "\n",
    "                print(\"Volume Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==s)]['volume_factor'][0])\n",
    "\n",
    "                print(\"sector_50td_tvf_vel:\",screener_sorted[screener_sorted.index==s]['sector_50td_tvf_vel'][0])\n",
    "                print(\"risk trend factor:\",screener_sorted.iloc[np.where(screener_sorted.index==s)]['50td_tvf_vel'][0])\n",
    "\n",
    "                temp = pd.DataFrame(market_data.loc[s])\n",
    "                print(temp[np.array(temp!='error')].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().T)\n",
    "\n",
    "                last_date = pd.DataFrame(subset.iloc[-1][['50tdBOLD','50tdMA-TP','50tdBOLU']],index=[prices_df[prices_df['Symbol']==s].index[-1].strftime('%Y-%m-%d')]).index[0]\n",
    "\n",
    "                bbands = pd.DataFrame(subset.iloc[-1][['Adj Close','50tdBOLD','50tdMA-TP','50tdBOLU','200tdSMA','200tdSDev']]).T\n",
    "                bbands['200td_lower'] = bbands['200tdSMA']-bbands['200tdSDev']*2\n",
    "                bbands['200td_upper'] = bbands['200tdSMA']+bbands['200tdSDev']*2\n",
    "\n",
    "                bbands.index = [last_date]\n",
    "                display(bbands)\n",
    "\n",
    "                display(metrics_df_)\n",
    "\n",
    "                mean_revert_flag = False\n",
    "\n",
    "                if(metrics_df_['adf_50td'][0]<.05):\n",
    "                    print(\"ADFuller H0 rejected @ .05, Mean Reverting TS\")\n",
    "                    if(bbands['Adj Close'][0]<bbands['200td_lower'][0]):\n",
    "                        colored_text = colored(255, 0, 0, \"Quarter Mean Reverting buy signal\")\n",
    "                        print(colored_text)\n",
    "                        mean_revert_flag = True\n",
    "                    if(bbands['Adj Close'][0]<bbands['50tdBOLU'][0]):\n",
    "                        colored_text = colored(255, 0, 0, \"50 td Mean Reverting buy signal\")\n",
    "                        print(colored_text)\n",
    "                        mean_revert_flag = True    \n",
    "\n",
    "                l_axis_legend = pd.DataFrame(['symbol', 'trailing_1yr_max', 'trailing_1yr_min', '30d_vol_2yr','50td_tvf_vel/linear','supply_trend_1yr'],index=['blue','green','red','orange','black','yellow'],columns=['legend'])\n",
    "\n",
    "                r_axis_legend = pd.DataFrame(['sector','index'],index=['magenta','cyan'],columns=['legend'])\n",
    "\n",
    "                display_side_by_side([l_axis_legend, r_axis_legend], ['l axis', 'r axis'])        \n",
    "\n",
    "                f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, sharey=False,figsize=(22,5))\n",
    "                ax1.plot(subset['30d_vol_2yr'],color='orange')\n",
    "                #plt.title('30d_vol_2yr')\n",
    "                ax1.set_xticklabels(subset[['30d_vol_2yr']].dropna().index, rotation = 45)\n",
    "\n",
    "                locator = matplotlib.dates.AutoDateLocator()\n",
    "                formatter = matplotlib.dates.ConciseDateFormatter(locator)\n",
    "\n",
    "                ax1.xaxis.set_major_locator(locator)\n",
    "                ax1.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "                ax1.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "                ax2.plot(subset['50td_tvf_vel'],color='black')\n",
    "                ax2.set_xticklabels(subset[['50td_tvf_vel']].dropna().index, rotation = 45)\n",
    "\n",
    "                locator = matplotlib.dates.AutoDateLocator()\n",
    "                formatter = matplotlib.dates.ConciseDateFormatter(locator)\n",
    "\n",
    "                ax2.xaxis.set_major_locator(locator)\n",
    "                ax2.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "                ax2.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "                ax3_ = ax3.twinx()\n",
    "                ax5_ = ax5.twinx()        \n",
    "                ax4_ = ax4.twinx()\n",
    "\n",
    "                y = subset['Adj Close']\n",
    "\n",
    "                def myfunc(x):\n",
    "                    return slope * x + intercept\n",
    "\n",
    "                slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "                mymodel = list(map(myfunc, x))\n",
    "\n",
    "                ax3.plot(x, y,marker = '.',markersize=msize, color = 'b')\n",
    "                ax3.plot(x, subset['trailing_1yr_max'],marker = '.',markersize=msize, color = 'g')\n",
    "                ax3.plot(x, subset['trailing_1yr_min'],marker = '.',markersize=msize, color = 'r')\n",
    "                ax3_.plot(x, subset['supply_trend_1yr'],marker = '.',markersize=msize, color = 'y')\n",
    "                ax3.plot(x, mymodel, color = 'k')\n",
    "\n",
    "                l = matplotlib.dates.AutoDateLocator()\n",
    "                f = matplotlib.dates.ConciseDateFormatter(l)    \n",
    "\n",
    "                ax3.set_xticklabels(ax3.get_xticks(), rotation = 45)\n",
    "\n",
    "                locator = matplotlib.dates.AutoDateLocator()\n",
    "                formatter = matplotlib.dates.ConciseDateFormatter(locator)\n",
    "\n",
    "                ax3.xaxis.set_major_locator(locator)\n",
    "                ax3.xaxis.set_major_formatter(formatter)\n",
    "                ax3.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "                if(symbol_sector=='error'):\n",
    "                    pass\n",
    "                else:\n",
    "                    if(np.sum(sectors['Symbol'].values==s)>0):\n",
    "                        pass\n",
    "                    else:\n",
    "                        sector_subset = prices_df[prices_df['Symbol']==symbol_sector]\n",
    "                        print(\"Sector Volume Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==symbol_sector)]['volume_factor'][0])\n",
    "                        print(\"Sector 50td_tvf_vel:\",screener_sorted.iloc[np.where(screener_sorted.index==symbol_sector)]['sector_50td_tvf_vel'][0])\n",
    "                        #ax3_.plot(x, (sector_subset['Adj Close']).iloc[-len(subset):],marker = '.',markersize=msize,color='m',linestyle=(0, (3, 10, 1, 10)))\n",
    "                        ax4.plot(x, (sector_subset['Adj Close']).iloc[-len(subset):],marker = '.',markersize=msize,color='m',linestyle=(0, (3, 10, 1, 10)))\n",
    "                        ax4.plot(x, (sector_subset['trailing_1yr_max']).iloc[-len(subset):],marker = '.',markersize=msize, color = 'g')\n",
    "                        ax4.plot(x, (sector_subset['trailing_1yr_min']).iloc[-len(subset):],marker = '.',markersize=msize, color = 'r')\n",
    "                        ax4_.plot(x, (sector_subset['supply_trend_1yr']).iloc[-len(subset):],marker = '.',markersize=msize,color='y',linestyle=(0, (3, 10, 1, 10)))\n",
    "                        ax4.set_xticklabels(subset.dropna().index, rotation = 45)\n",
    "                        ax4.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "                if(str(screener_sorted.loc[s]['Index Symbol'])!='nan'):\n",
    "                    if(screener_sorted.loc[s]['Index Symbol']!='error'):\n",
    "                        index_subset = prices_df[prices_df['Symbol']==screener_sorted.loc[s]['Index Symbol']]\n",
    "                        print(\"Index Volume Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==screener_sorted.loc[s]['Index Symbol'])]['volume_factor'][0])\n",
    "                        #print(\"Index 50td_tvf_vel:\",screener_sorted.iloc[np.where(screener_sorted.index==screener_sorted.loc[s]['Index Symbol'])]['50td_tvf_vel'][0])\n",
    "                        ax5.plot(x, index_subset['Adj Close'].iloc[-len(subset):],marker = '.',markersize=msize,color='c',linestyle=(0, (1, 10)))\n",
    "                        ax5.plot(x, index_subset['trailing_1yr_max'].iloc[-len(subset):],marker = '.',markersize=msize, color = 'g')\n",
    "                        ax5.plot(x, index_subset['trailing_1yr_min'].iloc[-len(subset):],marker = '.',markersize=msize, color = 'r')\n",
    "                        ax5_.plot(x, index_subset['supply_trend_1yr'].iloc[-len(subset):],marker = '.',markersize=msize,color='y',linestyle=(0, (1, 10)))\n",
    "                        ax5.set_xticklabels(index_subset.dropna().index, rotation = 45)\n",
    "                        ax5.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                data = subset[['Adj Close']].asfreq('D').interpolate(method='time').asfreq('W-'+subset.index[-1].strftime('%a'))\n",
    "\n",
    "                npa_rmse_inner = []\n",
    "\n",
    "                for trainv_ix, test_ix in cv_inner.split(data.index):\n",
    "\n",
    "                    npa_rmse_inner.append([data.iloc[trainv_ix],data.iloc[test_ix]])\n",
    "\n",
    "                npa_rmse_outer = []\n",
    "\n",
    "                for trainv_ix, test_ix in cv_outer.split(data.index):\n",
    "\n",
    "                    npa_rmse_outer.append([data.iloc[trainv_ix],data.iloc[test_ix]])        \n",
    "\n",
    "                print(\"fbprophet next 13 weeks\")\n",
    "\n",
    "                #starting from next week\n",
    "\n",
    "                future = client.map(derive_fb_test_error, npa_rmse_inner)        \n",
    "\n",
    "                rmses_inner = []\n",
    "\n",
    "                for f in as_completed(future):\n",
    "                    if(f.status==\"error\"):\n",
    "                        rmses_inner.append(np.nan)\n",
    "                    else:\n",
    "                        rmses_inner.append(f.result())\n",
    "\n",
    "                rmses_inner_ = [t[2] for t in rmses_inner]\n",
    "                rmse_ = [r for r in rmses_inner_]\n",
    "\n",
    "                rmse_inner_flags = [np.nanmean(rmse_),np.nanstd(rmse_)]\n",
    "\n",
    "                print(\"inner cv scores:\")\n",
    "                inner_rmse_df = pd.DataFrame([rmse_inner_flags],columns=['mean','std'])\n",
    "\n",
    "                scores = inner_rmse_df['mean'].values\n",
    "                sdevs = inner_rmse_df['std'].values\n",
    "                print(\"best inner cv score, sdev (11 folds):\",scores[np.argmin(scores)],sdevs[np.argmin(scores)])\n",
    "\n",
    "                future = client.map(derive_fb_test_error, npa_rmse_outer)\n",
    "                results_rmses_outer = []\n",
    "\n",
    "                for f in as_completed(future):\n",
    "                    if(f.status==\"error\"):\n",
    "                        results_rmses_outer.append([np.nan])\n",
    "                    else:\n",
    "                        results_rmses_outer.append(f.result()) \n",
    "\n",
    "                results_rmses_outer_ = [t[2] for t in results_rmses_outer]\n",
    "                test_score_mean = np.nanmean([r for r in results_rmses_outer_])\n",
    "                test_score_std = np.nanstd([r for r in results_rmses_outer_])\n",
    "\n",
    "                client = Client('192.168.3.100:8786')\n",
    "\n",
    "                y_s = [t[0] for t in results_rmses_outer]\n",
    "                y_hats = [t[1] for t in results_rmses_outer]\n",
    "                test_errors_ = np.array(y_s)-np.array(y_hats)\n",
    "                np.std(test_errors_,axis=0)\n",
    "                std_resid = test_errors_/((np.sum(test_errors_)**2)/(len(test_errors_)-2)**.5)\n",
    "\n",
    "                std_error_test = np.std(test_errors_,axis=0)\n",
    "\n",
    "                print(\"test cv mean error, stdev (10 folds):\",test_score_mean,test_score_std)\n",
    "\n",
    "                m = Prophet(interval_width=0.95)\n",
    "\n",
    "                prophet_df = data['Adj Close'].reset_index()#data.reset_index()\n",
    "                prophet_df.columns = ['ds','y']\n",
    "                prophet_df['y'] = np.log(prophet_df['y'])\n",
    "                m.fit(prophet_df)\n",
    "\n",
    "                future_ = m.make_future_dataframe(periods = n_ahead,freq='W-'+nyse_dates.index[-1].strftime('%a'))\n",
    "\n",
    "                forecast = m.predict(future_).set_index('ds')[['yhat','yhat_lower','yhat_upper']]\n",
    "                df_pred = np.exp(forecast)\n",
    "\n",
    "                #fb forecast\n",
    "                temp_df = pd.DataFrame(data['Adj Close']).reset_index()\n",
    "                temp_df.columns = ['ds','Adj Close']\n",
    "                temp_df.set_index('ds',inplace=True)\n",
    "\n",
    "                s_date = df_pred.tail(n_ahead).index[np.argmax(df_pred['yhat'].tail(n_ahead).values)].strftime('%Y-%m-%d')\n",
    "\n",
    "                print(\"sell date:\",s_date)\n",
    "                e_return = np.array((np.max(df_pred['yhat'].tail(n_ahead).values)-metrics_df_['Adj Close'])/metrics_df_['Adj Close'])[0]\n",
    "                p_metrics = pd.DataFrame(df_pred.tail(n_ahead).iloc[np.argmax(df_pred['yhat'].tail(n_ahead).values)]).T\n",
    "                print(\"expected return:\",e_return)\n",
    "\n",
    "                days_delta = (datetime.strptime(s_date, '%Y-%m-%d') - datetime.strptime(end.strftime('%Y-%m-%d'), '%Y-%m-%d')).days\n",
    "                try:\n",
    "                    discounted_return = (1+e_return)**(1/days_delta)-1\n",
    "                except:\n",
    "                    discounted_return = 0\n",
    "                qtr_return = (1+discounted_return)**92\n",
    "\n",
    "                print(\"discounted return:\",discounted_return)\n",
    "                print(\"quarter return:\",qtr_return)\n",
    "\n",
    "                #95% 2 tail\n",
    "                t_score = stats.t.ppf(1-0.025, len(test_errors_))\n",
    "\n",
    "                prediction_interval_yhat_upper = df_pred[['yhat']].tail(n_ahead)+(std_error_test.reshape(n_ahead,1)*t_score)\n",
    "                prediction_interval_yhat_lower = df_pred[['yhat']].tail(n_ahead)-(std_error_test.reshape(n_ahead,1)*t_score)\n",
    "\n",
    "                cv_outter_std_ratio = test_score_std / e_return\n",
    "                cv_outter_err_ratio = test_score_mean / e_return                        \n",
    "\n",
    "                stop_loss_price = pd.DataFrame(np.mean(pd.concat([df_pred[['yhat']].tail(n_ahead),prediction_interval_yhat_lower],axis=1),axis=1)).iloc[0].values[0]\n",
    "                decision_metrics_df_ = pd.DataFrame([s,e_return,discounted_return,qtr_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['yhat_upper'].values[0],p_metrics['yhat_lower'].values[0]])#,columns=)#,index=[s_])#.sort_values(by='disc_rtn',ascending=False,inplace=True)\n",
    "                decision_metrics_df_ = decision_metrics_df_.T\n",
    "                decision_metrics_df_.columns=['SYMBOL','exp_return','discounted_return','qtr_return','sell_date','stop_loss_price','days_delta','disc_rtn','qtr_rtn','outer_cv_avg_abs_err_n11','outer_cv_std_n11','mean_revert_flag','yhat_upper','yhat_lower']\n",
    "                decision_metrics_df_.index = [symbol_]       \n",
    "\n",
    "                bbands_ = bbands[set(bbands.columns).difference(['Adj Close'])]\n",
    "                bbands_.index = [symbol_]\n",
    "\n",
    "                outer_cv_avg_abs_err_n11_ratio = pd.DataFrame(test_score_mean/screener_sorted.loc[symbol_]['Adj Close'],columns=['outer_cv_avg_abs_err_n11_ratio'],index=[symbol_])\n",
    "                outer_cv_std_n11_ratio = pd.DataFrame(test_score_std/screener_sorted.loc[symbol_]['Adj Close'],columns=['outer_cv_std_n11_ratio'],index=[symbol_])\n",
    "\n",
    "\n",
    "                decision_metrics_df_ = pd.concat([decision_metrics_df_,bbands_,metrics_df_[metrics_df_.columns.difference(['50tdBOLD', '50tdMA-TP', '50tdBOLU','200tdSMA', '200tdSDev'])],outer_cv_avg_abs_err_n11_ratio,outer_cv_std_n11_ratio],axis=1)\n",
    "                #decision_metrics_df_ = decision_metrics_df_.sort_values(by='exp_return',ascending=True)                        \n",
    "\n",
    "                print(\"Outer CV Error / Price Ratio\",decision_metrics_df_['outer_cv_avg_abs_err_n11_ratio'])\n",
    "                print(\" Outer CV StdDev / Price Ratio\",decision_metrics_df_['outer_cv_std_n11_ratio'])\n",
    "\n",
    "                decision_metrics_df = pd.concat([decision_metrics_df,decision_metrics_df_],axis=0)            \n",
    "\n",
    "                savePlot=False\n",
    "                if(decision_metrics_df_['outer_cv_avg_abs_err_n11_ratio'].values[0]<.9):\n",
    "                    if(decision_metrics_df_['outer_cv_std_n11_ratio'].values[0]<.9):\n",
    "                        if(decision_metrics_df_['qtr_return'].values[0]>1.089):\n",
    "                            forecast_winners_df = pd.concat([forecast_winners_df,decision_metrics_df_],axis=0)\n",
    "                            savePlot=True                 \n",
    "\n",
    "                plt.plot(temp_df)\n",
    "                plt.plot(df_pred)\n",
    "                plt.legend(['Adj Close','yhat','yhat_lower','yhat_upper'],loc=2)\n",
    "                plt.xticks(rotation = 45,size=8)\n",
    "\n",
    "                if(savePlot):\n",
    "                    plt.savefig('..\\\\reports\\\\figures\\\\'+end.strftime('%Y-%m-%d')+'_'+symbol_+'_full_forecast.png', dpi=300, format='png', bbox_inches='tight')           \n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(temp_df.tail(n_ahead))\n",
    "                plt.plot(df_pred.tail(n_ahead*2))\n",
    "                plt.plot(prediction_interval_yhat_upper,linestyle = 'dashed')\n",
    "                plt.plot(prediction_interval_yhat_lower,linestyle = 'dashed')\n",
    "\n",
    "                plt.legend(['Adj Close','yhat','yhat_lower','yhat_upper','pi_upper','pi_lower'],loc=2)\n",
    "\n",
    "                plt.xticks(rotation = 45,size=8)\n",
    "\n",
    "                if(savePlot):\n",
    "                    plt.savefig('..\\\\reports\\\\figures\\\\'+end.strftime('%Y-%m-%d')+'_'+symbol_+'_13w_forecast.png', dpi=300, format='png', bbox_inches='tight')\n",
    "                plt.show()\n",
    "\n",
    "                fcst = m.predict(future_)\n",
    "                fig = m.plot(fcst)\n",
    "\n",
    "                if(savePlot):\n",
    "                    plt.savefig('..\\\\reports\\\\figures\\\\'+end.strftime('%Y-%m-%d')+'_'+symbol_+'_fb_sim_forecast.png', dpi=300, format='png', bbox_inches='tight')\n",
    "                plt.show()            \n",
    "\n",
    "                if(np.sum(np.array(fundamental_entries)==s)>0):\n",
    "                    loc = np.where(np.array(fundamental_entries)==s)[0][0]\n",
    "                    for item in fundamentals_quarterlies[loc][1]:\n",
    "                        if(type(item[1]) == type(None)):\n",
    "                            pass\n",
    "                        else:\n",
    "                            if(len(item[1])>0):\n",
    "                                #print(len(item[1]))\n",
    "                                #print(item)\n",
    "                                print(item[0])\n",
    "                                #with pd.option_context('display.precision', 2):\n",
    "                                    #display(format_vertical_headers(pd.DataFrame(item[1]).T.sort_index(ascending=True)))\n",
    "                                display(pd.DataFrame(item[1]).sort_index(ascending=True))\n",
    "                client.close()\n",
    "\n",
    "    decision_metrics_df.sort_values(by='exp_return',ascending=False,inplace=True) \n",
    "    \n",
    "    #V.dump(techniqueUsed = end.strftime('%Y-%m-%d')+'_FBProphet', filename = 'fbpropet_metrics.xlsx', message = \"FBProphet\", version =1)\n",
    "    decision_metrics_df.to_csv('..\\\\data\\\\processed\\\\'+end.strftime('%Y-%m-%d')+'_decision_metrics_df.csv')\n",
    "    forecast_winners_df.to_csv('..\\\\data\\\\processed\\\\'+end.strftime('%Y-%m-%d')+'_forecast_winners_df.csv')\n",
    "\n",
    "    display(decision_metrics_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b055c-2464-4903-9bbb-993c7f4c4e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c8fdd-14d1-49ab-b0c4-2e3c33c20fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260d1e6-607a-472e-a52e-920c057b4efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edba80-547f-484b-8b97-39cbb2030d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a889c11-8b78-48dc-bad1-0f7eef45f11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eda05e-aeab-4f3f-b98b-6ff5275874ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c27f57-caf2-4839-9878-8746ba9d7257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b008f-6a32-4f90-9746-0e93cde00bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored(r, g, b, text):\n",
    "    return f\"\\033[38;2;{r};{g};{b}m{text}\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01062e39-ec5e-4aff-9b7d-a4881369b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_side_by_side(dfs:list, captions:list, tablespacing=5):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    for (caption, df) in zip(captions, dfs):\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += tablespacing * \"\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834d092-79f2-4351-bb3f-d5824664ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.color_palette(\"blend:red,yellow,green\", as_cmap=True)\n",
    "\n",
    "def b_g(s, cmap=cm, low=0, high=0):\n",
    "    # Pass the columns from Dataframe A \n",
    "    a = A.loc[:,s.name].copy()\n",
    "    #rng = a.max() - a.min()\n",
    "    rng = np.nanmax(A.values.ravel()) - np.nanmin(A.values.ravel())\n",
    "    norm = mp.colors.Normalize(np.nanmin(A.values.ravel()) - (rng * low),\n",
    "                        np.nanmax(A.values.ravel()) + (rng * high))\n",
    "    normed = norm(a.values)\n",
    "    #c = [mp.colors.rgb2hex(x) for x in plt.cm.get_cmap(cmap)(normed)]\n",
    "    c = [mp.colors.rgb2hex(x) for x in plt.cm.get_cmap(cm)(normed)]\n",
    "    return ['background-color: %s' % color for color in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33406af6-de98-4076-8ba5-3d3f01cf8ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nyse = mcal.get_calendar('NYSE')\n",
    "nyse_dates = nyse.schedule(start_date=start, end_date=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3ca9d-729a-4fd1-91c9-6a5ada30bf12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471b2ef-d9e2-43ac-8da6-9fcb1974aec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a2b10-dacb-4077-8b2a-49bae6c4773e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sector_performance_return = pd.DataFrame()\n",
    "sector_performance_Q_smoothed_return = pd.DataFrame()\n",
    "\n",
    "for v in [*indexes['Symbol'],*sectors['Symbol']]:\n",
    "    subset = prices_df[prices_df['Symbol'] == v]\n",
    "    #subset_ = subset.set_index('Date').asfreq('Q')[['Adj Close']].pct_change()\n",
    "    subset_ = subset.asfreq('D').interpolate(method='time').asfreq('Q')[['Adj Close']].pct_change()\n",
    "    #print(subset_)\n",
    "    #subset_qs = subset.set_index('Date')[['Adj Close']].pct_change().rolling(63).mean()\n",
    "    subset_qs = subset[['Adj Close']].pct_change().rolling(63).mean()\n",
    "    subset_.index = subset_.index.values.astype('M8[D]')\n",
    "    subset_qs.index = subset_qs.index.values.astype('M8[D]')\n",
    "    dt_str = subset_.index[-1].strftime('%Y-%m-%d')\n",
    "    #tail = subset[subset.set_index('Date').index>=dt_str]\n",
    "    tail = subset[subset.index>=dt_str]\n",
    "    #dt_str = subset.set_index('Date').index[-1].strftime('%Y-%m-%d')\n",
    "    dt_str = subset.index[-1].strftime('%Y-%m-%d')\n",
    "    #tail_ = pd.DataFrame([(tail.set_index('Date')['Adj Close'][-1]-tail.set_index('Date')['Adj Close'][0])/tail.set_index('Date')['Adj Close'][0]],index=[datetime.strptime(dt_str, '%Y-%m-%d')],columns=['Adj Close'])\n",
    "    tail_ = pd.DataFrame([(tail['Adj Close'][-1]-tail['Adj Close'][0])/tail['Adj Close'][0]],index=[datetime.strptime(dt_str, '%Y-%m-%d')],columns=['Adj Close'])\n",
    "    subset__ = pd.concat([subset_,tail_],axis=0)\n",
    "    sector_performance_return = pd.concat([sector_performance_return,subset__],axis=1)\n",
    "    sector_performance_Q_smoothed_return = pd.concat([sector_performance_Q_smoothed_return,subset_qs],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c20583-f7e6-44d0-81b2-565578e81943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sector_performance_Q_smoothed_return.columns = [*[i for i in indexes.index],*[v for v in sectors.index]]\n",
    "sector_performance_return.columns = [*[i for i in indexes.index],*[v for v in sectors.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c4c77-278c-4ac8-837d-5634d3e7fded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1a300-3a80-4a2e-8103-1a0c38f77503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from scipy import stats as st\n",
    "from scipy.stats import t\n",
    "\n",
    "std_indexes = pd.DataFrame()\n",
    "seasonal_indexes = pd.DataFrame()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for spr in sector_performance_return.columns:\n",
    "    #print(spr)\n",
    "    s = sector_performance_return[[spr]]\n",
    "    #print(s)\n",
    "    years = []\n",
    "    quarters = []\n",
    "    for d in sector_performance_return[spr].index:\n",
    "\n",
    "        d_ = d.strftime('%Y-%m-%d')\n",
    "        #print(d_)\n",
    "\n",
    "        datem = dt.datetime.strptime(d_, \"%Y-%m-%d\")\n",
    "        years.append(str(datem.year))\n",
    "        #print(datem.year)       # 2021\n",
    "        m = datem.month\n",
    "        d = datem.day\n",
    "        if(len(str(m))==1):\n",
    "            m = '0'+str(m)\n",
    "        else:\n",
    "            m = str(m)\n",
    "        if(len(str(d))==1):\n",
    "            d = '0'+str(d)\n",
    "        else:\n",
    "            d = str(d)\n",
    "        quarters.append(m+\"-\"+d)\n",
    "\n",
    "    s['Years'] = years\n",
    "    s['Quarters'] = quarters\n",
    "    ct = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).mean(axis=0).sort_index()\n",
    "    ct.columns = [spr]\n",
    "    \n",
    "    ct_std = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).std(axis=0).sort_index()\n",
    "    ct_std.columns = [spr]\n",
    "    \n",
    "    std_indexes = pd.concat([std_indexes,ct_std],axis=1)\n",
    "    seasonal_indexes = pd.concat([seasonal_indexes,ct],axis=1)\n",
    "\n",
    "seasonal_indexes.columns = sector_performance_return.columns\n",
    "\n",
    "std_indexes.columns = sector_performance_return.columns\n",
    "    \n",
    "seasonal_indexes = seasonal_indexes.T\n",
    "\n",
    "std_indexes = std_indexes.T\n",
    "\n",
    "si = ['03-31','06-30','09-30','12-31']\n",
    "\n",
    "print(\"Seasonal Indexes\")\n",
    "\n",
    "seasonal_index_values_sorted = []\n",
    "seasonal_index_names_sorted = []\n",
    "#B = seasonal_indexes[si]\n",
    "for c in seasonal_indexes[si].columns:\n",
    "    seasonal_index_values_sorted.append(seasonal_indexes[si][c].sort_values(ascending=False).values)\n",
    "    seasonal_index_names_sorted.append(seasonal_indexes[si][c].sort_values(ascending=False).index.values)\n",
    "\n",
    "temp_seasonal_index_values_sorted = pd.DataFrame(seasonal_index_values_sorted).T\n",
    "temp_seasonal_index_values_sorted.columns = seasonal_indexes[si].columns\n",
    "\n",
    "temp_seasonal_index_names_sorted = pd.DataFrame(seasonal_index_names_sorted).T\n",
    "temp_seasonal_index_names_sorted.columns = seasonal_indexes[si].columns\n",
    "\n",
    "A = temp_seasonal_index_values_sorted\n",
    "B = temp_seasonal_index_names_sorted \n",
    "\n",
    "display(B.style.apply(b_g,cmap=cm))\n",
    "\n",
    "display(seasonal_indexes[si].style.background_gradient(cmap = cm,axis=0))\n",
    "\n",
    "print(\"Note if the final data in the prices ends on a quarter, this will aggregate into the seasonal_index above and there will be no comparison\")\n",
    "print(\"Current\")\n",
    "\n",
    "display(seasonal_indexes[seasonal_indexes.columns.difference(si)].sort_values(by=seasonal_indexes[seasonal_indexes.columns.difference(si)].columns[0],ascending=False).style.background_gradient(cmap = cm,axis=0))    \n",
    "\n",
    "#calculate p-value\n",
    "n=5\n",
    "\n",
    "print(\"standard deviations\")\n",
    "display(std_indexes[si])\n",
    "t_scores = (seasonal_indexes[si])/(std_indexes[si]/np.sqrt(n))\n",
    "print(\"t scores\")\n",
    "display(t_scores)\n",
    "print(\"p values\")\n",
    "p_values = pd.DataFrame(t.cdf(t_scores, df=n-2),index=seasonal_indexes[si].index,columns=seasonal_indexes[si].columns)\n",
    "\n",
    "display(p_values.style.applymap(highlight_cells, color_if_true='green', color_if_false='yellow', threshold_=.5))\n",
    "\n",
    "p_values.hist()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c1ddd-9e58-4720-beaf-5d7f1512dc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7eb29-705b-4e85-b229-a4555630ba35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cycles_ = ['Expansion','Slowdown','Recession','Recovery']\n",
    "\n",
    "path=r\"..\\data\\\\interim\\\\Business cycles.png\"\n",
    "display(Image.open(path))\n",
    "path=r\"..\\data\\\\interim\\\\Business Cycles-2.png\"\n",
    "display(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b9c801-d5fd-4f10-bd02-4e4c40cd0ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb933634-e9ed-4668-9284-a118f4f07d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0414d0e-36bd-4b64-b5a4-24b8b7932aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62134d-c867-414f-804b-400d0e8e29b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54d0ec-a466-4feb-9471-6b523521c8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca435f40-9712-4d35-b805-724d8d8b1a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257bf38-1952-4509-be46-715f579645cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sector_performance_returned_no_dup = sector_performance_return.loc[~sector_performance_return.index.duplicated(keep ='first')]\n",
    "sector_performance_return_pvt = sector_performance_returned_no_dup[sector_performance_returned_no_dup.iloc[-1].sort_values(ascending=False).index]\n",
    "\n",
    "sector_performance_return_pvt_heatmap = sector_performance_return_pvt.style.background_gradient(cmap = cm,axis=None)\n",
    "display(sector_performance_return_pvt_heatmap)\n",
    "\n",
    "sector_performances = pd.DataFrame()\n",
    "sector_performances_values = pd.DataFrame()\n",
    "for c in sector_performance_returned_no_dup.T.columns:\n",
    "    #print(c)\n",
    "    temp = pd.DataFrame(sector_performance_returned_no_dup.T[c].sort_values(ascending=False).index,columns=[c])\n",
    "    #print(temp)\n",
    "    temp2 = pd.DataFrame(sector_performance_returned_no_dup.T[c].sort_values(ascending=False),columns=[c])\n",
    "    #print(temp2)\n",
    "    temp2.reset_index(drop=True,inplace=True)    \n",
    "    sector_performances = pd.concat([sector_performances,temp],axis=1)\n",
    "    sector_performances_values = pd.concat([sector_performances_values,temp2],axis=1)\n",
    "    \n",
    "A = sector_performances_values\n",
    "B = sector_performance_returned_no_dup.T\n",
    "\n",
    "df = B.style.apply(b_g,cmap='RdYlGn')\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12f766-8f48-4ea5-b403-425a5dd952f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfff60-c3f0-496e-a6ce-375edac96d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982011bf-09cf-4749-8f63-b077931fc4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#cm = sns.color_palette(\"blend:red,yellow,green\", as_cmap=True)\n",
    "#pd.crosstab(shares_viz['Year'], shares_viz['Month'])\n",
    "\n",
    "#seasonal_indexes[si]\n",
    "seasonally_adjusted = pd.DataFrame()\n",
    "\n",
    "for s in sector_performance_return.columns:\n",
    "    \n",
    "    s_ = pd.DataFrame(sector_performance_return[s])\n",
    "    #print(sector_performance_return[s])\n",
    "    years = []\n",
    "    quarters = []\n",
    "    \n",
    "    for d in s_.index:\n",
    "        d_ = d.strftime('%Y-%m-%d')\n",
    "        #print(d_)\n",
    "\n",
    "        datem = dt.datetime.strptime(d_, \"%Y-%m-%d\")\n",
    "        years.append(str(datem.year))\n",
    "        #print(datem.year)       # 2021\n",
    "        m = datem.month\n",
    "        d = datem.day\n",
    "        if(len(str(m))==1):\n",
    "            m = '0'+str(m)\n",
    "        else:\n",
    "            m = str(m)\n",
    "        if(len(str(d))==1):\n",
    "            d = '0'+str(d)\n",
    "        else:\n",
    "            d = str(d)\n",
    "        quarters.append(m+\"-\"+d)\n",
    "        \n",
    "    s_['Quarter'] = quarters\n",
    "    si_ = seasonal_indexes.loc[s]\n",
    "    \n",
    "    modified = pd.DataFrame()\n",
    "    #print(si_.index)\n",
    "    for s_i_ in si_.index:\n",
    "        #print(s_i_)\n",
    "        #when it finds the last date (which hopefully isn't a quarter date)\n",
    "        if(np.sum(np.array(si)==s_i_)==0):\n",
    "            #print(\"don't modify\")\n",
    "            #print(s_i_)\n",
    "            match = []\n",
    "            for entry in si:\n",
    "                if(int(s_i_.rsplit(\"-\")[0])<=int(entry.rsplit(\"-\")[0])):\n",
    "                    match = entry\n",
    "                    break            \n",
    "\n",
    "            delta_months = int(match.rsplit(\"-\")[0])-int(s_i_.rsplit(\"-\")[0])\n",
    "            delta_days_ = int(match.rsplit(\"-\")[1])-int(s_i_.rsplit(\"-\")[1])\n",
    "            \n",
    "            delta_days = int(delta_months*(91.25/3)+delta_days_)\n",
    "            #daily interest\n",
    "            \n",
    "            #print(delta_days)\n",
    "            #print(seasonal_indexes.loc[s].loc[match])\n",
    "            seasonal_index_to_daily = (1+seasonal_indexes.loc[s].loc[match])**(1/91.25)-1\n",
    "            #print(\"Seasonal Index to Daily Discounted Interest Rate:\",seasonal_index_to_daily)\n",
    "            daily_extrapolated = (1+seasonal_index_to_daily)**delta_days-1\n",
    "            #print(daily_extrapolated)\n",
    "            #print(\"Daily ^ delta_days:\",daily_extrapolated)\n",
    "            \n",
    "            #print(match)\n",
    "            #print(s_i_)\n",
    "            seasonally_adjusted_column = pd.DataFrame([seasonal_indexes.loc[s].loc[match] - daily_extrapolated],columns=[s],index=[s_.index[-1]])\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            seasonally_adjusted_column = pd.DataFrame(s_[s][s_['Quarter']==s_i_] - seasonal_indexes.loc[s].loc[s_i_],columns=[s])\n",
    "        modified = pd.concat([modified,seasonally_adjusted_column],axis=0)\n",
    "        modified.sort_index(inplace=True)\n",
    "    #print(modified)\n",
    "    seasonally_adjusted = pd.concat([seasonally_adjusted,modified],axis=1)\n",
    "\n",
    "print(\"Comparative to Seasonal Indexes, tells you who is over or underperforming.\")\n",
    "print(\"This is Seasonal Index - Extrapolated Current Quarter.\")\n",
    "print(\"+: seasonal > current\")\n",
    "print(\"-: current > seasonal\")\n",
    "\n",
    "print(\"Note if the final data in the prices ends on a quarter, this will aggregate into the seasonal_index above and there will be no comparison\")\n",
    "    \n",
    "    \n",
    "std_indexes_seas_adj = pd.DataFrame()\n",
    "seasonal_indexes_seas_adj = pd.DataFrame()\n",
    "\n",
    "temp_ = pd.DataFrame(seasonally_adjusted.T.iloc[:,-1])\n",
    "temp_.columns = pd.DataFrame(seasonally_adjusted.T.iloc[:,-1]).columns.strftime('%Y-%m-%d')\n",
    "display(temp_.sort_values(by=temp_.columns[0],ascending=False).style.background_gradient(cmap = cm,axis=0))\n",
    "\n",
    "#display(seasonally_adjusted[seasonally_adjusted.columns.difference(si)].style.background_gradient(cmap = cm,axis=0))\n",
    "\n",
    "for spr in seasonally_adjusted.columns:\n",
    "    #print(spr)\n",
    "    s = seasonally_adjusted[[spr]]\n",
    "    #print(s)\n",
    "    years = []\n",
    "    quarters = []\n",
    "    for d in seasonally_adjusted[spr].index:\n",
    "        d_ = d.strftime('%Y-%m-%d')\n",
    "        #print(d_)\n",
    "\n",
    "        datem = dt.datetime.strptime(d_, \"%Y-%m-%d\")\n",
    "        years.append(str(datem.year))\n",
    "        #print(datem.year)       # 2021\n",
    "        m = datem.month\n",
    "        d = datem.day\n",
    "        if(len(str(m))==1):\n",
    "            m = '0'+str(m)\n",
    "        else:\n",
    "            m = str(m)\n",
    "        if(len(str(d))==1):\n",
    "            d = '0'+str(d)\n",
    "        else:\n",
    "            d = str(d)\n",
    "        quarters.append(m+\"-\"+d)\n",
    "\n",
    "    s['Years'] = years\n",
    "    s['Quarters'] = quarters\n",
    "    ct = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).mean(axis=0).sort_index()\n",
    "    ct.columns = [spr]\n",
    "    #print(ct)\n",
    "    \n",
    "    ct_std = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).std(axis=0).sort_index()\n",
    "    ct_std.columns = [spr]\n",
    "    \n",
    "    std_indexes_seas_adj = pd.concat([std_indexes_seas_adj,ct_std],axis=1)\n",
    "    seasonal_indexes_seas_adj = pd.concat([seasonal_indexes_seas_adj,ct],axis=1)\n",
    "\n",
    "seasonal_indexes_seas_adj.columns = seasonally_adjusted.columns\n",
    "\n",
    "std_indexes_seas_adj.columns = seasonally_adjusted.columns\n",
    "    \n",
    "seasonal_indexes_seas_adj = seasonal_indexes_seas_adj.T\n",
    "\n",
    "std_indexes_seas_adj = std_indexes_seas_adj.T\n",
    "\n",
    "sector_performances_sea_adj = pd.DataFrame()\n",
    "sector_performances_values_sea_adj = pd.DataFrame()\n",
    "for c in seasonally_adjusted.T.columns:\n",
    "    temp = pd.DataFrame(seasonally_adjusted.T[c].sort_values(ascending=False).index,columns=[c])\n",
    "    temp2 = pd.DataFrame(seasonally_adjusted.T[c].sort_values(ascending=False),columns=[c])\n",
    "    temp2.reset_index(drop=True,inplace=True)    \n",
    "    sector_performances_sea_adj = pd.concat([sector_performances_sea_adj,temp],axis=1)\n",
    "    sector_performances_values_sea_adj = pd.concat([sector_performances_values_sea_adj,temp2],axis=1)\n",
    "\n",
    "A = sector_performances_values_sea_adj\n",
    "B = sector_performances_sea_adj\n",
    "\n",
    "df_sea_adj = B.style.apply(b_g,cmap='RdYlGn')\n",
    "display(df_sea_adj)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b39b6-9237-4645-bbdb-8a34dfa1c6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d032d-0cf3-400a-a801-185619948a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "index_performance = []\n",
    "for v in indexes['Symbol'].values:\n",
    "    index_performance.append([v,screener.loc[v]['risk_trend_factor']])\n",
    "temp_i = pd.DataFrame(index_performance,index=indexes.index)\n",
    "temp_i.columns = ['Symbol','risk_trend_factor']\n",
    "index_risk_sorted = pd.DataFrame(index_performance,columns=['Symbol','risk_trend_factor'],index=indexes.index).sort_values(by='risk_trend_factor',ascending=False).reset_index()\n",
    "index_risk_sorted.columns = ['Index','Symbol','risk_trend_factor']\n",
    "index_risk_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56630f8-6533-4540-856b-d8d9451ef65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sector_performance = []\n",
    "for v in sectors['Symbol'].values:\n",
    "    sector_performance.append([v,screener.loc[v]['risk_trend_factor']])\n",
    "temp_v = sectors.reset_index()\n",
    "temp_v.columns = ['Sector','Symbol']\n",
    "sectors_risk_sorted = pd.DataFrame(sector_performance,columns=['Symbol','risk_trend_factor']).merge(temp_v, on='Symbol', how='left').sort_values(by='risk_trend_factor',ascending=False)    \n",
    "sectors_risk_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a2ec6-395f-4da5-bfa5-7e7c988ae08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a771c-5610-4928-a935-9b82d1fb9cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Rolling Quarterly Mean Return\")\n",
    "plt.plot(sector_performance_Q_smoothed_return)\n",
    "plt.legend([*[i for i in indexes.index],*[v for v in sectors.index]],loc=2,fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c50ea-5870-498b-b7da-617d97c578f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13a3ec-5048-4acc-ab5c-f798e1216b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"Quarterly Returns\")\n",
    "for v in sector_performance_return.T.index:\n",
    "    subset = pd.DataFrame(sector_performance_return.T.loc[v])\n",
    "    subset.columns = ['Return']\n",
    "    plt.plot(subset)\n",
    "    plt.xticks(subset.index, rotation=45)\n",
    "plt.legend(sector_performance_return.T.index,loc=2)    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf881ad7-da51-46d1-b8c9-eb903b7aa6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0716a-3b2d-43e9-93b3-c659efa306d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.plot(seasonal_indexes[si].T)\n",
    "plt.legend(seasonal_indexes[si].T.columns,loc=2,fontsize=8)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a954f-1e41-4112-a980-a9691a8f63c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59a21d-0820-4a62-908f-54ecac2e45f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683e62d-4d0e-476d-afa3-52ad82a1c96c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e546c98-ca0c-425c-acb2-7a3f965c2a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#risk_trend_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd8fd4-950c-4bc9-ba28-af6baf1ae54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71ada5-3b22-4191-90d1-f15b7fb7e5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#market_data['sector'] = stock_fundamentals['sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa318b-d659-4ccc-a9f0-690cf4ceac36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf398b-c971-4a14-a7ed-9fd5c2b7a3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c01705-6411-4957-90f6-521e7155ce71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a825ee5-d4bd-4637-b588-f5118cf49f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#screener[['risk_trend_factor']].replace(['missing','error'], np.NaN).dropna().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25448842-ee84-4647-87e3-d992eef0bc9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(screener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f3156-444c-451b-a326-9df38293d66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e93bc0-29aa-45fe-8c9e-6a8a5596a8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prices_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b194139-71d1-4533-a98f-365fd3091584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887c1c3-269e-4ff7-97d7-0f629b1e02e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfda1b2-a4a5-4d30-a1cb-de0c8cf35c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bceec-0d5c-4f79-a610-dead31b3a405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607a019-d78d-40f1-b870-f3e9c8b0f7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f70f23-e164-4cbc-9b36-56179475fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16abc74-da31-4bb2-bd4b-f4c04e0a671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold_value = summary.dropna()['risk_trend_factor'].quantile([threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b6deb-8a67-4153-82df-5c163093db01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e4361-ac3b-4d6e-b549-eb253ef708ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af351818-c6ba-4266-a7c4-e51749929cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae8bc3-ac12-4d8e-813f-8a40be23dfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65f6cf-37e8-4d73-934b-5f59ad2c69f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a417218-6f64-46c7-98b4-86a5f7f3257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9700e2-c4a4-43a9-8a16-247223bbee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "screener_sorted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f712bf-fdfc-4ad7-91a8-a06e2eaeead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_pvt_sample = completed_fred_pvt_df[fred_names].asfreq('D').interpolate(method='time').asfreq('Q').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4802753b-506c-41cc-b7c1-101a9252a5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcc7c77-508c-4251-b118-2b6d98e32bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53de2713-c9ce-48da-b383-7b43984d14f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvv_50td_filter = screener_sorted['50td_tvf_vel'].replace(['missing','missingmissing','error'], np.nan).dropna()\n",
    "tvv_50td_filter = tvv_50td_filter[tvv_50td_filter>np.max([tvv_50td_filter.median(),tvv_50td_filter.mean()])]\n",
    "\n",
    "tvv_20td_filter = screener_sorted['20td_tvf_vel'].replace(['missing','missingmissing','error'], np.nan).dropna()\n",
    "tvv_20td_filter = tvv_50td_filter[tvv_20td_filter>np.max([tvv_20td_filter.median(),tvv_20td_filter.mean()])]\n",
    "\n",
    "risk_trend_factor_filter = screener_sorted['risk_trend_factor'].replace(['missing','missingmissing','error'], np.nan).dropna()\n",
    "risk_trend_factor_filter = risk_trend_factor_filter[risk_trend_factor_filter>np.max([risk_trend_factor_filter.median(),risk_trend_factor_filter.mean()])]\n",
    "\n",
    "filtered = np.unique([*tvv_50td_filter.index,*tvv_20td_filter.index, *risk_trend_factor_filter.index])\n",
    "\n",
    "filtered = set(risk_trend_factor_filter.index).intersection(set(tvv_50td_filter.index).intersection(tvv_20td_filter.index))\n",
    "\n",
    "filtered = screener_sorted.loc[filtered][['50td_tvf_vel','20td_tvf_vel','risk_trend_factor']]\n",
    "filtered = (filtered>filtered.median()).all(axis=1)\n",
    "filtered = filtered[filtered].index\n",
    "\n",
    "#filtered = screener_sorted.loc[filtered][['50td_tvf_vel','20td_tvf_vel','risk_trend_factor']]\n",
    "#filtered = filtered[filtered>np.max([filtered.median()])]\n",
    "print(len(filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c7f72-2513-4f5c-9667-905ccaf3887b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_screener_sorted = screener_sorted.loc[filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d4468e-9e99-4b7f-bb2c-f11ebd72279d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f103181-630a-4d27-9f84-00fed7a121e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906292e2-912d-49ee-ad5b-d1128c0f3538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82868ce-8cd8-4f8f-af52-712a09a280c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c34240-3bca-4e91-9e10-46349d9df6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd232d-8b14-4a80-8936-9aef1d831282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f9bc2-d935-4b61-82a7-b71a59ecaf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_screener_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d6116-d3eb-4e6f-abc2-7c0590e2c51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff5e6f-7fdc-45af-93bb-5805a16c3f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18049f-28ca-456f-afbe-7d16941b6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "      r_from_pd_df = ro.conversion.py2rpy(fred_pvt_sample.melt(ignore_index=False).reset_index().rename(columns={'index': 'Date'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c0e51-bf0c-4aac-bcf5-bbce8e0fc97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136679c-5478-4f78-8256-52cabe04debe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd0649-1c64-4f77-8a14-ee9db088a4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ro.X11()\n",
    "#ro.windows()\n",
    "ro.r('''\n",
    "\n",
    "my_mean <- function(x, na.rm=TRUE) {\n",
    "  mean(x, na.rm = na.rm)\n",
    "}\n",
    "\n",
    "f <- function(y) {\n",
    "#print(y)\n",
    "\n",
    "#library(arfima)\n",
    "#varvefd = arfima(y)\n",
    "#d = summary(varvefd)$coef[[1]][1]\n",
    "#return(d)\n",
    "\n",
    "tsfeature_tbl <- y %>%\n",
    "group_by(variable) %>%\n",
    "tk_tsfeatures(\n",
    "  .date_var = Date,\n",
    "  .value    = value,\n",
    "  .period   = 4,\n",
    "  .features = c(\"frequency\", \"stl_features\", \"entropy\", \"acf_features\", \"my_mean\"),\n",
    "  .scale    = TRUE,\n",
    "  .prefix   = \"ts_\"\n",
    ") %>%\n",
    "ungroup()\n",
    "    \n",
    "print(tsfeature_tbl)\n",
    "\n",
    "set.seed(123)\n",
    "\n",
    "cluster_tbl <- tibble(\n",
    "    cluster = tsfeature_tbl %>% \n",
    "        select(-variable) %>%\n",
    "        as.matrix() %>%\n",
    "        kmeans(centers = 7, nstart = 100) %>%\n",
    "        pluck(\"cluster\")\n",
    ") %>%\n",
    "    bind_cols(\n",
    "        tsfeature_tbl\n",
    "    )\n",
    "\n",
    "cluster_tbl\n",
    "\n",
    "cluster_tbl %>%\n",
    "    select(cluster, variable) %>%\n",
    "    right_join(y, by = \"variable\") %>%\n",
    "    group_by(variable) %>%\n",
    "    plot_time_series(\n",
    "      Date, value, \n",
    "      .color_var   = cluster, \n",
    "      .facet_ncol  = 2, \n",
    "      .interactive = FALSE\n",
    "    )\n",
    "plot(cluster_tbl)\n",
    "\n",
    "return(tsfeature_tbl)\n",
    "}\n",
    "''')\n",
    "grdevices.png(file=\"..\\\\reports\\\\figures\\\\cluster_tbl.png\", width=4096, height=1024)\n",
    "r_f = ro.globalenv['f']\n",
    "\n",
    "d=ro.conversion.rpy2py((r_f(ro.conversion.py2rpy(r_from_pd_df))))\n",
    "\n",
    "#rprint(pp)\n",
    "\n",
    "time.sleep(3)\n",
    "#grdevices.dev_copy(device = r.png, filename = \"plot.png\", width = 1000, height = 500)\n",
    "grdevices.dev_off()\n",
    "\n",
    "#From here optional, if you want a waiting time\n",
    "#Elsewise close the plot manually afterwards with grdevices.dev_off()\n",
    "\n",
    "#grdevices.dev_off()\n",
    "#grdevices.dev_off()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c975dc5b-4d2c-494f-a3ce-aeeb91e867e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d8a46-c161-40fe-8491-3fb0662a136a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0594f8e8-ba4a-47bc-a41d-63ac2150b4ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a8247-911b-467d-b2b8-b777e9b3b500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3f3de-8061-4f38-af34-954d2ffe48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99, svd_solver='full')\n",
    "\n",
    "X = np.array(d.iloc[:,1:])\n",
    "\n",
    "pca.fit(scale(X))\n",
    "#pca.explained_variance_\n",
    "pca.explained_variance_ratio_.cumsum()\n",
    "X_pca = pd.DataFrame(pca.transform(d.iloc[0:,1:]))\n",
    "X_pca.index = d.index\n",
    "X_pca.sort_values(by=[0],ascending=False,inplace=True)\n",
    "\n",
    "TSS_ = []\n",
    "BSS_ = []\n",
    "WSS_ = []\n",
    "silhouettes_ = []\n",
    "\n",
    "for k in range(2,int(len(d)/2)):\n",
    "    model = KMeans(n_clusters=k, random_state=0, n_init=100).fit(X)\n",
    "    #print(model.inertia_)\n",
    "\n",
    "    codebook = np.array(model.cluster_centers_)\n",
    "    partition, euc_distance_to_centroids = vq(X, codebook)\n",
    "    WSS = np.sum(euc_distance_to_centroids**2)\n",
    "    \n",
    "    silhouette_avg = silhouette_score(X, model.labels_)\n",
    "\n",
    "    silhouettes_.append(silhouette_avg)\n",
    "    \n",
    "    TSS = np.sum((X-X.mean(0))**2)\n",
    "\n",
    "    BSS = TSS - WSS\n",
    "\n",
    "    TSS_.append(TSS)\n",
    "    BSS_.append(BSS)\n",
    "    WSS_.append(WSS)\n",
    "    \n",
    "    #print(TSS, WSS, BSS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a9a21-21c3-4031-80f2-d4fc12e11b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_min = 2\n",
    "init_max = 5\n",
    "\n",
    "\n",
    "mink = 2\n",
    "maxk = 6\n",
    "\n",
    "tss, bss, wss = findOptimalK_ANOVA(X_pca, mink = mink, maxk = maxk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182f2bd-0ff2-40af-a11e-b7bf788584f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(BSS_)/np.array(TSS_))\n",
    "plt.show()\n",
    "plt.plot(np.array(WSS_))\n",
    "plt.show()\n",
    "plt.plot(np.array(silhouettes_))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb8154-dbdd-499b-9c36-db1a30aa1c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15fa52-a62e-4ba0-922a-bd573c1c9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bss_ = findknee(bss)\n",
    "bss_ = bss_/np.max(bss_)\n",
    "\n",
    "wss_ = findknee(np.array(pd.DataFrame(wss).mean(1)))\n",
    "wss_ = wss_/np.max(wss_)\n",
    "\n",
    "temp_df = pd.DataFrame(bss_/wss_).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "temp_df.index = np.array(range(0,len(wss_)))+mink\n",
    "#plt.plot(temp_df)\n",
    "\n",
    "set_ = np.abs(temp_df-1)\n",
    "plt.plot(set_)\n",
    "\n",
    "optimal_k = np.argmin(set_)+mink\n",
    "plt.plot(abs(set_-1))\n",
    " \n",
    "print(optimal_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028bfb7a-bfe8-49a1-909e-6d43111d55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeansConstrained(n_clusters=optimal_k, size_min=init_min, size_max=max(np.ceil(len(X_pca)/optimal_k),init_max), init='k-means++', n_init=100, max_iter=100, tol=0.0001, verbose=False, random_state=None, copy_x=True, n_jobs=4)\n",
    "clf.fit_predict(X_pca)\n",
    "\n",
    "labels = clf.labels_\n",
    "clusters = clf.n_clusters\n",
    "centers = clf.cluster_centers_\n",
    "\n",
    "print(labels)\n",
    "\n",
    "tot_ss, BSS, within_ss = deriveANOVA(clf, X_pca)\n",
    "\n",
    "Global_F = (BSS/(optimal_k-1))/(np.mean(within_ss)/(len(X_pca)-optimal_k))\n",
    "global_sig = 1-f_.cdf(Global_F, (len(X_pca)-optimal_k), len(X_pca)-1)\n",
    "\n",
    "ind_F_scores = []\n",
    "\n",
    "for w in range(0,len(within_ss)):\n",
    "\n",
    "    dfn = (optimal_k-1)\n",
    "    dfd = np.sum(labels==w)-optimal_k\n",
    "\n",
    "    F_score = (BSS/dfn)/(within_ss[w]/(dfd))\n",
    "    ind_F_scores.append(F_score)\n",
    "\n",
    "print(\"Global F:\",Global_F)\n",
    "print(\"Global Sig:\",global_sig)\n",
    "print(\"F-Scores:\", ind_F_scores)\n",
    "\n",
    "print(\"P-Scores:\", 1-f_.cdf(ind_F_scores, dfn, dfd))\n",
    "\n",
    "X_pca['cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04cef0f-e105-4f71-b08b-5226cc57ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cgram = Clustergram(range(1, 8))\n",
    "cgram.fit(X_pca)\n",
    "cgram.plot()\n",
    "cgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba7236-c48f-496f-8982-1945d80ab96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b676e27-10c3-4b4e-b2f9-6f4079bc73f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ba281e-7c0e-4626-ba07-09de582ca029",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ad7c2-9624-425c-b37c-f084137f72ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dba091-352c-46b7-8441-f7e546783143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d785d-3520-4bfc-afa4-c2df19c65b96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1467172-addd-4eff-a114-b2d69da4c465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbf7be-e25a-4e46-9ec9-b14efeb6124f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba2503-ae16-452e-8881-13a9b5403f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585498f-046a-4816-a69f-6c19e41c1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "model = VARMAX(future_commodities_n_w_index_pvt_w_Fred_, order=(1,1,))\n",
    "model_fit = model.fit(disp=False)\n",
    "yhat = model_fit.forecast(13)\n",
    "print(yhat)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db8ad00-876f-4195-8bb2-ec182817c429",
   "metadata": {},
   "outputs": [],
   "source": [
    "prices_pvt = pd.pivot_table(prices_df, values=['Adj Close'], index=prices_df.index,columns='Symbol').asfreq('D').interpolate(method='time',limit_direction='forward',limit_area='inside').reindex(nyse_dates.index)\n",
    "prices_pvt.index = [d.strftime('%Y-%m-%d') for d in prices_pvt.index]\n",
    "prices_pvt.columns = prices_pvt.columns.droplevel(0)\n",
    "prices_pvt.index = [pd.to_datetime(d) for d in prices_pvt.index]\n",
    "combined_prices_w_commodities = prices_pvt.join(future_commodities_n_w_index_pvt_w_Fred.reindex(prices_pvt.index)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9022738a-27fe-4c76-9328-dd6376622317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e15bdb-89e0-44c5-96bb-5e070187d1ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab0122e-d488-4d81-a6a0-a5193669ebb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed1825-65f6-470e-b16c-17fd47637773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7560344f-5d3c-4094-8134-cd4d8e7f6d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbc568-8ecb-4ff5-8475-8f93118a634e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034cb614-e77d-433b-973b-e12d73f3f2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc809f-27df-4db2-918d-eb5496f5299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lengths = []\n",
    "for i in range(0,max(X_pca['cluster'])+1):\n",
    "    subset = d.loc[X_pca[X_pca['cluster']==i].index]\n",
    "    lengths.append(len(subset))\n",
    "    \n",
    "colors = ['purple','cyan','magenta','green','red','black','pink','yellow','blue','brown','orange','grey']\n",
    "my_cmap = LinearSegmentedColormap.from_list(\n",
    "    'color_map', colors, N=max(lengths))\n",
    "\n",
    "rescale = lambda y: (y - 0) / (np.max(lengths) - 0)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de78e2-847e-4044-9fcb-e0798132dbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce802a-6ce4-44d7-9e77-0704dc7d495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0,max(X_pca['cluster'])+1):\n",
    "    print(\"Group: \",i)\n",
    "    subset = d.loc[X_pca[X_pca['cluster']==i].index]\n",
    "    #\n",
    "    for c_ in range(0,len(subset['variable'])):\n",
    "        c = subset['variable'].values[c_]\n",
    "        try:\n",
    "            #print(dict_fred[c])\n",
    "            display(html_print(' '.join([cstr(ti, color=ci) for ti,ci in ((dict_fred[c], colors[c_]),)])))\n",
    "\n",
    "            #display(html_print(' '.join([cstr(ti, color=my_cmap(rescale(c_))) for ti in (('hello my name is'),)])))\n",
    "            #print(colored(\"hello red world\", my_cmap(rescale(c_))))\n",
    "            if(c_==0):\n",
    "                fig, ax1 = plt.subplots( figsize=(30,4))\n",
    "                ax1.plot(fred_pvt_sample[c],color=my_cmap(rescale(c_)))\n",
    "                ax1.get_yaxis().set_ticks([])\n",
    "            else: \n",
    "                ax2 = ax1.twinx()\n",
    "                ax2.plot(fred_pvt_sample[c],color=my_cmap(rescale(c_)))\n",
    "                ax2.get_yaxis().set_ticks([])\n",
    "        #ax1.legend(subset['variable'].values,loc=2)\n",
    "        except:\n",
    "            pass\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef1d40-755f-43a0-a306-b26273cc1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ = fred_pvt_sample.columns.tolist()\n",
    "def f3(Y):\n",
    "    \n",
    "    #Y = x\n",
    "    #output_slider_variable.value\n",
    "    internalFilter = filter_.copy()\n",
    "    internalFilter.remove(Y)\n",
    "    all_data_ = pd.concat([fred_pvt_sample[Y],fred_pvt_sample[internalFilter]], axis=1)    \n",
    "    #print(all_data_.describe())\n",
    "    display(fred_pvt_sample.describe())\n",
    "    #x_ticks = all_data_.index[np.arange(0, len(all_data.index), int(len(internalFilter)/5))]\n",
    "    x_ticks  = []\n",
    "    for index, element in enumerate(fred_pvt_sample.index):\n",
    "        if index % int(np.round(len(fred_pvt_sample.index)/10)) == 0:\n",
    "            x_ticks.append(element)\n",
    "    plt.plot(fred_pvt_sample[Y])\n",
    "    plt.xticks(x_ticks, rotation = 45)\n",
    "    plt.show()        \n",
    "    plt.hist(fred_pvt_sample[Y], bins='auto')\n",
    "    plt.show()\n",
    "    diff = pd.DataFrame((fred_pvt_sample[Y].pct_change())).dropna()\n",
    "    plt.hist(diff, bins='auto')\n",
    "    plt.show()\n",
    "    return(fred_pvt_sample)\n",
    "    \n",
    "out = interactive(f3, Y=filter_)\n",
    "\n",
    "#output_slider_variable.observe(f4, 'value')\n",
    "\n",
    "print(\"choose Y\")\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81fcd6-e8a7-4fb6-a874-e9edb8f4f3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b2b91-888f-4d53-9336-295f64e41028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('nominal,','pct_change,','pct_change().cumsum')\n",
    "for pos in range(0,len(fred_names)):\n",
    "    print(fred_friendly_names[pos],fred_names[pos])\n",
    "    name = fred_names[pos]\n",
    "    \n",
    "    \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False,figsize=(15,6))\n",
    "    ax1.plot(completed_fred_pvt_df[name])\n",
    "    ax1.set_xticklabels(np.array(completed_fred_pvt_df.index.map(lambda t: t.strftime('%Y-%m-%d')))[np.arange(0,len(completed_fred_pvt_df.index),int(len(completed_fred_pvt_df.index)/10))], rotation=45)\n",
    "    ax2.plot(completed_fred_pvt_df[name].pct_change())\n",
    "    ax2.set_xticklabels(np.array(completed_fred_pvt_df.index.map(lambda t: t.strftime('%Y-%m-%d')))[np.arange(0,len(completed_fred_pvt_df.index),int(len(completed_fred_pvt_df.index)/10))], rotation=45)\n",
    "    ax3.plot(completed_fred_pvt_df[name].pct_change().cumsum())\n",
    "    ax3.set_xticklabels(np.array(completed_fred_pvt_df.index.map(lambda t: t.strftime('%Y-%m-%d')))[np.arange(0,len(completed_fred_pvt_df.index),int(len(completed_fred_pvt_df.index)/10))], rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f248ba-d0b2-4b25-a9ca-ac78643ce98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#screener['vol_30d_2yr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c752f-c4e7-4beb-bb9a-2dad9d0f4aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447fa06-6e2a-4b18-b40c-817411a5980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(np.mean(np.exp(final_model.get_prediction(start=end,end=(end + dt.timedelta(92)).strftime('%Y-%m-%d')).summary_frame())[['mean','pi_lower']],axis=1)).iloc[0].values[0]\n",
    "#[s,e_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['pi_lower'].values[0],p_metrics['pi_upper'].values[0]]\n",
    "#screener['Adj Close'].loc[decision_metrics_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c39487-0321-4d3e-94f9-ae163abafb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fcedb9-fc57-4852-9bc6-dd38793ae013",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "#tscv = expanding_window(initial =52*2, horizon = 13,period = 26)\n",
    "\n",
    "#batchClearLimit = round(len(list__)/7)\n",
    "\n",
    "print(\"adf < .05 or .01, mean reverting\")\n",
    "print(\"Hurst\")\n",
    "print(\"> .5 - The time series is mean reverting.\")\n",
    "print(\"= .5 - The time series is a Geometric Brownian Motion.\")\n",
    "print(\"< .5 - The time series is trending.\")\n",
    "\"\"\"*indexes['Symbol'].values,*sectors['Symbol'].values,\"\"\"\n",
    "\"\"\"\n",
    "widgets.Dropdown(\n",
    "    #options=stocks_,\n",
    "    #value=None,\n",
    "    description='Choose Stock:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "#y_=widgets.Select(options=stocks_,disabled=False)\n",
    "y_=widgets.Select(options=np.sort([*list_sector_n_indexes,*list_stocks]),value=None,disabled=False)\n",
    "\n",
    "a=interact(plot_,symbol_=y_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93930c9-b48a-4210-8bb1-548985765530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128ef090-f524-44f4-931d-41bdb26338b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbef826-dcaf-4e7e-bb8a-e601fc41b7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2c975e-e0d8-4b90-9e56-81c8f8a6ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "observer_set = [*[d for d in dict_sectors_reverse]][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af39fd0e-7ff4-452e-88a4-6a2cffe8d657",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3449d260-c085-4d31-8f21-4fb6f7361281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077bf6ff-84c6-4344-98dc-33f23d3112c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = prices_df[prices_df['Symbol']=='SPY'][['Adj Close']].asfreq('D').interpolate(method='time').asfreq('W-'+end.strftime('%a')).reset_index()\n",
    "df.columns = ['ds','y']\n",
    "\n",
    "m = Prophet()\n",
    "#m = MultiProphet(columns=observer_set)\n",
    "\n",
    "for o in observer_set:\n",
    "    temp = prices_df[prices_df['Symbol']==o][['Adj Close']].asfreq('D').interpolate(method='time').asfreq('W-'+end.strftime('%a')).reset_index()[['Adj Close']]\n",
    "    temp.columns = [o]\n",
    "    \n",
    "    df = pd.concat([df,temp],axis=1)\n",
    "    \n",
    "#plt.plot(df['y'])\n",
    "\n",
    "m.fit(df[['ds','y']])\n",
    "future_ = m.make_future_dataframe(periods = 14,freq='W-'+nyse_dates.index[-1].strftime('%a')).tail(13)\n",
    "\n",
    "forecast = m.predict(future_).set_index('ds')[['yhat','yhat_lower','yhat_upper']]\n",
    "\n",
    "m.plot(forecast.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a61915-f490-4ca9-8b4a-084fa7447646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARMAX\n",
    "\n",
    "dates = [pd.to_datetime(d).value for d in df['ds']]\n",
    "dates = np.array(dates)-np.array(dates[0])/10**11\n",
    "dates=dates-dates.min()\n",
    "dates = [int(d/10**11) for d in dates]\n",
    "\n",
    "orders = []\n",
    "for p in range(1,13):\n",
    "    for q in range(1,13):\n",
    "        orders.append([p,q])\n",
    "\n",
    "        \n",
    "        \n",
    "df2 = df.copy()\n",
    "df2['ds'] = dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee6911-fedd-4033-9963-ceb18190062d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VARMAX\n",
    "\n",
    "\n",
    "quarterly_13_index = []\n",
    "for i in range(df2.index[0],df2.index[-1],13):\n",
    "    quarterly_13_index.append(i)\n",
    "    \n",
    "#add delta of last two records\n",
    "quarterly_13_index = np.array(quarterly_13_index) + df2.index[-1]-quarterly_13_index[-1]  \n",
    "\n",
    "\"\"\"\n",
    "for o in orders:\n",
    "    model = VARMAX(df2,order=o)\n",
    "    model_fit = model.fit(disp=False)\n",
    "    yhat = model_fit.forecast(n_ahead)\n",
    "    print(yhat)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "from zca import zca\n",
    "zca = zca.ZCA()\n",
    "zca.fit(df.set_index('ds').iloc[quarterly_13_index])\n",
    "\n",
    "\n",
    "model = VARMAX(zca.fit_transform(df.set_index('ds').iloc[quarterly_13_index]),order=(1,1))\n",
    "model_fit = model.fit(disp=False)\n",
    "yhat = model_fit.forecast(n_ahead)        \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba1dd10-10df-4a92-93cf-1a9729758d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a179328-9cac-4994-81e1-c75a02becea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237c1352-fe82-4bc3-9f52-024a109eafbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95de53c8-30de-4390-b18e-b7a08889b5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f945c6d-3b5d-43e7-9dd5-e21df54d8818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d37b30-434b-4697-aa81-ee7cd232f329",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506d564-c0ed-4836-9fe3-ef3ede60fe50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a94c89c-02eb-4d01-a3a5-bf551145d2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c15ca-bcbf-4c11-b5de-a0a44214485b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bd7b7d-ec2e-4fd8-a316-264399b211c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "18e8675e-2e97-49c1-a090-053c28da66ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>VAW</th>\n",
       "      <th>VOX</th>\n",
       "      <th>VCR</th>\n",
       "      <th>VDC</th>\n",
       "      <th>VDE</th>\n",
       "      <th>VFH</th>\n",
       "      <th>VHT</th>\n",
       "      <th>VIS</th>\n",
       "      <th>VNQ</th>\n",
       "      <th>VGT</th>\n",
       "      <th>VPU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>218.154114</td>\n",
       "      <td>109.897758</td>\n",
       "      <td>88.014359</td>\n",
       "      <td>130.713669</td>\n",
       "      <td>125.953690</td>\n",
       "      <td>82.794884</td>\n",
       "      <td>55.101727</td>\n",
       "      <td>129.330521</td>\n",
       "      <td>115.430725</td>\n",
       "      <td>69.720940</td>\n",
       "      <td>129.467850</td>\n",
       "      <td>98.670860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6048</td>\n",
       "      <td>217.654419</td>\n",
       "      <td>110.054825</td>\n",
       "      <td>89.433792</td>\n",
       "      <td>129.665802</td>\n",
       "      <td>126.096977</td>\n",
       "      <td>83.162994</td>\n",
       "      <td>54.527641</td>\n",
       "      <td>129.048981</td>\n",
       "      <td>115.300125</td>\n",
       "      <td>70.497574</td>\n",
       "      <td>128.513260</td>\n",
       "      <td>98.898636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12096</td>\n",
       "      <td>215.641651</td>\n",
       "      <td>107.502344</td>\n",
       "      <td>89.999718</td>\n",
       "      <td>128.974369</td>\n",
       "      <td>126.649988</td>\n",
       "      <td>81.808186</td>\n",
       "      <td>53.356727</td>\n",
       "      <td>128.596241</td>\n",
       "      <td>113.599855</td>\n",
       "      <td>71.354429</td>\n",
       "      <td>127.162512</td>\n",
       "      <td>99.452768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18144</td>\n",
       "      <td>217.089874</td>\n",
       "      <td>109.417267</td>\n",
       "      <td>89.712120</td>\n",
       "      <td>131.393341</td>\n",
       "      <td>126.804474</td>\n",
       "      <td>79.841278</td>\n",
       "      <td>53.962696</td>\n",
       "      <td>128.101227</td>\n",
       "      <td>115.934479</td>\n",
       "      <td>71.839828</td>\n",
       "      <td>129.257812</td>\n",
       "      <td>99.380478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24192</td>\n",
       "      <td>220.319565</td>\n",
       "      <td>111.098923</td>\n",
       "      <td>89.944038</td>\n",
       "      <td>133.932632</td>\n",
       "      <td>127.314949</td>\n",
       "      <td>79.901230</td>\n",
       "      <td>54.728115</td>\n",
       "      <td>131.498215</td>\n",
       "      <td>117.576447</td>\n",
       "      <td>69.889778</td>\n",
       "      <td>132.493774</td>\n",
       "      <td>99.327919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>1651104</td>\n",
       "      <td>390.079987</td>\n",
       "      <td>166.110001</td>\n",
       "      <td>98.430000</td>\n",
       "      <td>243.699997</td>\n",
       "      <td>187.300003</td>\n",
       "      <td>99.599998</td>\n",
       "      <td>79.410004</td>\n",
       "      <td>238.190002</td>\n",
       "      <td>166.339996</td>\n",
       "      <td>93.120003</td>\n",
       "      <td>344.029999</td>\n",
       "      <td>150.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>1657152</td>\n",
       "      <td>381.239990</td>\n",
       "      <td>161.190002</td>\n",
       "      <td>95.019997</td>\n",
       "      <td>231.639999</td>\n",
       "      <td>187.960007</td>\n",
       "      <td>100.690002</td>\n",
       "      <td>78.239998</td>\n",
       "      <td>238.500000</td>\n",
       "      <td>164.940002</td>\n",
       "      <td>92.750000</td>\n",
       "      <td>327.529999</td>\n",
       "      <td>156.220001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>1663200</td>\n",
       "      <td>388.670013</td>\n",
       "      <td>159.070007</td>\n",
       "      <td>98.150002</td>\n",
       "      <td>242.039993</td>\n",
       "      <td>187.300003</td>\n",
       "      <td>98.400002</td>\n",
       "      <td>78.750000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>165.350006</td>\n",
       "      <td>92.080002</td>\n",
       "      <td>342.540009</td>\n",
       "      <td>151.830002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1669248</td>\n",
       "      <td>385.130005</td>\n",
       "      <td>157.229996</td>\n",
       "      <td>95.910004</td>\n",
       "      <td>239.619995</td>\n",
       "      <td>187.490005</td>\n",
       "      <td>95.550003</td>\n",
       "      <td>77.870003</td>\n",
       "      <td>240.300003</td>\n",
       "      <td>163.110001</td>\n",
       "      <td>91.790001</td>\n",
       "      <td>340.029999</td>\n",
       "      <td>151.850006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>1675296</td>\n",
       "      <td>395.089996</td>\n",
       "      <td>163.919998</td>\n",
       "      <td>96.360001</td>\n",
       "      <td>255.910004</td>\n",
       "      <td>188.449997</td>\n",
       "      <td>99.290001</td>\n",
       "      <td>80.360001</td>\n",
       "      <td>240.149994</td>\n",
       "      <td>170.339996</td>\n",
       "      <td>94.510002</td>\n",
       "      <td>353.130005</td>\n",
       "      <td>151.210007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds           y         VAW        VOX         VCR         VDC  \\\n",
       "0          0  218.154114  109.897758  88.014359  130.713669  125.953690   \n",
       "1       6048  217.654419  110.054825  89.433792  129.665802  126.096977   \n",
       "2      12096  215.641651  107.502344  89.999718  128.974369  126.649988   \n",
       "3      18144  217.089874  109.417267  89.712120  131.393341  126.804474   \n",
       "4      24192  220.319565  111.098923  89.944038  133.932632  127.314949   \n",
       "..       ...         ...         ...        ...         ...         ...   \n",
       "273  1651104  390.079987  166.110001  98.430000  243.699997  187.300003   \n",
       "274  1657152  381.239990  161.190002  95.019997  231.639999  187.960007   \n",
       "275  1663200  388.670013  159.070007  98.150002  242.039993  187.300003   \n",
       "276  1669248  385.130005  157.229996  95.910004  239.619995  187.490005   \n",
       "277  1675296  395.089996  163.919998  96.360001  255.910004  188.449997   \n",
       "\n",
       "            VDE        VFH         VHT         VIS        VNQ         VGT  \\\n",
       "0     82.794884  55.101727  129.330521  115.430725  69.720940  129.467850   \n",
       "1     83.162994  54.527641  129.048981  115.300125  70.497574  128.513260   \n",
       "2     81.808186  53.356727  128.596241  113.599855  71.354429  127.162512   \n",
       "3     79.841278  53.962696  128.101227  115.934479  71.839828  129.257812   \n",
       "4     79.901230  54.728115  131.498215  117.576447  69.889778  132.493774   \n",
       "..          ...        ...         ...         ...        ...         ...   \n",
       "273   99.599998  79.410004  238.190002  166.339996  93.120003  344.029999   \n",
       "274  100.690002  78.239998  238.500000  164.940002  92.750000  327.529999   \n",
       "275   98.400002  78.750000  242.000000  165.350006  92.080002  342.540009   \n",
       "276   95.550003  77.870003  240.300003  163.110001  91.790001  340.029999   \n",
       "277   99.290001  80.360001  240.149994  170.339996  94.510002  353.130005   \n",
       "\n",
       "            VPU  \n",
       "0     98.670860  \n",
       "1     98.898636  \n",
       "2     99.452768  \n",
       "3     99.380478  \n",
       "4     99.327919  \n",
       "..          ...  \n",
       "273  150.100006  \n",
       "274  156.220001  \n",
       "275  151.830002  \n",
       "276  151.850006  \n",
       "277  151.210007  \n",
       "\n",
       "[278 rows x 13 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "64b7f9fe-837c-435f-a380-c2d693693ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df2.iloc[quarterly_13_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "cc252b5c-50c6-49c2-875b-40f223f084fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([220.31956482, 229.60510254, 240.8374939 , 269.1862793 ,\n",
       "       251.38418579, 266.58987427, 252.4855957 , 254.39076233,\n",
       "       282.07376099, 291.75360107, 292.70300293, 320.64019775,\n",
       "       277.59558105, 316.17080688, 342.06918335, 380.38562012,\n",
       "       415.38104248, 439.94000244, 453.11999512, 437.98001099,\n",
       "       426.04000854, 395.08999634])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "feeca09b-4390-4b37-a760-355f3ae09fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 9, 3) (12, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed\n",
    " \n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "in_seq1 = np.array(df_['y'])#array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array(df_['ds'])#array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "out_seq = array([in_seq1[i]+in_seq2[i] for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 9, 2\n",
    "# convert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "#for i in range(len(X)):\n",
    "\t#print(X[i], y[i])\n",
    "    \n",
    "\n",
    "# flatten output\n",
    "n_output = y.shape[1] * y.shape[2]\n",
    "y = y.reshape((y.shape[0], n_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ede37b33-94e2-455a-b576-dd112c7fb213",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_seq_01 = np.array(df_['y'])\n",
    "in_seq_02 = np.array(df_['VAW'])\n",
    "in_seq_03 = np.array(df_['VOX'])\n",
    "in_seq_04 = np.array(df_['VCR'])\n",
    "in_seq_05 = np.array(df_['VDC'])\n",
    "in_seq_06 = np.array(df_['VDE'])\n",
    "in_seq_07 = np.array(df_['VFH'])\n",
    "in_seq_08 = np.array(df_['VHT'])\n",
    "in_seq_09 = np.array(df_['VIS'])\n",
    "in_seq_10 = np.array(df_['VNQ'])\n",
    "in_seq_11 = np.array(df_['VGT'])\n",
    "in_seq_12 = np.array(df_['VPU'])\n",
    "in_seq_13 = np.array(df_['ds'])\n",
    "\n",
    "out_seq = array([\n",
    "in_seq_01[i]\n",
    "+in_seq_02[i]\n",
    "+in_seq_03[i]\n",
    "+in_seq_04[i]\n",
    "+in_seq_05[i]\n",
    "+in_seq_06[i]\n",
    "+in_seq_07[i]\n",
    "+in_seq_08[i]\n",
    "+in_seq_09[i]\n",
    "+in_seq_10[i]\n",
    "+in_seq_11[i]\n",
    "+in_seq_12[i]\n",
    "+in_seq_13[i]\n",
    "for i in range(len(in_seq_01))\n",
    "])\n",
    "\n",
    "out_seq = array([\n",
    "in_seq_01[i]\n",
    "+in_seq_02[i]                \n",
    "+in_seq_03[i]\n",
    "+in_seq_04[i]\n",
    "+in_seq_05[i]\n",
    "+in_seq_06[i]\n",
    "+in_seq_07[i]\n",
    "+in_seq_08[i]\n",
    "+in_seq_09[i]\n",
    "+in_seq_10[i]\n",
    "+in_seq_11[i]\n",
    "+in_seq_12[i]\n",
    "+in_seq_13[i]\n",
    "for i in range(len(in_seq_01))])\n",
    "\n",
    "\n",
    "\n",
    "in_seq_01 = in_seq_01.reshape((len(in_seq_01),1))\n",
    "in_seq_02 = in_seq_02.reshape((len(in_seq_01),1))\n",
    "in_seq_03 = in_seq_03.reshape((len(in_seq_01),1))\n",
    "in_seq_04 = in_seq_04.reshape((len(in_seq_01),1))\n",
    "in_seq_05 = in_seq_05.reshape((len(in_seq_01),1))\n",
    "in_seq_06 = in_seq_06.reshape((len(in_seq_01),1))\n",
    "in_seq_07 = in_seq_07.reshape((len(in_seq_01),1))\n",
    "in_seq_08 = in_seq_08.reshape((len(in_seq_01),1))\n",
    "in_seq_09 = in_seq_09.reshape((len(in_seq_01),1))\n",
    "in_seq_10 = in_seq_10.reshape((len(in_seq_01),1))\n",
    "in_seq_11 = in_seq_11.reshape((len(in_seq_01),1))\n",
    "in_seq_12 = in_seq_12.reshape((len(in_seq_01),1))\n",
    "in_seq_13 = in_seq_13.reshape((len(in_seq_01),1))\n",
    "out_seq = out_seq.reshape((len(out_seq),1))\n",
    "\n",
    "\n",
    "dataset = np.hstack((\n",
    "in_seq_01,\n",
    "in_seq_02,\n",
    "in_seq_03,\n",
    "in_seq_04,\n",
    "in_seq_05,\n",
    "in_seq_06,\n",
    "in_seq_07,\n",
    "in_seq_08,\n",
    "in_seq_09,\n",
    "in_seq_10,\n",
    "in_seq_11,\n",
    "in_seq_12,\n",
    "in_seq_13,\n",
    "out_seq\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9687691-8d0b-4f2f-ae5f-01c7d598ee4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e98bd-51a0-448a-9734-44d916a5e2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import RepeatVector\n",
    "from keras.layers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24f119-10bd-4c6d-8abb-4611f38c48c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "f08f7077-7cd6-49b1-99d6-045da9d54677",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_17\" (type Sequential).\n    \n    Input 0 of layer \"repeat_vector_4\" is incompatible with the layer: expected ndim=2, found ndim=3. Full shape received: (None, 9, 504)\n    \n    Call arguments received by layer \"sequential_17\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 9, 14), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [310]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m x_input \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m-\u001b[39mn_steps_in:]\n\u001b[0;32m     28\u001b[0m x_input \u001b[38;5;241m=\u001b[39m x_input\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m, n_steps_in, n_features))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filetykrr7gw.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\training.py\", line 889, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\User\\AppData\\Local\\Programs\\3.9-JupyterLab\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 214, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_17\" (type Sequential).\n    \n    Input 0 of layer \"repeat_vector_4\" is incompatible with the layer: expected ndim=2, found ndim=3. Full shape received: (None, 9, 504)\n    \n    Call arguments received by layer \"sequential_17\" (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 9, 14), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 9, 2\n",
    "\n",
    "# split into samples\n",
    "X, y = split_sequence(dataset, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = X.shape[2]\n",
    "\n",
    "model_size = n_features*n_steps_in*n_steps_out\n",
    "\n",
    "#X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "with tf.device(gpus[0]):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(int((model_size)), activation='tanh',recurrent_activation = 'sigmoid',recurrent_dropout=0,unroll=False,use_bias =True,return_sequences=True, input_shape=(n_steps_in, n_features))))\n",
    "    model.add(RepeatVector(n_steps_out))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(int((model_size)), activation='tanh',recurrent_activation = 'sigmoid',recurrent_dropout=0,unroll=False,use_bias =True)))\n",
    "    model.add(TimeDistributed(Dense(n_features)))\n",
    "    #model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# fit model\n",
    "model.fit(X, y, epochs=50, verbose=0)\n",
    "\n",
    "x_input = dataset[-n_steps_in:]\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "\n",
    "\n",
    "# demonstrate prediction\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "   \n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc80fb9-1722-46f0-b87c-e64fb612b812",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a120addd-a1b3-437a-a691-c9f88cc05b0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3cf869-88d5-4eab-9920-ea134b5dde03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df = prices_df[pr ices_df['Symbol']=='SPY'][['Adj Close']].asfreq('D').interpolate(method='time').asfreq('W-'+end.strftime('%a')).reset_index()\n",
    "df.columns = ['ds','y']\n",
    "\n",
    "m = Prophet()\n",
    "#m = MultiProphet(columns=observer_set)\n",
    "\n",
    "for o in observer_set:\n",
    "    temp = prices_df[prices_df['Symbol']==o][['Adj Close']].asfreq('D').interpolate(method='time').asfreq('W-'+end.strftime('%a')).reset_index()[['Adj Close']]\n",
    "    temp.columns = [o]\n",
    "    \n",
    "    df = pd.concat([df,temp],axis=1)\n",
    "\n",
    "for o in observer_set:\n",
    "    m.add_regressor(o)\n",
    "    \n",
    "    \n",
    "m.fit(df)\n",
    "\n",
    "#have to have future values, pretty much multiple regression (find stationary (cv tested?) ccf lead/lag? values)\n",
    "future_ = m.make_future_dataframe(periods = 14,freq='W-'+end.strftime('%a')).tail(13)\n",
    "forecast = m.predict(pd.concat([df.set_index('ds')[observer_set],future_.set_index('ds')],axis=0).reset_index().dropna()).set_index('ds')\n",
    "\n",
    "m.plot(forecast.reset_index())\n",
    "    \n",
    "#plt.plot(df['y'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a14834-b9a1-47c7-be49-87764f699324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181d07b8-3e21-451e-8960-0efff8a5cb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c214d9-c52c-407a-a098-ebff3b223859",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_commodities_n_w_index_pvt_w_Fred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db068e2-7946-4cc1-a53a-f974f977b5cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4344a0-78d4-4af8-af45-eaeedf6e2f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b73c249-81c8-4acc-bd92-12b7755f3891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa805e-802c-4425-9bc3-b6a232351801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521aef55-fa4d-41cd-833d-aab0ed4c7b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f58a0-6658-4f71-b198-c19265a9b140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625bb70d-ff99-4f9c-9c57-df8bdbfd02ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2d9fb8-8e15-47bb-a5d6-dcece9531864",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca558d6-19af-41c3-ac1f-806648814111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f84610-260e-4673-a33b-89d83bf57dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294260e5-d513-4c4f-b76d-e423b2f572a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58a11e8-7aee-48af-af9f-2141b9562567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f43e4-6aae-48f9-a34b-2f844b0e8693",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33d630-46ef-4ed5-8360-84efabf97719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2067aa3a-8f35-4e57-9465-5604395d43d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ce1903-5d42-43fd-971c-0ada735c5f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4517a0-b47d-4ea0-bd41-14728dca3055",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff4da6d-86b8-49d7-9b8b-ec04c0a821a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680a334-faa2-4fe7-bdcb-9e06c9b51e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6caa00-54b5-45d1-8180-395050b35964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27382f-ba19-4183-a194-bcef3ecf80b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(filtered_screener_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0526ba40-0c06-496b-a60f-fdaef16a7cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_values(values):\n",
    "    \n",
    "    sector_list = []\n",
    "    symbol_list = []\n",
    "    for i in np.array(values):\n",
    "        t= dict_sectors[i]\n",
    "        sector_list.append(t)\n",
    "        \n",
    "        sublist = filtered_screener_sorted[filtered_screener_sorted['Sector Symbol']==t].index\n",
    "        temp_df = filtered_screener_sorted.loc[sublist]\n",
    "        #temp_df_ = temp_df['risk_trend_factor'].replace(['error','missing'], np.nan).dropna()\n",
    "        \n",
    "        #temp_df_filtered = temp_df_[temp_df_>0]\n",
    "        \n",
    "        flat_list = [item for item in temp_df.index]\n",
    "        symbol_list.extend(flat_list)        \n",
    "    \n",
    "    button = widgets.Button(description=\"Process\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    display(button, output)\n",
    "\n",
    "    print(\"Symbols > 1 (50td_tvf_vel + risk_trend_factor)\")\n",
    "    print(len(sector_list),sector_list)\n",
    "    print(len(symbol_list),symbol_list)\n",
    "    \n",
    "    def on_button_clicked(b):\n",
    "        with output:            \n",
    "            plot_(symbol_list)\n",
    "\n",
    "    button.on_click(on_button_clicked)    \n",
    "    \n",
    "    \n",
    "y_=widgets.SelectMultiple(\n",
    "    options=list(dict_sectors.keys()),\n",
    "    description='Choose Sectors: ',\n",
    "    disabled=False)\n",
    "\n",
    "a=interact(process_values,values=y_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d84cc2-b80b-40d8-b615-9a4429c1c4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4af2c1-bc8d-4ffd-90a3-d42460ab1f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba99821-8eb1-427b-a706-d523f74d7f78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decision_metrics_df = pd.read_csv('..\\\\data\\\\processed\\\\'+end.strftime('%Y-%m-%d')+'_decision_metrics_df.csv')\n",
    "decision_metrics_df.set_index(decision_metrics_df.iloc[:, 0],inplace=True)\n",
    "\n",
    "counts_df = pd.DataFrame(decision_metrics_df['Sector'].value_counts())\n",
    "\n",
    "print(counts_df)\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(counts_df['Sector'], labels=counts_df.index)\n",
    "ax.set_title('Sector Participartion > (50td_tvf_vel + risk_trend_factor) of 0')\n",
    "plt.tight_layout()\n",
    "plt.savefig('..\\\\reports\\\\figures\\\\'+end.strftime('%Y-%m-%d')+'_piechart-sectors.png', dpi=300, format='png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95bca4-2b67-429b-8285-c5d28d320785",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prices_pvt_wk = pd.pivot_table(prices_df, values=['Adj Close'], index=prices_df.index,columns=['Symbol']).asfreq('d').interpolate(method='time').asfreq('W-'+nyse_dates.index[-1].strftime('%a'))\n",
    "prices_pvt_wk.columns = prices_pvt_wk.columns.droplevel(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d21de0e-8726-45dd-982c-0bb8d01817eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c_df = prices_pvt_wk.corr()\n",
    "c_df.sort_values(by='SPY',inplace=True,ascending=False,axis=1)\n",
    "c_df.sort_values(by='SPY',inplace=True,ascending=False,axis=0)\n",
    "c_df.to_csv('..\\\\reports\\\\'+end.strftime('%Y-%m-%d')+'_corr_5_yr_prices_pvt_wk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8edbe29-7393-42d2-8729-cd1bad2cb72b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8298663-0813-465b-8044-251da8d62ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vevestaX import vevesta as v\n",
    "\n",
    "try:\n",
    "    V=v.Experiment(speedUp = True)\n",
    "    V.start()\n",
    "    V.ds=decision_metrics_df\n",
    "    V.fe=decision_metrics_df\n",
    "    V.end()\n",
    "    V.dump(techniqueUsed='fbprophet',filename='..\\\\reports\\\\'+end.strftime('%Y-%m-%d')+'_decision_metrics_df.xlsx',message=\"EDA-fbprophet-nested-CV\",version=1)\n",
    "    os.rename('EDA.pdf','..\\\\reports\\\\'+end.strftime('%Y-%m-%d')+'_decision_metrics_df.pdf')\n",
    "    #os.remove('EDA.pdf')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    V=v.Experiment()\n",
    "    V.start()\n",
    "    V.ds=fred_pvt_sample\n",
    "    V.fe=fred_pvt_sample\n",
    "    V.end()\n",
    "    V.dump(techniqueUsed='fred_data',filename='..\\\\reports\\\\'+end.strftime('%Y-%m-%d')+'_completed_fred_pvt.xlsx',message=\"EDA-fred\",version=2)\n",
    "    os.rename('EDA.pdf','..\\\\reports\\\\'+end.strftime('%Y-%m-%d')+'_completed_fred_pvt.pdf')\n",
    "    \n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    V=v.Experiment()\n",
    "    V.start()\n",
    "    V.ds=prices_pvt_wk[filtered_screener_sorted.index]\n",
    "    V.fe=prices_pvt_wk[filtered_screener_sorted.index]\n",
    "    V.end()\n",
    "    V.dump(techniqueUsed='price_data',filename='..\\\\reports\\\\'+end.strftime('%Y-%m-%d')+'_completed_prices_pvt_wk.xlsx',message=\"EDA-prices\",version=3)\n",
    "    os.rename('EDA.pdf','..\\\\reports\\\\'+end.strftime('%Y-%m-%d')+'_completed_prices_pvt_wk.pdf')\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602598b5-84c9-4685-ae45-40ecc992bb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70399d47-07ec-4e2d-98f8-ebd9460ab980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fcd37b-e001-4f83-a746-3d71f50189d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ecd805-8b46-4cf7-a458-37a38ece109b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autots import AutoTS, load_daily\n",
    "\n",
    "# sample datasets can be used in either of the long or wide import shapes\n",
    "long = False\n",
    "#df = load_daily(long=long)\n",
    "df = prices_pvt_wk['HSY']\n",
    "\n",
    "model = AutoTS(\n",
    "    forecast_length=13,\n",
    "    frequency='infer',\n",
    "    prediction_interval=0.9,\n",
    "    ensemble=False,\n",
    "    model_list=\"fast_parallel\",  # \"superfast\", \"default\", \"fast_parallel\"\n",
    "    transformer_list=\"superfast\",  # \"superfast\",\n",
    "    drop_most_recent=1,\n",
    "    max_generations=4,\n",
    "    num_validations=2,\n",
    "    validation_method=\"backwards\"\n",
    ")\n",
    "model = model.fit(\n",
    "    df,\n",
    "    date_col='datetime' if long else None,\n",
    "    value_col='value' if long else None,\n",
    "    id_col='series_id' if long else None,\n",
    ")\n",
    "\n",
    "prediction = model.predict()\n",
    "# plot a sample\n",
    "prediction.plot(model.df_wide_numeric,\n",
    "                series=model.df_wide_numeric.columns[0],\n",
    "                start_date=\"2019-01-01\")\n",
    "# Print the details of the best model\n",
    "print(model)\n",
    "\n",
    "# point forecasts dataframe\n",
    "forecasts_df = prediction.forecast\n",
    "# upper and lower forecasts\n",
    "forecasts_up, forecasts_low = prediction.upper_forecast, prediction.lower_forecast\n",
    "\n",
    "# accuracy of all tried model results\n",
    "model_results = model.results()\n",
    "# and aggregated from cross validation\n",
    "validation_results = model.results(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1988288-7c28-4ea7-b6c2-bd7a62a9680c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f0eb1-61b0-4688-9c57-0769608b31df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6449e787-9380-414a-8071-6789be0ec5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a203bb-7593-4f4c-8fe5-fd0b5b7a827a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355c60d6-a648-4553-91b6-079a7d279b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798491da-4b87-4320-9df1-e486e322db66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3503b39a-5c13-42ef-9a70-1f29c5fd7970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a1e4a-5431-4387-8d69-290dab90ffb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296b0c5-0c1b-404a-9720-80bbc9fb0d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d7a1c7-ed09-4688-8445-bf6c4d046dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06e9c1e-eb4b-4971-bee6-3068a36135e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0359b07d-be67-493a-8689-d74bc45ca26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568abb2-b2b9-493a-99ee-e77813ccf43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
