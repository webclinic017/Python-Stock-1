{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d17485-23dd-483e-8c86-be2cea0e5b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7191004d-380d-41a8-b1f9-4baa99dabb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pandas_datareader import data\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "import pandas_datareader.data as web\n",
    "import statsmodels.tsa.stattools as ts\n",
    "from numpy import cumsum, log, polyfit, sqrt, std, subtract\n",
    "import pandas_market_calendars as mcal\n",
    "import os\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0814e-c3ad-4c26-9c51-e39a16c802ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ad8909-f0fb-48eb-b7d6-b940feec48a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_ = datetime.today()\n",
    "#start = end - relativedelta(years=2) - relativedelta(days=3)\n",
    "start_ = end_ - relativedelta(months=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e62dae8b-702e-4dc6-a41f-406f54339ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-03-16\n",
      "2022-07-15\n"
     ]
    }
   ],
   "source": [
    "#print(end.strftime('%Y-%m-%d'))\n",
    "#print(start.strftime('%Y-%m-%d'))\n",
    "\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "nyse_dates = nyse.schedule(start_date=start_, end_date=end_)\n",
    "\n",
    "start = nyse_dates.index[0].strftime('%Y-%m-%d')\n",
    "end = nyse_dates.index[-1].strftime('%Y-%m-%d')\n",
    "print(start)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fd45d3-fb03-41af-8dc4-bd9b87a32ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "db_filename = '.\\\\data\\\\interim\\\\todo.db'\n",
    "\n",
    "db_is_new = not os.path.exists(db_filename)\n",
    "\n",
    "conn = sqlite3.connect(db_filename)\n",
    "\n",
    "if db_is_new:\n",
    "    print('Need to create schema')\n",
    "else:\n",
    "    print('Database exists, assume schema does, too.')\n",
    "\n",
    "conn.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f94b7-d3ec-4564-a63b-4d0460289858",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sectors = {'Basic Materials':'VAW', 'Communication Services':'VOX', 'Consumer Cyclical':'VCR',\n",
    "       'Consumer Defensive':'VDC', 'Energy':'VDE', 'Financial Services':'VFH', 'Healthcare':'VHT',\n",
    "       'Industrials':'VIS', 'Real Estate':'VNQ', 'Technology':'VGT', 'Utilities':'VPU', 'error':'error'}\n",
    "\n",
    "dict_indexes = {'SPTM':'SP1500', 'SPY':'SP500', 'SLY':'SP600', 'MDYG':'SP400','error':'error'}\n",
    "\n",
    "invert_dict_indexes = {v: k for k, v in dict_indexes.items()}\n",
    "\n",
    "dict_sectors_reverse = {'VAW':'Basic Materials',\n",
    " 'VOX':'Communication Services',\n",
    " 'VCR':'Consumer Cyclical',\n",
    " 'VDC':'Consumer Defensive',\n",
    " 'VDE':'Energy',\n",
    " 'VFH':'Financial Services',\n",
    " 'VHT':'Healthcare',\n",
    " 'VIS':'Industrials',\n",
    " 'VNQ':'Real Estate',\n",
    " 'VGT':'Technology',\n",
    " 'VPU':'Utilities',\n",
    " 'error': 'error'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc96e28-ecf6-40fb-8eb3-541de2039c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_names = ['SP1500', 'SP500', 'SP600', 'SP400']\n",
    "indexes = ['SPTM','SPY','SLY','MDYG']\n",
    "sector_names = ['Communication Services ETF', 'Consumer Discretionary ETF', 'Consumer Staples ETF', 'Energy ETF', 'Financials ETF', 'Health Care ETF', 'Industrials ETF', 'Information Technology ETF', 'Materials ETF', 'Real Estate ETF', 'Utilities ETF']\n",
    "sectors = ['VOX','VCR','VDC','VDE','VFH','VHT','VIS','VGT','VAW','VNQ','VPU']\n",
    "\n",
    "etf_bonds = ['LQD', 'AGG', 'NEAR', 'IUSB', 'ISTB', 'IMTB', 'ILTB', 'GBF']\n",
    "etf_muni_bonds = ['MUB', 'SUB', 'MEAR']\n",
    "\n",
    "etf_treasuries = ['AGZ', 'GOVT', 'BIL', 'SHV', 'SHY', 'IEI', 'IEF', 'TLT']\n",
    "\n",
    "#M1_MONEY_MULTIPLIER = M1NS/BOGMBASE\n",
    "\n",
    "FRED_Indicators = [\n",
    "\"ASPUS\",\\\n",
    "\"AWHAETP\",\\\n",
    "\"B432RG3A086NBEA\",\\\n",
    "\"BAA10Y\",\\\n",
    "\"BACDINA066MNFRBNY\",\\\n",
    "\"BACTSAMFRBDAL\",\\\n",
    "\"BAMLC0A0CM\",\\\n",
    "\"BAMLCC0A1AAATRIV\",\\\n",
    "\"BAMLCC0A4BBBTRIV\",\\\n",
    "\"BAMLH0A3HYC\",\\\n",
    "\"BAMLHYH0A0HYM2TRIV\",\\\n",
    "\"BOGMBASE\",\\\n",
    "\"BOGZ1FA105015103Q\",\\\n",
    "\"BOGZ1FA145050005Q\",\\\n",
    "\"BOGZ1FA205050005Q\",\\\n",
    "\"BOGZ1FA315050005Q\",\\\n",
    "\"BOGZ1FA385050005Q\",\\\n",
    "\"BOGZ1FL105015105Q\",\\\n",
    "\"BUSAPPWNSACA\",\\\n",
    "\"BUSLOANS\",\\\n",
    "\"CASTHPI\",\\\n",
    "\"CES0500000003\",\\\n",
    "\"CES4348400001\",\\\n",
    "\"CFNAI\",\\\n",
    "\"CFNAIDIFF\",\\\n",
    "\"CFSBCACTIVITYMFG\",\\\n",
    "\"CILACBQ158SBOG\",\\\n",
    "\"CIVPART\",\\\n",
    "\"COMREPUSQ159N\",\\\n",
    "\"CONSUMER\",\\\n",
    "\"CP\",\\\n",
    "\"CPALTT01USQ657N\",\\\n",
    "\"CPIAUCSL\",\\\n",
    "\"CSCICP03USM665S\",\\\n",
    "\"CSUSHPINSA\",\\\n",
    "\"CUSR0000SEHA\",\\\n",
    "\"CUUR0000SEHA\",\\\n",
    "\"DALLCIACBEP\",\\\n",
    "\"DCOILBRENTEU\",\\\n",
    "\"DCOILWTICO\",\\\n",
    "\"DEXCHUS\",\\\n",
    "\"DEXUSUK\",\\\n",
    "\"DFF\",\\\n",
    "\"DFII10\",\\\n",
    "\"DGORDER\",\\\n",
    "\"DGS1\",\\\n",
    "\"DGS10\",\\\n",
    "\"DGS1MO\",\\\n",
    "\"DGS2\",\\\n",
    "\"DGS30\",\\\n",
    "\"DGS3MO\",\\\n",
    "\"DGS5\",\\\n",
    "\"DRBLACBS\",\\\n",
    "\"DRCCLACBS\",\\\n",
    "\"DRSFRMACBS\",\\\n",
    "\"DTB3\",\\\n",
    "\"DTWEXBGS\",\\\n",
    "\"EMRATIO\",\\\n",
    "\"ERENTUSQ176N\",\\\n",
    "\"ETOTALUSQ176N\",\\\n",
    "\"FEDFUNDS\",\\\n",
    "\"FGCCSAQ027S\",\\\n",
    "\"FPCPITOTLZGUSA\",\\\n",
    "\"GASREGW\",\\\n",
    "\"GDPC1\",\\\n",
    "\"GFDEBTN\",\\\n",
    "\"GFDEGDQ188S\",\\\n",
    "\"GOLDAMGBD228NLBM\",\\\n",
    "\"GVZCLS\",\\\n",
    "\"HDTGPDUSQ163N\",\\\n",
    "\"HOSMEDUSM052N\",\\\n",
    "\"IC4WSA\",\\\n",
    "\"ICSA\",\\\n",
    "\"IIPUSNETIQ\",\\\n",
    "\"INDPRO\",\\\n",
    "\"INTDSRUSM193N\",\\\n",
    "\"IRLTLT01USM156N\",\\\n",
    "\"KCFSI\",\\\n",
    "\"LES1252881600Q\",\\\n",
    "\"LEU0252918500Q\",\\\n",
    "\"LFWA64TTUSM647S\",\\\n",
    "\"LRUN64TTUSQ156S\",\\\n",
    "\"LXXRCSA\",\\\n",
    "\"M1\",\\\n",
    "\"M1V\",\\\n",
    "\"M1NS\",\\\n",
    "\"M2V\",\\\n",
    "\"MABMM301USM189S\",\\\n",
    "\"MANMM101USA189S\",\\\n",
    "\"MEFAINUSA672N\",\\\n",
    "\"MEHOINUSA672N\",\\\n",
    "\"MEPAINUSA672N\",\\\n",
    "\"MICH\",\\\n",
    "\"MOGMBASE\",\\\n",
    "\"MORTGAGE30US\",\\\n",
    "\"MPRIME\",\\\n",
    "\"MSPUS\",\\\n",
    "\"MZMSL\",\\\n",
    "\"NEWORDER\",\\\n",
    "\"NFCI\",\\\n",
    "\"NROU\",\\\n",
    "\"NYSTHPI\",\\\n",
    "\"PAYEMS\",\\\n",
    "\"PCE\",\\\n",
    "\"PERMIT\",\\\n",
    "\"POP\",\\\n",
    "\"POPTOTUSA647NWDB\",\\\n",
    "\"PPIACO\",\\\n",
    "\"PRFI\",\\\n",
    "\"PSAVERT\",\\\n",
    "\"Q10096USQ144NNBR\",\\\n",
    "\"RECPROUSM156N\",\\\n",
    "\"RSAHORUSQ156S\",\\\n",
    "\"SPCS20RSA\",\\\n",
    "\"STLFSI2\",\\\n",
    "\"T10Y2Y\",\\\n",
    "\"T10Y3M\",\\\n",
    "\"T10YIE\",\\\n",
    "\"T5YIE\",\\\n",
    "\"T5YIFR\",\\\n",
    "\"TB3MS\",\\\n",
    "\"TCU\",\\\n",
    "\"TDSP\",\\\n",
    "\"TEDRATE\",\\\n",
    "\"TOTALSA\",\\\n",
    "\"TREAST\",\\\n",
    "\"TTLHH\",\\\n",
    "\"TWEXB\",\\\n",
    "\"UMCSENT\",\\\n",
    "\"U6RATE\",\\\n",
    "\"UNRATE\",\\\n",
    "\"USALOLITONOSTSAM\",\\\n",
    "\"USPHCI\",\\\n",
    "\"USREC\",\\\n",
    "\"USROA\",\\\n",
    "\"USROE\",\\\n",
    "\"USSLIND\",\\\n",
    "\"USSTHPI\",\\\n",
    "\"VIXCLS\",\\\n",
    "\"VXVCLS\",\\\n",
    "\"WDFUELLA\",\\\n",
    "\"WGS3MO\",\\\n",
    "\"WILLLRGCAPVAL\",\\\n",
    "\"WILLMICROCAPPR\",\\\n",
    "\"WPU0911\",\\\n",
    "\"WPUSI019011\",\\\n",
    "\"WPU101\",\\\n",
    "\"WTB3MS\"    \n",
    "]\n",
    "\n",
    "etf_bonds = [*etf_bonds,*etf_muni_bonds,*etf_treasuries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ec357b-b4a7-4cef-ab26-21b0067836ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "SP500ticker_list = pd.read_html('http://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "SP600ticker_list = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_600_companies')[1]\n",
    "SP400ticker_list = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_400_companies')[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ef454c-a181-47bd-86e1-a4057d2ef192",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = SP500ticker_list['Symbol']\n",
    "sp500 = [w.replace('.', '-') for w in sp500]\n",
    "sp600 = SP600ticker_list['Ticker symbol']\n",
    "sp600 = [w.replace('.', '-') for w in sp600]\n",
    "sp400 = SP400ticker_list['Ticker symbol']\n",
    "sp400 = [w.replace('.', '-') for w in sp400]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37854ad3-4fe2-483f-9597-dcc7504b50af",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sp500)+len(sp600)+len(sp400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70dc73-5b3a-4865-aa4e-ece09235a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(sp500))\n",
    "SP1500 = list()\n",
    "SP1500.extend(sp500)\n",
    "sp600 = list(set(sp600).difference(SP1500))\n",
    "print(len(sp600))\n",
    "SP1500.extend(sp600)\n",
    "sp400 = list(set(sp400).difference(SP1500))\n",
    "print(len(sp400))\n",
    "SP1500.extend(set(sp400).difference(SP1500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc2a30-097c-470d-b6bf-f524c965bc83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f83930a-c582-4686-9d56-c73712d25db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#>.5The time series is mean reverting\n",
    "#=.5 time series is a Geometric Brownian Motion\n",
    "#<.5 time series is trending\n",
    "\n",
    "def hurst(ts):\n",
    "    \"\"\"\n",
    "    Returns the Hurst Exponent of the time series vector ts\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ts : `numpy.array`\n",
    "        Time series upon which the Hurst Exponent will be calculated\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    'float'\n",
    "        The Hurst Exponent from the poly fit output\n",
    "    \"\"\"\n",
    "    # Create the range of lag values\n",
    "    lags = range(2, 100)\n",
    "\n",
    "    # Calculate the array of the variances of the lagged differences\n",
    "    tau = [sqrt(std(subtract(ts[lag:], ts[:-lag]))) for lag in lags]\n",
    "\n",
    "    # Use a linear fit to estimate the Hurst Exponent\n",
    "    poly = polyfit(log(lags), log(tau), 1)\n",
    "\n",
    "    # Return the Hurst exponent from the polyfit output\n",
    "    return poly[0]*2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675c840-534a-41ca-861e-d0accdb076e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c2cdb-9ae2-44e7-834d-fc35e39d417b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9be00b-7d31-426b-a859-5591e02a7d4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e0e422-c87d-49c4-ac26-fe1e419e45ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569a219-261e-4ec8-bff4-3b645aad7be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp1500_index_df = pd.DataFrame()\n",
    "\n",
    "lists = [\"sp500\",\"sp600\",\"sp400\"]\n",
    "\n",
    "for l in lists:\n",
    "    if(l=='sp500'):\n",
    "        df = pd.DataFrame(sp500,columns=['Symbol'])\n",
    "        print(len(df))\n",
    "        #range_ = \n",
    "        #print(range_)\n",
    "        df['Market Index'] = pd.Series([\"SP500\" for x in range(0,len(df.index),1)])\n",
    "    elif(l=='sp600'):\n",
    "        df = pd.DataFrame(np.array(sp600),columns=['Symbol'])        \n",
    "        print(len(df))        \n",
    "        df['Market Index'] = pd.Series([\"SP600\" for x in range(len(df.index))])\n",
    "        df.index = range(len(sp500),(len(sp500)+len(df.index)),1)        \n",
    "    else:\n",
    "        df = pd.DataFrame(np.array(sp400),columns=['Symbol'])\n",
    "        print(len(df))\n",
    "        df['Market Index'] = pd.Series([\"SP400\" for x in range(len(df.index))])\n",
    "        df.index = range((len(sp500)+len(sp600)),(len(sp500)+len(sp600)+len(df.index)),1)\n",
    "    sp1500_index_df = pd.concat([sp1500_index_df,df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afecc03-b536-4a60-9742-6be019181891",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sp1500_index_df)-len(SP1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d084364-b2ea-41b6-a824-00d418a993f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed84b613-5a31-4543-98c6-d37725183967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1d1f2-1525-4ae8-b7dd-2d4c008d1b71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d431c58f-99f2-4da2-9df0-4461cfb0599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fred_Data(npa):\n",
    "    name = npa[0]\n",
    "    start_ = npa[1]\n",
    "    end_ = npa[2]\n",
    "    nyse_dates_ = npa[3]\n",
    "    \n",
    "    temp = web.DataReader(str(name), 'fred', start_, end_)\n",
    "    #temp = web.DataReader(npa[1][0],'fred',start,end)\n",
    "    temp = temp.asfreq('D').interpolate(method='time',limit_direction='forward',limit_area='inside').reindex(nyse_dates_.index)\n",
    "    temp.columns = ['Value']\n",
    "    #temp.index = pd.to_datetime(temp.index)\n",
    "    \n",
    "    #temp['Symbol'] = name\n",
    "    \n",
    "    #print(temp)\n",
    "    #temp_new = temp.asfreq('D').interpolate(method='time')    \n",
    "    temp_dates = pd.date_range(temp.index[0].strftime('%Y-%m-%d'), temp.index[-1].strftime('%Y-%m-%d'), freq='D').map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "    nyse_inbetween_temp_dates = nyse_dates_.index[(nyse_dates_.index >= temp_dates[0]) & (nyse_dates_.index <= temp_dates[-1])]\n",
    "    temp_new = temp.reindex(nyse_inbetween_temp_dates)\n",
    "    temp_new['Symbol'] = name\n",
    "    \n",
    "    #temp = temp.resample(frequency).mean().dropna()\n",
    "    return(temp_new)\n",
    "    #return(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9d29c-3d80-4b4f-931b-352b10fc4840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dl(npa):\n",
    "    name = npa[0]\n",
    "    start_ = npa[1]\n",
    "    end_ = npa[2]\n",
    "    nyse_dates_ = npa[3]\n",
    "    subset = yf.download(name, start=start_, end=end_, auto_adjust=True).iloc[:, :6].dropna(axis=0, how='any')\n",
    "    \n",
    "    temp_new = subset.asfreq('D').interpolate(method='time',limit_area='inside').reindex(nyse_dates_.index)\n",
    "    temp_dates = pd.date_range(subset.index[0].strftime('%Y-%m-%d'), subset.index[-1].strftime('%Y-%m-%d'), freq='D').map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "    nyse_inbetween_temp_dates = nyse_dates_.index[(nyse_dates_.index >= temp_dates[0]) & (nyse_dates_.index <= temp_dates[-1])]\n",
    "    temp_new = temp_new.reindex(nyse_inbetween_temp_dates)\n",
    "    subset_ = temp_new\n",
    "    subset_['Symbol'] = name\n",
    "\n",
    "    return (subset_)\n",
    "    \n",
    "def dl2(assets):\n",
    "\n",
    "    yahoo_financials = YahooFinancials(assets)\n",
    "\n",
    "    data = yahoo_financials.get_historical_price_data(start_date=start_date.strftime('%Y-%m-%d'), end_date=end_date.strftime('%Y-%m-%d'), time_interval='daily')\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea87bb-f40b-49a9-9060-4b8a4dd809fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStock(npa):\n",
    "    symbol = npa[0]\n",
    "    start_=npa[1]\n",
    "    end_=npa[2]\n",
    "    \n",
    "    data_ = yf.download(symbol, start=start_,end=end_)\n",
    "  \n",
    "    return([symbol,data_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f009c3-0390-4caf-ba6b-9c8de57e8cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTickerData(npa):\n",
    "    symbol = npa[0]\n",
    "    \n",
    "    stock_data = yf.Ticker(symbol) \n",
    "    return([symbol,stock_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2521e1-d0dc-4b2b-ad44-676ed7af6a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e051b-43f4-4b43-9cbd-0a9e6ffc4b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSector(npa):\n",
    "    #position = npa[0]\n",
    "    symbol = npa[0]\n",
    "    #start_=npa[2]\n",
    "    #end_=npa[3]\n",
    "    \n",
    "    tickerdata = yf.Ticker(symbol)\n",
    "    \n",
    "    if 'sector' in tickerdata.info:\n",
    "        sector = tickerdata.info['sector']\n",
    "    else:\n",
    "        sector = 'error'\n",
    "\n",
    "    if 'industry' in tickerdata.info:\n",
    "        industry = tickerdata.info['industry']\n",
    "    else:\n",
    "        industry = 'error'\n",
    "\n",
    "    return([symbol,sector,industry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcba4df-6959-4df3-bc51-bc62bd5126c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_price_supply_trends(npa_):\n",
    "    name = npa_[0]\n",
    "    data = npa_[1]\n",
    "    nyse_dates_ = npa_[2]\n",
    "    \n",
    "    temp_new = data.asfreq('D').interpolate(method='time',limit_area='inside').reindex(nyse_dates_.index)\n",
    "    temp_dates = pd.date_range(data.index[0].strftime('%Y-%m-%d'), data.index[-1].strftime('%Y-%m-%d'), freq='D').map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "    nyse_inbetween_temp_dates = nyse_dates_.index[(nyse_dates_.index >= temp_dates[0]) & (nyse_dates_.index <= temp_dates[-1])]\n",
    "    temp_new = temp_new.reindex(nyse_inbetween_temp_dates)\n",
    "    \n",
    "    data_ = temp_new\n",
    "    data_['Symbol'] = name\n",
    "\n",
    "    \"\"\"\n",
    "    if(np.sum(duplicates==names_prices[n])>0):\n",
    "        #potential duplicate\n",
    "        if((np.sum((np.unique(prices_df['Symbol']))==n))>0):\n",
    "            pass\n",
    "        else:\n",
    "            prices_df = pd.concat([prices_df,data_],axis=0)            \n",
    "    else:\n",
    "    \"\"\"\n",
    "    \n",
    "    data_['trailing_1yr_max'] = (pd.DataFrame(data_)['High']).rolling(252).max()\n",
    "    data_['MIN_Lookback_One_Year'] = data_['trailing_1yr_max'].rolling(252).min()\n",
    "    #data_['MIN_Lookback_6_Months'] = data_['trailing_1yr_max'].rolling(126).min()\n",
    "    data_['MIN_Lookback_2_Months'] = data_['trailing_1yr_max'].rolling(42).min()\n",
    "    data_['MIN_Lookback_1_Months'] = data_['trailing_1yr_max'].rolling(21).min()\n",
    "\n",
    "    data_['trailing_1yr_min'] = (pd.DataFrame(data_)['Low']).rolling(252).min()\n",
    "    \n",
    "    data_['supply_trend_1yr'] = pd.DataFrame(data_)['Adj Close']-(pd.DataFrame(data_)['High']).rolling(252).min()\n",
    "    \n",
    "    #data_['supply_trend_180d'] = pd.DataFrame(data_)['Adj Close']-(pd.DataFrame(data_)['High']).rolling(126).min()\n",
    "    \n",
    "    #data_['supply_trend_90d'] = pd.DataFrame(data_)['Adj Close']-(pd.DataFrame(data_)['High']).rolling(63).min()\n",
    "    \n",
    "    data_['supply_trend_60d'] = pd.DataFrame(data_)['Adj Close']-(pd.DataFrame(data_)['High']).rolling(42).min()\n",
    "    \n",
    "    data_['supply_trend_30d'] = pd.DataFrame(data_)['Adj Close']-(pd.DataFrame(data_)['High']).rolling(21).min()\n",
    "\n",
    "    data_['trailing_60d_max'] = (pd.DataFrame(data_)['High']).rolling(42).max()\n",
    "    data_['trailing_60d_min'] = (pd.DataFrame(data_)['Low']).rolling(42).min()\n",
    "    \n",
    "    data_['trailing_30d_max'] = (pd.DataFrame(data_)['High']).rolling(21).max()\n",
    "    data_['trailing_30d_min'] = (pd.DataFrame(data_)['Low']).rolling(21).min()\n",
    "    \n",
    "    data_['90dSMA'] = (pd.DataFrame(data_)['Adj Close']).rolling(63).mean()\n",
    "    \n",
    "    data_['90dSDev'] = (pd.DataFrame(data_)['Adj Close']).rolling(63 ).std()\n",
    "    \n",
    "    data_['TP'] = (data_['Adj Close'] + data_['Low'] + data_['High'])/3\n",
    "    data_['21dstdTP'] = data_['TP'].rolling(21).std(ddof=0)\n",
    "    data_['21dMA-TP'] = data_['TP'].rolling(21).mean()\n",
    "    data_['21dBOLU'] = data_['21dMA-TP'] + 2*data_['21dstdTP']\n",
    "    data_['21dBOLD'] = data_['21dMA-TP'] - 2*data_['21dstdTP']    \n",
    "\n",
    "    data_['trailing_risk_40d_max'] = (pd.DataFrame(data_)['High']).rolling(40).max()\n",
    "    data_['trailing_risk_40d_min'] = (pd.DataFrame(data_)['Low']).rolling(40).min()\n",
    "    \n",
    "    data_['risk_per_share'] = data_['trailing_risk_40d_max']-data_['trailing_risk_40d_min']\n",
    "    \n",
    "    data_['30d_vol'] = (pd.DataFrame(data_)['Volume']).rolling(21).sum()\n",
    "    data_['30d_vol_2yr'] = data_['30d_vol'].rolling(512).mean()\n",
    "    data_['volume_factor'] = data_['30d_vol']/data_['30d_vol_2yr']\n",
    "    \n",
    "    #data_['1YMF'] = (data_['Adj Close']-data_['MIN_Lookback_One_Year']) + (data_['Adj Close']-data_['MIN_Lookback_6_Months']) + (data_['Adj Close']-data_['MIN_Lookback_2_Months']) + (data_['Adj Close']-data_['MIN_Lookback_1_Months'])\n",
    "    data_['1YMF'] = (data_['Adj Close']-data_['MIN_Lookback_One_Year']) + (data_['Adj Close']-data_['MIN_Lookback_2_Months']) + (data_['Adj Close']-data_['MIN_Lookback_1_Months'])\n",
    "    \n",
    "    data_['risk_trend_factor'] = data_['1YMF']/data_['risk_per_share']\n",
    "    \n",
    "    return(data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b800fb24-5a5f-4a26-b274-b8baf2d926f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e148bf7-9896-4e72-a9eb-de4e250bb65d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3950359d-cb0a-4653-bd1b-ce6d1f892553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMetrics(data_):\n",
    "    \n",
    "    df_line = data_[['Symbol','MIN_Lookback_One_Year', 'MIN_Lookback_2_Months', 'MIN_Lookback_1_Months','risk_trend_factor','risk_per_share','volume_factor','Adj Close','21dBOLD','21dMA-TP','21dBOLU','90dSMA','90dSDev']].iloc[[-1]].reset_index().set_index('Symbol')\n",
    "    name = df_line.index[0]\n",
    "    adf = ts.adfuller(data_['Adj Close'].values)[1]\n",
    "    \n",
    "    hurst_ = hurst(data_['Adj Close'].values)\n",
    "    \n",
    "    #temp_ = prices_df[prices_df['Symbol']=='GO']\n",
    "    #temp__ = temp_[['Symbol','MIN_Lookback_One_Year', 'MIN_Lookback_2_Months', 'MIN_Lookback_1_Months','risk_trend_factor','risk_per_share','volume_factor','Adj Close','21dBOLD','21dMA-TP','21dBOLU','90dSMA','90dSDev']].iloc[[-1]].reset_index().set_index('Symbol')\n",
    "\n",
    "    try:\n",
    "        adf = ts.adfuller(data_['Adj Close'].values)[1]\n",
    "    except:\n",
    "        adf = 'error'\n",
    "\n",
    "    try:\n",
    "        hurst_ = hurst(data_['Adj Close'].values)\n",
    "    except:\n",
    "        hurst_ = 'error'\n",
    "\n",
    "    temp = pd.concat([df_line,pd.DataFrame([adf],index=[name],columns=['adf']),pd.DataFrame([hurst_],index=[name],columns=['hurst'])],axis=1)\n",
    "    temp.columns = ['Date',*temp.columns[1:]]\n",
    "    return(temp)\n",
    "    \n",
    "    \"\"\"\n",
    "    n_ = data_df['Symbol'].values[-1]\n",
    "    \n",
    "    latest_p = pd.DataFrame(data_df)['Adj Close'][-1]\n",
    "    oneYearDate = pd.DataFrame(data_df)['Adj Close'][[-1]].index[0] - relativedelta(years=1)\n",
    "    \n",
    "    #separate subset for past year.\n",
    "    past_year = data_df[data_df.index>=oneYearDate.strftime('%Y-%m-%d')]\n",
    "    \n",
    "    #np.max(npa[np.where(np.array(names_prices)=='GBX')[0][0]]['High'])\n",
    "    #max_2y = pd.DataFrame(data_df)['High'].rolling(504).max()[-1]\n",
    "    #min_2y = pd.DataFrame(data_df)['Low'].rolling(504).min()[-1]\n",
    "    \n",
    "    #quantiles_close_2y = data_df['Adj Close'].rolling(504).quantile(q=[0, .02, .09, .25, .5, .75, .91, .98, 1])[-1]\n",
    "    #quantiles_close_2y = data_df['Adj Close'].quantile(q=[0, .02, .09, .25, .5, .75, .91, .98, 1])\n",
    "    \n",
    "    std_2y = pd.DataFrame(data_df)['Adj Close'].rolling(504).std()[-1]\n",
    "    mean_2y = pd.DataFrame(data_df)['Adj Close'].rolling(504).mean()[-1]\n",
    "    \n",
    "    #max_1y = past_year['High'].rolling(252).max()[-1]\n",
    "    #min_1y = past_year['Low'].rolling(252).min()[-1]\n",
    "    \n",
    "    #quantiles_close_1y = data_df['Adj Close'].rolling(252).quantile(q=[0, .02, .09, .25, .5, .75, .91, .98, 1])[-1]\n",
    "    #quantiles_close_1y = past_year['Adj Close'].quantile(q=[0, .02, .09, .25, .5, .75, .91, .98, 1])\n",
    "    \n",
    "    std_1y = past_year['Adj Close'].rolling(252).std()[-1]\n",
    "    mean_1y = past_year['Adj Close'].rolling(252).mean()[-1]\n",
    "    \n",
    "    risk_trend_factor = data_df['risk_trend_factor'][-1]\n",
    "    \n",
    "    supply_trend_1yr = data_df['supply_trend_1yr'][-1]\n",
    "    #supply_trend_180d = data_df['supply_trend_180d'][-1]\n",
    "    #supply_trend_90d = data_df['supply_trend_90d'][-1]\n",
    "    supply_trend_60d = data_df['supply_trend_60d'][-1]\n",
    "    supply_trend_30d = data_df['supply_trend_30d'][-1]\n",
    "    \n",
    "    MIN_Lookback_One_Year = data_df['MIN_Lookback_One_Year'][-1]\n",
    "    #MIN_Lookback_6_Months = data_df['MIN_Lookback_6_Months'][-1]\n",
    "    MIN_Lookback_2_Months = data_df['MIN_Lookback_2_Months'][-1]\n",
    "    MIN_Lookback_1_Months = data_df['MIN_Lookback_1_Months'][-1]\n",
    "    \n",
    "    adf = ts.adfuller(data_df['Adj Close'].values)[1]\n",
    "    \n",
    "    hurst_ = hurst(data_df['Adj Close'].values)\n",
    "\n",
    "    volume_factor = data_df['volume_factor'][-1]\n",
    "    vol_30d = data_df['30d_vol'][-1]\n",
    "    vol_30d_2yr = data_df['30d_vol_2yr'][-1]\n",
    "    \n",
    "    pct_2yr = (latest_p - min_2y)/(max_2y-min_2y)\n",
    "    pct_1yr = (latest_p - min_1y)/(max_1y-min_1y)\n",
    "    \n",
    "    ymf = data_df['1YMF'][-1]\n",
    "    \n",
    "    return([n_,max_2y,min_2y,std_2y,mean_2y,max_1y,min_1y,std_1y,mean_1y,latest_p,*quantiles_close_2y,*quantiles_close_1y,risk_trend_factor,supply_trend_1yr,supply_trend_60d,supply_trend_30d,vol_30d_2yr,pct_1yr,pct_2yr,MIN_Lookback_One_Year, MIN_Lookback_2_Months, MIN_Lookback_1_Months,vol_30d,volume_factor,adf,hurst_,ymf])\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "080fa645-60d8-451d-be78-8cd3d42190c1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcd5932-c32a-4569-a95e-cb41fd87df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTickerValues(npa):\n",
    "    \n",
    "    n_ = npa[0]\n",
    "    r_ = npa[1]\n",
    "    #print(r_)\n",
    "    print(n_)\n",
    "\n",
    "    subset = pd.DataFrame([r_.info])\n",
    "\n",
    "    others = ['quarterly_balance_sheet','quarterly_cashflow','quarterly_dividends','quarterly_earnings','quarterly_financials','mutualfund_holders','options','sustainability']\n",
    "\n",
    "    o_items = []\n",
    "\n",
    "    #print(r_)\n",
    "    for o in others:\n",
    "        if(np.sum(np.array(dir(r_))==[o])>0):\n",
    "            o_item = getattr(r_, o)\n",
    "            o_items.append([o,o_item])            \n",
    "\n",
    "    \n",
    "    values = pd.DataFrame()\n",
    "\n",
    "    trackers = ['beta','currentRatio','debtToEquity','dividendRate','dividendYield','earningsGrowth','ebitda','ebitdaMargins','forwardPE','freeCashflow','grossMargins','grossProfits','heldPercentInstitutions','industry','marketCap','operatingCashflow','operatingMargins','payoutRatio','pegRatio','priceToBook','priceToSalesTrailing12Months','profitMargins','quickRatio','returnOnAssets','returnOnEquity','revenueGrowth','revenuePerShare','sector','sharesOutstanding','shortRatio','totalAssets','totalCash','totalCashPerShare','totalDebt','totalRevenue','trailingPE']\n",
    "\n",
    "    for t in trackers:\n",
    "        if(np.sum(np.where(subset.columns==t))==0):\n",
    "            values = pd.concat([values,pd.DataFrame('error',index=[n_],columns=[t])],axis=1)\n",
    "        else:\n",
    "            values = pd.concat([values,pd.DataFrame(subset[t].values[0],index=[n_],columns=[t])],axis=1)\n",
    "\n",
    "    return([n_,values,o_items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e80f967-b14c-4dc4-99da-dd1fd599eb86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98802d47-bc74-42d5-bb94-21ee8a12b6fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43bd8bc-1cff-4640-937b-40623195a3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8050022b-a851-4e33-bd40-ec68df9b2b08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e9f1f-2e9e-4a5b-8256-714590c08089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "dates = []\n",
    "for d in pd.read_csv('..\\\\data\\\\raw\\\\sample.csv')['Date']:\n",
    "    dates.append(dt.datetime.strptime(d, '%d-%b-%y'))\n",
    "\n",
    "temp = pd.read_csv('..\\\\data\\\\raw\\\\sample.csv',thousands=\",\")\n",
    "temp.index = dates\n",
    "temp = temp.iloc[:,1:]\n",
    "temp.columns = ['Open','High','Low','Adj Close','Volume']\n",
    "#temp['Close'] = temp['Close'].astype(float)\n",
    "temp.sort_index(inplace=True)\n",
    "temp['Symbol'] = 'Test'\n",
    "\n",
    "temp_new = derive_price_supply_trends(['temp',temp,nyse_dates]).sort_index(ascending=False)\n",
    "print(temp_new)\n",
    "print(calculateMetrics(temp_new))\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75c064-9b69-4bf4-8b9d-742c103760ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3393b8a2-5999-4feb-85f1-c0a76282f443",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "for i in range(0,len([*SP1500,*indexes,*sectors])):\n",
    "    npa.append([[*SP1500,*indexes,*sectors][i],start.strftime('%Y-%m-%d'),end.strftime('%Y-%m-%d')])\n",
    "    \n",
    "# = getStock(npa[0])\n",
    "    \n",
    "client = Client('192.168.3.100:8786')\n",
    "#client = Client(n_workers=4,threads_per_worker=1)\n",
    "client.restart()\n",
    "future = client.map(getStock, npa)\n",
    "results_prices = []\n",
    "#my intent was to capture future objects vs results and this gave me results\n",
    "for f in as_completed(future):\n",
    "    if(f.status==\"error\"):\n",
    "        results_prices.append(\"error\")\n",
    "    else:\n",
    "        results_prices.append(f.result()) \n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b990a045-2680-438b-8806-95253a57655d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafd0e0-67f4-4b09-9f9e-e3cb949aebb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "for i in range(0,len([*SP1500,*indexes,*sectors])):\n",
    "    npa.append([[*SP1500,*indexes,*sectors][i]])\n",
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "#client = Client(n_workers=4,threads_per_worker=1)\n",
    "client.restart()\n",
    "\n",
    "future = client.map(getTickerData, npa)\n",
    "\n",
    "results_ticker_data = []\n",
    "\n",
    "#my intent was to capture future objects vs results and this gave me results\n",
    "for f in as_completed(future):\n",
    "    if(f.status==\"error\"):\n",
    "        results_ticker_data.append(\"error\")\n",
    "    else:\n",
    "        results_ticker_data.append(f.result()) \n",
    "#client.restart()\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d32e5c9-9e3b-4b85-b17a-72024d1d56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results_ticker_data[0][1].info)\n",
    "print(results_ticker_data[0][1].quarterly_balance_sheet)\n",
    "print(results_ticker_data[0][1].quarterly_cashflow)\n",
    "#print(results_ticker_data[0][1].quarterly_dividends)\n",
    "print(results_ticker_data[0][1].quarterly_earnings)\n",
    "print(results_ticker_data[0][1].quarterly_financials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590a3971-2e6b-4e50-8ae4-fef713653413",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ticker_data[0][1].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986e3984-bdb7-44bd-8aa5-8e27d42a5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "results_ticker_names = [r[0] for r in results_ticker_data]\n",
    "for n in range(0,len(results_ticker_names),1):\n",
    "    npa.append([results_ticker_names[n],results_ticker_data[n][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ab2ff-426b-467c-ade3-3aab268a38b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513afe01-7bdf-45d2-93b2-332200ac1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "#client = Client(n_workers=4,threads_per_worker=1)\n",
    "client.restart()\n",
    "\n",
    "future = client.map(extractTickerValues, npa)\n",
    "\n",
    "results_ticker_values = []\n",
    "\n",
    "#my intent was to capture future objects vs results and this gave me results\n",
    "for f in as_completed(future):\n",
    "    if(f.status==\"error\"):\n",
    "        results_ticker_values.append(\"error\")\n",
    "    else:\n",
    "        results_ticker_values.append(f.result()) \n",
    "client.close()\n",
    "\n",
    "\"\"\"\n",
    "trackers = ['beta','currentRatio','debtToEquity','dividendRate','dividendYield','earningsGrowth','ebitda','ebitdaMargins','forwardPE','freeCashflow','grossMargins','grossProfits','heldPercentInstitutions','industry','marketCap','operatingCashflow','operatingMargins','payoutRatio','pegRatio','priceToBook','priceToSalesTrailing12Months','profitMargins','quickRatio','returnOnAssets','returnOnEquity','revenueGrowth','revenuePerShare','sector','sharesOutstanding','shortRatio','totalAssets','totalCash','totalCashPerShare','totalDebt','totalRevenue','trailingPE']\n",
    "\n",
    "for t in trackers:\n",
    "    if(np.sum(np.where(subset.columns==t))==0):\n",
    "        values = pd.concat([values,pd.DataFrame('error',index=[n_],columns=[t])],axis=1)\n",
    "    else:\n",
    "        values = pd.concat([values,pd.DataFrame(subset[t].values[0],index=[n_],columns=[t])],axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f936edc-bafe-44ae-bbd6-0f4eb2bbe7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7f9112-ad67-48f5-acba-695672cd4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "ticker_values = pd.DataFrame()\n",
    "\n",
    "pickle_dumps = []\n",
    "\n",
    "for r in results_ticker_values:\n",
    "    if(r=='error'):\n",
    "        pass\n",
    "        #pd.DataFrame(np.repeat('error', len(trackers), axis = None),index=)\n",
    "    else:                \n",
    "        #print(r[1])\n",
    "        subset = pd.DataFrame(r[1])\n",
    "        subset.index = [r[0]]\n",
    "        #print(subset)\n",
    "        ticker_values = pd.concat([ticker_values,subset],axis=0)\n",
    "        pickle_dumps.append([r[0],r[2]])\n",
    "        #ticker_values = pd.concat([ticker_values,pd.DataFrame(r[1],index=[r[0]])],axis=0)\n",
    "\n",
    "pd.DataFrame(ticker_values)\n",
    "\n",
    "pickle.dump(pickle_dumps, open('..\\\\data\\\\interim\\\\fundamental.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463c0b7b-2575-4538-ba33-5a618451a2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504e126d-6051-4a6d-b872-2a98bc9c870c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "missing_ticker_values = list(set([*SP1500,*indexes,*sectors]).difference([n for n in pd.DataFrame(ticker_values).index]))\n",
    "print(missing_ticker_values)\n",
    "\n",
    "for r in range(0,len(missing_ticker_values)):\n",
    "    r_ = missing_ticker_values[r]\n",
    "    temp = pd.DataFrame(np.array([r_,*np.repeat('missing',len(pd.DataFrame(ticker_values.columns)))])).T.set_index(0)\n",
    "    temp.columns = ticker_values.columns\n",
    "    #.set_index(0).iloc[[0]].columns))])\n",
    "    ticker_values = pd.concat([ticker_values,temp],axis=0)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311f5c6-4e84-4268-898d-3b529bff2bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2047a9d4-3997-41a4-b57b-bc3320766730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5fbb2b-8eb4-42d5-ad00-205bfbdbddee",
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data = pd.concat([ticker_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bdbfbd-49fd-4698-9d75-37ffa654ea25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ae2222-3345-4267-a041-209115555cf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e319b0ed-d29f-4cc4-b0b9-8c236cad6edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_prices = [rp[0] for rp in results_prices]\n",
    "\n",
    "#def process_df(data_):\n",
    "npa = []    \n",
    "for n in range(0,len(names_prices)):\n",
    "    #print(names_prices[n])\n",
    "    n_ = names_prices[n]\n",
    "    npa.append([n_,results_prices[n][1],nyse_dates])\n",
    "    \n",
    "    \n",
    "prices_df = pd.DataFrame()\n",
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "#client = Client(n_workers=4,threads_per_worker=1)\n",
    "client.restart()\n",
    "\n",
    "future = client.map(derive_price_supply_trends, npa)\n",
    "#results_sectors = []\n",
    "#my intent was to capture future objects vs results and this gave me results\n",
    "for f in as_completed(future):\n",
    "    if(f.status==\"error\"):\n",
    "        #results_sectors.append(\"error\")\n",
    "        pass\n",
    "    else:\n",
    "        #results_sectors.append(f.result())\n",
    "        prices_df = pd.concat([f.result(),prices_df],axis=0)\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c45887-558d-46b9-9790-2dc4e0102ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aef3b6-206b-4eee-92dd-951b93791911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "npa = []\n",
    "for s in names_prices:\n",
    "    #print(s)\n",
    "    subset = prices_df.iloc[np.where(prices_df['Symbol']==s)]\n",
    "    if(len(subset)==0):\n",
    "        pass\n",
    "    else:\n",
    "        npa.append(subset)\n",
    "\n",
    "screenerMetrics = []\n",
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "#client = Client(n_workers=4,threads_per_worker=1)\n",
    "client.restart()\n",
    "\n",
    "future = client.map(calculateMetrics, npa)\n",
    "\n",
    "#my intent was to capture future objects vs results and this gave me results\n",
    "for f in as_completed(future):\n",
    "    if(f.status==\"error\"):\n",
    "        screenerMetrics.append(\"error\")\n",
    "    else:\n",
    "        screenerMetrics.append(f.result()) \n",
    "client.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ac3277-7c42-4716-a030-3f620d0a1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "screener_metrics = pd.concat(screenerMetrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767b7e62-711d-4c53-a55b-7ff311032c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_screener_metrics = list(set([*SP1500,*indexes,*sectors]).difference([n for n in screener_metrics.index]))\n",
    "print(missing_screener_metrics)\n",
    "\n",
    "for r in range(0,len(missing_screener_metrics)):\n",
    "    r_ = missing_screener_metrics[r]\n",
    "    test = pd.DataFrame([np.repeat('missing',len(screener_metrics.columns))],index=[r_],columns=screener_metrics.columns)\n",
    "    screener_metrics = pd.concat([screener_metrics,test],axis=0)\n",
    "\n",
    "#pd.DataFrame(screener_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30a3041-d0f8-43cf-8918-282f5b8cd597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498be7a-33b9-442a-8339-bcfea7a4d483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39cf13b-500b-469d-943f-80dd4eb9d2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fundamentals_quarterlies = pickle.load(open('./fundamental.pkl', 'rb'))\n",
    "fundamental_entries = [e[0] for e in pickle_dumps]#[e[0] for e in fundamentals_quarterlies]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608d35d2-8da6-423b-bc23-8d4baf2ccf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb80f53-46b0-4104-8821-fc60fe42306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary = pd.concat([prices_df[prices_df['Symbol']==name_][['Symbol','MIN_Lookback_One_Year', 'MIN_Lookback_2_Months', 'MIN_Lookback_1_Months','risk_trend_factor','risk_per_share','volume_factor']].iloc[[-1]].reset_index().set_index('Symbol') for name_ in np.unique(prices_df['Symbol'].values)]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee312d5f-4916-4c0a-81bc-7aa31b2c38e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d55e1dd-7c76-4d3a-ac71-d0b67045fc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sector_performance = []\n",
    "for v in sectors:\n",
    "    sector_performance.append([v,screener_metrics.loc[[v]]['risk_trend_factor'].values[0]])\n",
    "temp_v = pd.concat([pd.DataFrame([dict_sectors_reverse[v] for v in sectors]),pd.DataFrame(sectors)],axis=1)\n",
    "temp_v.columns = ['Sector','Symbol']\n",
    "sectors_risk_sorted = pd.DataFrame(sector_performance,columns=['Symbol','risk_trend_factor']).merge(temp_v, on='Symbol', how='left').sort_values(by='risk_trend_factor',ascending=False)    \n",
    "sectors_risk_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4f2c3-547e-4caf-a31b-78976117c627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbe75d-0bfe-4a44-9939-b13a8c146e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_performance = []\n",
    "for v in indexes:\n",
    "    index_performance.append([v,screener_metrics.loc[[v]]['risk_trend_factor'].values[0]])\n",
    "temp_i = pd.DataFrame(index_performance,index=indexes)\n",
    "temp_i.columns = ['Symbol','risk_trend_factor']\n",
    "index_risk_sorted = pd.DataFrame(index_performance,columns=['Symbol','risk_trend_factor'],index=indexes).sort_values(by='risk_trend_factor',ascending=False).reset_index()\n",
    "index_risk_sorted.columns = ['Index','Symbol','risk_trend_factor']\n",
    "index_risk_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b413487-afc4-41b3-8d27-caf37fe764bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa639191-3ec1-4471-91f5-283372618fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold = 0\n",
    "#stock_fundamentals = market_data\n",
    "#screener = screener_metrics\n",
    "#stock_indexes = sp1500_index_df\n",
    "\n",
    "\n",
    "#spdr_indexes = indexes\n",
    "#spdr_indexes.columns=['Symbol']\n",
    "#vanguard_sectors = sectors\n",
    "#vanguard_sectors.columns=['Symbol']\n",
    "screener_metrics_w_sp1500index = screener_metrics.reset_index().rename(columns={'index': 'Symbol'}).merge(sp1500_index_df,on='Symbol',how='left')\n",
    "\n",
    "screener_metrics_w_sp1500index_good = screener_metrics_w_sp1500index[screener_metrics_w_sp1500index['risk_trend_factor']!='missing']\n",
    "\n",
    "risk_trend_threshold = screener_metrics_w_sp1500index_good['risk_trend_factor'].quantile(q=[threshold]).values[0]\n",
    "stock_sectors = market_data['sector']\n",
    "\n",
    "temp = stock_sectors.reset_index()\n",
    "temp.columns = ['Symbol','Sector']\n",
    "sector_merged = screener_metrics.reset_index().rename(columns={'index': 'Symbol'}).merge(temp, on='Symbol', how='right')\n",
    "temp_sm = sector_merged.merge(sp1500_index_df, on='Symbol', how='left').set_index('Symbol')\n",
    "#temp_sm.columns = ['risk_trend_factor', 'Sector', 'index']\n",
    "\n",
    "temp_index_symbol_map = pd.concat([sp1500_index_df,pd.DataFrame([invert_dict_indexes[s] for s in sp1500_index_df['Market Index']])],axis=1)\n",
    "temp_index_symbol_map.columns = ['Symbol','Market Index','Index Symbol']\n",
    "\n",
    "index_sector_merged = temp_sm.merge(temp_index_symbol_map.iloc[:,[0,2]], on='Symbol', how='left')\n",
    "\n",
    "\"\"\"\n",
    "for spdr_ in range(0,len(indexes)):\n",
    "    spdr__ = indexes[spdr_]\n",
    "    #spdr__i = indexes[spdr_]\n",
    "    #temp_sm.iloc[np.where(temp_sm.index==spdr__)][['index']] = spdr__i\n",
    "    temp_sm.iloc[np.where(temp_sm.index==spdr__)][['index_Symbol']] = spdr__\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d546c05-0aeb-424d-9d1a-6e95077438f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_screened = screener_metrics_w_sp1500index_good[(screener_metrics_w_sp1500index_good['risk_trend_factor']>risk_trend_threshold) & (screener_metrics_w_sp1500index_good['volume_factor']!= 'missing')]\n",
    "risk_screened = risk_screened.merge(temp, on='Symbol', how='left')\n",
    "print(risk_screened.columns)\n",
    "#temp_df = risk_screened[['Symbol','Adj Close','MIN_Lookback_One_Year', 'MIN_Lookback_2_Months', 'MIN_Lookback_1_Months','risk_trend_factor','volume_factor','adf','hurst','Sector','Market Index']]\n",
    "#temp_df.set_index('Symbol',inplace=True)\n",
    "#pd.concat([temp_df,temp_sm],axis=0)\n",
    "\n",
    "#screened_final_set = risk_screened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0e7325-848a-4ae5-a72a-ec40b29f81ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4fefb0-5d2f-4e6f-9adb-00280e1019b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = screener_metrics_w_sp1500index_good.dropna()['risk_trend_factor'].quantile([threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342941c-a1ba-491f-8a13-6a3b9ef5875b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c502a-2f60-4d35-a814-45c1a60adee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790daf2f-70b4-402f-a14f-13e27d9896a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc457e-7582-4b59-8ceb-4c3a7f97c5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2c5e3-1756-4d3a-8c9c-71dc0d70b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_trend_factor_sector_dict = dict()\n",
    "for s in sectors:\n",
    "    risk_trend_factor_sector_dict[s] = screener_metrics.loc[[s]]['risk_trend_factor'].values[-1]\n",
    "    \n",
    "risk_trend_factor_sector_dict['error']='error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7d337-c734-43be-a9f6-fb27ab8d496c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "inv_dict_map = {v: k for k, v in dict_indexes.items()}\n",
    "inv_dict_map[np.nan] = 'error'\n",
    "in_ = [inv_dict_map[t[0]] for t in temp_sm[['Market Index']].values]\n",
    "se_ = [dict_sectors[t[0]] for t in temp_sm[['Sector']].values]\n",
    "#temp_sm[['Sector','index']]\n",
    "\"\"\"\n",
    "#symbols_w_index_sector = pd.concat([pd.DataFrame(se_,columns=['index'],index=temp_sm.index),pd.DataFrame(in_,columns=['sector'],index=temp_sm.index)],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabd7127-f518-429f-844c-c63f19f78b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbols_w_index_sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fdac26-d381-4b2d-bac4-02d0ee782571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3a437-2580-4614-ac68-e5326c4c1bc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854f0d06-7a40-46a8-b3b5-f1b6bccaa868",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e08831-53c1-431a-b4f9-4fedf964eda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ca101-be69-4a64-9f5a-0219032807c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_sector_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9b158-51e3-46f5-b1cd-98dabf116a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e76b6-be24-49af-8c17-e84c21615687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame([dict_sectors[s] for s in index_sector_merged['Sector']],columns=['Sector Symbol'],index=index_sector_merged['Symbol']\n",
    "sector_symbols = pd.DataFrame([dict_sectors[s] for s in index_sector_merged['Sector']],index=index_sector_merged['Symbol'],columns=['Sector Symbol'])\n",
    "\n",
    "symbols_w_sector_rtf = pd.DataFrame([risk_trend_factor_sector_dict[s] for s in sector_symbols['Sector Symbol']],columns=['sector_risk_trend_factor'],index=sector_symbols.index)\n",
    "\n",
    "#screener_final = pd.concat([screener_metrics,symbols_w_index_sector.set_index),symbols_w_sector_rtf,index_sector_merged[['Market Index','Sector']]],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa78cf3-d3e2-4451-a8d1-7c4cde2cb5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727042e-e5eb-49b5-b075-a386952b962a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9127f687-2f8b-404b-86d0-55f2f95e434e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dedf93-960e-4eea-97ba-85a4e75d134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "screener_final = pd.concat([screener_metrics,symbols_w_sector_rtf,index_sector_merged.set_index('Symbol')[['Sector']],sector_symbols,index_sector_merged.set_index('Symbol')[['Market Index','Index Symbol']]],axis=1)\n",
    "\n",
    "a = screener_final[screener_final['risk_trend_factor'].apply(type) != np.str_].sort_values(by='risk_trend_factor',ascending=False)\n",
    "b = screener_final[screener_final['risk_trend_factor'].apply(type) == np.str_]\n",
    "screener_sorted = pd.concat([a,b],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf5afba-6c21-4977-8d3a-3aa0da1f6345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a19f11-80f6-4b5a-acf0-9fe1659bc871",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.concat([screener_metrics.sort_values(by='risk_trend_factor',ascending=False).iloc[:,1:],symbols_w_index_sector,symbols_w_sector_rtf,temp_sm[['Market Index','Sector']]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3779fc2-cab0-4b0a-8322-0e2a26607382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccb97d3-5c71-41ac-a7a1-e7782db83a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a2c84-140a-4ef4-850b-d639ec13df5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sector_n_indexes = []\n",
    "list_stocks = []\n",
    "for i in index_risk_sorted['Symbol'].values:\n",
    "    list_sector_n_indexes.append(i)\n",
    "for i in sectors_risk_sorted['Symbol'].values:\n",
    "    list_sector_n_indexes.append(i)\n",
    "#for i in screened_final_set['Symbol'].values:\n",
    "for i in sp1500_index_df['Symbol'].values:\n",
    "    list_stocks.append(i)\n",
    "stocks_ = list_stocks\n",
    "#stocks_ = np.unique(list_stocks, return_index=True)[1]\n",
    "#list__ = [list_[symbol] for symbol in sorted(stocks_)]\n",
    "#list__ = ['MCK','MPC','APA','LNTH','MUSA','CIVI','VAW','VGT','EQT','XOM','DVN','MRO','EOG','HES','CEIX','SM','RRC','MUR','MTDR','PXD','OXY','PDCE','NFG','FANG','TWI','PBF','MANT','HRB','VDC','ACC','GO','TVTY','FCN','VIVO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6aab3e-c9ed-45ce-b364-db5bb3b59a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#screener_sorted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99282da-2725-480c-8fb3-7056441b0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "rick_screener_final = rick_screener.dropna()[rick_screener.dropna()['risk_trend_factor'].values > threshold_value.values[0]]\n",
    "rick_screener_final = pd.concat([rick_screener,rick_screener_final],axis=0).drop_duplicates(keep='last')\n",
    "\n",
    "diff_ = np.setdiff1d(np.array([*list_sector_n_indexes,*stocks_]),rick_screener_final.index)\n",
    "\n",
    "for d in diff_:\n",
    "    rick_screener_final = pd.concat([rick_screener_final,pd.DataFrame([np.repeat(np.nan, len(rick_screener_final.columns))],columns=rick_screener_final.columns,index=[d])],axis=0)\n",
    "    \n",
    "rick_screener_final.loc[np.setdiff1d([*rick_screener_final.index],list_sector_n_indexes)].sort_values(by='risk_trend_factor',ascending=False).to_csv('rick_screener_final.csv')\n",
    "\"\"\"\n",
    "#screener_sorted.loc[np.setdiff1d([*screener_final.index],list_sector_n_indexes)].head(50)\n",
    "screener_sorted.to_csv('..\\\\data\\\\processed\\\\'+end.strftime('%Y-%m-%d')+'_screener_sorted.csv')\n",
    "screener_sorted.to_csv('..\\\\data\\\\processed\\\\screener_sorted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ba1d0-9bd2-4f07-824f-666930a75a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#screener_final.loc[np.setdiff1d([*screener_final.index],list_sector_n_indexes)]['risk_trend_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8a0d04-42dd-4200-b657-3fd77cf5aea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c2ac9a-823e-4067-93d8-b1e8a36db4b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a6922-86bf-4d86-98ab-adbafc793d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "npa = []\n",
    "for f in FRED_Indicators:\n",
    "    npa.append([f,start.strftime('%Y-%m-%d'),end.strftime('%Y-%m-%d'),nyse_dates])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531c1cf1-abd6-479f-ae4b-0ead583c67ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c6cd0f-4de1-4cfa-b347-ae0d8b553b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completed_fred = pd.DataFrame()\n",
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "#client = Client(n_workers=4,threads_per_worker=1)\n",
    "client.restart()\n",
    "\n",
    "future = client.map(Fred_Data, npa)\n",
    "\n",
    "#my intent was to capture future objects vs results and this gave me results\n",
    "for f in as_completed(future):\n",
    "    if(f.status==\"error\"):\n",
    "        pass\n",
    "    else:\n",
    "        completed_fred = pd.concat([completed_fred,f.result()],axis=0)\n",
    "client.close()\n",
    "\n",
    "completed_fred_pvt = pd.pivot_table(completed_fred, values=['Value'], index=completed_fred.index,columns=['Symbol'])\n",
    "completed_fred_pvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af742db-dabd-47cb-9e4e-1abe93e4a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa = []\n",
    "for e in etf_bonds:\n",
    "    npa.append([e,start.strftime('%Y-%m-%d'),end.strftime('%Y-%m-%d'),nyse_dates])\n",
    "    \n",
    "completed_bonds = pd.DataFrame()\n",
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "#client = Client(n_workers=4,threads_per_worker=1)\n",
    "client.restart()\n",
    "\n",
    "future = client.map(dl, npa)\n",
    "\n",
    "#my intent was to capture future objects vs results and this gave me resultsa\n",
    "for f in as_completed(future):\n",
    "    if(f.status==\"error\"):\n",
    "        pass\n",
    "    else:\n",
    "        completed_bonds = pd.concat([completed_bonds,f.result()],axis=0)\n",
    "client.close()\n",
    "\n",
    "completed_bonds_pvt = pd.pivot_table(completed_bonds, values='Close', index=completed_bonds.index,columns=['Symbol'])\n",
    "completed_bonds_pvt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9094491-57bc-4f28-bc3b-f6559581a93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab7178-fe3f-4482-84f8-7bee0eb3d713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed589a9-2bb5-485a-bc33-9769a199f24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#writer = pd.ExcelWriter('SP1500_screener_multiple.xlsx', engine='xlsxwriter')\n",
    "\n",
    "data_object = [start,end,prices_df, sp1500_index_df, sp500, sp600, sp400, market_data, completed_fred_pvt, completed_bonds, completed_bonds_pvt, pd.DataFrame(sectors,sector_names), pd.DataFrame(indexes,index_names), screener_sorted, dict_sectors, dict_indexes, dict_sectors_reverse,invert_dict_indexes, list_sector_n_indexes, list_stocks]\n",
    "               \n",
    "pickle.dump(data_object, open('..\\\\data\\\\interim\\\\data_object.pkl', 'wb'))\n",
    "\"\"\"\n",
    "#prices_df.to_excel(writer, sheet_name='SP1500_Sectors_Indexes_Prices')\n",
    "#prices_df.drop(['Sector', 'Market Cap'], axis=1).to_excel(writer, sheet_name='SP1500Prices')\n",
    "\n",
    "#sectors_df.to_excel(writer, sheet_name='stock_sectors')\n",
    "\n",
    "#mktcap_df.to_excel(writer, sheet_name='market_caps')\n",
    "\n",
    "sp1500_index_df.to_excel(writer, sheet_name='SP1500')\n",
    "\n",
    "pd.DataFrame(sp500).to_excel(writer, sheet_name='SP500')\n",
    "pd.DataFrame(sp600).to_excel(writer, sheet_name='SP600')\n",
    "pd.DataFrame(sp400).to_excel(writer, sheet_name='SP400')\n",
    "pd.DataFrame(market_data).to_excel(writer, sheet_name='Stock_Fundamentals')\n",
    "completed_fred_pvt.to_excel(writer, sheet_name='completed_fred_pvt')\n",
    "completed_bonds.to_excel(writer, sheet_name='completed_bonds')\n",
    "completed_bonds_pvt.to_excel(writer, sheet_name='completed_bonds_pvt')\n",
    "pd.DataFrame(pd.DataFrame(sectors,sector_names)).to_excel(writer, sheet_name='vanguard_sectors')\n",
    "pd.DataFrame(pd.DataFrame(indexes,index_names)).to_excel(writer, sheet_name='spdr_indexes')\n",
    "screener_metrics.to_excel(writer, sheet_name='Screener')\n",
    "\n",
    "writer.save()\n",
    "\n",
    "wb = openpyxl.load_workbook('SP1500_screener_multiple.xlsx')\n",
    "#openpyxl.Workbook()\n",
    "new_range = openpyxl.workbook.defined_name.DefinedName('Prices', attr_text='SP1500_Sectors_Indexes_Prices!$A$1:$H$'+str(len(prices_df)+1))\n",
    "wb.defined_names.append(new_range)\n",
    "new_range = openpyxl.workbook.defined_name.DefinedName('SP1500', attr_text='SP1500!$B$1:$C$'+str(len(sp1500_index_df)+1))\n",
    "wb.defined_names.append(new_range)\n",
    "new_range = openpyxl.workbook.defined_name.DefinedName('Vanguard_Sectors', attr_text='vanguard_sectors!$B$1:$C$'+str(len(sectors)+1))\n",
    "wb.defined_names.append(new_range)\n",
    "new_range = openpyxl.workbook.defined_name.DefinedName('SPDR_Indexes', attr_text='spdr_indexes!$B$1:$C$'+str(len(indexes)+1))\n",
    "wb.defined_names.append(new_range)\n",
    "\n",
    "\n",
    "#wb.defined_names.append(new_range)\n",
    "wb.save('SP1500_screener_multiple.xlsx')\n",
    "wb.close()\n",
    "#named_range = NamedRange(\"test_nr\", [(new_sheet, \"A1\")])\n",
    "#wb.add_named_range(new_range)\n",
    "wb.close()\n",
    "writer.close()\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "workbook = xlsxwriter.Workbook('SP1500_screener_multiple.xlsx')\n",
    "workbook.define_name('Prices', '=SP1500Prices!$A$1:$J$'+str(len(prices_df)+1))\n",
    "workbook.define_name('Sectors', '=stock_sectors!$A$1:$B$'+str(len(sectors_df)+1))\n",
    "workbook.define_name('market_caps', '=market_caps!$A$1:$B$'+str(len(mktcap_df)+1))\n",
    "workbook.define_name('SP1500', '=SP1500!$B$1:$C$'+str(len(sp1500_index_df)+1))\n",
    "\n",
    "workbook.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4e843-3b76-49ca-b7be-c2327bda7d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
