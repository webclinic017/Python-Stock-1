{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Do this to support SHAP\n!pip install 'tensorflow==1.14.0'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"variables_name = pd.read_csv(\"../input/variables_name.csv\")\nfeatures = variables_name.values[:,1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open(\"../input/X_train_HPCC_1_20.json\") as of:\n    X_train = np.array(json.load(of))\nwith open(\"../input/y_train_HPCC_1_20.json\") as of:\n    y_train = np.array(json.load(of))\nwith open(\"../input/X_test_HPCC_1_20.json\") as of:\n    X_test = np.array(json.load(of))\nwith open(\"../input/y_test_HPCC_1_20.json\") as of:\n    y_test = np.array(json.load(of))    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from keras import regularizers\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nfrom keras.layers import Dense\nfrom keras.layers import Activation\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.optimizers import Adam\n\n\ndef createModel(l1Nodes, l2Nodes, d1Nodes, d2Nodes, inputShape):\n    # input layer\n    lstm1 = LSTM(l1Nodes, input_shape=inputShape, return_sequences=True)\n    lstm2 = LSTM(l2Nodes, return_sequences=True)\n    flatten = Flatten()\n    dense1 = Dense(d1Nodes)\n    dense2 = Dense(d2Nodes)\n\n    # output layer\n    outL = Dense(1, activation='relu')\n    # combine the layers\n    layers = [lstm1, lstm2, flatten,  dense1, dense2, outL]\n    # create the model\n    model = Sequential(layers)\n    opt = Adam(learning_rate=0.005)\n    model.compile(optimizer=opt, loss='mse')\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create model\nmodel = createModel(8, 8, 8, 4, (X_train.shape[1], X_train.shape[2]))\nmodel.fit(X_train, y_train, batch_size=8, epochs=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SHAP","metadata":{}},{"cell_type":"code","source":"import shap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the training data for deep explainer => can use fewer instances\nexplainer = shap.DeepExplainer(model, X_train)\n# explain the the testing instances (can use fewer instanaces)\n# explaining each prediction requires 2 * background dataset size runs\nshap_values = explainer.shap_values(X_test)\n# init the JS visualization code\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0][0], features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train_outlier\nwith open(\"../input/X_train_outlier.json\") as of:\n    X_train_outlier = np.array(json.load(of))\nwith open(\"../input/y_train_outlier.json\") as of:\n    y_train_outlier = np.array(json.load(of))\n\n    # X_train_normal\nwith open(\"../input/X_train_not_outlier.json\") as of:\n    X_train_not_outlier = np.array(json.load(of))\nwith open(\"../input/y_train_not_outlier.json\") as of:\n    y_train_not_outlier = np.array(json.load(of))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# explain the the testing instances (can use fewer instanaces)\n# explaining each prediction requires 2 * background dataset size runs\nshap_values = explainer.shap_values(X_train_outlier)\n# init the JS visualization code\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0][0], features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# explain the the testing instances (can use fewer instanaces)\n# explaining each prediction requires 2 * background dataset size runs\nshap_values = explainer.shap_values(X_train_not_outlier)\n# init the JS visualization code\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0][0], features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# explain the the testing instances (can use fewer instanaces)\n# explaining each prediction requires 2 * background dataset size runs\nshap_values = explainer.shap_values(X_train_outlier[:1])\n# init the JS visualization code\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0][0], features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# explain the the testing instances (can use fewer instanaces)\n# explaining each prediction requires 2 * background dataset size runs\nshap_values = explainer.shap_values(X_train_not_outlier[:1])\n# init the JS visualization code\nshap.initjs()\nshap.force_plot(explainer.expected_value[0], shap_values[0][0], features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_not_outlier[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_outlier[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}