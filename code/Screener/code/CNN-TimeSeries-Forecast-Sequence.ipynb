{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0601ea-9997-4a44-852c-e62f88bb20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate multi-step stacked lstm example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Layer\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from sklearn.preprocessing import PowerTransformer\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5a0faa-01a9-4912-9565-19422ee2e1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('..\\\\data\\\\processed\\\\weekly_stocks_w_fred.csv').set_index('Unnamed: 0')\n",
    "data.index.names = ['Date']\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "69f741a5-83c9-4a64-942a-6b2be1d30941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VOX', 'VCR', 'VDC', 'VDE', 'VFH', 'VHT', 'VIS', 'VGT', 'VAW', 'VNQ',\n",
       "       'VPU', 'SPTM', 'SPY', 'SLY', 'MDYG', 'CONSUMER', 'WPUSI019011',\n",
       "       'WPU101', 'GVZCLS', 'UNRATE', 'VIXCLS', 'BUSLOANS', 'AWHAETP',\n",
       "       'UMCSENT', 'TDSP', 'DCOILWTICO', 'CPIAUCSL', 'CSUSHPINSA', 'FEDFUNDS',\n",
       "       'T10Y3M', 'USREC', 'USALOLITONOSTSAM', 'USPHCI', 'INDPRO', 'NEWORDER',\n",
       "       'PCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367879d6-ba4a-47cc-b4a4-d11dc54b1117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eacf910-197b-484e-a83d-12c312fc4b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 104, 2) (150, 13)\n",
      "Current Time = 22:14:30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "power = PowerTransformer(method='yeo-johnson')\n",
    " \n",
    "# Add attention layer to the deep learning network\n",
    "class attention(Layer):\n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "        super(attention,self).__init__()\n",
    " \n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
    "                               initializer='zeros', trainable=True)        \n",
    "        super(attention, self).build(input_shape)\n",
    " \n",
    "    def call(self,x):\n",
    "        # Alignment scores. Pass them through tanh function\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)   \n",
    "        # Compute the weights\n",
    "        alpha = K.softmax(e)\n",
    "        # Reshape to tensorFlow format\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context\n",
    "    \n",
    "def stable_sigmoid(x):\n",
    "    sig = np.where(x < 0, np.exp(x)/(1 + np.exp(x)), 1/(1 + np.exp(-x)))\n",
    "    return sig\n",
    "\n",
    "def inverse_sigmoid(x):\n",
    "    inv_sig = -np.log((1 / (x + 1e-8)) - 1)\n",
    "    return inv_sig\n",
    "    \n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, 0:2], sequences[end_ix-1:out_end_ix, 0][1:1+n_steps_out]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "     \n",
    "# define input sequence\n",
    "#in_seq1 = np.arange(0,200,10)\n",
    "#in_seq2 = np.arange(5,205,10)*100\n",
    "\n",
    "in_seq1 = data['SPY']\n",
    "in_seq2 = data['FEDFUNDS']\n",
    "in_seq3 = data['BUSLOANS']\n",
    "in_seq4 = data['INDPRO']\n",
    "in_seq5 = data['DCOILWTICO']\n",
    "\n",
    "\n",
    "in_seq = np.transpose((\n",
    "    in_seq1, \n",
    "    in_seq2, \n",
    "    in_seq3, \n",
    "    in_seq4,\n",
    "    in_seq5\n",
    "))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(in_seq)\n",
    "in_seq = scaler.transform(in_seq)\n",
    "in_seq = stable_sigmoid(in_seq)\n",
    "\n",
    "in_seq1 = in_seq[:,0]\n",
    "in_seq2 = in_seq[:,1]\n",
    "in_seq3 = in_seq[:,2]\n",
    "in_seq4 = in_seq[:,3]\n",
    "in_seq5 = in_seq[:,4]\n",
    "\n",
    "out_seq = np.sum([\n",
    "    in_seq1,\n",
    "    in_seq2, \n",
    "    in_seq3, \n",
    "    in_seq4,\n",
    "    in_seq5\n",
    "],axis=0)\n",
    "# convert to [rows, columns] structure\n",
    "\n",
    "#in_seqs = np.array()\n",
    "\n",
    "in_seq1 = in_seq1.reshape((len(in_seq1), 1))\n",
    "in_seq2 = in_seq2.reshape((len(in_seq2), 1))\n",
    "in_seq3 = in_seq3.reshape((len(in_seq3), 1))\n",
    "in_seq4 = in_seq3.reshape((len(in_seq4), 1))\n",
    "in_seq5 = in_seq3.reshape((len(in_seq5), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((\n",
    "    in_seq1,\n",
    "    in_seq2,\n",
    "    in_seq3,\n",
    "    in_seq4,\n",
    "    in_seq5,\n",
    "    out_seq))\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 52*2, 13\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "\n",
    "#x_train = preprocessing.scale(dataset, with_mean=True, with_std=True)\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "\n",
    "\"\"\"\n",
    "for i in range(len(X)):\n",
    "\tprint(X[i], y[i])\n",
    "\"\"\"\n",
    "\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, activation='tanh', return_sequences=True), input_shape=(n_steps_in, n_features)))\n",
    "model.add((LSTM(128, activation='tanh', return_sequences=True)))\n",
    "model.add((LSTM(128, activation='tanh', return_sequences=True)))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(attention(return_sequences=True)) #\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(n_steps_out))\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "# fit model\n",
    "model.fit(X[:-1], y[:-1], epochs=512, verbose=0,batch_size = 128)\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "# demonstrate prediction\n",
    "x_input = X[-1]\n",
    "x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "print(x_input)\n",
    "yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "current_time = now.strftime(\"%H:%M:%S\")\n",
    "print(\"Current Time =\", current_time)\n",
    "\n",
    "y_ = inverse_sigmoid(y[-1])*scaler.scale_[0]+scaler.mean_[0]\n",
    "yhat = inverse_sigmoid(yhat)*scaler.scale_[0]+scaler.mean_[0]\n",
    "print(y_)\n",
    "print(*yhat)\n",
    "plt.plot(y_)\n",
    "#plt.show()\n",
    "plt.plot(*yhat)\n",
    "plt.show()\n",
    "\n",
    "rmse = mean_squared_error(y_, *yhat, squared=True)\n",
    "print(\"RMSE:\",rmse,\"MAPE:\",MAPE(y_, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7b2edd24-da15-4e6b-b786-023904da0924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8fc5c4-caf6-4367-8fd5-f8e05551b705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "7bd57ec1-ff94-43b0-ada3-d5eb2127eb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51c5324-01f1-4317-a156-75bbef4f41d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eec6add-88a6-4646-bf2b-f61e7b46b535",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037172e0-4242-4a61-a131-52d26078af1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
