{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f7e7b-0679-4fd9-b03f-1e49583dadd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "class attention(Layer):\n",
    "    def __init__(self, return_sequences=True):\n",
    "        self.return_sequences = return_sequences\n",
    "\n",
    "        super(attention,self).__init__()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
    "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1), \n",
    "\n",
    "        super(attention,self).build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        a = K.softmax(e, axis=1)\n",
    "        output = x*a\n",
    "        if self.return_sequences:\n",
    "\n",
    "            return output\n",
    "        return K.sum(output, axis=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d3af21-d463-40e5-9afb-803f1388dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_t = subset_df_\n",
    "# multivariate multi-step stacked lstm example\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Attention\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    " \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "power = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "def stable_sigmoid(x):\n",
    "\n",
    "    sig = np.where(x < 0, np.exp(x)/(1 + np.exp(x)), 1/(1 + np.exp(-x)))\n",
    "    return sig\n",
    "\n",
    "def inverse_sigmoid(x):\n",
    "    inv_sig = -np.log((1 / (x + 1e-8)) - 1)\n",
    "    return inv_sig\n",
    "    \n",
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the dataset\n",
    "\t\tif out_end_ix > len(sequences):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, 0:2], sequences[end_ix-1:out_end_ix, 1][1:3]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    "     \n",
    "# define input sequence\n",
    "\"\"\"\n",
    "in_seq1 = np.array(df_t['ds'])#array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "in_seq2 = np.array(df_t['y'])#array([15, 25, 35, 45, 55, 65, 75, 85, 95])\n",
    "\"\"\"\n",
    "in_seq01 = np.array(df_t['ds'])\n",
    "in_seq02 = np.array(df_t['y'])\n",
    "in_seq03 = np.array(df_t['VAW'])\n",
    "in_seq04 = np.array(df_t['VOX'])\n",
    "in_seq05 = np.array(df_t['VCR'])\n",
    "in_seq06 = np.array(df_t['VDC'])\n",
    "in_seq07 = np.array(df_t['VDE'])\n",
    "in_seq08 = np.array(df_t['VFH'])\n",
    "in_seq09 = np.array(df_t['VHT'])\n",
    "in_seq10 = np.array(df_t['VIS'])\n",
    "in_seq11 = np.array(df_t['VNQ'])\n",
    "in_seq12 = np.array(df_t['VGT'])\n",
    "in_seq13 = np.array(df_t['VPU'])\n",
    "in_seq14 = np.array(df_t['DGS3MO'])\n",
    "in_seq15 = np.array(df_t['DGS2'])\n",
    "in_seq16 = np.array(df_t['DGS10'])\n",
    "\n",
    "out_seq = array([\n",
    "    in_seq1[i]+\n",
    "    in_seq2[i]\n",
    "    for i in range(len(in_seq1))])\n",
    "# convert to [rows, columns] structure\n",
    "in_seq01 = np.array(df_t['ds'])\n",
    "in_seq02 = np.array(df_t['y'])\n",
    "in_seq03 = np.array(df_t['VAW'])\n",
    "in_seq04 = np.array(df_t['VOX'])\n",
    "in_seq05 = np.array(df_t['VCR'])\n",
    "in_seq06 = np.array(df_t['VDC'])\n",
    "in_seq07 = np.array(df_t['VDE'])\n",
    "in_seq08 = np.array(df_t['VFH'])\n",
    "in_seq09 = np.array(df_t['VHT'])\n",
    "in_seq10 = np.array(df_t['VIS'])\n",
    "in_seq11 = np.array(df_t['VNQ'])\n",
    "in_seq12 = np.array(df_t['VGT'])\n",
    "in_seq13 = np.array(df_t['VPU'])\n",
    "in_seq14 = np.array(df_t['DGS3MO'])\n",
    "in_seq15 = np.array(df_t['DGS2'])\n",
    "in_seq16 = np.array(df_t['DGS10'])\n",
    "#in_seq17 = np.array(df_t['USALOLITONOSTSAM'])\n",
    "#in_seq18 = np.array(df_t['BUSLOANS'])\n",
    "#in_seq19 = np.array(df_t['CPIAUCSL'])\n",
    "#out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "out_seq = array([\n",
    "    in_seq01[i]+\n",
    "    in_seq02[i]+\n",
    "    in_seq03[i]+\n",
    "    in_seq04[i]+                 \n",
    "    in_seq05[i]+\n",
    "    in_seq06[i]+\n",
    "    in_seq07[i]+\n",
    "    in_seq08[i]+\n",
    "    in_seq09[i]+\n",
    "    in_seq10[i]+\n",
    "    in_seq11[i]+\n",
    "    in_seq12[i]+\n",
    "    in_seq13[i]+\n",
    "    in_seq14[i]+\n",
    "    in_seq15[i]+\n",
    "    in_seq16[i]\n",
    "#    in_seq17[i]+\n",
    "#    in_seq18[i]+\n",
    "#    in_seq19[i]\n",
    "    for i in range(len(in_seq01))])\n",
    "\n",
    "# horizontally stack columns\n",
    "#dataset = hstack((in_seq1, in_seq2, out_seq))\n",
    "# convert to [rows, columns] structure\n",
    "in_seq01 = in_seq01.reshape((len(in_seq01), 1))\n",
    "in_seq02 = in_seq02.reshape((len(in_seq02), 1))\n",
    "in_seq03 = in_seq03.reshape((len(in_seq03), 1))\n",
    "in_seq04 = in_seq04.reshape((len(in_seq04), 1))\n",
    "in_seq05 = in_seq05.reshape((len(in_seq05), 1))\n",
    "in_seq06 = in_seq06.reshape((len(in_seq06), 1))\n",
    "in_seq07 = in_seq07.reshape((len(in_seq07), 1))\n",
    "in_seq08 = in_seq08.reshape((len(in_seq08), 1))\n",
    "in_seq09 = in_seq09.reshape((len(in_seq09), 1))\n",
    "in_seq10 = in_seq10.reshape((len(in_seq10), 1))\n",
    "in_seq11 = in_seq11.reshape((len(in_seq11), 1))\n",
    "in_seq12 = in_seq12.reshape((len(in_seq12), 1))\n",
    "in_seq13 = in_seq13.reshape((len(in_seq13), 1))\n",
    "in_seq14 = in_seq13.reshape((len(in_seq14), 1))\n",
    "in_seq15 = in_seq13.reshape((len(in_seq15), 1))\n",
    "in_seq16 = in_seq13.reshape((len(in_seq16), 1))\n",
    "#in_seq17 = in_seq13.reshape((len(in_seq17), 1))\n",
    "#in_seq18 = in_seq13.reshape((len(in_seq18), 1))\n",
    "#in_seq19 = in_seq13.reshape((len(in_seq19), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((\n",
    "    in_seq01,\n",
    "    in_seq02,\n",
    "    in_seq03,\n",
    "    in_seq04,\n",
    "    in_seq05,\n",
    "    in_seq06,\n",
    "    in_seq07,\n",
    "    in_seq08,\n",
    "    in_seq09,\n",
    "    in_seq10,\n",
    "    in_seq11,\n",
    "    in_seq12,\n",
    "    in_seq13,\n",
    "    in_seq14,\n",
    "    in_seq15,\n",
    "    in_seq16,\n",
    "    #in_seq17,\n",
    "    #in_seq18,\n",
    "    #in_seq19,\n",
    "    out_seq))\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 52*2, 2\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "\n",
    "\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "\n",
    "#for i in range(len(X)):\n",
    "#\tprint(X[i], y[i])\n",
    "\n",
    "\n",
    "n_features = X.shape[2]\n",
    "# define model\n",
    "# Run inference on CPU\n",
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps_in, n_features))))\n",
    "    model.add(Attention(LSTM(100, activation='relu', return_sequences=True)))\n",
    "    #model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "    #model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "    model.add(LSTM(100, activation='relu'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=200, verbose=0)\n",
    "    # demonstrate prediction\n",
    "    #x_input = array([[70, 75], [80, 85], [90, 95]])\n",
    "    x_input = np.array(pd.DataFrame(X[-n_steps_in]))\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08f452-5110-4862-aa4a-3dccafb58fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "in_seq01 = np.array(df_t['ds'])\n",
    "in_seq02 = np.array(df_t['y'])\n",
    "in_seq03 = np.array(df_t['VAW'])\n",
    "in_seq04 = np.array(df_t['VOX'])\n",
    "in_seq05 = np.array(df_t['VCR'])\n",
    "in_seq06 = np.array(df_t['VDC'])\n",
    "in_seq07 = np.array(df_t['VDE'])\n",
    "in_seq08 = np.array(df_t['VFH'])\n",
    "in_seq09 = np.array(df_t['VHT'])\n",
    "in_seq10 = np.array(df_t['VIS'])\n",
    "in_seq11 = np.array(df_t['VNQ'])\n",
    "in_seq12 = np.array(df_t['VGT'])\n",
    "in_seq13 = np.array(df_t['VPU'])\n",
    "in_seq14 = np.array(df_t['DGS3MO'])\n",
    "in_seq15 = np.array(df_t['DGS2'])\n",
    "in_seq16 = np.array(df_t['DGS10'])\n",
    "#in_seq17 = np.array(df_t['USALOLITONOSTSAM'])\n",
    "#in_seq18 = np.array(df_t['BUSLOANS'])\n",
    "#in_seq19 = np.array(df_t['CPIAUCSL'])\n",
    "\n",
    "out_seq = array([\n",
    "    in_seq01[i]+\n",
    "    in_seq02[i]+\n",
    "    in_seq03[i]+\n",
    "    in_seq04[i]+                 \n",
    "    in_seq05[i]+\n",
    "    in_seq06[i]+\n",
    "    in_seq07[i]+\n",
    "    in_seq08[i]+\n",
    "    in_seq09[i]+\n",
    "    in_seq10[i]+\n",
    "    in_seq11[i]+\n",
    "    in_seq12[i]+\n",
    "    in_seq13[i]+\n",
    "    in_seq14[i]+\n",
    "    in_seq15[i]+\n",
    "    in_seq16[i]\n",
    "#    in_seq17[i]+\n",
    "#    in_seq18[i]+\n",
    "#    in_seq19[i]\n",
    "    for i in range(len(in_seq01))])\n",
    "\n",
    "# convert to [rows, columns] structure\n",
    "in_seq01 = in_seq01.reshape((len(in_seq01), 1))\n",
    "in_seq02 = in_seq02.reshape((len(in_seq02), 1))\n",
    "in_seq03 = in_seq03.reshape((len(in_seq03), 1))\n",
    "in_seq04 = in_seq04.reshape((len(in_seq04), 1))\n",
    "in_seq05 = in_seq05.reshape((len(in_seq05), 1))\n",
    "in_seq06 = in_seq06.reshape((len(in_seq06), 1))\n",
    "in_seq07 = in_seq07.reshape((len(in_seq07), 1))\n",
    "in_seq08 = in_seq08.reshape((len(in_seq08), 1))\n",
    "in_seq09 = in_seq09.reshape((len(in_seq09), 1))\n",
    "in_seq10 = in_seq10.reshape((len(in_seq10), 1))\n",
    "in_seq11 = in_seq11.reshape((len(in_seq11), 1))\n",
    "in_seq12 = in_seq12.reshape((len(in_seq12), 1))\n",
    "in_seq13 = in_seq13.reshape((len(in_seq13), 1))\n",
    "in_seq14 = in_seq13.reshape((len(in_seq14), 1))\n",
    "in_seq15 = in_seq13.reshape((len(in_seq15), 1))\n",
    "in_seq16 = in_seq13.reshape((len(in_seq16), 1))\n",
    "#in_seq17 = in_seq13.reshape((len(in_seq17), 1))\n",
    "#in_seq18 = in_seq13.reshape((len(in_seq18), 1))\n",
    "#in_seq19 = in_seq13.reshape((len(in_seq19), 1))\n",
    "out_seq = out_seq.reshape((len(out_seq), 1))\n",
    "# horizontally stack columns\n",
    "dataset = hstack((\n",
    "    in_seq01,\n",
    "    in_seq02,\n",
    "    in_seq03,\n",
    "    in_seq04,\n",
    "    in_seq05,\n",
    "    in_seq06,\n",
    "    in_seq07,\n",
    "    in_seq08,\n",
    "    in_seq09,\n",
    "    in_seq10,\n",
    "    in_seq11,\n",
    "    in_seq12,\n",
    "    in_seq13,\n",
    "    in_seq14,\n",
    "    in_seq15,\n",
    "    in_seq16,\n",
    "    #in_seq17,\n",
    "    #in_seq18,\n",
    "    #in_seq19,\n",
    "    out_seq))\n",
    "\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 52*2, 13\n",
    "# covert into input/output\n",
    "X, y = split_sequences(dataset, n_steps_in, n_steps_out)\n",
    "print(X.shape, y.shape)\n",
    "# summarize the data\n",
    "#for i in range(len(X)):\n",
    "\n",
    "#print(X[i], y[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417dcb46-7b7f-4562-9364-ddc4a427d7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Run inference on CPU\n",
    "with tf.device('/cpu:0'):\n",
    "    n_features = X.shape[2]\n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(model_size, activation='tanh', return_sequences=True, input_shape=(n_steps_in, n_features)))\n",
    "    model.add(LSTM(model_size, activation='tanh'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=1000, verbose=1)\n",
    "    \n",
    "    x_input = np.array(pd.DataFrame(X[-n_steps_in]))\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6bccf5-146e-444e-840d-db948897d4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "# univariate multi-step vector-output 1d cnn example\n",
    "from numpy import array\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "# split a univariate sequence into samples\n",
    "def split_sequence(sequence, n_steps_in, n_steps_out):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequence)):\n",
    "\t\t# find the end of this pattern\n",
    "\t\tend_ix = i + n_steps_in\n",
    "\t\tout_end_ix = end_ix + n_steps_out\n",
    "\t\t# check if we are beyond the sequence\n",
    "\t\tif out_end_ix > len(sequence):\n",
    "\t\t\tbreak\n",
    "\t\t# gather input and output parts of the pattern\n",
    "\t\tseq_x, seq_y = sequence[i:end_ix], sequence[end_ix:out_end_ix]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn array(X), array(y)\n",
    " \n",
    "# define input sequence\n",
    "raw_seq = [10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
    "# choose a number of time steps\n",
    "n_steps_in, n_steps_out = 3, 2\n",
    "# split into samples\n",
    "X, y = split_sequence(raw_seq, n_steps_in, n_steps_out)\n",
    "# reshape from [samples, timesteps] into [samples, timesteps, features]\n",
    "n_features = 1\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "# define model\n",
    "with tf.device(gpus[0]):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=2, activation='tanh', input_shape=(n_steps_in, n_features)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(50, activation='tanh'))\n",
    "    model.add(Dense(n_steps_out))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=2000, verbose=0)\n",
    "    # demonstrate prediction\n",
    "    x_input = array([70, 80, 90])\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "print(yhat)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4ecfbb-da74-4a2e-9799-c44b383ff21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the dataset knows the number of features, e.g. 2\n",
    "#m-m model\n",
    "n_features = X.shape[2]\n",
    "\n",
    "#vector output\n",
    "#n_features = 1\n",
    "\n",
    "model_size = int(n_features*n_steps_in*n_steps_out/50)\n",
    "# define model\n",
    "\n",
    "#client = Client('192.168.3.100:8786')\n",
    "\n",
    "with tf.device(gpus[0]):\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(model_size, activation='tanh', input_shape=(n_steps_in, n_features))))\n",
    "    model.add(RepeatVector(n_steps_out))\n",
    "    model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    #model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    #model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    #model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    #model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))\n",
    "    \"\"\"\n",
    "    model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))    \n",
    "    model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))    \n",
    "    model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))    \n",
    "    model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))    \n",
    "    model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))    \n",
    "    model.add(LSTM(model_size, activation='tanh', return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(n_features)))   \n",
    "    \"\"\"\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    # fit model\n",
    "    model.fit(X, y, epochs=10, verbose=1,batch_size = 128)\n",
    "    # demonstrate prediction\n",
    "    x_input = np.array(pd.DataFrame(X[-n_steps_in]))\n",
    "    x_input = x_input.reshape((1, n_steps_in, n_features))\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "#client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b183d-2f6c-4646-a167-ed452c3ed4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(power.inverse_transform(inverse_sigmoid(X[-90][-1][:-1].reshape(1, -1))))\n",
    "pd.DataFrame(power.inverse_transform(inverse_sigmoid(y[-90][-1][:-1].reshape(1, -1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2e974-9972-4ede-a31f-66f192bf5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts = pd.DataFrame()\n",
    "for i in range(0,len(yhat[0])):\n",
    "    #print(i)\n",
    "    forecasts = pd.concat([forecasts,pd.DataFrame(power.inverse_transform(np.array(inverse_sigmoid(yhat[0][i][:-1].reshape(1, -1)))),columns=df_t.columns)],axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9509606-8e96-4bc4-94d9-09f8d704dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts.index=range(0,len(forecasts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9d1eb-066a-42cc-a07f-55cc43b4c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(forecasts['VPU'])\n",
    "#fig, ax1 = plt.subplots( figsize=(30,4) )\n",
    "#ax2 = ax1.twinx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1876dc17-6067-482a-b37b-81ddef2d2b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = np.sum(abs(np.array(df_.iloc[-1][1:n_features])-yhat[0][-1][1:]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
