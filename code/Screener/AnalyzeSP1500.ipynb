{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9d05a-a1d5-4f4c-a68f-884d49aeb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ade43c-b6c3-4b09-8331-8cfeea94eeef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from matplotlib.dates import DateFormatter\n",
    "from pandas.io.formats.style import Styler\n",
    "from pivottablejs import pivot_ui\n",
    "from pmdarima.arima import auto_arima\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib as mp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "import pickle\n",
    "import rpy2\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "import pandas as pd\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccb3eb-f028-43da-aa35-2afd62c7fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "si = ['03-31','06-30','09-30','12-31']\n",
    "\n",
    "               \n",
    "[start,end,prices_df, sp1500_index_df, sp500, sp600, sp400, market_data, completed_fred_pvt, completed_bonds, completed_bonds_pvt, sectors, indexes, screener_sorted, dict_sectors, dict_indexes, dict_sectors_reverse, invert_dict_indexes, list_sector_n_indexes, list_stocks] = pickle.load(open('./data_object.pkl', 'rb'))\n",
    "\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "nyse_dates = nyse.schedule(start_date=start, end_date=end)\n",
    "\n",
    "fundamentals_quarterlies = pickle.load(open('./fundamental.pkl', 'rb'))\n",
    "fundamental_entries = [e[0] for e in fundamentals_quarterlies]\n",
    "\n",
    "sectors.columns = ['Symbol']\n",
    "indexes.columns = ['Symbol']\n",
    "\n",
    "newDates = pd.date_range((end+ dt.timedelta(7)).strftime('%Y-%m-%d'), (end + dt.timedelta(92)).strftime('%Y-%m-%d'), freq='W-'+nyse_dates.index[-1].strftime('%a')).map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "db_is_new = not os.path.exists(db_filename)\n",
    "\n",
    "conn = sqlite3.connect(db_filename)\n",
    "\n",
    "if db_is_new:\n",
    "    print('Need to create schema')\n",
    "else:\n",
    "    print('Database exists, assume schema does, too.')\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d68f4-e6ea-41dd-8b87-4fd29cb22e5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed1442-0c89-43a1-ab60-ba829fa4b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ets(npa_):\n",
    "    train,test,model_func,flag_ = npa_\n",
    "    \n",
    "    #try:\n",
    "    if(len(flag_)==2):\n",
    "        if(flag_[1] is None):\n",
    "            model = model_func(np.log(train['Adj Close']),initialization_method='heuristic',seasonal=flag_[0],trend=flag_[1],dates=train.index).fit()\n",
    "        else:\n",
    "            model = model_func(np.log(train['Adj Close']),initialization_method='heuristic',seasonal=flag_[0],seasonal_periods=52,trend=flag_[1],dates=train.index).fit()\n",
    "    else:\n",
    "        model = model_func(np.log(train['Adj Close']),initialization_method='heuristic',seasonal=flag_[0],seasonal_periods=52,trend=flag_[1],damped_trend=flag_[2],dates=train.index).fit()\n",
    "\n",
    "    fc_ets_ = np.exp(model.get_prediction(start=test.index[0],end=test.index[-1]).summary_frame())\n",
    "    rmse_ = mean_squared_error(test, fc_ets_['mean'], squared=True)\n",
    "    #except:\n",
    "        #not enough data points\n",
    "        #rmse_ = np.nan\n",
    "    \n",
    "    return([flag_,rmse_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4c743-7f04-4405-b0a4-a20d02cd34b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_to_int(dateobj):\n",
    "    total = int(dateobj.strftime('%S'))\n",
    "    total += int(dateobj.strftime('%M')) * 60\n",
    "    total += int(dateobj.strftime('%H')) * 60 * 60\n",
    "    total += (int(dateobj.strftime('%j')) - 1) * 60 * 60 * 24\n",
    "    total += (int(dateobj.strftime('%Y')) - 1970) * 60 * 60 * 24 * 365\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca18dd-3ef1-4b3d-ae25-688131622be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_cells(val, color_if_true, color_if_false, threshold_):\n",
    "    color = color_if_true if val >= threshold_ else color_if_false\n",
    "    return 'background-color: {}'.format(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f6257-2b54-4172-8252-2c6eee439a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb030bec-71c2-4dd3-81d1-ad2940757efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c87150e-a5e6-4376-9397-22c65f9570cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0d8bb4-25d2-4ef0-98ed-72f199fc2fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5889342-865c-4c68-a1cd-b0e91458a5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e90d4d-2731-424b-b178-021e714319d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83086d3b-42bb-490f-8003-88abe4351669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fa925-e207-4e18-b9e7-8c995c38068d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e93ff1-1957-4260-b7f6-a013c5cfb763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7dc96-9214-40de-be05-b8ddb0fa4180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prophet(npa_):\n",
    "    train,test = npa_\n",
    "\n",
    "    m = Prophet()\n",
    "\n",
    "    temp_train = train.reset_index()\n",
    "    temp_train.iloc[:,1] = np.log(temp_train.iloc[:,1])\n",
    "    temp_train.columns = ['ds','y']\n",
    "\n",
    "    m.fit(temp_train)\n",
    "    future = m.make_future_dataframe(periods=14,freq='W-'+nyse_dates.index[-1].strftime('%a'))\n",
    "\n",
    "    forecast = m.predict(future.tail(13))\n",
    "    #forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "    rmse_ = mean_squared_error(test, np.exp(forecast[['yhat']]).tail(13), squared=True)\n",
    "    #print(rmse_)\n",
    "    return(rmse_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0ec9a-37de-43c4-b752-fac1dc2fd683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3b7f37b-05c3-4c51-a2e3-e7c1e24f0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "\n",
    "#decision_metrics = []\n",
    "\n",
    "def plot_(symbol_):\n",
    "    #symbol_ = 'AAL'\n",
    "    print(symbol_)\n",
    "    print(type(symbol_))\n",
    "    print(str(symbol_))\n",
    "    if(str(symbol_)=='None'):\n",
    "        run=False\n",
    "    else:\n",
    "        run=True\n",
    "\n",
    "    if(run):\n",
    "        client = Client('192.168.3.100:8786')\n",
    "        #client = Client(n_workers=4,threads_per_worker=1)\n",
    "\n",
    "        s = symbol_\n",
    "        #for s in ['CEIX']:\n",
    "        msize = 2\n",
    "        date_form = DateFormatter(\"%Y-%m-%d\")\n",
    "\n",
    "        metrics_df_ = pd.DataFrame(pd.DataFrame(screener_sorted.loc[s]).T[['volume_factor','Adj Close','adf','hurst']])\n",
    "\n",
    "        subset=prices_df[prices_df['Symbol']==s]\n",
    "\n",
    "        dates = []\n",
    "        for t in subset.index.values:\n",
    "            d = pd.Timestamp(t).strftime('%Y-%m-%d')\n",
    "            dates.append(d)\n",
    "            dto = datetime.strptime(d, '%Y-%m-%d').date()\n",
    "\n",
    "        old_ordinal = [datetime.strptime(i, '%Y-%m-%d').toordinal() for i in dates]\n",
    "        new_ordinal = old_ordinal + md.date2num(np.datetime64('0000-12-31'))\n",
    "        x = new_ordinal    \n",
    "\n",
    "        lookup_index_ = []\n",
    "\n",
    "        labels = list()\n",
    "        print(\"symbol:\",s)   \n",
    "\n",
    "        symbol_sector = screener_sorted.loc[symbol_]['Sector Symbol']\n",
    "        \"\"\"\n",
    "        try:\n",
    "            symbol_sector = dict_sectors[sector_merged[sector_merged['Symbol']==s]['Sector'].values[0]]\n",
    "            symbol_sector = screener_sorted.loc[symbol_]['Sector']\n",
    "            print(\"sector:\",dict_sectors_reverse[symbol_sector])\n",
    "        except:\n",
    "            symbol_sector=='error'\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        if(symbol_sector=='error'):\n",
    "            if(np.sum([sectors['Symbol'].values==s])):\n",
    "                symbol_sector = s\n",
    "                print(\"sector:\",dict_sectors_reverse[symbol_sector])\n",
    "        #else:\n",
    "            symbol_sector = 'error'\n",
    "            print(\"sector:\",'error')\n",
    "        \"\"\"\n",
    "        print(\"sector:\",dict_sectors_reverse[symbol_sector])\n",
    "        symbol_index = screener_sorted.loc[s]['Index Symbol']\n",
    "\n",
    "        try:\n",
    "            matched_index_name = indexes.iloc[np.where(indexes['Symbol'].values==s)].index[0]\n",
    "        except:\n",
    "            try:\n",
    "                matched_index_name = screener_sorted.loc[s]['Index Symbol']\n",
    "            except:\n",
    "                matched_index_name = \"none\"\n",
    "\n",
    "        print(\"Index:\",matched_index_name)\n",
    "\n",
    "        print(\"Volume Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==s)]['volume_factor'][0])\n",
    "        #print(\"1YMF:\",subset['1YMF'].values[-1])\n",
    "        print(\"sector_risk_trend_factor:\",screener_sorted[screener_sorted.index==s]['sector_risk_trend_factor'][0])\n",
    "        print(\"risk trend factor:\",screener_sorted.iloc[np.where(screener_sorted.index==s)]['risk_trend_factor'][0])\n",
    "\n",
    "        temp = pd.DataFrame(market_data.loc[s])\n",
    "        print(temp[np.array(temp!='error')].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().T)\n",
    "\n",
    "        last_date = pd.DataFrame(subset.iloc[-1][['21dBOLD','21dMA-TP','21dBOLU']],index=[prices_df[prices_df['Symbol']==s].index[-1].strftime('%Y-%m-%d')]).index[0]\n",
    "\n",
    "        bbands = pd.DataFrame(subset.iloc[-1][['Adj Close','21dBOLD','21dMA-TP','21dBOLU','90dSMA','90dSDev']]).T\n",
    "        bbands['90d_lower'] = bbands['90dSMA']-bbands['90dSDev']*2\n",
    "        bbands['90d_upper'] = bbands['90dSMA']+bbands['90dSDev']*2\n",
    "\n",
    "        bbands.index = [last_date]\n",
    "        display(bbands)\n",
    "\n",
    "        display(metrics_df_)\n",
    "\n",
    "        mean_revert_flag = False\n",
    "\n",
    "        if(metrics_df_['adf'][0]<.05):\n",
    "            print(\"ADFuller H0 rejected @ .05, Mean Reverting TS\")\n",
    "            if(bbands['Adj Close'][0]<bbands['90d_lower'][0]):\n",
    "                colored_text = colored(255, 0, 0, \"Quarter Mean Reverting buy signal\")\n",
    "                print(colored_text)\n",
    "                mean_revert_flag = True\n",
    "            if(bbands['Adj Close'][0]<bbands['21dBOLU'][0]):\n",
    "                colored_text = colored(255, 0, 0, \"Month Mean Reverting buy signal\")\n",
    "                print(colored_text)\n",
    "                mean_revert_flag = True    \n",
    "\n",
    "        l_axis_legend = pd.DataFrame(['symbol', 'trailing_1yr_max', 'trailing_1yr_min', '30d_vol_2yr','risk_trend_factor/linear','supply_trend_1yr'],index=['blue','green','red','orange','black','yellow'],columns=['legend'])\n",
    "\n",
    "        r_axis_legend = pd.DataFrame(['sector','index'],index=['magenta','cyan'],columns=['legend'])\n",
    "\n",
    "        display_side_by_side([l_axis_legend, r_axis_legend], ['l axis', 'r axis'])        \n",
    "\n",
    "        f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, sharey=False,figsize=(22,5))\n",
    "        ax1.plot(subset['30d_vol_2yr'],color='orange')\n",
    "        #plt.title('30d_vol_2yr')\n",
    "        ax1.set_xticklabels(subset[['30d_vol_2yr']].dropna().index, rotation = 45)\n",
    "\n",
    "        locator = matplotlib.dates.AutoDateLocator()\n",
    "        formatter = matplotlib.dates.ConciseDateFormatter(locator)\n",
    "\n",
    "        ax1.xaxis.set_major_locator(locator)\n",
    "        ax1.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "        ax1.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "        #plt.title('30d_vol_2yr')\n",
    "        ax2.plot(subset['risk_trend_factor'],color='black')\n",
    "        #plt.title('risk_trend_factor')\n",
    "        ax2.set_xticklabels(subset[['risk_trend_factor']].dropna().index, rotation = 45)\n",
    "\n",
    "        locator = matplotlib.dates.AutoDateLocator()\n",
    "        formatter = matplotlib.dates.ConciseDateFormatter(locator)\n",
    "\n",
    "        ax2.xaxis.set_major_locator(locator)\n",
    "        ax2.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "        ax2.xaxis.set_major_formatter(date_form)\n",
    "        #plt.title('risk_trend_factor')\n",
    "\n",
    "        #fig, ax1 = plt.subplots()   \n",
    "\n",
    "        ax3_ = ax3.twinx()\n",
    "        ax5_ = ax5.twinx()        \n",
    "        ax4_ = ax4.twinx()\n",
    "\n",
    "        y = subset['Adj Close']\n",
    "\n",
    "        def myfunc(x):\n",
    "            return slope * x + intercept\n",
    "\n",
    "        slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "        mymodel = list(map(myfunc, x))\n",
    "\n",
    "        ax3.plot(x, y,marker = '.',markersize=msize, color = 'b')\n",
    "        ax3.plot(x, subset['trailing_1yr_max'],marker = '.',markersize=msize, color = 'g')\n",
    "        ax3.plot(x, subset['trailing_1yr_min'],marker = '.',markersize=msize, color = 'r')\n",
    "        #ax1.plot(x, subset['risk_trend_factor'],marker = '.',markersize=msize, color = 'orange')\n",
    "\n",
    "        ax3_.plot(x, subset['supply_trend_1yr'],marker = '.',markersize=msize, color = 'y')\n",
    "\n",
    "        ax3.plot(x, mymodel, color = 'k')\n",
    "        \"\"\"\n",
    "        try:\n",
    "            ax5.plot(x, y,marker = '.',markersize=msize, color = 'b')\n",
    "            ax5.plot(x, subset['trailing_1yr_max'],marker = '.',markersize=msize, color = 'g')\n",
    "            ax5.plot(x, subset['trailing_1yr_min'],marker = '.',markersize=msize, color = 'r')\n",
    "            #ax1.plot(x, subset['risk_trend_factor'],marker = '.',markersize=msize, color = 'orange')\n",
    "\n",
    "            ax5_.plot(x, subset['supply_trend_1yr'],marker = '.',markersize=msize, color = 'y')\n",
    "\n",
    "            ax5.plot(x, mymodel, color = 'k')\n",
    "        except:\n",
    "            pass\n",
    "        \"\"\"\n",
    "        #for l in ['symbol','1yrMax','1yrMin','risk_trend_factor','supply_trend_1yr','linear']:\n",
    "            #labels.append(l)\n",
    "\n",
    "        l = matplotlib.dates.AutoDateLocator()\n",
    "        f = matplotlib.dates.ConciseDateFormatter(l)    \n",
    "\n",
    "        ax3.set_xticklabels(ax3.get_xticks(), rotation = 45)\n",
    "\n",
    "        locator = matplotlib.dates.AutoDateLocator()\n",
    "        formatter = matplotlib.dates.ConciseDateFormatter(locator)\n",
    "\n",
    "        ax3.xaxis.set_major_locator(locator)\n",
    "        ax3.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "        ax3.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "        if(symbol_sector=='error'):\n",
    "            pass\n",
    "        else:\n",
    "            if(np.sum(sectors['Symbol'].values==s)>0):\n",
    "                pass\n",
    "            else:\n",
    "                sector_subset = prices_df[prices_df['Symbol']==symbol_sector]\n",
    "                #print(\"sector\",)\n",
    "                #print(\"else_sector:\",dict_sectors_reverse[s])            \n",
    "                #print(\"Sector 1YMF:\",screener_sorted[screener_sorted.index==symbol_sector]['risk_trend_factor'][0])\n",
    "                print(\"Sector Volume Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==symbol_sector)]['volume_factor'][0])\n",
    "                print(\"Sector Risk Trend Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==symbol_sector)]['risk_trend_factor'][0])\n",
    "                #ax3_.plot(x, (sector_subset['Adj Close']).iloc[-len(subset):],marker = '.',markersize=msize,color='m',linestyle=(0, (3, 10, 1, 10)))\n",
    "                ax4.plot(x, (sector_subset['Adj Close']).iloc[-len(subset):],marker = '.',markersize=msize,color='m',linestyle=(0, (3, 10, 1, 10)))\n",
    "                ax4.plot(x, (sector_subset['trailing_1yr_max']).iloc[-len(subset):],marker = '.',markersize=msize, color = 'g')\n",
    "                ax4.plot(x, (sector_subset['trailing_1yr_min']).iloc[-len(subset):],marker = '.',markersize=msize, color = 'r')\n",
    "                ax4_.plot(x, (sector_subset['supply_trend_1yr']).iloc[-len(subset):],marker = '.',markersize=msize,color='y',linestyle=(0, (3, 10, 1, 10)))\n",
    "\n",
    "                ax4.set_xticklabels(subset.dropna().index, rotation = 45)\n",
    "                ax4.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "                #ax2.plot(x, prices_df[prices_df['Symbol']==symbol_sector]['Adj Close'],marker = '.',markersize=msize,color='m',linestyle=(0, (3, 10, 1, 10)))        \n",
    "                #plt.legend([screener_sorted.loc[s]['Sector']])\n",
    "                #labels_ax2.append(screener_sorted.loc[s]['Sector'])\n",
    "                #plt.show()\n",
    "\n",
    "        if(str(screener_sorted.loc[s]['Index Symbol'])!='nan'):\n",
    "            if(screener_sorted.loc[s]['Index Symbol']!='error'):\n",
    "                index_subset = prices_df[prices_df['Symbol']==screener_sorted.loc[s]['Index Symbol']]\n",
    "                #print(screener_sorted.loc[s]['Index Symbol'])\n",
    "                #print(\"Index 1YMF:\",screener_sorted[screener_sorted.index==screener_sorted.loc[s]['Index Symbol']]['risk_trend_factor'][0])\n",
    "                print(\"Index Volume Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==screener_sorted.loc[s]['Index Symbol'])]['volume_factor'][0])\n",
    "                print(\"Index Risk Trend Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==screener_sorted.loc[s]['Index Symbol'])]['risk_trend_factor'][0])\n",
    "                #ax3_.plot(x, index_subset['Adj Close'].iloc[-len(subset):],marker = '.',markersize=msize,color='c',linestyle=(0, (1, 10)))\n",
    "                ax5.plot(x, index_subset['Adj Close'].iloc[-len(subset):],marker = '.',markersize=msize,color='c',linestyle=(0, (1, 10)))\n",
    "                ax5.plot(x, index_subset['trailing_1yr_max'].iloc[-len(subset):],marker = '.',markersize=msize, color = 'g')\n",
    "                ax5.plot(x, index_subset['trailing_1yr_min'].iloc[-len(subset):],marker = '.',markersize=msize, color = 'r')\n",
    "                ax5_.plot(x, index_subset['supply_trend_1yr'].iloc[-len(subset):],marker = '.',markersize=msize,color='y',linestyle=(0, (1, 10)))\n",
    "\n",
    "                ax5.set_xticklabels(index_subset.dropna().index, rotation = 45)\n",
    "                ax5.xaxis.set_major_formatter(date_form)\n",
    "                #plt.plot()\n",
    "                #plt.legend([screener_sorted.loc[s]['index']])\n",
    "                #labels_ax2.append(screener_sorted.loc[s]['index'])\n",
    "                #plt.show()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"ets next 13 weeks\")\n",
    "\n",
    "        #ets\n",
    "        if(True):\n",
    "\n",
    "            #take last nyse date and extrapolate weeks from that point\n",
    "            #starting from next week\n",
    "            newDates = pd.date_range((subset.index[-1] + dt.timedelta(7)).strftime('%Y-%m-%d'), (subset.index[-1] + dt.timedelta(92)).strftime('%Y-%m-%d'), freq='W-'+nyse_dates.index[-1].strftime('%a')).map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "\n",
    "            print(subset.index[-1].strftime('%Y-%m-%d'))\n",
    "            print(newDates[0])\n",
    "            #data = subset[['Adj Close']].asfreq('D').interpolate().asfreq('W-'+subset.index[-1].strftime('%a'))\n",
    "            data = subset[['Adj Close']].asfreq('D').interpolate().asfreq('W-'+nyse_dates.index[-1].strftime('%a'))            \n",
    "\n",
    "            #if(np.where(np.array(list__)==s)[0][0]%batchClearLimit==0):        \n",
    "            #client.restart()\n",
    "\n",
    "            cv_inner = TimeSeriesSplit(n_splits=11,test_size=13)\n",
    "\n",
    "            #has to be different makeup than cv_inner because there is no randomization.  Recommend a number that isn't a divisor of cv_inner's n_splits to ensure training is mixed up and not aligned\n",
    "            cv_outer = TimeSeriesSplit(n_splits=10,test_size=13)\n",
    "\n",
    "            outer_results = []\n",
    "\n",
    "            #sm.tsa.statespace.ExponentialSmoothing\n",
    "            \"\"\"\n",
    "            flags = []\n",
    "            seasonal_flags1 = ['add','mul',None]\n",
    "\n",
    "            trend_flags2 = ['add','mul',None]\n",
    "\n",
    "            damped__trend_flags3 = [True,False]\n",
    "\n",
    "            for sf in seasonal_flags1:\n",
    "                for dt_ in trend_flags2:\n",
    "                    if(dt_ is None):          \n",
    "                        for d_ in damped__trend_flags3:\n",
    "                            flags.append([sf,dt_,d_])\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            flags = [['add', 'add', True],\\\n",
    "             ['add', 'add', False],\\\n",
    "             ['add', 'mul', True],\\\n",
    "             ['add', 'mul', False],\\\n",
    "             ['add', None],\\\n",
    "             ['mul', 'add', True],\\\n",
    "             ['mul', 'add', False],\\\n",
    "             ['mul', 'mul', True],\\\n",
    "             ['mul', 'mul', False],\\\n",
    "             ['mul', None],\\\n",
    "             [None, 'add', True],\\\n",
    "             [None, 'add', False],\\\n",
    "             [None, 'mul', True],\\\n",
    "             [None, 'mul', False],\\\n",
    "             [None, None]]\n",
    "\n",
    "            #print(flags)\n",
    "\n",
    "            #flags = [['T','T'],['T','F'],['F','F'],['F','T']]       \n",
    "\n",
    "            rmse_inner_flags = []\n",
    "\n",
    "            for flag in flags:\n",
    "                #print(flag)\n",
    "\n",
    "                npa = []\n",
    "\n",
    "                for trainv_ix, test_ix in cv_inner.split(data.index):\n",
    "\n",
    "                    npa.append([data.iloc[trainv_ix],data.iloc[test_ix],ETSModel,flag])\n",
    "\n",
    "                #rmses_inner = []\n",
    "                #rmses_inner\n",
    "                #for n in npa:\n",
    "                    #r = evaluate_ets(n)\n",
    "                    #print(r)\n",
    "                    #rmses_inner.append(r)\n",
    "                future = client.map(evaluate_ets, npa)        \n",
    "\n",
    "                rmses_inner = []\n",
    "                #flag_order = []\n",
    "                #my intent was to capture future objects vs results and this gave me results\n",
    "\n",
    "                for f in as_completed(future):\n",
    "                    #exclude errors\n",
    "                    if(f.status==\"error\"):\n",
    "                        #pass\n",
    "                        #this causes errors with [flag,rmse] being passed by evaluate_ets\n",
    "                        rmses_inner.append([flag,np.nan])\n",
    "                    else:\n",
    "                        rmses_inner.append(f.result())\n",
    "\n",
    "                #I don't want to keep track of flag here\n",
    "                #flag_order = [r[0] for r in results_rmses].copy()\n",
    "                #print(rmses_inner)\n",
    "                rmse_ = [r[1] for r in rmses_inner].copy()\n",
    "\n",
    "\n",
    "                #print(rmse_)\n",
    "                #print(flag)\n",
    "                rmse_inner_flags.append([flag,np.nanmean(rmse_),np.nanstd(rmse_)])\n",
    "\n",
    "            #rmse_scores = []\n",
    "            #flag_rmses = []\n",
    "\n",
    "            #for fn_ in range(0,len(flags)):\n",
    "                #flag_ = flags[fn_]\n",
    "                #rmse_scores.append([flag_rmses[fn_],rmses[fn_][1]])\n",
    "\n",
    "            print(\"inner cv scores:\")\n",
    "            inner_rmse_df = pd.DataFrame(rmse_inner_flags,columns=['flags','mean','std'])\n",
    "            #print(\"inner cv scores:\",[r[rmses)\n",
    "            #print(\"inner cv sdevs:\",sdevs)\n",
    "\n",
    "            scores = inner_rmse_df['mean'].values\n",
    "            sdevs = inner_rmse_df['std'].values\n",
    "            best_model = inner_rmse_df['flags'].values[np.argmin(scores)]\n",
    "\n",
    "            print(\"best model:\",best_model)\n",
    "            print(\"best inner cv score, sdev (11 folds):\",scores[np.argmin(scores)],sdevs[np.argmin(scores)])\n",
    "\n",
    "            npa = []\n",
    "\n",
    "            for trainv_ix, test_ix in cv_outer.split(data.index):\n",
    "\n",
    "                npa.append([data.iloc[trainv_ix],data.iloc[test_ix],ETSModel,best_model])\n",
    "\n",
    "            future = client.map(evaluate_ets, npa)\n",
    "            results_rmses_outer = []\n",
    "\n",
    "            #my intent was to capture future objects vs results and this gave me results\n",
    "            for f in as_completed(future):\n",
    "                #exclude errors\n",
    "                if(f.status==\"error\"):\n",
    "                    #pass\n",
    "                    results_rmses_outer.append([np.nan])\n",
    "                else:\n",
    "                    results_rmses_outer.append(f.result()) \n",
    "\n",
    "            test_score_mean = np.nanmean([r[1] for r in results_rmses_outer])\n",
    "            test_score_std = np.nanstd([r[1] for r in results_rmses_outer])\n",
    "\n",
    "            #test_score = [np.nanmean(rmse_outer_df['mean'].values),np.nanstd(rmse_outer_df['mean'].values)]\n",
    "            print(\"test cv mean error, stdev (10 folds):\",test_score_mean,test_score_std)\n",
    "\n",
    "            #final_model=ETSModel(np.log(data),initialization_method='heuristic',seasonal=52,trend=F1,damped_trend=F2).fit()    \n",
    "\n",
    "\n",
    "            #final_model=ETSModel(np.log(data),initialization_method='heuristic',seasonal=52,trend=F1,damped_trend=F2).fit()    \n",
    "            flag = best_model\n",
    "            if(len(flag)==2):\n",
    "                if(flag[1] is None):\n",
    "                    final_model = ETSModel(np.log(data['Adj Close']),initialization_method='heuristic',seasonal=flag[0],trend=flag[1],dates=data.index).fit()\n",
    "                else:\n",
    "                    final_model = ETSModel(np.log(data['Adj Close']),initialization_method='heuristic',seasonal=flag[0],seasonal_periods=52,trend=flag[1],dates=data.index).fit()\n",
    "            else:\n",
    "                final_model = ETSModel(np.log(data['Adj Close']),initialization_method='heuristic',seasonal=flag[0],seasonal_periods=52,trend=flag[1],damped_trend=flag[2],dates=data.index).fit()\n",
    "\n",
    "            try:\n",
    "\n",
    "                df_pred = np.exp(final_model.get_prediction(start=data.index[0].strftime('%Y-%m-%d'),end=(end + dt.timedelta(92)).strftime('%Y-%m-%d')).summary_frame())\n",
    "\n",
    "            except:\n",
    "                test = pd.DataFrame(final_model.get_prediction(start=data.index[0].strftime('%Y-%m-%d'),end=(end + dt.timedelta(92)).strftime('%Y-%m-%d')).predicted_mean)\n",
    "                test.columns = ['mean']\n",
    "                df_pred = test\n",
    "\n",
    "            #df_conf = np.exp(final_model.get_prediction(start=end,end=(end + dt.timedelta(92)).strftime('%Y-%m-%d')).pred_int(alpha = .05))\n",
    "            #df_conf.columns = ['ci_lower','ci_upper']\n",
    "\n",
    "            #final_model = ETSModel(np.log(data['Adj Close']),initialization_method='heuristic',seasonal=['add','mul','None'][0],seasonal_periods=52,trend=['add','mul','None'][0],damped_trend=['True','False'][0],dates=data.index).fit()\n",
    "            #pred = final_model.get_prediction(start=end,end=(end + dt.timedelta(92)).strftime('%Y-%m-%d'))\n",
    "\n",
    "            #final_model.get_prediction(start=end,end=(end + dt.timedelta(92)).strftime('%Y-%m-%d')).summary_frame()\n",
    "\n",
    "            #df_pred = np.exp(pred.summary_frame(alpha=0.05))\n",
    "            #df_pred = np.exp(pred.summary(alpha=0.05))\n",
    "            s_date = df_pred.index[np.argmax(df_pred['mean'].values)].strftime('%Y-%m-%d')\n",
    "\n",
    "            print(\"sell date:\",s_date)\n",
    "            e_return = np.array((np.max(df_pred['mean'].values)-metrics_df_['Adj Close'])/metrics_df_['Adj Close'])[0]\n",
    "            p_metrics = pd.DataFrame(df_pred.iloc[np.argmax(df_pred['mean'].values)]).T\n",
    "            #c_metrics = pd.DataFrame(df_conf.iloc[np.argmax(df_pred['mean'].values)]).T\n",
    "            #print(c_metrics)\n",
    "            print(\"expected return:\",e_return)\n",
    "\n",
    "            days_delta = (datetime.strptime(s_date, '%Y-%m-%d') - datetime.strptime(end.strftime('%Y-%m-%d'), '%Y-%m-%d')).days\n",
    "            discounted_return = (1+e_return)**(1/days_delta)-1\n",
    "            qtr_return = (1+discounted_return)**92\n",
    "\n",
    "            print(\"discounted return:\",discounted_return)\n",
    "\n",
    "            print(\"quarter return:\",qtr_return)\n",
    "\n",
    "            try:\n",
    "                #used to help filter at the end, not sdevs is chosen based on min score\n",
    "                stop_loss_price = pd.DataFrame(np.mean(np.exp(final_model.get_prediction(start=end,end=(end + dt.timedelta(92)).strftime('%Y-%m-%d')).summary_frame())[['mean','pi_lower']],axis=1)).iloc[0].values[0]\n",
    "                #decision_metrics.append([s,e_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['pi_lower'].values[0],p_metrics['pi_upper'].values[0]])\n",
    "                decision_metrics_df = pd.DataFrame([s,e_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['pi_lower'].values[0],p_metrics['pi_upper'].values[0]])#,columns=)#,index=[s_])#.sort_values(by='disc_rtn',ascending=False,inplace=True)\n",
    "                decision_metrics_df = decision_metrics_df.T\n",
    "                decision_metrics_df.columns=['SYMBOL','exp_return','sell_date','stop_loss_price','days_delta','disc_rtn','qtr_rtn','outer_cv_avg_rmse_n11','outer_cv_std_n11','mean_revert_flag','pi_lower','pi_upper']\n",
    "                decision_metrics_df.index = [symbol_]\n",
    "            except:\n",
    "                #used to help filter at the end, not sdevs is chosen based on min score\n",
    "                stop_loss_price = df_pred[['mean']].iloc[0].values[0]\n",
    "                #decision_metrics.append([s,e_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['pi_lower'].values[0],p_metrics['pi_upper'].values[0]])\n",
    "                decision_metrics_df = pd.DataFrame([s,e_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag])#,columns=)#,index=[s_])#.sort_values(by='disc_rtn',ascending=False,inplace=True)\n",
    "                decision_metrics_df = decision_metrics_df.T\n",
    "                decision_metrics_df.columns=['SYMBOL','exp_return','sell_date','stop_loss_price','days_delta','disc_rtn','qtr_rtn','outer_cv_avg_rmse_n11','outer_cv_std_n11','mean_revert_flag']\n",
    "                decision_metrics_df.index = [symbol_]\n",
    "\n",
    "\n",
    "            print(\"Price / Outer CV Error Ratio:\",screener_sorted.loc[symbol_]['Adj Close']/decision_metrics_df['outer_cv_avg_rmse_n11'])\n",
    "            print(\"Price / Outer CV StdDev Ratio:\",screener_sorted.loc[symbol_]['Adj Close']/decision_metrics_df['outer_cv_std_n11'])\n",
    "\n",
    "            #display(decision_metrics_df.style.applymap(highlight_cells, color_if_false='yellow', color_if_true='#C6E2E9', subset=['error_price_ratio','mean_revert_flag','std_price_ratio'], threshold_=.75))\n",
    "\n",
    "            try:\n",
    "\n",
    "                temp_price = data\n",
    "                temp_price.columns = ['mean']\n",
    "                plt.plot(temp_price)\n",
    "                plt.plot(df_pred)\n",
    "                #plt.xticks([*data.tail(13).index.map(lambda t: t.strftime('%Y-%m-%d')),*newDates],rotation = 45,size=8)\n",
    "                plt.xticks(rotation = 45,size=8)\n",
    "                plt.legend(['actual','mean prediction','pi_lower','pi_upper'],loc=2)\n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(temp_price.tail(13))\n",
    "                plt.plot(df_pred.tail(26))\n",
    "                #plt.xticks([*data.tail(13).index.map(lambda t: t.strftime('%Y-%m-%d')),*newDates],rotation = 45,size=8)\n",
    "                plt.xticks(rotation = 45,size=8)\n",
    "                plt.legend(['actual','mean prediction','pi_lower','pi_upper'],loc=2)\n",
    "                plt.show()\n",
    "            except:\n",
    "\n",
    "                temp_price = data\n",
    "                temp_price.columns = ['mean']\n",
    "                plt.plot(temp_price)\n",
    "                plt.plot(df_pred)\n",
    "                #plt.xticks([*data.tail(13).index.map(lambda t: t.strftime('%Y-%m-%d')),*newDates],rotation = 45,size=8)\n",
    "                plt.xticks(rotation = 45,size=8)\n",
    "                plt.legend(['actual','mean prediction'],loc=2)\n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(temp_price.tail(13))\n",
    "                plt.plot(df_pred.tail(26))\n",
    "                #plt.xticks([*data.tail(13).index.map(lambda t: t.strftime('%Y-%m-%d')),*newDates],rotation = 45,size=8)\n",
    "                plt.xticks(rotation = 45,size=8)\n",
    "                plt.legend(['actual','mean prediction'],loc=2)\n",
    "                plt.show()\n",
    "    \n",
    "        display(decision_metrics_df)\n",
    "        \n",
    "        #take last nyse date and extrapolate weeks from that point\n",
    "        #starting from next week\n",
    "\n",
    "        data = subset[['Adj Close']].asfreq('D').interpolate().asfreq('W-'+subset.index[-1].strftime('%a'))\n",
    "\n",
    "        #if(np.where(np.array(list__)==s)[0][0]%batchClearLimit==0):        \n",
    "        #client.restart()\n",
    "\n",
    "        cv_inner = TimeSeriesSplit(n_splits=11,test_size=13)\n",
    "\n",
    "        #has to be different makeup than cv_inner because there is no randomization.  Recommend a number that isn't a divisor of cv_inner's n_splits to ensure training is mixed up and not aligned\n",
    "        cv_outer = TimeSeriesSplit(n_splits=10,test_size=13)\n",
    "\n",
    "        outer_results = []\n",
    "        #print(flag)\n",
    "\n",
    "        npa = []\n",
    "\n",
    "        for trainv_ix, test_ix in cv_inner.split(data.index):\n",
    "\n",
    "            npa.append([data.iloc[trainv_ix],data.iloc[test_ix]])\n",
    "\n",
    "        #rmses_inner = []\n",
    "        #rmses_inner\n",
    "        #for n in npa:\n",
    "            #r = evaluate_ets(n)\n",
    "            #print(r)\n",
    "            #rmses_inner.append(r)\n",
    "        future = client.map(evaluate_prophet, npa)        \n",
    "\n",
    "        rmses_inner = []\n",
    "        #flag_order = []\n",
    "        #my intent was to capture future objects vs results and this gave me results\n",
    "\n",
    "        for f in as_completed(future):\n",
    "            #exclude errors\n",
    "            if(f.status==\"error\"):\n",
    "                #pass\n",
    "                #this causes errors with [flag,rmse] being passed by evaluate_ets\n",
    "                rmses_inner.append(np.nan)\n",
    "            else:\n",
    "                rmses_inner.append(f.result())\n",
    "\n",
    "        #I don't want to keep track of flag here\n",
    "        #flag_order = [r[0] for r in results_rmses].copy()\n",
    "        #print(rmses_inner)\n",
    "        rmse_ = [r for r in rmses_inner].copy()\n",
    "\n",
    "        #print(rmse_)\n",
    "        #print(flag)\n",
    "        rmse_inner_flags = [np.nanmean(rmse_),np.nanstd(rmse_)]\n",
    "\n",
    "        #rmse_scores = []\n",
    "        #flag_rmses = []\n",
    "\n",
    "        #for fn_ in range(0,len(flags)):\n",
    "            #flag_ = flags[fn_]\n",
    "            #rmse_scores.append([flag_rmses[fn_],rmses[fn_][1]])\n",
    "\n",
    "        print(\"inner cv scores:\")\n",
    "        inner_rmse_df = pd.DataFrame([rmse_inner_flags],columns=['mean','std'])\n",
    "        #print(\"inner cv scores:\",[r[rmses)\n",
    "        #print(\"inner cv sdevs:\",sdevs)\n",
    "\n",
    "        scores = inner_rmse_df['mean'].values\n",
    "        sdevs = inner_rmse_df['std'].values\n",
    "        print(\"best inner cv score, sdev (11 folds):\",scores[np.argmin(scores)],sdevs[np.argmin(scores)])\n",
    "\n",
    "        npa = []\n",
    "\n",
    "        for trainv_ix, test_ix in cv_outer.split(data.index):\n",
    "\n",
    "            npa.append([data.iloc[trainv_ix],data.iloc[test_ix]])\n",
    "\n",
    "        future = client.map(evaluate_prophet, npa)\n",
    "        results_rmses_outer = []\n",
    "\n",
    "        #my intent was to capture future objects vs results and this gave me results\n",
    "        for f in as_completed(future):\n",
    "            #exclude errors\n",
    "            if(f.status==\"error\"):\n",
    "                #pass\n",
    "                results_rmses_outer.append([np.nan])\n",
    "            else:\n",
    "                results_rmses_outer.append(f.result()) \n",
    "\n",
    "        test_score_mean = np.nanmean([r for r in results_rmses_outer])\n",
    "        test_score_std = np.nanstd([r for r in results_rmses_outer])\n",
    "\n",
    "        #test_score = [np.nanmean(rmse_outer_df['mean'].values),np.nanstd(rmse_outer_df['mean'].values)]\n",
    "        print(\"test cv mean error, stdev (10 folds):\",test_score_mean,test_score_std)\n",
    "\n",
    "        \"\"\"\n",
    "        m = Prophet()\n",
    "\n",
    "        prophet_df = data.reset_index()\n",
    "        prophet_df.columns = ['ds','y']\n",
    "        prophet_df['y'] = np.log(prophet_df['y'])\n",
    "        m.fit(prophet_df)\n",
    "        #m = Prophet(mcmc_samples=300)\n",
    "\n",
    "        future_ = m.make_future_dataframe(periods = 14,freq='W-'+nyse_dates.index[-1].strftime('%a')).tail(13)\n",
    "\n",
    "        forecast = m.predict(future_).set_index('ds')[['yhat','yhat_lower','yhat_upper']]\n",
    "        #forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "        df_pred = np.exp(forecast)\n",
    "        #df_pred.index = future_['ds']\n",
    "        \"\"\"\n",
    "\n",
    "        m = Prophet()\n",
    "\n",
    "        #prophet_df = subset['Adj Close'].reset_index()#data.reset_index()\n",
    "        prophet_df = data['Adj Close'].reset_index()#data.reset_index()\n",
    "        prophet_df.columns = ['ds','y']\n",
    "        prophet_df['y'] = np.log(prophet_df['y'])\n",
    "        m.fit(prophet_df)\n",
    "        #m = Prophet(mcmc_samples=300)\n",
    "\n",
    "        #future_ = m.make_future_dataframe(periods = 14,freq='W-'+nyse_dates.index[-1].strftime('%a')).tail(13)\n",
    "        future_ = m.make_future_dataframe(periods = 14,freq='W-'+nyse_dates.index[-1].strftime('%a'))\n",
    "        #future_ = m.make_future_dataframe(periods = 92)\n",
    "\n",
    "        forecast = m.predict(future_).set_index('ds')[['yhat','yhat_lower','yhat_upper']]\n",
    "        #forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()\n",
    "        #df_pred = np.exp(forecast)\n",
    "        df_pred = np.exp(forecast)\n",
    "        #df_pred.index = future_['ds']\n",
    "\n",
    "        s_date = df_pred.index[np.argmax(df_pred['yhat'].values)].strftime('%Y-%m-%d')\n",
    "        temp_df = pd.DataFrame(data['Adj Close']).reset_index()\n",
    "        temp_df.columns = ['ds','Adj Close']\n",
    "        temp_df.set_index('ds',inplace=True)\n",
    "\n",
    "        #plt.plot(temp_df.asfreq('d').interpolate().asfreq('W-'+nyse_dates.index[-1].strftime('%a')))\n",
    "        #plt.plot(df_pred.asfreq('d').interpolate().asfreq('W-'+nyse_dates.index[-1].strftime('%a')))\n",
    "        #plt.legend(['Adj Close','yhat','yhat_lower','yhat_upper'],loc=1)\n",
    "        #plt.show()\n",
    "        #plt.plot(temp_df.asfreq('d').interpolate().asfreq('W-'+nyse_dates.index[-1].strftime('%a')).tail(13))\n",
    "        #plt.plot(df_pred.asfreq('d').interpolate().asfreq('W-'+nyse_dates.index[-1].strftime('%a')).tail(26))\n",
    "        #plt.legend(['Adj Close','yhat','yhat_lower','yhat_upper'],loc=1)\n",
    "\n",
    "        s_date = df_pred.index[np.argmax(df_pred['yhat'].values)].strftime('%Y-%m-%d')\n",
    "\n",
    "        print(\"sell date:\",s_date)\n",
    "        e_return = np.array((np.max(df_pred['yhat'].values)-metrics_df_['Adj Close'])/metrics_df_['Adj Close'])[0]\n",
    "        p_metrics = pd.DataFrame(df_pred.iloc[np.argmax(df_pred['yhat'].values)]).T\n",
    "        #c_metrics = pd.DataFrame(df_conf.iloc[np.argmax(df_pred['mean'].values)]).T\n",
    "        #print(c_metrics)\n",
    "        print(\"expected return:\",e_return)\n",
    "\n",
    "        days_delta = (datetime.strptime(s_date, '%Y-%m-%d') - datetime.strptime(end.strftime('%Y-%m-%d'), '%Y-%m-%d')).days\n",
    "        discounted_return = (1+e_return)**(1/days_delta)-1\n",
    "        qtr_return = (1+discounted_return)**92\n",
    "\n",
    "        print(\"discounted return:\",discounted_return)\n",
    "\n",
    "        print(\"quarter return:\",qtr_return)\n",
    "\n",
    "        #used to help filter at the end, not sdevs is chosen based on min score\n",
    "        #+ dt.timedelta(7)).strftime('%Y-%m-%d'), (subset.index[-1] + dt.timedelta(13)).strftime('%Y-%m-%d'), freq='W-'+nyse_dates.index[-1].strftime('%a')).map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "\n",
    "        #nyse_dates\n",
    "\n",
    "        stop_loss_price = pd.DataFrame(np.mean(df_pred[['yhat','yhat_lower']],axis=1)).iloc[0].values[0]\n",
    "        #decision_metrics.append([s,e_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['pi_lower'].values[0],p_metrics['pi_upper'].values[0]])\n",
    "        decision_metrics_df = pd.DataFrame([s,e_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['yhat_upper'].values[0],p_metrics['yhat_lower'].values[0]])#,columns=)#,index=[s_])#.sort_values(by='disc_rtn',ascending=False,inplace=True)\n",
    "        decision_metrics_df = decision_metrics_df.T\n",
    "        decision_metrics_df.columns=['SYMBOL','exp_return','sell_date','stop_loss_price','days_delta','disc_rtn','qtr_rtn','outer_cv_avg_rmse_n11','outer_cv_std_n11','mean_revert_flag','yhat_upper','yhat_lower']\n",
    "        decision_metrics_df.index = [symbol_]\n",
    "\n",
    "        print(\"Price / Outer CV Error Ratio:\",screener_sorted.loc[symbol_]['Adj Close']/decision_metrics_df['outer_cv_avg_rmse_n11'])\n",
    "        print(\"Price / Outer CV StdDev Ratio:\",screener_sorted.loc[symbol_]['Adj Close']/decision_metrics_df['outer_cv_std_n11'])\n",
    "\n",
    "        plt.plot(temp_df)\n",
    "        plt.plot(df_pred)\n",
    "        plt.legend(['Adj Close','yhat','yhat_lower','yhat_upper'],loc=2)\n",
    "        #plt.xticks([*data.tail(13).index.map(lambda t: t.strftime('%Y-%m-%d')),*newDates],rotation = 45,size=8)\n",
    "        plt.xticks(rotation = 45,size=8)\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(temp_df.tail(13))\n",
    "        plt.plot(df_pred.tail(26))\n",
    "        plt.legend(['Adj Close','yhat','yhat_lower','yhat_upper'],loc=2)\n",
    "        #plt.xticks([*data.tail(13).index.map(lambda t: t.strftime('%Y-%m-%d')),*newDates],rotation = 45,size=8)\n",
    "        plt.xticks(rotation = 45,size=8)\n",
    "        plt.show()\n",
    "\n",
    "        fcst = m.predict(future_)\n",
    "        fig = m.plot(fcst)\n",
    "        plt.show()\n",
    "\n",
    "        display(decision_metrics_df)\n",
    "        #display(decision_metrics_df.style.applymap(highlight_cells, color_if_false='yellow', color_if_true='#C6E2E9', subset=['error_price_ratio','mean_revert_flag','std_price_ratio'], threshold_=.75))\n",
    "\n",
    "        if(np.sum(np.array(fundamental_entries)==s)>0):\n",
    "            loc = np.where(np.array(fundamental_entries)==s)[0][0]\n",
    "            #print(fundamentals_quarterlies[loc[0]][0])\n",
    "            #fundamentals_quarterlies[loc][1]\n",
    "            for item in fundamentals_quarterlies[loc][1]:\n",
    "                if(type(item[1]) == type(None)):\n",
    "                    pass\n",
    "                else:\n",
    "                    if(len(item[1])>0):\n",
    "                        #print(len(item[1]))\n",
    "                        print(item)\n",
    "        client.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b055c-2464-4903-9bbb-993c7f4c4e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260d1e6-607a-472e-a52e-920c057b4efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edba80-547f-484b-8b97-39cbb2030d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a889c11-8b78-48dc-bad1-0f7eef45f11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eda05e-aeab-4f3f-b98b-6ff5275874ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c27f57-caf2-4839-9878-8746ba9d7257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b008f-6a32-4f90-9746-0e93cde00bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored(r, g, b, text):\n",
    "    return f\"\\033[38;2;{r};{g};{b}m{text}\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01062e39-ec5e-4aff-9b7d-a4881369b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_side_by_side(dfs:list, captions:list, tablespacing=5):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    for (caption, df) in zip(captions, dfs):\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += tablespacing * \"\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834d092-79f2-4351-bb3f-d5824664ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.color_palette(\"blend:red,yellow,green\", as_cmap=True)\n",
    "\n",
    "def b_g(s, cmap=cm, low=0, high=0):\n",
    "    # Pass the columns from Dataframe A \n",
    "    a = A.loc[:,s.name].copy()\n",
    "    #rng = a.max() - a.min()\n",
    "    rng = np.nanmax(A.values.ravel()) - np.nanmin(A.values.ravel())\n",
    "    norm = mp.colors.Normalize(np.nanmin(A.values.ravel()) - (rng * low),\n",
    "                        np.nanmax(A.values.ravel()) + (rng * high))\n",
    "    normed = norm(a.values)\n",
    "    #c = [mp.colors.rgb2hex(x) for x in plt.cm.get_cmap(cmap)(normed)]\n",
    "    c = [mp.colors.rgb2hex(x) for x in plt.cm.get_cmap(cm)(normed)]\n",
    "    return ['background-color: %s' % color for color in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33406af6-de98-4076-8ba5-3d3f01cf8ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nyse = mcal.get_calendar('NYSE')\n",
    "nyse_dates = nyse.schedule(start_date=start, end_date=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3ca9d-729a-4fd1-91c9-6a5ada30bf12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471b2ef-d9e2-43ac-8da6-9fcb1974aec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a2b10-dacb-4077-8b2a-49bae6c4773e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sector_performance_return = pd.DataFrame()\n",
    "sector_performance_Q_smoothed_return = pd.DataFrame()\n",
    "\n",
    "for v in [*indexes['Symbol'],*sectors['Symbol']]:\n",
    "    subset = prices_df[prices_df['Symbol'] == v]\n",
    "    #subset_ = subset.set_index('Date').asfreq('Q')[['Adj Close']].pct_change()\n",
    "    subset_ = subset.asfreq('D').interpolate().asfreq('Q')[['Adj Close']].pct_change()\n",
    "    #print(subset_)\n",
    "    #subset_qs = subset.set_index('Date')[['Adj Close']].pct_change().rolling(63).mean()\n",
    "    subset_qs = subset[['Adj Close']].pct_change().rolling(63).mean()\n",
    "    subset_.index = subset_.index.values.astype('M8[D]')\n",
    "    subset_qs.index = subset_qs.index.values.astype('M8[D]')\n",
    "    dt_str = subset_.index[-1].strftime('%Y-%m-%d')\n",
    "    #tail = subset[subset.set_index('Date').index>=dt_str]\n",
    "    tail = subset[subset.index>=dt_str]\n",
    "    #dt_str = subset.set_index('Date').index[-1].strftime('%Y-%m-%d')\n",
    "    dt_str = subset.index[-1].strftime('%Y-%m-%d')\n",
    "    #tail_ = pd.DataFrame([(tail.set_index('Date')['Adj Close'][-1]-tail.set_index('Date')['Adj Close'][0])/tail.set_index('Date')['Adj Close'][0]],index=[datetime.strptime(dt_str, '%Y-%m-%d')],columns=['Adj Close'])\n",
    "    tail_ = pd.DataFrame([(tail['Adj Close'][-1]-tail['Adj Close'][0])/tail['Adj Close'][0]],index=[datetime.strptime(dt_str, '%Y-%m-%d')],columns=['Adj Close'])\n",
    "    subset__ = pd.concat([subset_,tail_],axis=0)\n",
    "    sector_performance_return = pd.concat([sector_performance_return,subset__],axis=1)\n",
    "    sector_performance_Q_smoothed_return = pd.concat([sector_performance_Q_smoothed_return,subset_qs],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c20583-f7e6-44d0-81b2-565578e81943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sector_performance_Q_smoothed_return.columns = [*[i for i in indexes.index],*[v for v in sectors.index]]\n",
    "sector_performance_return.columns = [*[i for i in indexes.index],*[v for v in sectors.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c4c77-278c-4ac8-837d-5634d3e7fded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1a300-3a80-4a2e-8103-1a0c38f77503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from scipy import stats as st\n",
    "from scipy.stats import t\n",
    "\n",
    "std_indexes = pd.DataFrame()\n",
    "seasonal_indexes = pd.DataFrame()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for spr in sector_performance_return.columns:\n",
    "    #print(spr)\n",
    "    s = sector_performance_return[[spr]]\n",
    "    #print(s)\n",
    "    years = []\n",
    "    quarters = []\n",
    "    for d in sector_performance_return[spr].index:\n",
    "\n",
    "        d_ = d.strftime('%Y-%m-%d')\n",
    "        #print(d_)\n",
    "\n",
    "        datem = dt.datetime.strptime(d_, \"%Y-%m-%d\")\n",
    "        years.append(str(datem.year))\n",
    "        #print(datem.year)       # 2021\n",
    "        m = datem.month\n",
    "        d = datem.day\n",
    "        if(len(str(m))==1):\n",
    "            m = '0'+str(m)\n",
    "        else:\n",
    "            m = str(m)\n",
    "        if(len(str(d))==1):\n",
    "            d = '0'+str(d)\n",
    "        else:\n",
    "            d = str(d)\n",
    "        quarters.append(m+\"-\"+d)\n",
    "\n",
    "    s['Years'] = years\n",
    "    s['Quarters'] = quarters\n",
    "    ct = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).mean(axis=0).sort_index()\n",
    "    ct.columns = [spr]\n",
    "    \n",
    "    ct_std = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).std(axis=0).sort_index()\n",
    "    ct_std.columns = [spr]\n",
    "    \n",
    "    std_indexes = pd.concat([std_indexes,ct_std],axis=1)\n",
    "    seasonal_indexes = pd.concat([seasonal_indexes,ct],axis=1)\n",
    "\n",
    "seasonal_indexes.columns = sector_performance_return.columns\n",
    "\n",
    "std_indexes.columns = sector_performance_return.columns\n",
    "    \n",
    "seasonal_indexes = seasonal_indexes.T\n",
    "\n",
    "std_indexes = std_indexes.T\n",
    "\n",
    "si = ['03-31','06-30','09-30','12-31']\n",
    "\n",
    "print(\"Seasonal Indexes\")\n",
    "\n",
    "seasonal_index_values_sorted = []\n",
    "seasonal_index_names_sorted = []\n",
    "#B = seasonal_indexes[si]\n",
    "for c in seasonal_indexes[si].columns:\n",
    "    seasonal_index_values_sorted.append(seasonal_indexes[si][c].sort_values(ascending=False).values)\n",
    "    seasonal_index_names_sorted.append(seasonal_indexes[si][c].sort_values(ascending=False).index.values)\n",
    "\n",
    "temp_seasonal_index_values_sorted = pd.DataFrame(seasonal_index_values_sorted).T\n",
    "temp_seasonal_index_values_sorted.columns = seasonal_indexes[si].columns\n",
    "\n",
    "temp_seasonal_index_names_sorted = pd.DataFrame(seasonal_index_names_sorted).T\n",
    "temp_seasonal_index_names_sorted.columns = seasonal_indexes[si].columns\n",
    "\n",
    "A = temp_seasonal_index_values_sorted\n",
    "B = temp_seasonal_index_names_sorted \n",
    "\n",
    "display(B.style.apply(b_g,cmap=cm))\n",
    "\n",
    "display(seasonal_indexes[si].style.background_gradient(cmap = cm,axis=0))\n",
    "\n",
    "print(\"Note if the final data in the prices ends on a quarter, this will aggregate into the seasonal_index above and there will be no comparison\")\n",
    "print(\"Current\")\n",
    "\n",
    "display(seasonal_indexes[seasonal_indexes.columns.difference(si)].sort_values(by=seasonal_indexes[seasonal_indexes.columns.difference(si)].columns[0],ascending=False).style.background_gradient(cmap = cm,axis=0))    \n",
    "\n",
    "#calculate p-value\n",
    "n=5\n",
    "\n",
    "print(\"standard deviations\")\n",
    "display(std_indexes[si])\n",
    "t_scores = (seasonal_indexes[si])/(std_indexes[si]/np.sqrt(n))\n",
    "print(\"t scores\")\n",
    "display(t_scores)\n",
    "print(\"p values\")\n",
    "p_values = pd.DataFrame(t.cdf(t_scores, df=n-2),index=seasonal_indexes[si].index,columns=seasonal_indexes[si].columns)\n",
    "\n",
    "display(p_values.style.applymap(highlight_cells, color_if_true='green', color_if_false='yellow', threshold_=.5))\n",
    "\n",
    "p_values.hist()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c1ddd-9e58-4720-beaf-5d7f1512dc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7eb29-705b-4e85-b229-a4555630ba35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cycles_ = ['Expansion','Slowdown','Recession','Recovery']\n",
    "\n",
    "path=r\"C:\\Users\\User\\Documents\\wiki\\wiki\\dev\\python\\Python-Stock\\reports\\figures\\Business cycles.png\"\n",
    "display(Image.open(path))\n",
    "path=r\"C:\\Users\\User\\Documents\\wiki\\wiki\\Finance\\Business Cycles-2.png\"\n",
    "display(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b9c801-d5fd-4f10-bd02-4e4c40cd0ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb933634-e9ed-4668-9284-a118f4f07d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0414d0e-36bd-4b64-b5a4-24b8b7932aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62134d-c867-414f-804b-400d0e8e29b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54d0ec-a466-4feb-9471-6b523521c8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca435f40-9712-4d35-b805-724d8d8b1a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257bf38-1952-4509-be46-715f579645cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sector_performance_returned_no_dup = sector_performance_return.loc[~sector_performance_return.index.duplicated(keep ='first')]\n",
    "sector_performance_return_pvt = sector_performance_returned_no_dup[sector_performance_returned_no_dup.iloc[-1].sort_values(ascending=False).index]\n",
    "\n",
    "sector_performance_return_pvt_heatmap = sector_performance_return_pvt.style.background_gradient(cmap = cm,axis=None)\n",
    "display(sector_performance_return_pvt_heatmap)\n",
    "\n",
    "sector_performances = pd.DataFrame()\n",
    "sector_performances_values = pd.DataFrame()\n",
    "for c in sector_performance_returned_no_dup.T.columns:\n",
    "    #print(c)\n",
    "    temp = pd.DataFrame(sector_performance_returned_no_dup.T[c].sort_values(ascending=False).index,columns=[c])\n",
    "    #print(temp)\n",
    "    temp2 = pd.DataFrame(sector_performance_returned_no_dup.T[c].sort_values(ascending=False),columns=[c])\n",
    "    #print(temp2)\n",
    "    temp2.reset_index(drop=True,inplace=True)    \n",
    "    sector_performances = pd.concat([sector_performances,temp],axis=1)\n",
    "    sector_performances_values = pd.concat([sector_performances_values,temp2],axis=1)\n",
    "    \n",
    "A = sector_performances_values\n",
    "B = sector_performance_returned_no_dup.T\n",
    "\n",
    "df = B.style.apply(b_g,cmap='RdYlGn')\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12f766-8f48-4ea5-b403-425a5dd952f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfff60-c3f0-496e-a6ce-375edac96d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982011bf-09cf-4749-8f63-b077931fc4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#cm = sns.color_palette(\"blend:red,yellow,green\", as_cmap=True)\n",
    "#pd.crosstab(shares_viz['Year'], shares_viz['Month'])\n",
    "\n",
    "#seasonal_indexes[si]\n",
    "seasonally_adjusted = pd.DataFrame()\n",
    "\n",
    "for s in sector_performance_return.columns:\n",
    "    \n",
    "    s_ = pd.DataFrame(sector_performance_return[s])\n",
    "    #print(sector_performance_return[s])\n",
    "    years = []\n",
    "    quarters = []\n",
    "    \n",
    "    for d in s_.index:\n",
    "        d_ = d.strftime('%Y-%m-%d')\n",
    "        #print(d_)\n",
    "\n",
    "        datem = dt.datetime.strptime(d_, \"%Y-%m-%d\")\n",
    "        years.append(str(datem.year))\n",
    "        #print(datem.year)       # 2021\n",
    "        m = datem.month\n",
    "        d = datem.day\n",
    "        if(len(str(m))==1):\n",
    "            m = '0'+str(m)\n",
    "        else:\n",
    "            m = str(m)\n",
    "        if(len(str(d))==1):\n",
    "            d = '0'+str(d)\n",
    "        else:\n",
    "            d = str(d)\n",
    "        quarters.append(m+\"-\"+d)\n",
    "        \n",
    "    s_['Quarter'] = quarters\n",
    "    si_ = seasonal_indexes.loc[s]\n",
    "    \n",
    "    modified = pd.DataFrame()\n",
    "    #print(si_.index)\n",
    "    for s_i_ in si_.index:\n",
    "        #print(s_i_)\n",
    "        #when it finds the last date (which hopefully isn't a quarter date)\n",
    "        if(np.sum(np.array(si)==s_i_)==0):\n",
    "            #print(\"don't modify\")\n",
    "            #print(s_i_)\n",
    "            match = []\n",
    "            for entry in si:\n",
    "                if(int(s_i_.rsplit(\"-\")[0])<=int(entry.rsplit(\"-\")[0])):\n",
    "                    match = entry\n",
    "                    break            \n",
    "\n",
    "            delta_months = int(match.rsplit(\"-\")[0])-int(s_i_.rsplit(\"-\")[0])\n",
    "            delta_days_ = int(match.rsplit(\"-\")[1])-int(s_i_.rsplit(\"-\")[1])\n",
    "            \n",
    "            delta_days = int(delta_months*(91.25/3)+delta_days_)\n",
    "            #daily interest\n",
    "            \n",
    "            #print(delta_days)\n",
    "            #print(seasonal_indexes.loc[s].loc[match])\n",
    "            seasonal_index_to_daily = (1+seasonal_indexes.loc[s].loc[match])**(1/91.25)-1\n",
    "            #print(\"Seasonal Index to Daily Discounted Interest Rate:\",seasonal_index_to_daily)\n",
    "            daily_extrapolated = (1+seasonal_index_to_daily)**delta_days-1\n",
    "            #print(daily_extrapolated)\n",
    "            #print(\"Daily ^ delta_days:\",daily_extrapolated)\n",
    "            \n",
    "            #print(match)\n",
    "            #print(s_i_)\n",
    "            seasonally_adjusted_column = pd.DataFrame([seasonal_indexes.loc[s].loc[match] - daily_extrapolated],columns=[s],index=[s_.index[-1]])\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            seasonally_adjusted_column = pd.DataFrame(s_[s][s_['Quarter']==s_i_] - seasonal_indexes.loc[s].loc[s_i_],columns=[s])\n",
    "        modified = pd.concat([modified,seasonally_adjusted_column],axis=0)\n",
    "        modified.sort_index(inplace=True)\n",
    "    #print(modified)\n",
    "    seasonally_adjusted = pd.concat([seasonally_adjusted,modified],axis=1)\n",
    "\n",
    "print(\"Comparative to Seasonal Indexes, tells you who is over or underperforming.\")\n",
    "print(\"This is Seasonal Index - Extrapolated Current Quarter.\")\n",
    "print(\"+: seasonal > current\")\n",
    "print(\"-: current > seasonal\")\n",
    "\n",
    "print(\"Note if the final data in the prices ends on a quarter, this will aggregate into the seasonal_index above and there will be no comparison\")\n",
    "    \n",
    "    \n",
    "std_indexes_seas_adj = pd.DataFrame()\n",
    "seasonal_indexes_seas_adj = pd.DataFrame()\n",
    "\n",
    "temp_ = pd.DataFrame(seasonally_adjusted.T.iloc[:,-1])\n",
    "temp_.columns = pd.DataFrame(seasonally_adjusted.T.iloc[:,-1]).columns.strftime('%Y-%m-%d')\n",
    "display(temp_.sort_values(by=temp_.columns[0],ascending=False).style.background_gradient(cmap = cm,axis=0))\n",
    "\n",
    "#display(seasonally_adjusted[seasonally_adjusted.columns.difference(si)].style.background_gradient(cmap = cm,axis=0))\n",
    "\n",
    "for spr in seasonally_adjusted.columns:\n",
    "    #print(spr)\n",
    "    s = seasonally_adjusted[[spr]]\n",
    "    #print(s)\n",
    "    years = []\n",
    "    quarters = []\n",
    "    for d in seasonally_adjusted[spr].index:\n",
    "        d_ = d.strftime('%Y-%m-%d')\n",
    "        #print(d_)\n",
    "\n",
    "        datem = dt.datetime.strptime(d_, \"%Y-%m-%d\")\n",
    "        years.append(str(datem.year))\n",
    "        #print(datem.year)       # 2021\n",
    "        m = datem.month\n",
    "        d = datem.day\n",
    "        if(len(str(m))==1):\n",
    "            m = '0'+str(m)\n",
    "        else:\n",
    "            m = str(m)\n",
    "        if(len(str(d))==1):\n",
    "            d = '0'+str(d)\n",
    "        else:\n",
    "            d = str(d)\n",
    "        quarters.append(m+\"-\"+d)\n",
    "\n",
    "    s['Years'] = years\n",
    "    s['Quarters'] = quarters\n",
    "    ct = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).mean(axis=0).sort_index()\n",
    "    ct.columns = [spr]\n",
    "    #print(ct)\n",
    "    \n",
    "    ct_std = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).std(axis=0).sort_index()\n",
    "    ct_std.columns = [spr]\n",
    "    \n",
    "    std_indexes_seas_adj = pd.concat([std_indexes_seas_adj,ct_std],axis=1)\n",
    "    seasonal_indexes_seas_adj = pd.concat([seasonal_indexes_seas_adj,ct],axis=1)\n",
    "\n",
    "seasonal_indexes_seas_adj.columns = seasonally_adjusted.columns\n",
    "\n",
    "std_indexes_seas_adj.columns = seasonally_adjusted.columns\n",
    "    \n",
    "seasonal_indexes_seas_adj = seasonal_indexes_seas_adj.T\n",
    "\n",
    "std_indexes_seas_adj = std_indexes_seas_adj.T\n",
    "\n",
    "sector_performances_sea_adj = pd.DataFrame()\n",
    "sector_performances_values_sea_adj = pd.DataFrame()\n",
    "for c in seasonally_adjusted.T.columns:\n",
    "    temp = pd.DataFrame(seasonally_adjusted.T[c].sort_values(ascending=False).index,columns=[c])\n",
    "    temp2 = pd.DataFrame(seasonally_adjusted.T[c].sort_values(ascending=False),columns=[c])\n",
    "    temp2.reset_index(drop=True,inplace=True)    \n",
    "    sector_performances_sea_adj = pd.concat([sector_performances_sea_adj,temp],axis=1)\n",
    "    sector_performances_values_sea_adj = pd.concat([sector_performances_values_sea_adj,temp2],axis=1)\n",
    "\n",
    "A = sector_performances_values_sea_adj\n",
    "B = sector_performances_sea_adj\n",
    "\n",
    "df_sea_adj = B.style.apply(b_g,cmap='RdYlGn')\n",
    "display(df_sea_adj)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b39b6-9237-4645-bbdb-8a34dfa1c6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d032d-0cf3-400a-a801-185619948a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "index_performance = []\n",
    "for v in indexes['Symbol'].values:\n",
    "    index_performance.append([v,screener.loc[v]['risk_trend_factor']])\n",
    "temp_i = pd.DataFrame(index_performance,index=indexes.index)\n",
    "temp_i.columns = ['Symbol','risk_trend_factor']\n",
    "index_risk_sorted = pd.DataFrame(index_performance,columns=['Symbol','risk_trend_factor'],index=indexes.index).sort_values(by='risk_trend_factor',ascending=False).reset_index()\n",
    "index_risk_sorted.columns = ['Index','Symbol','risk_trend_factor']\n",
    "index_risk_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56630f8-6533-4540-856b-d8d9451ef65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sector_performance = []\n",
    "for v in sectors['Symbol'].values:\n",
    "    sector_performance.append([v,screener.loc[v]['risk_trend_factor']])\n",
    "temp_v = sectors.reset_index()\n",
    "temp_v.columns = ['Sector','Symbol']\n",
    "sectors_risk_sorted = pd.DataFrame(sector_performance,columns=['Symbol','risk_trend_factor']).merge(temp_v, on='Symbol', how='left').sort_values(by='risk_trend_factor',ascending=False)    \n",
    "sectors_risk_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a2ec6-395f-4da5-bfa5-7e7c988ae08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a771c-5610-4928-a935-9b82d1fb9cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Rolling Quarterly Mean Return\")\n",
    "plt.plot(sector_performance_Q_smoothed_return)\n",
    "plt.legend([*[i for i in indexes.index],*[v for v in sectors.index]],loc=2,fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c50ea-5870-498b-b7da-617d97c578f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13a3ec-5048-4acc-ab5c-f798e1216b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"Quarterly Returns\")\n",
    "for v in sector_performance_return.T.index:\n",
    "    subset = pd.DataFrame(sector_performance_return.T.loc[v])\n",
    "    subset.columns = ['Return']\n",
    "    plt.plot(subset)\n",
    "    plt.xticks(subset.index, rotation=45)\n",
    "plt.legend(sector_performance_return.T.index,loc=2)    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf881ad7-da51-46d1-b8c9-eb903b7aa6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0716a-3b2d-43e9-93b3-c659efa306d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.plot(seasonal_indexes[si].T)\n",
    "plt.legend(seasonal_indexes[si].T.columns,loc=2,fontsize=8)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a954f-1e41-4112-a980-a9691a8f63c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59a21d-0820-4a62-908f-54ecac2e45f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683e62d-4d0e-476d-afa3-52ad82a1c96c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e546c98-ca0c-425c-acb2-7a3f965c2a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#risk_trend_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd8fd4-950c-4bc9-ba28-af6baf1ae54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71ada5-3b22-4191-90d1-f15b7fb7e5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#market_data['sector'] = stock_fundamentals['sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa318b-d659-4ccc-a9f0-690cf4ceac36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf398b-c971-4a14-a7ed-9fd5c2b7a3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c01705-6411-4957-90f6-521e7155ce71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a825ee5-d4bd-4637-b588-f5118cf49f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#screener[['risk_trend_factor']].replace(['missing','error'], np.NaN).dropna().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25448842-ee84-4647-87e3-d992eef0bc9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(screener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f3156-444c-451b-a326-9df38293d66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e93bc0-29aa-45fe-8c9e-6a8a5596a8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prices_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b194139-71d1-4533-a98f-365fd3091584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887c1c3-269e-4ff7-97d7-0f629b1e02e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfda1b2-a4a5-4d30-a1cb-de0c8cf35c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bceec-0d5c-4f79-a610-dead31b3a405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607a019-d78d-40f1-b870-f3e9c8b0f7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f70f23-e164-4cbc-9b36-56179475fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16abc74-da31-4bb2-bd4b-f4c04e0a671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold_value = summary.dropna()['risk_trend_factor'].quantile([threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b6deb-8a67-4153-82df-5c163093db01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e4361-ac3b-4d6e-b549-eb253ef708ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af351818-c6ba-4266-a7c4-e51749929cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae8bc3-ac12-4d8e-813f-8a40be23dfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65f6cf-37e8-4d73-934b-5f59ad2c69f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a417218-6f64-46c7-98b4-86a5f7f3257a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9700e2-c4a4-43a9-8a16-247223bbee76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f712bf-fdfc-4ad7-91a8-a06e2eaeead1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c7f72-2513-4f5c-9667-905ccaf3887b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd232d-8b14-4a80-8936-9aef1d831282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f9bc2-d935-4b61-82a7-b71a59ecaf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "screener_sorted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18049f-28ca-456f-afbe-7d16941b6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed_fred_pvt_df = completed_fred_pvt.asfreq('D').reindex(nyse_dates.index).interpolate(method='time')\n",
    "completed_fred_pvt_df = completed_fred_pvt\n",
    "\n",
    "temp_new = completed_fred_pvt.asfreq('D').interpolate(method='time',limit_area='inside').reindex(nyse_dates.index)\n",
    "temp_dates = pd.date_range(completed_fred_pvt.index[0].strftime('%Y-%m-%d'), completed_fred_pvt.index[-1].strftime('%Y-%m-%d'), freq='D').map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "nyse_inbetween_temp_dates = nyse_dates.index[(nyse_dates.index >= temp_dates[0]) & (nyse_dates.index <= temp_dates[-1])]\n",
    "temp_new = temp_new.reindex(nyse_inbetween_temp_dates)\n",
    "\n",
    "completed_fred_pvt_df = temp_new\n",
    "completed_fred_pvt_df.columns = [name[1] for name in completed_fred_pvt_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd0649-1c64-4f77-8a14-ee9db088a4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b2b91-888f-4d53-9336-295f64e41028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fred_friendly_names = ['Average Weekly Hours','Market volatility','Consumer Confidence','Unemployment','Inflation','Mfr Orders Excl AC','Oil Prices','Housing Prices','Interest Rates','10 Year to 3 Month','Recession Indicator','OECD Leading Indicator','Coincident Index']\n",
    "fred_names = ['AWHAETP','VIXCLS','UMCSENT','UNRATE','NEWORDER','DCOILWTICO','FPCPITOTLZGUSA','CSUSHPINSA','FEDFUNDS','T10Y3M','USREC','USALOLITONOSTSAM','USPHCI']\n",
    "#fred_names = ['AWHAETP','VIXCLS','UMCSENT','UNRATE','DGORDER','DCOILWTICO','FPCPITOTLZGUSA','CSUSHPINSA','FEDFUNDS','T10Y3M','USREC','USALOLITONOSTSAM','USPHCI']\n",
    "print('nominal,','pct_change,','pct_change().cumsum')\n",
    "for pos in range(0,len(fred_names)):\n",
    "    print(fred_friendly_names[pos])\n",
    "    name = fred_names[pos]\n",
    "    \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False,figsize=(15,6))\n",
    "    ax1.plot(completed_fred_pvt_df[name])\n",
    "    ax2.plot(completed_fred_pvt_df[name].pct_change())\n",
    "    ax3.plot(completed_fred_pvt_df[name].pct_change().cumsum())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f248ba-d0b2-4b25-a9ca-ac78643ce98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#screener['vol_30d_2yr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c752f-c4e7-4beb-bb9a-2dad9d0f4aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447fa06-6e2a-4b18-b40c-817411a5980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(np.mean(np.exp(final_model.get_prediction(start=end,end=(end + dt.timedelta(92)).strftime('%Y-%m-%d')).summary_frame())[['mean','pi_lower']],axis=1)).iloc[0].values[0]\n",
    "#[s,e_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['pi_lower'].values[0],p_metrics['pi_upper'].values[0]]\n",
    "#screener['Adj Close'].loc[decision_metrics_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c39487-0321-4d3e-94f9-ae163abafb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63de933-72ca-4216-8c1b-a10efcce5939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1279851-e29f-4c5d-adc6-55c80fc583ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e129ba4d-965f-4ffb-8471-5b1a0a5db5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0fcedb9-fc57-4852-9bc6-dd38793ae013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adf < .05 or .01, mean reverting\n",
      "Hurst\n",
      "> .5 - The time series is mean reverting.\n",
      "= .5 - The time series is a Geometric Brownian Motion.\n",
      "< .5 - The time series is trending.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\traitlets.py:697: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  silent = bool(old_value == new_value)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3759c539dac441f5bbc3a1aa7be866c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Select(description='symbol_', options=('A', 'AA', 'AAL', 'AAN', 'AAON', 'AAP', 'AAPL', '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "#tscv = expanding_window(initial =52*2, horizon = 13,period = 26)\n",
    "\n",
    "#batchClearLimit = round(len(list__)/7)\n",
    "\n",
    "print(\"adf < .05 or .01, mean reverting\")\n",
    "print(\"Hurst\")\n",
    "print(\"> .5 - The time series is mean reverting.\")\n",
    "print(\"= .5 - The time series is a Geometric Brownian Motion.\")\n",
    "print(\"< .5 - The time series is trending.\")\n",
    "\"\"\"*indexes['Symbol'].values,*sectors['Symbol'].values,\"\"\"\n",
    "\n",
    "widgets.Dropdown(\n",
    "    #options=stocks_,\n",
    "    #value=None,\n",
    "    description='Choose Stock:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "#y_=widgets.Select(options=stocks_,disabled=False)\n",
    "y_=widgets.Select(options=np.sort([*list_sector_n_indexes,*list_stocks]),value=None,disabled=False)\n",
    "\n",
    "a=interact(plot_,symbol_=y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37ae05e-dff6-4a86-8c45-2ff51516044d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc656b-ad7b-44b6-a73f-f640d5f88418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
