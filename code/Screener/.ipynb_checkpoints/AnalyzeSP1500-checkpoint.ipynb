{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9d05a-a1d5-4f4c-a68f-884d49aeb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#v10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ade43c-b6c3-4b09-8331-8cfeea94eeef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import display, HTML\n",
    "from PIL import Image\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from matplotlib.dates import DateFormatter\n",
    "from pandas.io.formats.style import Styler\n",
    "from pivottablejs import pivot_ui\n",
    "from pmdarima.arima import auto_arima\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import re\n",
    "from statsmodels.stats.outliers_influence import summary_table\n",
    "import datetime as dt\n",
    "import matplotlib\n",
    "import matplotlib as mp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.dates as md\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pandas_market_calendars as mcal\n",
    "import pickle\n",
    "import rpy2\n",
    "import seaborn as sns\n",
    "import sqlite3\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import statsmodels\n",
    "from statsmodels.tsa.exponential_smoothing.ets import ETSModel\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "from rpy2.robjects.packages import importr\n",
    "import rpy2\n",
    "import rpy2.robjects as ro\n",
    "import time\n",
    "from clustergram import Clustergram\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.vq import vq\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import scale\n",
    "from k_means_constrained import KMeansConstrained\n",
    "from scipy.stats import f\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from IPython.display import HTML as html_print\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 200\n",
    "\n",
    "import pandas as pd\n",
    "from rpy2.robjects import pandas2ri\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37e766-4331-4821-99bd-0680ffdf3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not sys.warnoptions:\n",
    "#    import warnings\n",
    "#    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "wd = os.getcwd()\n",
    "\n",
    "if (os.defpath==\".;C:\\\\bin\"):\n",
    "    os.environ['R_HOME'] = 'C:/Users/User/Documents/R/R-4.1.2'\n",
    "    os.environ['R_LIBS'] = 'C:/Users/User/Documents/R/R-4.1.2/library'\n",
    "    from OLS_LR_DiagnosticPlots.ModelDiagnostics import Plot\n",
    "else:\n",
    "    os.environ['R_HOME'] = '/mnt/distvol/R/4.0.5/lib64/R/'\n",
    "\n",
    "pandas2ri.activate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c955f43d-9872-4b22-8b0b-686d51bbacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#robjects.ro['version']\n",
    "\n",
    "base = importr('base')\n",
    "#grdevices = importr('grDevices')\n",
    "print(base._libPaths())\n",
    "\n",
    "timetk = importr('timetk')\n",
    "magrittr = importr('magrittr')\n",
    "dplyr = importr('dplyr')\n",
    "tidyverse = importr('tidyverse')\n",
    "nbclust = importr('NbClust')\n",
    "grdevices = importr('grDevices')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ccb3eb-f028-43da-aa35-2afd62c7fd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "si = ['03-31','06-30','09-30','12-31']\n",
    "               \n",
    "[start,end,prices_df, sp1500_index_df, sp500, sp600, sp400, market_data, completed_fred_pvt, completed_bonds, completed_bonds_pvt, sectors, indexes, screener_sorted, dict_sectors, dict_indexes, dict_sectors_reverse, invert_dict_indexes, list_sector_n_indexes, list_stocks] = pickle.load(open('./data_object.pkl', 'rb'))\n",
    "\n",
    "fred_friendly_names = ['Consumer Loans','Copper','Iron and Steel','Gold','Unemployment','Market volatility','Commercial-Industrial Loans','Average Weekly Hours','Credit to Income','Consumer Confidence','Oil Prices','Inflation','Housing Prices','Interest Rates','10 Year to 3 Month','Recession Indicator','OECD Leading Indicator','Coincident Index','Index: Industrial Production','Mfr Orders Excl AC','Personal Expenditures',]\n",
    "fred_names = ['CONSUMER','WPUSI019011','WPU101','GVZCLS','UNRATE','VIXCLS','BUSLOANS','AWHAETP','UMCSENT','TDSP','DCOILWTICO','CPIAUCSL','CSUSHPINSA','FEDFUNDS','T10Y3M','USREC','USALOLITONOSTSAM','USPHCI','INDPRO','NEWORDER','PCE']\n",
    "\n",
    "dict_fred = dict(zip(*[fred_names,fred_friendly_names]))\n",
    "\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "nyse_dates = nyse.schedule(start_date=start, end_date=end)\n",
    "\n",
    "fundamentals_quarterlies = pickle.load(open('./fundamental.pkl', 'rb'))\n",
    "fundamental_entries = [e[0] for e in fundamentals_quarterlies]\n",
    "\n",
    "sectors.columns = ['Symbol']\n",
    "indexes.columns = ['Symbol']\n",
    "\n",
    "newDates = pd.date_range((end+ dt.timedelta(7)).strftime('%Y-%m-%d'), (end + dt.timedelta(92)).strftime('%Y-%m-%d'), freq='W-'+nyse_dates.index[-1].strftime('%a')).map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "\n",
    "db_filename = 'todo.db'\n",
    "\n",
    "db_is_new = not os.path.exists(db_filename)\n",
    "\n",
    "conn = sqlite3.connect(db_filename)\n",
    "\n",
    "if db_is_new:\n",
    "    print('Need to create schema')\n",
    "else:\n",
    "    print('Database exists, assume schema does, too.')\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a47b5ce-1bf7-404e-9bfd-e7af76417251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#completed_fred_pvt_df = completed_fred_pvt.asfreq('D').reindex(nyse_dates.index).interpolate(method='time')\n",
    "completed_fred_pvt_df = completed_fred_pvt\n",
    "\n",
    "temp_new = completed_fred_pvt.asfreq('D').interpolate(method='time',limit_area='inside').reindex(nyse_dates.index)\n",
    "temp_dates = pd.date_range(completed_fred_pvt.index[0].strftime('%Y-%m-%d'), completed_fred_pvt.index[-1].strftime('%Y-%m-%d'), freq='D').map(lambda t: t.strftime('%Y-%m-%d'))\n",
    "nyse_inbetween_temp_dates = nyse_dates.index[(nyse_dates.index >= temp_dates[0]) & (nyse_dates.index <= temp_dates[-1])]\n",
    "temp_new = temp_new.reindex(nyse_inbetween_temp_dates)\n",
    "\n",
    "completed_fred_pvt_df = temp_new\n",
    "completed_fred_pvt_df.columns = [name[1] for name in completed_fred_pvt_df.columns]\n",
    "\n",
    "np.array(completed_fred_pvt_df.index.map(lambda t: t.strftime('%Y-%m-%d')))[np.arange(0,len(completed_fred_pvt_df.index),int(len(completed_fred_pvt_df.index)/10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7d68f4-e6ea-41dd-8b87-4fd29cb22e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_ahead = 13\n",
    "\n",
    "cv_inner = TimeSeriesSplit(n_splits=10,test_size=n_ahead)\n",
    "cv_outer = TimeSeriesSplit(n_splits=11,test_size=n_ahead)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75f256-bd00-463f-b5bf-36d429b1e45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cstr(s, color='black'):\n",
    "    return \"<text style=color:{}>{}</text>\".format(color, s)\n",
    "\n",
    "def print_color(t):\n",
    "    print(t)\n",
    "    display(html_print(' '.join([cstr(ti, color=ci) for ti,ci in t])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dc38bd-0235-4486-b957-a7674fefc307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findknee(xdata):\n",
    "    rate_of_change=(xdata[0]-xdata[-1])/(len(xdata)-1)\n",
    "    #print(rate_of_change)\n",
    "    delta = xdata-xdata[-1]\n",
    "    deltas = []\n",
    "    deltas.append(delta[0])\n",
    "    for d in range(1,len(xdata)):\n",
    "        deltas.append(deltas[d-1]-rate_of_change)\n",
    "    #print(deltas)\n",
    "    for d in range(0,len(xdata)):\n",
    "        deltas[d]=delta[d]-deltas[d]\n",
    "    return(np.round(np.abs(deltas)))\n",
    "\n",
    "def deriveANOVA(clf, df):\n",
    "\n",
    "    labels = clf.labels_\n",
    "    clusters = clf.n_clusters\n",
    "    centers = clf.cluster_centers_\n",
    "        \n",
    "    within_ss = []\n",
    "\n",
    "    for n in range(0,clusters):\n",
    "      #WSS means the sum of distances between the points and the corresponding centroids for each cluster\n",
    "      data = df[labels==(n)]\n",
    "      within_ss.append(((data - centers[n])**2).sum(1).sum())\n",
    "\n",
    "    WSS = total_within_ss = np.sum(within_ss)\n",
    "\n",
    "    print('wss',total_within_ss)\n",
    "\n",
    "    #sum of ((deviation from variable means) squared)\n",
    "    tot_ss = np.sum(np.sum((df-df.mean())**2))\n",
    "    print('tot_ss',tot_ss)\n",
    "\n",
    "    cluster_BSS = []\n",
    "    for n in range(0,clusters):\n",
    "      #sum((variable/column means cluster - variable/column means data)^2)*len(cluster members)\n",
    "      BSS = np.sum((df[labels==(n)].mean()-np.array(np.mean(df)))**2)*len(df[labels==(n)])\n",
    "      cluster_BSS.append(BSS)\n",
    "\n",
    "    BSS = np.sum(cluster_BSS)\n",
    "    print('bss',BSS)\n",
    "    \n",
    "    return(tot_ss, BSS, within_ss)\n",
    "\n",
    "def findOptimalK_ANOVA(df, mink=2, maxk=6, init_min=2, init_max=5):\n",
    "\n",
    "    tss = []\n",
    "    bss = []\n",
    "    wss = []\n",
    "\n",
    "    for k in range(mink,maxk):\n",
    "        print(k)\n",
    "\n",
    "        print(max(init_min,k+1))\n",
    "        size_min_ = max(init_min,k+1)\n",
    "        size_max_ = max(np.ceil(len(df)/k),init_max)\n",
    "        if(size_min_>size_max_):\n",
    "            break\n",
    "        else:\n",
    "            clf = KMeansConstrained(n_clusters=k, size_min=size_min_, size_max=size_max_, init='k-means++', n_init=100, max_iter=100, tol=0.0001, verbose=False, random_state=int(time.time()), copy_x=True, n_jobs=4)\n",
    "            clf.fit_predict(np.array(df))\n",
    "\n",
    "            tot_ss, BSS, within_ss = deriveANOVA(clf, df)\n",
    "\n",
    "            wss.append(within_ss)\n",
    "            tss.append(tot_ss)\n",
    "            bss.append(BSS)\n",
    "\n",
    "    return(tss, bss, wss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ed1442-0c89-43a1-ab60-ba829fa4b086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e4c743-7f04-4405-b0a4-a20d02cd34b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def time_to_int(dateobj):\n",
    "    total = int(dateobj.strftime('%S'))\n",
    "    total += int(dateobj.strftime('%M')) * 60\n",
    "    total += int(dateobj.strftime('%H')) * 60 * 60\n",
    "    total += (int(dateobj.strftime('%j')) - 1) * 60 * 60 * 24\n",
    "    total += (int(dateobj.strftime('%Y')) - 1970) * 60 * 60 * 24 * 365\n",
    "    return total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ca18dd-3ef1-4b3d-ae25-688131622be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_cells(val, color_if_true, color_if_false, threshold_):\n",
    "    color = color_if_true if val >= threshold_ else color_if_false\n",
    "    return 'background-color: {}'.format(color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e93ff1-1957-4260-b7f6-a013c5cfb763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d7dc96-9214-40de-be05-b8ddb0fa4180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbfcad-ace0-4f5e-a474-cdf2d25e01fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_fb_test_error(npa):\n",
    "    n_ahead = 13\n",
    "\n",
    "    subset_train = npa[0]\n",
    "    subset_test = npa[1]\n",
    "\n",
    "    base_model = Prophet()\n",
    "\n",
    "    prophet_df_base = subset_train['Adj Close'].reset_index()#data.reset_index()\n",
    "    prophet_df_base.columns = ['ds','y']\n",
    "    prophet_df_base['y'] = np.log(prophet_df_base['y'])\n",
    "\n",
    "    base_model.fit(prophet_df_base)\n",
    "\n",
    "    future_base = base_model.make_future_dataframe(periods = n_ahead,freq='W-'+subset_train.index[-1].strftime('%a'))\n",
    "\n",
    "    forecast_base = base_model.predict(future_base).set_index('ds')[['yhat','yhat_lower','yhat_upper']]\n",
    "    df_pred_base = np.exp(forecast_base)\n",
    "\n",
    "    rmse_ = mean_squared_error(subset_test['Adj Close'].tail(n_ahead), df_pred_base['yhat'].tail(n_ahead), squared=True)\n",
    "    return([[subset_test['Adj Close'].tail(n_ahead)],[df_pred_base['yhat'].tail(n_ahead)],rmse_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ee731-6770-4f82-b064-0050b2944473",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "symbol_ = 'BA'\n",
    "\n",
    "if(str(symbol_)=='None'):\n",
    "    run=False\n",
    "else:\n",
    "    run=True\n",
    "\n",
    "if(run):\n",
    "    client = Client('192.168.3.100:8786')\n",
    "    #client = Client(n_workers=4,threads_per_worker=1)\n",
    "\n",
    "    s = symbol_\n",
    "    msize = 2\n",
    "    date_form = DateFormatter(\"%Y-%m-%d\")\n",
    "\n",
    "    metrics_df_ = pd.DataFrame(pd.DataFrame(screener_sorted.loc[s]).T[['volume_factor','Adj Close','adf','hurst']])\n",
    "    subset=prices_df[prices_df['Symbol']==s]\n",
    "    \n",
    "    y = subset['Adj Close']\n",
    "    data = subset[['Adj Close']].asfreq('D').interpolate().asfreq('W-'+subset.index[-1].strftime('%a'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027b0ca-06f8-4679-b42f-59adcbe223f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0bf8bd-a49c-4bc5-891a-daabca660927",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cdcbb8-de81-4ff4-b20c-cca4d39a3406",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7f37b-05c3-4c51-a2e3-e7c1e24f0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_(symbols):\n",
    "    \n",
    "    decision_metrics_df = pd.DataFrame()\n",
    "    \n",
    "    for symbol_ in symbols:\n",
    "\n",
    "        print(symbol_)\n",
    "        if(str(symbol_)=='None'):\n",
    "            run=False\n",
    "        else:\n",
    "            run=True\n",
    "\n",
    "        if(run):\n",
    "            client = Client('192.168.3.100:8786')\n",
    "            #client = Client(n_workers=4,threads_per_worker=1)\n",
    "\n",
    "            s = symbol_\n",
    "            msize = 2\n",
    "            date_form = DateFormatter(\"%Y-%m-%d\")\n",
    "\n",
    "            metrics_df_ = pd.DataFrame(pd.DataFrame(screener_sorted.loc[s]).T[['volume_factor','Adj Close','adf','hurst']])\n",
    "            subset=prices_df[prices_df['Symbol']==s]\n",
    "\n",
    "            dates = []\n",
    "            for t in subset.index.values:\n",
    "                d = pd.Timestamp(t).strftime('%Y-%m-%d')\n",
    "                dates.append(d)\n",
    "                dto = datetime.strptime(d, '%Y-%m-%d').date()\n",
    "\n",
    "            old_ordinal = [datetime.strptime(i, '%Y-%m-%d').toordinal() for i in dates]\n",
    "            new_ordinal = old_ordinal + md.date2num(np.datetime64('0000-12-31'))\n",
    "            x = new_ordinal    \n",
    "\n",
    "            lookup_index_ = []\n",
    "\n",
    "            labels = list()\n",
    "            print(\"symbol:\",s)\n",
    "\n",
    "            symbol_sector = screener_sorted.loc[symbol_]['Sector Symbol']\n",
    "\n",
    "            print(\"sector:\",dict_sectors_reverse[symbol_sector])\n",
    "            symbol_index = screener_sorted.loc[s]['Index Symbol']\n",
    "\n",
    "            try:\n",
    "                matched_index_name = indexes.iloc[np.where(indexes['Symbol'].values==s)].index[0]\n",
    "            except:\n",
    "                try:\n",
    "                    matched_index_name = screener_sorted.loc[s]['Index Symbol']\n",
    "                except:\n",
    "                    matched_index_name = \"error\"\n",
    "\n",
    "            print(\"Index:\",dict_indexes[matched_index_name])\n",
    "\n",
    "            print(\"Volume Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==s)]['volume_factor'][0])\n",
    "\n",
    "            print(\"sector_risk_trend_factor:\",screener_sorted[screener_sorted.index==s]['sector_risk_trend_factor'][0])\n",
    "            print(\"risk trend factor:\",screener_sorted.iloc[np.where(screener_sorted.index==s)]['risk_trend_factor'][0])\n",
    "\n",
    "            temp = pd.DataFrame(market_data.loc[s])\n",
    "            print(temp[np.array(temp!='error')].replace([np.inf,'inf','error', -np.inf], np.nan).dropna().T)\n",
    "\n",
    "            last_date = pd.DataFrame(subset.iloc[-1][['21dBOLD','21dMA-TP','21dBOLU']],index=[prices_df[prices_df['Symbol']==s].index[-1].strftime('%Y-%m-%d')]).index[0]\n",
    "\n",
    "            bbands = pd.DataFrame(subset.iloc[-1][['Adj Close','21dBOLD','21dMA-TP','21dBOLU','90dSMA','90dSDev']]).T\n",
    "            bbands['90d_lower'] = bbands['90dSMA']-bbands['90dSDev']*2\n",
    "            bbands['90d_upper'] = bbands['90dSMA']+bbands['90dSDev']*2\n",
    "\n",
    "            bbands.index = [last_date]\n",
    "            display(bbands)\n",
    "\n",
    "            display(metrics_df_)\n",
    "\n",
    "            mean_revert_flag = False\n",
    "\n",
    "            if(metrics_df_['adf'][0]<.05):\n",
    "                print(\"ADFuller H0 rejected @ .05, Mean Reverting TS\")\n",
    "                if(bbands['Adj Close'][0]<bbands['90d_lower'][0]):\n",
    "                    colored_text = colored(255, 0, 0, \"Quarter Mean Reverting buy signal\")\n",
    "                    print(colored_text)\n",
    "                    mean_revert_flag = True\n",
    "                if(bbands['Adj Close'][0]<bbands['21dBOLU'][0]):\n",
    "                    colored_text = colored(255, 0, 0, \"Month Mean Reverting buy signal\")\n",
    "                    print(colored_text)\n",
    "                    mean_revert_flag = True    \n",
    "\n",
    "            l_axis_legend = pd.DataFrame(['symbol', 'trailing_1yr_max', 'trailing_1yr_min', '30d_vol_2yr','risk_trend_factor/linear','supply_trend_1yr'],index=['blue','green','red','orange','black','yellow'],columns=['legend'])\n",
    "\n",
    "            r_axis_legend = pd.DataFrame(['sector','index'],index=['magenta','cyan'],columns=['legend'])\n",
    "\n",
    "            display_side_by_side([l_axis_legend, r_axis_legend], ['l axis', 'r axis'])        \n",
    "\n",
    "            f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, sharey=False,figsize=(22,5))\n",
    "            ax1.plot(subset['30d_vol_2yr'],color='orange')\n",
    "            #plt.title('30d_vol_2yr')\n",
    "            ax1.set_xticklabels(subset[['30d_vol_2yr']].dropna().index, rotation = 45)\n",
    "\n",
    "            locator = matplotlib.dates.AutoDateLocator()\n",
    "            formatter = matplotlib.dates.ConciseDateFormatter(locator)\n",
    "\n",
    "            ax1.xaxis.set_major_locator(locator)\n",
    "            ax1.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "            ax1.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "            ax2.plot(subset['risk_trend_factor'],color='black')\n",
    "            ax2.set_xticklabels(subset[['risk_trend_factor']].dropna().index, rotation = 45)\n",
    "\n",
    "            locator = matplotlib.dates.AutoDateLocator()\n",
    "            formatter = matplotlib.dates.ConciseDateFormatter(locator)\n",
    "\n",
    "            ax2.xaxis.set_major_locator(locator)\n",
    "            ax2.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "            ax2.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "            ax3_ = ax3.twinx()\n",
    "            ax5_ = ax5.twinx()        \n",
    "            ax4_ = ax4.twinx()\n",
    "\n",
    "            y = subset['Adj Close']\n",
    "\n",
    "            def myfunc(x):\n",
    "                return slope * x + intercept\n",
    "\n",
    "            slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "            mymodel = list(map(myfunc, x))\n",
    "\n",
    "            ax3.plot(x, y,marker = '.',markersize=msize, color = 'b')\n",
    "            ax3.plot(x, subset['trailing_1yr_max'],marker = '.',markersize=msize, color = 'g')\n",
    "            ax3.plot(x, subset['trailing_1yr_min'],marker = '.',markersize=msize, color = 'r')\n",
    "            ax3_.plot(x, subset['supply_trend_1yr'],marker = '.',markersize=msize, color = 'y')\n",
    "            ax3.plot(x, mymodel, color = 'k')\n",
    "\n",
    "            l = matplotlib.dates.AutoDateLocator()\n",
    "            f = matplotlib.dates.ConciseDateFormatter(l)    \n",
    "\n",
    "            ax3.set_xticklabels(ax3.get_xticks(), rotation = 45)\n",
    "\n",
    "            locator = matplotlib.dates.AutoDateLocator()\n",
    "            formatter = matplotlib.dates.ConciseDateFormatter(locator)\n",
    "\n",
    "            ax3.xaxis.set_major_locator(locator)\n",
    "            ax3.xaxis.set_major_formatter(formatter)\n",
    "            ax3.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "            if(symbol_sector=='error'):\n",
    "                pass\n",
    "            else:\n",
    "                if(np.sum(sectors['Symbol'].values==s)>0):\n",
    "                    pass\n",
    "                else:\n",
    "                    sector_subset = prices_df[prices_df['Symbol']==symbol_sector]\n",
    "                    print(\"Sector Volume Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==symbol_sector)]['volume_factor'][0])\n",
    "                    print(\"Sector Risk Trend Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==symbol_sector)]['risk_trend_factor'][0])\n",
    "                    #ax3_.plot(x, (sector_subset['Adj Close']).iloc[-len(subset):],marker = '.',markersize=msize,color='m',linestyle=(0, (3, 10, 1, 10)))\n",
    "                    ax4.plot(x, (sector_subset['Adj Close']).iloc[-len(subset):],marker = '.',markersize=msize,color='m',linestyle=(0, (3, 10, 1, 10)))\n",
    "                    ax4.plot(x, (sector_subset['trailing_1yr_max']).iloc[-len(subset):],marker = '.',markersize=msize, color = 'g')\n",
    "                    ax4.plot(x, (sector_subset['trailing_1yr_min']).iloc[-len(subset):],marker = '.',markersize=msize, color = 'r')\n",
    "                    ax4_.plot(x, (sector_subset['supply_trend_1yr']).iloc[-len(subset):],marker = '.',markersize=msize,color='y',linestyle=(0, (3, 10, 1, 10)))\n",
    "                    ax4.set_xticklabels(subset.dropna().index, rotation = 45)\n",
    "                    ax4.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "            if(str(screener_sorted.loc[s]['Index Symbol'])!='nan'):\n",
    "                if(screener_sorted.loc[s]['Index Symbol']!='error'):\n",
    "                    index_subset = prices_df[prices_df['Symbol']==screener_sorted.loc[s]['Index Symbol']]\n",
    "                    print(\"Index Volume Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==screener_sorted.loc[s]['Index Symbol'])]['volume_factor'][0])\n",
    "                    print(\"Index Risk Trend Factor:\",screener_sorted.iloc[np.where(screener_sorted.index==screener_sorted.loc[s]['Index Symbol'])]['risk_trend_factor'][0])\n",
    "                    ax5.plot(x, index_subset['Adj Close'].iloc[-len(subset):],marker = '.',markersize=msize,color='c',linestyle=(0, (1, 10)))\n",
    "                    ax5.plot(x, index_subset['trailing_1yr_max'].iloc[-len(subset):],marker = '.',markersize=msize, color = 'g')\n",
    "                    ax5.plot(x, index_subset['trailing_1yr_min'].iloc[-len(subset):],marker = '.',markersize=msize, color = 'r')\n",
    "                    ax5_.plot(x, index_subset['supply_trend_1yr'].iloc[-len(subset):],marker = '.',markersize=msize,color='y',linestyle=(0, (1, 10)))\n",
    "                    ax5.set_xticklabels(index_subset.dropna().index, rotation = 45)\n",
    "                    ax5.xaxis.set_major_formatter(date_form)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            data = subset[['Adj Close']].asfreq('D').interpolate().asfreq('W-'+subset.index[-1].strftime('%a'))\n",
    "\n",
    "            npa_rmse_inner = []\n",
    "\n",
    "            for trainv_ix, test_ix in cv_inner.split(data.index):\n",
    "\n",
    "                npa_rmse_inner.append([data.iloc[trainv_ix],data.iloc[test_ix]])\n",
    "\n",
    "            npa_rmse_outer = []\n",
    "\n",
    "            for trainv_ix, test_ix in cv_outer.split(data.index):\n",
    "\n",
    "                npa_rmse_outer.append([data.iloc[trainv_ix],data.iloc[test_ix]])        \n",
    "\n",
    "            print(\"fbprophet next 13 weeks\")\n",
    "\n",
    "            #starting from next week\n",
    "\n",
    "            future = client.map(derive_fb_test_error, npa_rmse_inner)        \n",
    "\n",
    "            rmses_inner = []\n",
    "\n",
    "            for f in as_completed(future):\n",
    "                if(f.status==\"error\"):\n",
    "                    rmses_inner.append(np.nan)\n",
    "                else:\n",
    "                    rmses_inner.append(f.result())\n",
    "\n",
    "            rmses_inner_ = [t[2] for t in rmses_inner]\n",
    "            rmse_ = [r for r in rmses_inner_]\n",
    "\n",
    "            rmse_inner_flags = [np.nanmean(rmse_),np.nanstd(rmse_)]\n",
    "\n",
    "            print(\"inner cv scores:\")\n",
    "            inner_rmse_df = pd.DataFrame([rmse_inner_flags],columns=['mean','std'])\n",
    "\n",
    "            scores = inner_rmse_df['mean'].values\n",
    "            sdevs = inner_rmse_df['std'].values\n",
    "            print(\"best inner cv score, sdev (11 folds):\",scores[np.argmin(scores)],sdevs[np.argmin(scores)])\n",
    "\n",
    "            future = client.map(derive_fb_test_error, npa_rmse_outer)\n",
    "            results_rmses_outer = []\n",
    "\n",
    "            for f in as_completed(future):\n",
    "                if(f.status==\"error\"):\n",
    "                    results_rmses_outer.append([np.nan])\n",
    "                else:\n",
    "                    results_rmses_outer.append(f.result()) \n",
    "\n",
    "            results_rmses_outer_ = [t[2] for t in results_rmses_outer]\n",
    "            test_score_mean = np.nanmean([r for r in results_rmses_outer_])\n",
    "            test_score_std = np.nanstd([r for r in results_rmses_outer_])\n",
    "\n",
    "            client = Client('192.168.3.100:8786')\n",
    "\n",
    "            y_s = [t[0] for t in results_rmses_outer]\n",
    "            y_hats = [t[1] for t in results_rmses_outer]\n",
    "            test_errors_ = np.array(y_s)-np.array(y_hats)\n",
    "            np.std(test_errors_,axis=0)\n",
    "            std_resid = test_errors_/((np.sum(test_errors_)**2)/(len(test_errors_)-2)**.5)\n",
    "\n",
    "            std_error_test = np.std(test_errors_,axis=0)\n",
    "\n",
    "            print(\"test cv mean error, stdev (10 folds):\",test_score_mean,test_score_std)\n",
    "\n",
    "            m = Prophet(interval_width=0.95)\n",
    "\n",
    "            prophet_df = data['Adj Close'].reset_index()#data.reset_index()\n",
    "            prophet_df.columns = ['ds','y']\n",
    "            prophet_df['y'] = np.log(prophet_df['y'])\n",
    "            m.fit(prophet_df)\n",
    "\n",
    "            future_ = m.make_future_dataframe(periods = n_ahead,freq='W-'+nyse_dates.index[-1].strftime('%a'))\n",
    "\n",
    "            forecast = m.predict(future_).set_index('ds')[['yhat','yhat_lower','yhat_upper']]\n",
    "            df_pred = np.exp(forecast)\n",
    "\n",
    "            temp_df = pd.DataFrame(data['Adj Close']).reset_index()\n",
    "            temp_df.columns = ['ds','Adj Close']\n",
    "            temp_df.set_index('ds',inplace=True)\n",
    "\n",
    "            s_date = df_pred.tail(n_ahead).index[np.argmax(df_pred['yhat'].tail(n_ahead).values)].strftime('%Y-%m-%d')\n",
    "\n",
    "            print(\"sell date:\",s_date)\n",
    "            e_return = np.array((np.max(df_pred['yhat'].tail(n_ahead).values)-metrics_df_['Adj Close'])/metrics_df_['Adj Close'])[0]\n",
    "            p_metrics = pd.DataFrame(df_pred.tail(n_ahead).iloc[np.argmax(df_pred['yhat'].tail(n_ahead).values)]).T\n",
    "            print(\"expected return:\",e_return)\n",
    "\n",
    "            days_delta = (datetime.strptime(s_date, '%Y-%m-%d') - datetime.strptime(end.strftime('%Y-%m-%d'), '%Y-%m-%d')).days\n",
    "            try:\n",
    "                discounted_return = (1+e_return)**(1/days_delta)-1\n",
    "            except:\n",
    "                discounted_return = 0\n",
    "            qtr_return = (1+discounted_return)**92\n",
    "\n",
    "            print(\"discounted return:\",discounted_return)\n",
    "            print(\"quarter return:\",qtr_return)\n",
    "\n",
    "            #95% 2 tail\n",
    "            t_score = stats.t.ppf(1-0.025, len(test_errors_))\n",
    "\n",
    "            prediction_interval_yhat_upper = df_pred[['yhat']].tail(n_ahead)+(std_error_test.reshape(n_ahead,1)*t_score)\n",
    "            prediction_interval_yhat_lower = df_pred[['yhat']].tail(n_ahead)-(std_error_test.reshape(n_ahead,1)*t_score)\n",
    "\n",
    "            stop_loss_price = pd.DataFrame(np.mean(pd.concat([df_pred[['yhat']].tail(n_ahead),prediction_interval_yhat_lower],axis=1),axis=1)).iloc[0].values[0]\n",
    "            decision_metrics_df_ = pd.DataFrame([s,e_return,discounted_return,qtr_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['yhat_upper'].values[0],p_metrics['yhat_lower'].values[0]])#,columns=)#,index=[s_])#.sort_values(by='disc_rtn',ascending=False,inplace=True)\n",
    "            decision_metrics_df_ = decision_metrics_df_.T\n",
    "            decision_metrics_df_.columns=['SYMBOL','exp_return','discounted_return','qtr_return','sell_date','stop_loss_price','days_delta','disc_rtn','qtr_rtn','outer_cv_avg_rmse_n11','outer_cv_std_n11','mean_revert_flag','yhat_upper','yhat_lower']\n",
    "            decision_metrics_df_.index = [symbol_]\n",
    "            \n",
    "            bbands_ = bbands\n",
    "            bbands_.index = [symbol_]\n",
    "            decision_metrics_df_ = pd.concat([decision_metrics_df_,bbands_,metrics_df_],axis=1)\n",
    "            \n",
    "            print(decision_metrics_df_)\n",
    "            \n",
    "            decision_metrics_df = pd.concat([decision_metrics_df,decision_metrics_df_],axis=0)\n",
    "\n",
    "            print(\"Outer CV Error / Price Ratio\",decision_metrics_df['outer_cv_avg_rmse_n11']/screener_sorted.loc[symbol_]['Adj Close'])\n",
    "            print(\" Outer CV StdDev / Price Ratio\",decision_metrics_df['outer_cv_std_n11']/screener_sorted.loc[symbol_]['Adj Close'])\n",
    "\n",
    "            plt.plot(temp_df)\n",
    "            plt.plot(df_pred)\n",
    "            plt.legend(['Adj Close','yhat','yhat_lower','yhat_upper'],loc=2)\n",
    "            plt.xticks(rotation = 45,size=8)\n",
    "            plt.show()\n",
    "\n",
    "            plt.plot(temp_df.tail(n_ahead))\n",
    "            plt.plot(df_pred.tail(n_ahead*2))\n",
    "            plt.plot(prediction_interval_yhat_upper,linestyle = 'dashed')\n",
    "            plt.plot(prediction_interval_yhat_lower,linestyle = 'dashed')\n",
    "\n",
    "            plt.legend(['Adj Close','yhat','yhat_lower','yhat_upper','pi_upper','pi_lower'],loc=2)\n",
    "\n",
    "            plt.xticks(rotation = 45,size=8)\n",
    "            plt.show()\n",
    "\n",
    "            fcst = m.predict(future_)\n",
    "            fig = m.plot(fcst)\n",
    "            plt.show()            \n",
    "\n",
    "            if(np.sum(np.array(fundamental_entries)==s)>0):\n",
    "                loc = np.where(np.array(fundamental_entries)==s)[0][0]\n",
    "                for item in fundamentals_quarterlies[loc][1]:\n",
    "                    if(type(item[1]) == type(None)):\n",
    "                        pass\n",
    "                    else:\n",
    "                        if(len(item[1])>0):\n",
    "                            #print(len(item[1]))\n",
    "                            print(item)\n",
    "            client.close()\n",
    "            \n",
    "    display(decision_metrics_df)\n",
    "    decision_metrics_df.to_csv(end.strftime('%Y-%m-%d')+'_decision_metrics_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b055c-2464-4903-9bbb-993c7f4c4e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c8fdd-14d1-49ab-b0c4-2e3c33c20fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5260d1e6-607a-472e-a52e-920c057b4efe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edba80-547f-484b-8b97-39cbb2030d2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a889c11-8b78-48dc-bad1-0f7eef45f11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1eda05e-aeab-4f3f-b98b-6ff5275874ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c27f57-caf2-4839-9878-8746ba9d7257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854b008f-6a32-4f90-9746-0e93cde00bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def colored(r, g, b, text):\n",
    "    return f\"\\033[38;2;{r};{g};{b}m{text}\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01062e39-ec5e-4aff-9b7d-a4881369b6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_side_by_side(dfs:list, captions:list, tablespacing=5):\n",
    "    \"\"\"Display tables side by side to save vertical space\n",
    "    Input:\n",
    "        dfs: list of pandas.DataFrame\n",
    "        captions: list of table captions\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    for (caption, df) in zip(captions, dfs):\n",
    "        output += df.style.set_table_attributes(\"style='display:inline'\").set_caption(caption)._repr_html_()\n",
    "        output += tablespacing * \"\\xa0\"\n",
    "    display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834d092-79f2-4351-bb3f-d5824664ca21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = sns.color_palette(\"blend:red,yellow,green\", as_cmap=True)\n",
    "\n",
    "def b_g(s, cmap=cm, low=0, high=0):\n",
    "    # Pass the columns from Dataframe A \n",
    "    a = A.loc[:,s.name].copy()\n",
    "    #rng = a.max() - a.min()\n",
    "    rng = np.nanmax(A.values.ravel()) - np.nanmin(A.values.ravel())\n",
    "    norm = mp.colors.Normalize(np.nanmin(A.values.ravel()) - (rng * low),\n",
    "                        np.nanmax(A.values.ravel()) + (rng * high))\n",
    "    normed = norm(a.values)\n",
    "    #c = [mp.colors.rgb2hex(x) for x in plt.cm.get_cmap(cmap)(normed)]\n",
    "    c = [mp.colors.rgb2hex(x) for x in plt.cm.get_cmap(cm)(normed)]\n",
    "    return ['background-color: %s' % color for color in c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33406af6-de98-4076-8ba5-3d3f01cf8ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nyse = mcal.get_calendar('NYSE')\n",
    "nyse_dates = nyse.schedule(start_date=start, end_date=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf3ca9d-729a-4fd1-91c9-6a5ada30bf12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471b2ef-d9e2-43ac-8da6-9fcb1974aec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a2b10-dacb-4077-8b2a-49bae6c4773e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sector_performance_return = pd.DataFrame()\n",
    "sector_performance_Q_smoothed_return = pd.DataFrame()\n",
    "\n",
    "for v in [*indexes['Symbol'],*sectors['Symbol']]:\n",
    "    subset = prices_df[prices_df['Symbol'] == v]\n",
    "    #subset_ = subset.set_index('Date').asfreq('Q')[['Adj Close']].pct_change()\n",
    "    subset_ = subset.asfreq('D').interpolate().asfreq('Q')[['Adj Close']].pct_change()\n",
    "    #print(subset_)\n",
    "    #subset_qs = subset.set_index('Date')[['Adj Close']].pct_change().rolling(63).mean()\n",
    "    subset_qs = subset[['Adj Close']].pct_change().rolling(63).mean()\n",
    "    subset_.index = subset_.index.values.astype('M8[D]')\n",
    "    subset_qs.index = subset_qs.index.values.astype('M8[D]')\n",
    "    dt_str = subset_.index[-1].strftime('%Y-%m-%d')\n",
    "    #tail = subset[subset.set_index('Date').index>=dt_str]\n",
    "    tail = subset[subset.index>=dt_str]\n",
    "    #dt_str = subset.set_index('Date').index[-1].strftime('%Y-%m-%d')\n",
    "    dt_str = subset.index[-1].strftime('%Y-%m-%d')\n",
    "    #tail_ = pd.DataFrame([(tail.set_index('Date')['Adj Close'][-1]-tail.set_index('Date')['Adj Close'][0])/tail.set_index('Date')['Adj Close'][0]],index=[datetime.strptime(dt_str, '%Y-%m-%d')],columns=['Adj Close'])\n",
    "    tail_ = pd.DataFrame([(tail['Adj Close'][-1]-tail['Adj Close'][0])/tail['Adj Close'][0]],index=[datetime.strptime(dt_str, '%Y-%m-%d')],columns=['Adj Close'])\n",
    "    subset__ = pd.concat([subset_,tail_],axis=0)\n",
    "    sector_performance_return = pd.concat([sector_performance_return,subset__],axis=1)\n",
    "    sector_performance_Q_smoothed_return = pd.concat([sector_performance_Q_smoothed_return,subset_qs],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c20583-f7e6-44d0-81b2-565578e81943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sector_performance_Q_smoothed_return.columns = [*[i for i in indexes.index],*[v for v in sectors.index]]\n",
    "sector_performance_return.columns = [*[i for i in indexes.index],*[v for v in sectors.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6c4c77-278c-4ac8-837d-5634d3e7fded",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1a300-3a80-4a2e-8103-1a0c38f77503",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from scipy import stats as st\n",
    "from scipy.stats import t\n",
    "\n",
    "std_indexes = pd.DataFrame()\n",
    "seasonal_indexes = pd.DataFrame()\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for spr in sector_performance_return.columns:\n",
    "    #print(spr)\n",
    "    s = sector_performance_return[[spr]]\n",
    "    #print(s)\n",
    "    years = []\n",
    "    quarters = []\n",
    "    for d in sector_performance_return[spr].index:\n",
    "\n",
    "        d_ = d.strftime('%Y-%m-%d')\n",
    "        #print(d_)\n",
    "\n",
    "        datem = dt.datetime.strptime(d_, \"%Y-%m-%d\")\n",
    "        years.append(str(datem.year))\n",
    "        #print(datem.year)       # 2021\n",
    "        m = datem.month\n",
    "        d = datem.day\n",
    "        if(len(str(m))==1):\n",
    "            m = '0'+str(m)\n",
    "        else:\n",
    "            m = str(m)\n",
    "        if(len(str(d))==1):\n",
    "            d = '0'+str(d)\n",
    "        else:\n",
    "            d = str(d)\n",
    "        quarters.append(m+\"-\"+d)\n",
    "\n",
    "    s['Years'] = years\n",
    "    s['Quarters'] = quarters\n",
    "    ct = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).mean(axis=0).sort_index()\n",
    "    ct.columns = [spr]\n",
    "    \n",
    "    ct_std = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).std(axis=0).sort_index()\n",
    "    ct_std.columns = [spr]\n",
    "    \n",
    "    std_indexes = pd.concat([std_indexes,ct_std],axis=1)\n",
    "    seasonal_indexes = pd.concat([seasonal_indexes,ct],axis=1)\n",
    "\n",
    "seasonal_indexes.columns = sector_performance_return.columns\n",
    "\n",
    "std_indexes.columns = sector_performance_return.columns\n",
    "    \n",
    "seasonal_indexes = seasonal_indexes.T\n",
    "\n",
    "std_indexes = std_indexes.T\n",
    "\n",
    "si = ['03-31','06-30','09-30','12-31']\n",
    "\n",
    "print(\"Seasonal Indexes\")\n",
    "\n",
    "seasonal_index_values_sorted = []\n",
    "seasonal_index_names_sorted = []\n",
    "#B = seasonal_indexes[si]\n",
    "for c in seasonal_indexes[si].columns:\n",
    "    seasonal_index_values_sorted.append(seasonal_indexes[si][c].sort_values(ascending=False).values)\n",
    "    seasonal_index_names_sorted.append(seasonal_indexes[si][c].sort_values(ascending=False).index.values)\n",
    "\n",
    "temp_seasonal_index_values_sorted = pd.DataFrame(seasonal_index_values_sorted).T\n",
    "temp_seasonal_index_values_sorted.columns = seasonal_indexes[si].columns\n",
    "\n",
    "temp_seasonal_index_names_sorted = pd.DataFrame(seasonal_index_names_sorted).T\n",
    "temp_seasonal_index_names_sorted.columns = seasonal_indexes[si].columns\n",
    "\n",
    "A = temp_seasonal_index_values_sorted\n",
    "B = temp_seasonal_index_names_sorted \n",
    "\n",
    "display(B.style.apply(b_g,cmap=cm))\n",
    "\n",
    "display(seasonal_indexes[si].style.background_gradient(cmap = cm,axis=0))\n",
    "\n",
    "print(\"Note if the final data in the prices ends on a quarter, this will aggregate into the seasonal_index above and there will be no comparison\")\n",
    "print(\"Current\")\n",
    "\n",
    "display(seasonal_indexes[seasonal_indexes.columns.difference(si)].sort_values(by=seasonal_indexes[seasonal_indexes.columns.difference(si)].columns[0],ascending=False).style.background_gradient(cmap = cm,axis=0))    \n",
    "\n",
    "#calculate p-value\n",
    "n=5\n",
    "\n",
    "print(\"standard deviations\")\n",
    "display(std_indexes[si])\n",
    "t_scores = (seasonal_indexes[si])/(std_indexes[si]/np.sqrt(n))\n",
    "print(\"t scores\")\n",
    "display(t_scores)\n",
    "print(\"p values\")\n",
    "p_values = pd.DataFrame(t.cdf(t_scores, df=n-2),index=seasonal_indexes[si].index,columns=seasonal_indexes[si].columns)\n",
    "\n",
    "display(p_values.style.applymap(highlight_cells, color_if_true='green', color_if_false='yellow', threshold_=.5))\n",
    "\n",
    "p_values.hist()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c1ddd-9e58-4720-beaf-5d7f1512dc79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e7eb29-705b-4e85-b229-a4555630ba35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cycles_ = ['Expansion','Slowdown','Recession','Recovery']\n",
    "\n",
    "path=r\"C:\\Users\\User\\Documents\\wiki\\wiki\\dev\\python\\Python-Stock\\reports\\figures\\Business cycles.png\"\n",
    "display(Image.open(path))\n",
    "path=r\"C:\\Users\\User\\Documents\\wiki\\wiki\\Finance\\Business Cycles-2.png\"\n",
    "display(Image.open(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b9c801-d5fd-4f10-bd02-4e4c40cd0ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb933634-e9ed-4668-9284-a118f4f07d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0414d0e-36bd-4b64-b5a4-24b8b7932aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c62134d-c867-414f-804b-400d0e8e29b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54d0ec-a466-4feb-9471-6b523521c8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca435f40-9712-4d35-b805-724d8d8b1a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7257bf38-1952-4509-be46-715f579645cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sector_performance_returned_no_dup = sector_performance_return.loc[~sector_performance_return.index.duplicated(keep ='first')]\n",
    "sector_performance_return_pvt = sector_performance_returned_no_dup[sector_performance_returned_no_dup.iloc[-1].sort_values(ascending=False).index]\n",
    "\n",
    "sector_performance_return_pvt_heatmap = sector_performance_return_pvt.style.background_gradient(cmap = cm,axis=None)\n",
    "display(sector_performance_return_pvt_heatmap)\n",
    "\n",
    "sector_performances = pd.DataFrame()\n",
    "sector_performances_values = pd.DataFrame()\n",
    "for c in sector_performance_returned_no_dup.T.columns:\n",
    "    #print(c)\n",
    "    temp = pd.DataFrame(sector_performance_returned_no_dup.T[c].sort_values(ascending=False).index,columns=[c])\n",
    "    #print(temp)\n",
    "    temp2 = pd.DataFrame(sector_performance_returned_no_dup.T[c].sort_values(ascending=False),columns=[c])\n",
    "    #print(temp2)\n",
    "    temp2.reset_index(drop=True,inplace=True)    \n",
    "    sector_performances = pd.concat([sector_performances,temp],axis=1)\n",
    "    sector_performances_values = pd.concat([sector_performances_values,temp2],axis=1)\n",
    "    \n",
    "A = sector_performances_values\n",
    "B = sector_performance_returned_no_dup.T\n",
    "\n",
    "df = B.style.apply(b_g,cmap='RdYlGn')\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12f766-8f48-4ea5-b403-425a5dd952f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dfff60-c3f0-496e-a6ce-375edac96d52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982011bf-09cf-4749-8f63-b077931fc4d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "#cm = sns.color_palette(\"blend:red,yellow,green\", as_cmap=True)\n",
    "#pd.crosstab(shares_viz['Year'], shares_viz['Month'])\n",
    "\n",
    "#seasonal_indexes[si]\n",
    "seasonally_adjusted = pd.DataFrame()\n",
    "\n",
    "for s in sector_performance_return.columns:\n",
    "    \n",
    "    s_ = pd.DataFrame(sector_performance_return[s])\n",
    "    #print(sector_performance_return[s])\n",
    "    years = []\n",
    "    quarters = []\n",
    "    \n",
    "    for d in s_.index:\n",
    "        d_ = d.strftime('%Y-%m-%d')\n",
    "        #print(d_)\n",
    "\n",
    "        datem = dt.datetime.strptime(d_, \"%Y-%m-%d\")\n",
    "        years.append(str(datem.year))\n",
    "        #print(datem.year)       # 2021\n",
    "        m = datem.month\n",
    "        d = datem.day\n",
    "        if(len(str(m))==1):\n",
    "            m = '0'+str(m)\n",
    "        else:\n",
    "            m = str(m)\n",
    "        if(len(str(d))==1):\n",
    "            d = '0'+str(d)\n",
    "        else:\n",
    "            d = str(d)\n",
    "        quarters.append(m+\"-\"+d)\n",
    "        \n",
    "    s_['Quarter'] = quarters\n",
    "    si_ = seasonal_indexes.loc[s]\n",
    "    \n",
    "    modified = pd.DataFrame()\n",
    "    #print(si_.index)\n",
    "    for s_i_ in si_.index:\n",
    "        #print(s_i_)\n",
    "        #when it finds the last date (which hopefully isn't a quarter date)\n",
    "        if(np.sum(np.array(si)==s_i_)==0):\n",
    "            #print(\"don't modify\")\n",
    "            #print(s_i_)\n",
    "            match = []\n",
    "            for entry in si:\n",
    "                if(int(s_i_.rsplit(\"-\")[0])<=int(entry.rsplit(\"-\")[0])):\n",
    "                    match = entry\n",
    "                    break            \n",
    "\n",
    "            delta_months = int(match.rsplit(\"-\")[0])-int(s_i_.rsplit(\"-\")[0])\n",
    "            delta_days_ = int(match.rsplit(\"-\")[1])-int(s_i_.rsplit(\"-\")[1])\n",
    "            \n",
    "            delta_days = int(delta_months*(91.25/3)+delta_days_)\n",
    "            #daily interest\n",
    "            \n",
    "            #print(delta_days)\n",
    "            #print(seasonal_indexes.loc[s].loc[match])\n",
    "            seasonal_index_to_daily = (1+seasonal_indexes.loc[s].loc[match])**(1/91.25)-1\n",
    "            #print(\"Seasonal Index to Daily Discounted Interest Rate:\",seasonal_index_to_daily)\n",
    "            daily_extrapolated = (1+seasonal_index_to_daily)**delta_days-1\n",
    "            #print(daily_extrapolated)\n",
    "            #print(\"Daily ^ delta_days:\",daily_extrapolated)\n",
    "            \n",
    "            #print(match)\n",
    "            #print(s_i_)\n",
    "            seasonally_adjusted_column = pd.DataFrame([seasonal_indexes.loc[s].loc[match] - daily_extrapolated],columns=[s],index=[s_.index[-1]])\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            seasonally_adjusted_column = pd.DataFrame(s_[s][s_['Quarter']==s_i_] - seasonal_indexes.loc[s].loc[s_i_],columns=[s])\n",
    "        modified = pd.concat([modified,seasonally_adjusted_column],axis=0)\n",
    "        modified.sort_index(inplace=True)\n",
    "    #print(modified)\n",
    "    seasonally_adjusted = pd.concat([seasonally_adjusted,modified],axis=1)\n",
    "\n",
    "print(\"Comparative to Seasonal Indexes, tells you who is over or underperforming.\")\n",
    "print(\"This is Seasonal Index - Extrapolated Current Quarter.\")\n",
    "print(\"+: seasonal > current\")\n",
    "print(\"-: current > seasonal\")\n",
    "\n",
    "print(\"Note if the final data in the prices ends on a quarter, this will aggregate into the seasonal_index above and there will be no comparison\")\n",
    "    \n",
    "    \n",
    "std_indexes_seas_adj = pd.DataFrame()\n",
    "seasonal_indexes_seas_adj = pd.DataFrame()\n",
    "\n",
    "temp_ = pd.DataFrame(seasonally_adjusted.T.iloc[:,-1])\n",
    "temp_.columns = pd.DataFrame(seasonally_adjusted.T.iloc[:,-1]).columns.strftime('%Y-%m-%d')\n",
    "display(temp_.sort_values(by=temp_.columns[0],ascending=False).style.background_gradient(cmap = cm,axis=0))\n",
    "\n",
    "#display(seasonally_adjusted[seasonally_adjusted.columns.difference(si)].style.background_gradient(cmap = cm,axis=0))\n",
    "\n",
    "for spr in seasonally_adjusted.columns:\n",
    "    #print(spr)\n",
    "    s = seasonally_adjusted[[spr]]\n",
    "    #print(s)\n",
    "    years = []\n",
    "    quarters = []\n",
    "    for d in seasonally_adjusted[spr].index:\n",
    "        d_ = d.strftime('%Y-%m-%d')\n",
    "        #print(d_)\n",
    "\n",
    "        datem = dt.datetime.strptime(d_, \"%Y-%m-%d\")\n",
    "        years.append(str(datem.year))\n",
    "        #print(datem.year)       # 2021\n",
    "        m = datem.month\n",
    "        d = datem.day\n",
    "        if(len(str(m))==1):\n",
    "            m = '0'+str(m)\n",
    "        else:\n",
    "            m = str(m)\n",
    "        if(len(str(d))==1):\n",
    "            d = '0'+str(d)\n",
    "        else:\n",
    "            d = str(d)\n",
    "        quarters.append(m+\"-\"+d)\n",
    "\n",
    "    s['Years'] = years\n",
    "    s['Quarters'] = quarters\n",
    "    ct = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).mean(axis=0).sort_index()\n",
    "    ct.columns = [spr]\n",
    "    #print(ct)\n",
    "    \n",
    "    ct_std = pd.crosstab(s['Years'], s['Quarters'],values=s[spr],aggfunc=np.mean).std(axis=0).sort_index()\n",
    "    ct_std.columns = [spr]\n",
    "    \n",
    "    std_indexes_seas_adj = pd.concat([std_indexes_seas_adj,ct_std],axis=1)\n",
    "    seasonal_indexes_seas_adj = pd.concat([seasonal_indexes_seas_adj,ct],axis=1)\n",
    "\n",
    "seasonal_indexes_seas_adj.columns = seasonally_adjusted.columns\n",
    "\n",
    "std_indexes_seas_adj.columns = seasonally_adjusted.columns\n",
    "    \n",
    "seasonal_indexes_seas_adj = seasonal_indexes_seas_adj.T\n",
    "\n",
    "std_indexes_seas_adj = std_indexes_seas_adj.T\n",
    "\n",
    "sector_performances_sea_adj = pd.DataFrame()\n",
    "sector_performances_values_sea_adj = pd.DataFrame()\n",
    "for c in seasonally_adjusted.T.columns:\n",
    "    temp = pd.DataFrame(seasonally_adjusted.T[c].sort_values(ascending=False).index,columns=[c])\n",
    "    temp2 = pd.DataFrame(seasonally_adjusted.T[c].sort_values(ascending=False),columns=[c])\n",
    "    temp2.reset_index(drop=True,inplace=True)    \n",
    "    sector_performances_sea_adj = pd.concat([sector_performances_sea_adj,temp],axis=1)\n",
    "    sector_performances_values_sea_adj = pd.concat([sector_performances_values_sea_adj,temp2],axis=1)\n",
    "\n",
    "A = sector_performances_values_sea_adj\n",
    "B = sector_performances_sea_adj\n",
    "\n",
    "df_sea_adj = B.style.apply(b_g,cmap='RdYlGn')\n",
    "display(df_sea_adj)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920b39b6-9237-4645-bbdb-8a34dfa1c6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d032d-0cf3-400a-a801-185619948a14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "index_performance = []\n",
    "for v in indexes['Symbol'].values:\n",
    "    index_performance.append([v,screener.loc[v]['risk_trend_factor']])\n",
    "temp_i = pd.DataFrame(index_performance,index=indexes.index)\n",
    "temp_i.columns = ['Symbol','risk_trend_factor']\n",
    "index_risk_sorted = pd.DataFrame(index_performance,columns=['Symbol','risk_trend_factor'],index=indexes.index).sort_values(by='risk_trend_factor',ascending=False).reset_index()\n",
    "index_risk_sorted.columns = ['Index','Symbol','risk_trend_factor']\n",
    "index_risk_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56630f8-6533-4540-856b-d8d9451ef65b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sector_performance = []\n",
    "for v in sectors['Symbol'].values:\n",
    "    sector_performance.append([v,screener.loc[v]['risk_trend_factor']])\n",
    "temp_v = sectors.reset_index()\n",
    "temp_v.columns = ['Sector','Symbol']\n",
    "sectors_risk_sorted = pd.DataFrame(sector_performance,columns=['Symbol','risk_trend_factor']).merge(temp_v, on='Symbol', how='left').sort_values(by='risk_trend_factor',ascending=False)    \n",
    "sectors_risk_sorted\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9a2ec6-395f-4da5-bfa5-7e7c988ae08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a771c-5610-4928-a935-9b82d1fb9cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Rolling Quarterly Mean Return\")\n",
    "plt.plot(sector_performance_Q_smoothed_return)\n",
    "plt.legend([*[i for i in indexes.index],*[v for v in sectors.index]],loc=2,fontsize=7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c50ea-5870-498b-b7da-617d97c578f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13a3ec-5048-4acc-ab5c-f798e1216b86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (\"Quarterly Returns\")\n",
    "for v in sector_performance_return.T.index:\n",
    "    subset = pd.DataFrame(sector_performance_return.T.loc[v])\n",
    "    subset.columns = ['Return']\n",
    "    plt.plot(subset)\n",
    "    plt.xticks(subset.index, rotation=45)\n",
    "plt.legend(sector_performance_return.T.index,loc=2)    \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf881ad7-da51-46d1-b8c9-eb903b7aa6f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0716a-3b2d-43e9-93b3-c659efa306d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "plt.plot(seasonal_indexes[si].T)\n",
    "plt.legend(seasonal_indexes[si].T.columns,loc=2,fontsize=8)\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07a954f-1e41-4112-a980-a9691a8f63c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59a21d-0820-4a62-908f-54ecac2e45f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683e62d-4d0e-476d-afa3-52ad82a1c96c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e546c98-ca0c-425c-acb2-7a3f965c2a4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#risk_trend_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebd8fd4-950c-4bc9-ba28-af6baf1ae54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71ada5-3b22-4191-90d1-f15b7fb7e5cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#market_data['sector'] = stock_fundamentals['sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa318b-d659-4ccc-a9f0-690cf4ceac36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadf398b-c971-4a14-a7ed-9fd5c2b7a3ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c01705-6411-4957-90f6-521e7155ce71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a825ee5-d4bd-4637-b588-f5118cf49f39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#screener[['risk_trend_factor']].replace(['missing','error'], np.NaN).dropna().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25448842-ee84-4647-87e3-d992eef0bc9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(screener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062f3156-444c-451b-a326-9df38293d66c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e93bc0-29aa-45fe-8c9e-6a8a5596a8e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#prices_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b194139-71d1-4533-a98f-365fd3091584",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a887c1c3-269e-4ff7-97d7-0f629b1e02e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfda1b2-a4a5-4d30-a1cb-de0c8cf35c62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82bceec-0d5c-4f79-a610-dead31b3a405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607a019-d78d-40f1-b870-f3e9c8b0f7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f70f23-e164-4cbc-9b36-56179475fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16abc74-da31-4bb2-bd4b-f4c04e0a671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#threshold_value = summary.dropna()['risk_trend_factor'].quantile([threshold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82b6deb-8a67-4153-82df-5c163093db01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752e4361-ac3b-4d6e-b549-eb253ef708ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af351818-c6ba-4266-a7c4-e51749929cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae8bc3-ac12-4d8e-813f-8a40be23dfd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de65f6cf-37e8-4d73-934b-5f59ad2c69f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a417218-6f64-46c7-98b4-86a5f7f3257a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9700e2-c4a4-43a9-8a16-247223bbee76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f712bf-fdfc-4ad7-91a8-a06e2eaeead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fred_pvt_sample = completed_fred_pvt_df[fred_names].asfreq('D').interpolate(method='time').asfreq('Q').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c7f72-2513-4f5c-9667-905ccaf3887b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bd232d-8b14-4a80-8936-9aef1d831282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13f9bc2-d935-4b61-82a7-b71a59ecaf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "screener_sorted.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15d6116-d3eb-4e6f-abc2-7c0590e2c51b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ff5e6f-7fdc-45af-93bb-5805a16c3f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18049f-28ca-456f-afbe-7d16941b6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "      r_from_pd_df = ro.conversion.py2rpy(fred_pvt_sample.melt(ignore_index=False).reset_index().rename(columns={'index': 'Date'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd0649-1c64-4f77-8a14-ee9db088a4f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ro.X11()\n",
    "#ro.windows()\n",
    "ro.r('''\n",
    "\n",
    "my_mean <- function(x, na.rm=TRUE) {\n",
    "  mean(x, na.rm = na.rm)\n",
    "}\n",
    "\n",
    "f <- function(y) {\n",
    "#print(y)\n",
    "\n",
    "#library(arfima)\n",
    "#varvefd = arfima(y)\n",
    "#d = summary(varvefd)$coef[[1]][1]\n",
    "#return(d)\n",
    "\n",
    "tsfeature_tbl <- y %>%\n",
    "group_by(variable) %>%\n",
    "tk_tsfeatures(\n",
    "  .date_var = Date,\n",
    "  .value    = value,\n",
    "  .period   = 4,\n",
    "  .features = c(\"frequency\", \"stl_features\", \"entropy\", \"acf_features\", \"my_mean\"),\n",
    "  .scale    = TRUE,\n",
    "  .prefix   = \"ts_\"\n",
    ") %>%\n",
    "ungroup()\n",
    "    \n",
    "print(tsfeature_tbl)\n",
    "\n",
    "set.seed(123)\n",
    "\n",
    "cluster_tbl <- tibble(\n",
    "    cluster = tsfeature_tbl %>% \n",
    "        select(-variable) %>%\n",
    "        as.matrix() %>%\n",
    "        kmeans(centers = 7, nstart = 100) %>%\n",
    "        pluck(\"cluster\")\n",
    ") %>%\n",
    "    bind_cols(\n",
    "        tsfeature_tbl\n",
    "    )\n",
    "\n",
    "cluster_tbl\n",
    "\n",
    "cluster_tbl %>%\n",
    "    select(cluster, variable) %>%\n",
    "    right_join(y, by = \"variable\") %>%\n",
    "    group_by(variable) %>%\n",
    "    plot_time_series(\n",
    "      Date, value, \n",
    "      .color_var   = cluster, \n",
    "      .facet_ncol  = 2, \n",
    "      .interactive = FALSE\n",
    "    )\n",
    "plot(cluster_tbl)\n",
    "\n",
    "return(tsfeature_tbl)\n",
    "}\n",
    "''')\n",
    "grdevices.png(file=\"temp.png\", width=4096, height=1024)\n",
    "r_f = ro.globalenv['f']\n",
    "d=(r_f(r_from_pd_df))\n",
    "#rprint(pp)\n",
    "\n",
    "time.sleep(3)\n",
    "#grdevices.dev_copy(device = r.png, filename = \"plot.png\", width = 1000, height = 500)\n",
    "grdevices.dev_off()\n",
    "\n",
    "#From here optional, if you want a waiting time\n",
    "#Elsewise close the plot manually afterwards with grdevices.dev_off()\n",
    "\n",
    "#grdevices.dev_off()\n",
    "#grdevices.dev_off()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a8247-911b-467d-b2b8-b777e9b3b500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b3f3de-8061-4f38-af34-954d2ffe48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.99, svd_solver='full')\n",
    "\n",
    "X = np.array(d.iloc[:,1:])\n",
    "\n",
    "pca.fit(scale(X))\n",
    "#pca.explained_variance_\n",
    "pca.explained_variance_ratio_.cumsum()\n",
    "X_pca = pd.DataFrame(pca.transform(d.iloc[0:,1:]))\n",
    "X_pca.index = d.index\n",
    "X_pca.sort_values(by=[0],ascending=False,inplace=True)\n",
    "\n",
    "TSS_ = []\n",
    "BSS_ = []\n",
    "WSS_ = []\n",
    "silhouettes_ = []\n",
    "\n",
    "for k in range(2,int(len(d)/2)):\n",
    "    model = KMeans(n_clusters=k, random_state=0, n_init=100).fit(X)\n",
    "    #print(model.inertia_)\n",
    "\n",
    "    codebook = np.array(model.cluster_centers_)\n",
    "    partition, euc_distance_to_centroids = vq(X, codebook)\n",
    "    WSS = np.sum(euc_distance_to_centroids**2)\n",
    "    \n",
    "    silhouette_avg = silhouette_score(X, model.labels_)\n",
    "\n",
    "    silhouettes_.append(silhouette_avg)\n",
    "    \n",
    "    TSS = np.sum((X-X.mean(0))**2)\n",
    "\n",
    "    BSS = TSS - WSS\n",
    "\n",
    "    TSS_.append(TSS)\n",
    "    BSS_.append(BSS)\n",
    "    WSS_.append(WSS)\n",
    "    \n",
    "    #print(TSS, WSS, BSS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653a9a21-21c3-4031-80f2-d4fc12e11b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "init_min = 2\n",
    "init_max = 5\n",
    "\n",
    "\n",
    "mink = 2\n",
    "maxk = 6\n",
    "\n",
    "tss, bss, wss = findOptimalK_ANOVA(X_pca, mink = mink, maxk = maxk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0182f2bd-0ff2-40af-a11e-b7bf788584f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(BSS_)/np.array(TSS_))\n",
    "plt.show()\n",
    "plt.plot(np.array(WSS_))\n",
    "plt.show()\n",
    "plt.plot(np.array(silhouettes_))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cb8154-dbdd-499b-9c36-db1a30aa1c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e15fa52-a62e-4ba0-922a-bd573c1c9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bss_ = findknee(bss)\n",
    "bss_ = bss_/np.max(bss_)\n",
    "\n",
    "wss_ = findknee(np.array(pd.DataFrame(wss).mean(1)))\n",
    "wss_ = wss_/np.max(wss_)\n",
    "\n",
    "temp_df = pd.DataFrame(bss_/wss_).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "temp_df.index = np.array(range(0,len(wss_)))+mink\n",
    "#plt.plot(temp_df)\n",
    "\n",
    "set_ = np.abs(temp_df-1)\n",
    "plt.plot(set_)\n",
    "\n",
    "optimal_k = np.argmin(set_)+mink\n",
    "plt.plot(abs(set_-1))\n",
    " \n",
    "print(optimal_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028bfb7a-bfe8-49a1-909e-6d43111d55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeansConstrained(n_clusters=optimal_k, size_min=init_min, size_max=max(np.ceil(len(X_pca)/optimal_k),init_max), init='k-means++', n_init=100, max_iter=100, tol=0.0001, verbose=False, random_state=None, copy_x=True, n_jobs=4)\n",
    "clf.fit_predict(X_pca)\n",
    "\n",
    "labels = clf.labels_\n",
    "clusters = clf.n_clusters\n",
    "centers = clf.cluster_centers_\n",
    "\n",
    "print(labels)\n",
    "\n",
    "tot_ss, BSS, within_ss = deriveANOVA(clf, X_pca)\n",
    "\n",
    "Global_F = (BSS/(optimal_k-1))/(np.mean(within_ss)/(len(X_pca)-optimal_k))\n",
    "global_sig = 1-f.cdf(Global_F, (len(X_pca)-optimal_k), len(X_pca)-1)\n",
    "\n",
    "ind_F_scores = []\n",
    "\n",
    "for w in range(0,len(within_ss)):\n",
    "\n",
    "    dfn = (optimal_k-1)\n",
    "    dfd = np.sum(labels==w)-optimal_k\n",
    "\n",
    "    F_score = (BSS/dfn)/(within_ss[w]/(dfd))\n",
    "    ind_F_scores.append(F_score)\n",
    "\n",
    "print(\"Global F:\",Global_F)\n",
    "print(\"Global Sig:\",global_sig)\n",
    "print(\"F-Scores:\", ind_F_scores)\n",
    "\n",
    "print(\"P-Scores:\", 1-f.cdf(ind_F_scores, dfn, dfd))\n",
    "\n",
    "X_pca['cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04cef0f-e105-4f71-b08b-5226cc57ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cgram = Clustergram(range(1, 8))\n",
    "cgram.fit(X_pca)\n",
    "cgram.plot()\n",
    "cgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db8ad00-876f-4195-8bb2-ec182817c429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f3b67c-592c-48b4-9e52-97812142e28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc809f-27df-4db2-918d-eb5496f5299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lengths = []\n",
    "for i in range(0,max(X_pca['cluster'])+1):\n",
    "    subset = d.loc[X_pca[X_pca['cluster']==i].index]\n",
    "    lengths.append(len(subset))\n",
    "    \n",
    "colors = ['purple','cyan','magenta','green','red','black','pink']\n",
    "my_cmap = LinearSegmentedColormap.from_list(\n",
    "    'color_map', colors, N=max(lengths))\n",
    "\n",
    "rescale = lambda y: (y - 0) / (np.max(lengths) - 0)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94de78e2-847e-4044-9fcb-e0798132dbea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a276e51-ce5a-43d8-bbef-272a29f5e540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29285c32-a8a3-4d7a-8600-ad54cb706f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad79d82-c86c-4cdf-828e-f94854396614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323c95fe-6d63-4635-895e-a5af8475783e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab0e88-5ea1-46ab-93b2-63645d9db8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5a288-32a8-4b02-9e31-bce3ea409bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32854f93-3815-48fc-9556-ead47cdf1c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce802a-6ce4-44d7-9e77-0704dc7d495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(0,max(X_pca['cluster'])+1):\n",
    "    print(\"Group: \",i)\n",
    "    subset = d.loc[X_pca[X_pca['cluster']==i].index]\n",
    "    #\n",
    "    for c_ in range(0,len(subset['variable'])):\n",
    "        c = subset['variable'].values[c_]\n",
    "        #print(dict_fred[c])\n",
    "        display(html_print(' '.join([cstr(ti, color=ci) for ti,ci in ((dict_fred[c], colors[c_]),)])))\n",
    "        \n",
    "        #display(html_print(' '.join([cstr(ti, color=my_cmap(rescale(c_))) for ti in (('hello my name is'),)])))\n",
    "        #print(colored(\"hello red world\", my_cmap(rescale(c_))))\n",
    "        if(c_==0):\n",
    "            fig, ax1 = plt.subplots( figsize=(30,4))\n",
    "            ax1.plot(fred_pvt_sample[c],color=my_cmap(rescale(c_)))\n",
    "            ax1.get_yaxis().set_ticks([])\n",
    "        else: \n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(fred_pvt_sample[c],color=my_cmap(rescale(c_)))\n",
    "            ax2.get_yaxis().set_ticks([])\n",
    "    #ax1.legend(subset['variable'].values,loc=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ef1d40-755f-43a0-a306-b26273cc1393",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ = fred_pvt_sample.columns.tolist()\n",
    "def f3(Y):\n",
    "    \n",
    "    #Y = x\n",
    "    #output_slider_variable.value\n",
    "    internalFilter = filter_.copy()\n",
    "    internalFilter.remove(Y)\n",
    "    all_data_ = pd.concat([fred_pvt_sample[Y],fred_pvt_sample[internalFilter]], axis=1)    \n",
    "    #print(all_data_.describe())\n",
    "    display(fred_pvt_sample.describe())\n",
    "    #x_ticks = all_data_.index[np.arange(0, len(all_data.index), int(len(internalFilter)/5))]\n",
    "    x_ticks  = []\n",
    "    for index, element in enumerate(fred_pvt_sample.index):\n",
    "        if index % int(np.round(len(fred_pvt_sample.index)/10)) == 0:\n",
    "            x_ticks.append(element)\n",
    "    plt.plot(fred_pvt_sample[Y])\n",
    "    plt.xticks(x_ticks, rotation = 45)\n",
    "    plt.show()        \n",
    "    plt.hist(fred_pvt_sample[Y], bins='auto')\n",
    "    plt.show()\n",
    "    diff = pd.DataFrame((fred_pvt_sample[Y].pct_change())).dropna()\n",
    "    plt.hist(diff, bins='auto')\n",
    "    plt.show()\n",
    "    return(fred_pvt_sample)\n",
    "    \n",
    "out = interactive(f3, Y=filter_)\n",
    "\n",
    "#output_slider_variable.observe(f4, 'value')\n",
    "\n",
    "print(\"choose Y\")\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81fcd6-e8a7-4fb6-a874-e9edb8f4f3b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b2b91-888f-4d53-9336-295f64e41028",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('nominal,','pct_change,','pct_change().cumsum')\n",
    "for pos in range(0,len(fred_names)):\n",
    "    print(fred_friendly_names[pos],fred_names[pos])\n",
    "    name = fred_names[pos]\n",
    "    \n",
    "    \n",
    "    f, (ax1, ax2, ax3) = plt.subplots(1, 3, sharey=False,figsize=(15,6))\n",
    "    ax1.plot(completed_fred_pvt_df[name])\n",
    "    ax1.set_xticklabels(np.array(completed_fred_pvt_df.index.map(lambda t: t.strftime('%Y-%m-%d')))[np.arange(0,len(completed_fred_pvt_df.index),int(len(completed_fred_pvt_df.index)/10))], rotation=45)\n",
    "    ax2.plot(completed_fred_pvt_df[name].pct_change())\n",
    "    ax2.set_xticklabels(np.array(completed_fred_pvt_df.index.map(lambda t: t.strftime('%Y-%m-%d')))[np.arange(0,len(completed_fred_pvt_df.index),int(len(completed_fred_pvt_df.index)/10))], rotation=45)\n",
    "    ax3.plot(completed_fred_pvt_df[name].pct_change().cumsum())\n",
    "    ax3.set_xticklabels(np.array(completed_fred_pvt_df.index.map(lambda t: t.strftime('%Y-%m-%d')))[np.arange(0,len(completed_fred_pvt_df.index),int(len(completed_fred_pvt_df.index)/10))], rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f248ba-d0b2-4b25-a9ca-ac78643ce98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#screener['vol_30d_2yr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77c752f-c4e7-4beb-bb9a-2dad9d0f4aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3447fa06-6e2a-4b18-b40c-817411a5980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(np.mean(np.exp(final_model.get_prediction(start=end,end=(end + dt.timedelta(92)).strftime('%Y-%m-%d')).summary_frame())[['mean','pi_lower']],axis=1)).iloc[0].values[0]\n",
    "#[s,e_return,s_date,stop_loss_price,days_delta,discounted_return,qtr_return,test_score_mean,test_score_std,mean_revert_flag,p_metrics['pi_lower'].values[0],p_metrics['pi_upper'].values[0]]\n",
    "#screener['Adj Close'].loc[decision_metrics_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c39487-0321-4d3e-94f9-ae163abafb33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63de933-72ca-4216-8c1b-a10efcce5939",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1279851-e29f-4c5d-adc6-55c80fc583ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e129ba4d-965f-4ffb-8471-5b1a0a5db5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd4f89b-d24b-46ab-a9d0-20c8819aeb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fcedb9-fc57-4852-9bc6-dd38793ae013",
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "#tscv = expanding_window(initial =52*2, horizon = 13,period = 26)\n",
    "\n",
    "#batchClearLimit = round(len(list__)/7)\n",
    "\n",
    "print(\"adf < .05 or .01, mean reverting\")\n",
    "print(\"Hurst\")\n",
    "print(\"> .5 - The time series is mean reverting.\")\n",
    "print(\"= .5 - The time series is a Geometric Brownian Motion.\")\n",
    "print(\"< .5 - The time series is trending.\")\n",
    "\"\"\"*indexes['Symbol'].values,*sectors['Symbol'].values,\"\"\"\n",
    "\"\"\"\n",
    "widgets.Dropdown(\n",
    "    #options=stocks_,\n",
    "    #value=None,\n",
    "    description='Choose Stock:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "#y_=widgets.Select(options=stocks_,disabled=False)\n",
    "y_=widgets.Select(options=np.sort([*list_sector_n_indexes,*list_stocks]),value=None,disabled=False)\n",
    "\n",
    "a=interact(plot_,symbol_=y_)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca27382f-ba19-4183-a194-bcef3ecf80b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600a413-19fe-4269-94e3-2bebd2256e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c360e69-f4ec-46f6-8fc7-ebd445ef5f9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "0526ba40-0c06-496b-a60f-fdaef16a7cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c15b52a522d4208955fe3a223e25fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(SelectMultiple(description='Choose Sectors: ', options=('Basic Materials', 'Communicatio"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_values(values):\n",
    "    \n",
    "    sector_list = []\n",
    "    symbol_list = []\n",
    "    for i in np.array(values):\n",
    "        t= dict_sectors[i]\n",
    "        sector_list.append(t)\n",
    "        \n",
    "        sublist = screener_sorted[screener_sorted['Sector Symbol']==t].index\n",
    "        temp_df = screener_sorted.loc[sublist]\n",
    "        temp_df_ = temp_df['risk_trend_factor'].replace(['error','missing'], np.nan).dropna()\n",
    "        temp_df_filtered = temp_df_[temp_df_>0]\n",
    "        \n",
    "        flat_list = [item for item in temp_df_filtered.index]\n",
    "        symbol_list.extend(flat_list)        \n",
    "    \n",
    "    button = widgets.Button(description=\"Process\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    display(button, output)\n",
    "\n",
    "    print(\"Symbols > 0 trend_factor_score\")\n",
    "    print(len(sector_list),sector_list)\n",
    "    print(len(symbol_list),symbol_list)\n",
    "    \n",
    "    def on_button_clicked(b):\n",
    "        with output:            \n",
    "            plot_(symbol_list)\n",
    "\n",
    "    button.on_click(on_button_clicked)    \n",
    "    \n",
    "y_=widgets.SelectMultiple(\n",
    "    options=list(dict_sectors.keys()),\n",
    "    description='Choose Sectors: ',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "a=interact(process_values,values=y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8298663-0813-465b-8044-251da8d62ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4568abb2-b2b9-493a-99ee-e77813ccf43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
