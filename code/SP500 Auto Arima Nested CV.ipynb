{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a198babb-66b8-4bce-a5d9-cc61beb382e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as web\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "import pandas_market_calendars as mcal\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, KFold, cross_val_score, RepeatedKFold, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib\n",
    "from scipy import stats\n",
    "\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "from IPython.display import clear_output\n",
    "import time \n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import pmdarima as pm\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "import sys\n",
    "#if not sys.warnoptions:\n",
    "import warnings\n",
    "    \n",
    "from dask.distributed import Client\n",
    "from dask.distributed import as_completed\n",
    "\n",
    "pd.set_option(\"max_rows\", 10)\n",
    "\n",
    "start = \"1970-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61da52-3213-4aaf-803f-715478b2909e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp500_ancient = web.DataReader(\"^GSPC\", \"yahoo\",start=start)\n",
    "sp500 = web.DataReader(\"^GSPC\", \"yahoo\",start=start)\n",
    "vix = web.DataReader(\"VIXCLS\",\"fred\",start=start)\n",
    "T10Y3M = web.DataReader(\"T10Y3M\",\"fred\",start=start)\n",
    "FEDFUNDS = web.DataReader(\"FEDFUNDS\",\"fred\",start=start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ba1031-ae05-491b-b285-bcd7a8b9279e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4112b-b0b2-41de-a593-2bec7ccf1743",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae4ed5-8ddc-47a1-8947-60c76b5b1e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a94223b-9993-4114-820a-17985329fbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06032d7-4d4c-45c9-b29e-d4c7444b4f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adb4c5c-a727-40ba-af31-f2505066f3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = sp500[['Adj Close']].asfreq('Q',method='Pad')\n",
    "\n",
    "#cv_outer = KFold(n_splits=k_, shuffle=False)\n",
    "#cv_outer = train_test_split(data_, test_size=0.3, random_state=0,shuffle=False,)\n",
    "\n",
    "k_=3\n",
    "#tscv_outer = TimeSeriesSplit(n_splits=k_,max_train_size=int(len(data_)/k_),test_size=int(len(data_)/k_))\n",
    "tscv_outer = TimeSeriesSplit(n_splits=k_)\n",
    "\n",
    "outer_results = []\n",
    "outer_models = []\n",
    "\n",
    "outer_sets = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(tscv_outer.split(data_)):\n",
    "    print(\"Fold: {}\".format(fold))\n",
    "    print(\"TRAIN indices:\", train_index, \"\\n\", \"TEST indices:\", test_index)\n",
    "    print(\"\\n\")\n",
    "    X_train, X_test = data_.iloc[train_index], data_.iloc[test_index]\n",
    "    outer_sets.append([X_train, X_test])\n",
    "    #y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\"\"\"\n",
    "#for trainv_ix, test_ix in cv_outer.split(data_):\n",
    "#for trainv_ix, test_ix in cv_outer.split(data_):\n",
    "\n",
    "#data_index = ts_cv_kfolds(data_.index,k_,True,.75)\n",
    "\n",
    "#for di in range(0,len(data_index[0]),1):\n",
    "for trainv_ix, test_ix in tscv_outer.split(data_):\n",
    "    #trainv_ix = data_index[0][di]\n",
    "    #test_ix = data_index[1][di]\n",
    "    \n",
    "    # split data\n",
    "    #for i in range(0,len(data_index[0])):\n",
    "        #print(i)\n",
    "    X_trainv, X_test = data_.iloc[trainv_ix], data_.iloc[test_ix]\n",
    "    outer_sets.append([X_trainv, X_test])\n",
    "    #y_trainv, y_test = y.iloc[trainv_ix], y.iloc[test_ix]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d22e5-24b3-4497-be93-20df1b713157",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668e7c85-2472-4916-b50d-7f7dfb4ed8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outer_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fcff86-f624-4a7d-b920-c345660cecde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68f4bb8-9277-4280-8d8a-e5cd438ecc44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce550f31-d3f9-40e1-9e05-f7bf934097df",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(o[0]) for o in outer_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc80b97-d2b1-4e76-b4b1-4604f487a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(o[1]) for o in outer_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e0090-85e3-44eb-9d7f-1fa08344bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#[o[0] for o in outer_sets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10591ea7-0ea6-473c-bd79-1dcf94c983f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7b0d7c-0316-4c9a-920d-2ad5f9bcecc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_arima(test_sets,model_=False):\n",
    "    \n",
    "    k_=2\n",
    "    \n",
    "    #cv_inner = KFold(n_splits=k_, shuffle=False)\n",
    "    #tscv_inner = TimeSeriesSplit(n_splits=k_,max_train_size=int(len(test_sets[0])/k_),test_size=int(len(test_sets[0])/k_))    \n",
    "    tscv_inner = TimeSeriesSplit(n_splits=k_)\n",
    "    \n",
    "    X_trainv = test_sets[0]\n",
    "    #print(X_trainv)\n",
    "    X_test = test_sets[1]\n",
    "    #print(X_test)\n",
    "    #print(X_test.index)\n",
    "    \n",
    "    inner_results = list()\n",
    "    inner_models = list()\n",
    "\n",
    "    #for trainv_ix, test_ix in ts_cv_kfolds(data_.index,k_):\n",
    "    \n",
    "    # split data\n",
    "    \n",
    "    #X_trainv, X_test = data_.loc[trainv_ix], data_.loc[test_ix]\n",
    "    \n",
    "    #good juncture to fork locally\n",
    "    #for train_ix, valid_ix in tscv_inner.split(X_trainv):\n",
    "    #for train_ix, valid_ix in cv_inner.split(X_trainv):\n",
    "    X_valids = []\n",
    "    \n",
    "    for fold, (train_ix, valid_ix) in enumerate(tscv_inner.split(X_trainv)):\n",
    "        #print(\"Fold: {}\".format(fold))\n",
    "        #print(\"TRAIN indices:\", train_ix, \"\\n\", \"TEST indices:\", valid_ix)\n",
    "        #print(\"\\n\")\n",
    "        X_train, X_valid = X_trainv.iloc[train_ix], X_trainv.iloc[valid_ix]\n",
    "        \n",
    "        X_valids.append(X_valid)\n",
    "        \n",
    "        #y_train, y_valid = y_trainv.iloc[train_ix], y_trainv.iloc[valid_ix]\n",
    "        \n",
    "        #print(X_train)\n",
    "        if (model_==False):\n",
    "            #print(np.shape(X_train))\n",
    "            #model = pm.auto_arima(X_train, seasonal=True, m=4,stepwise=True)\n",
    "            model = pm.auto_arima(X_train, seasonal=True, m=4)\n",
    "            #model.fit()\n",
    "            forecasts = model.predict(len(X_valid))  # predict N steps into the future\n",
    "        else:\n",
    "            #else:\n",
    "            model = SARIMAX(X_train,order=model_.order,seasonal_order=model_.seasonal_order, intercept=model_.with_intercept)\n",
    "            model.fit()\n",
    "            #model.fit(disp=0)\n",
    "            #forecasts = model.predict(start=len(X_train)+1,end=len(X_train)+len(X_valid))\n",
    "            \n",
    "            #model_fit = model.fit(start=0, end=len(X_train),exog=X_train,disp=False)\n",
    "            model_fit = model.fit(disp=False)\n",
    "            \n",
    "            forecasts = model_fit.predict(start=len(model_fit.fittedvalues)+1, end=len(model_fit.fittedvalues)+len(X_valid),dynamic=True)\n",
    "            #print(forecasts)\n",
    "            #print(X_valid)\n",
    "            #sm.tsa.statespace.SARIMAX(X_train, seasonal=True, m=4, order=my_order, seasonal_order=my_seasonal_order, ...)\n",
    "            #pm.auto_arima(X_train, seasonal=True, m=4,)\n",
    "            \n",
    "        #plt.figure(figsize  = (8,8))\n",
    "        #plt.title('Forecast result and Test data')\n",
    "        # Visualize the forecasts (blue=train, green=forecasts)\n",
    "        #x = np.arange(y.shape[0])\n",
    "        #plt.plot(x[:150], train, c='blue')\n",
    "        #plt.plot(x[150:], forecasts, c='green', label = 'ARIMA Forecast')\n",
    "        #plt.plot(x[150:], test, c='red', label = 'Test Data')\n",
    "        #plt.legend()\n",
    "        #plt.show()\n",
    "        \n",
    "        inner_models.append(model)\n",
    "\n",
    "        #yhat = model.predict(X_valid[t])\n",
    "        yhat = forecasts\n",
    "        # evaluate the model\n",
    "        acc = np.mean(abs(X_valid.values.ravel()-forecasts))\n",
    "        # store the result\n",
    "        inner_results.append(acc)\n",
    "        # report progress\n",
    "        #print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "        # summarize the estimated performance of the model\n",
    "\n",
    "    #good juncture to fork locally\n",
    "    model_scores = list()\n",
    "\n",
    "    #test inner model as ansemble\n",
    "    for m_ in range(0,len(inner_models),1):\n",
    "        m = inner_models[m_]\n",
    "        X_valid = X_valids[m_]\n",
    "        \n",
    "        if(str(type(m))==\"<class 'statsmodels.tsa.statespace.sarimax.SARIMAX'>\"):\n",
    "            \n",
    "            #model_fit = m.fit(disp=0)\n",
    "            model_fit = m.fit(disp=False)\n",
    "            forecasts = model_fit.predict(start=len(model_fit.fittedvalues)+1,end=len(X_test)+len(X_valid))\n",
    "\n",
    "            predict = model_fit.predict(start=(len(model_fit.fittedvalues)+len(X_valid)+1),end=(len(model_fit.fittedvalues)+len(X_valid)+len(X_test)))\n",
    "            #print(predict)\n",
    "            model_scores.append(np.mean(abs(predict)-X_test.values.ravel()))\n",
    "        else:\n",
    "            \n",
    "            model_scores.append(np.mean(abs(m.predict(len(X_test))-X_test.values.ravel())))\n",
    "\n",
    "    #average internal model results and report as outer_result which*\n",
    "    return([np.mean(np.abs(model_scores)),inner_models])\n",
    "    #outer_results.append(np.mean(np.abs(model_scores)))\n",
    "    #outer_models.append(inner_models)\n",
    "\n",
    "    #print('I Accuracy: %.3f (%.3f)' % (mean(inner_results), std(inner_results)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2e5e5-923e-4104-b51b-807c329091c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedceb44-33e7-4a43-87d1-5cf3fa8d9b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_arima(outer_sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6972e29-fc22-46f5-8e89-8fa50c6e2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ARIMA(data_, order=(0,0,0))\n",
    "#model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34cd09-8b4c-4ae6-aa25-be0dfd8dbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_arima_model(X_train, X_test, arima_order):\n",
    "    # prepare training dataset\n",
    "    # make predictions\n",
    "    history = [x for x in X_train.values]\n",
    "    predictions = list()\n",
    "    for t in range(0,len(X_test),1):\n",
    "        model = ARIMA(history, order=arima_order)\n",
    "        model_fit = model.fit()\n",
    "        yhat = model_fit.forecast()[0]\n",
    "        #print(yhat)\n",
    "        predictions.append(yhat)\n",
    "        history.append(X_test.values[t])\n",
    "    # calculate out of sample error\n",
    "    #SEM\n",
    "    SEM = np.sqrt(np.sum(np.power((X_test.values - predictions),2))/(len(X_test)-1))\n",
    "    #error = mean_squared_error(X_test, predictions)\n",
    "    #print(SEM)\n",
    "    return SEM\n",
    "\n",
    "def evaluate_models(X_train, X_test, orders):\n",
    "    best_score, best_cfg = float(\"inf\"), None\n",
    "    parameters = []\n",
    "    for o in orders:\n",
    "        order = o\n",
    "   \n",
    "    rmse = evaluate_arima_model(X_train, X_test, order)\n",
    "    if rmse < best_score:\n",
    "        best_score, best_cfg = rmse, order\n",
    "    #print('ARIMA%s RMSE=%.3f' % (order,rmse))\n",
    "    #print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))\n",
    "    return([best_cfg, best_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "532196ff-eb4a-4c34-8888-7a9b4c14851d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 0, 1), 7517.0647067634345],\n",
       " [(2, 0, 1), 8171.49011504315],\n",
       " [(2, 0, 1), 7229.464139381818],\n",
       " [(2, 0, 1), 6391.825279838172],\n",
       " [(2, 0, 1), 7083.866923979185],\n",
       " [(2, 0, 1), 7837.371912954673],\n",
       " [(2, 0, 1), 5640.745368676535],\n",
       " [(2, 0, 1), 6399.824664090937],\n",
       " [(2, 0, 1), 7882.76387574643],\n",
       " [(2, 0, 1), 6627.652901344845]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db8c8a3-73ec-4d37-be47-55bed95850a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#outer_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3d5b087-5359-4c06-842e-444ed0ccd95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "X = data_\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "bestModels = []\n",
    "\n",
    "outer_results = []\n",
    "\n",
    "for train_ix, test_ix in cv_outer.split(X):\n",
    "\n",
    "    X_train, X_test = X.iloc[train_ix], X.iloc[test_ix]\n",
    "    \n",
    "    tscv_inner = TimeSeriesSplit(n_splits=k_)\n",
    "    \n",
    "    X_trainv = X_train\n",
    "   \n",
    "    inner_results = list()\n",
    "    inner_models = list()\n",
    "\n",
    "    #for trainv_ix, test_ix in ts_cv_kfolds(data_.index,k_):\n",
    "    \n",
    "    # split data\n",
    "    \n",
    "    #X_trainv, X_test = data_.loc[trainv_ix], data_.loc[test_ix]\n",
    "    \n",
    "    orders = [\n",
    "    (1,0,1),\n",
    "    (0,1,0),\n",
    "    (0,2,1),\n",
    "    (0,2,3),\n",
    "    (2,0,1)]\n",
    "    \n",
    "    intercepts = [True,False]\n",
    "    \n",
    "    #good juncture to fork locally\n",
    "    #for train_ix, valid_ix in tscv_inner.split(X_trainv):\n",
    "    #for train_ix, valid_ix in cv_inner.split(X_trainv):\n",
    "    X_valids = []\n",
    "    \n",
    "    for fold, (train_ix, valid_ix) in enumerate(tscv_inner.split(X_trainv)):\n",
    "        #print(\"Fold: {}\".format(fold))\n",
    "        X_train, X_valid = X_trainv.iloc[train_ix], X_trainv.iloc[valid_ix]\n",
    "        \n",
    "        X_valids.append(X_valid)\n",
    "        \n",
    "        cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "        bestModels.append(evaluate_models(X_train, X_valid, orders))\n",
    "    \n",
    "    #apply best model to test data\n",
    "    best_order = stats.mode([b[0] for b in bestModels])[0][0]\n",
    "    outer_results.append([best_order,evaluate_arima_model(X_valid,X_test,best_order)])\n",
    "\n",
    "        \n",
    "    #model_ = ARIMA(data_.values,order=stats.mode([b[0] for b in bestModels])[0][0])\n",
    "    #model_fit = model_.fit()\n",
    "    #forecasts = model_fit.predict(1,len(data_))\n",
    "\n",
    "\n",
    "    \n",
    "    \"\"\"\n",
    "    space = dict()\n",
    "    space['seasonal'] = [True]\n",
    "    space['n'] = [4] \n",
    "    \n",
    "    model = ARIMA()\n",
    "    search = GridSearchCV(model, space, scoring='neg_mean_squared_error', cv=cv_inner, refit=True)\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    model = pm.auto_arima(X_train, seasonal=True, m=4)\n",
    "    \n",
    "    # execute search\n",
    "    #result = model.fit(X_train, y_train)\n",
    "    forecasts = model.predict(len(X_test))  # predict N steps into the future\n",
    "    \n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "    # evaluate model on the hold out dataset\n",
    "    yhat = best_model.predict(X_test)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "    # summarize the estimated performance of the model\n",
    "    print('Accuracy: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d26e550-90b9-433d-8a09-7678906e4c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[array([2, 0, 1]), 7547.706154343495],\n",
       " [array([2, 0, 1]), 7812.891296911062],\n",
       " [array([2, 0, 1]), 7143.723166962982],\n",
       " [array([2, 0, 1]), 6285.849972029581],\n",
       " [array([2, 0, 1]), 6798.240955782283],\n",
       " [array([2, 0, 1]), 7657.907908933533],\n",
       " [array([2, 0, 1]), 5615.339181898318],\n",
       " [array([2, 0, 1]), 6419.842271960961],\n",
       " [array([2, 0, 1]), 7727.467464605026],\n",
       " [array([2, 0, 1]), 6595.929294322947]]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outer_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374cdff-a770-4017-9b40-b5fb8977e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_model = ARIMA(data_,order=stats.mode([b[0] for b in bestModels])[0][0])\n",
    "\n",
    "model_ = ARIMA(data_.values,order=stats.mode([b[0] for b in bestModels])[0][0])\n",
    "model_fit = model_.fit()\n",
    "forecasts = model_fit.predict(1,len(data_))\n",
    "\n",
    "#print(final_model)\n",
    "#final_model.fit()\n",
    "#final_model.predict(start=len(data_), end=len(data_), dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab04d9c-f2ec-4d69-b3ab-02e4745d73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(forecasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696822f8-88d3-463b-b50b-554ab5a29d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370b2f6-d6fe-4cd5-a92d-0acd90642487",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.DataFrame(forecasts))\n",
    "plt.show()\n",
    "plt.plot(data_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3300befe-d492-4095-84d5-7121339ad885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "final_model.fit(disp=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d8cdf8-fa92-478c-b107-7323c31d037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# fit model\n",
    "model = ARIMA(data_, order=stats.mode([b[0] for b in bestModels])[0][0])\n",
    "model_fit = model.fit()\n",
    "# print(model_fit.summary())\n",
    "\n",
    "# plot residual erros\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "#final_model.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f1c19-d5e3-4a83-bfac-d65d96b9c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "plot_acf(residuals)\n",
    "plt.show()\n",
    "plot_pacf(residuals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0084c306-f594-4817-bd38-6a9a05afd574",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for o in range(0,len(outer_sets)):\n",
    "    print(o)\n",
    "    print(inner_arima(outer_sets[o]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704265a-da19-41ba-971c-a8b158ae4a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "#client.restart()\n",
    "\n",
    "future = client.map(inner_arima, outer_sets)\n",
    "\n",
    "results = client.gather(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a12c3a7-8e7b-4896-a168-fd7e49b0eac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea06f9b-e0b0-4c8d-8d52-e1d3a00747ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([r[0] for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f176f8-94d8-4c47-8dbb-819c53eb6e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0][1][0].seasonal_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a71aac-b779-4539-b267-61dfeb18835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0][1][0].order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26679e12-11b9-4941-8fc6-100e43af8351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dir(results[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffe80d3-c833-4ec4-ab51-13ce4942fc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "client = Client('192.168.3.100:8786')\n",
    "#client.restart()\n",
    "\n",
    "future = client.map(evaluate_arima_model, outer_sets)\n",
    "\n",
    "results = client.gather(future)\n",
    "\"\"\"\n",
    "# evaluate an ARIMA model for a given order (p,d,q)\n",
    "def evaluate_arima_model(data_, arima_order):\n",
    "    \n",
    "    k_=3\n",
    "    #tscv_outer = TimeSeriesSplit(n_splits=k_,max_train_size=int(len(data_)/k_),test_size=int(len(data_)/k_))\n",
    "    tscv_outer = TimeSeriesSplit(n_splits=k_)\n",
    "\n",
    "    outer_results = []\n",
    "    outer_models = []\n",
    "\n",
    "    outer_sets = []\n",
    "\n",
    "    for fold, (train_index, test_index) in enumerate(tscv_outer.split(data_)):\n",
    "        print(\"Fold: {}\".format(fold))\n",
    "        print(\"TRAIN indices:\", train_index, \"\\n\", \"TEST indices:\", test_index)\n",
    "        print(\"\\n\")\n",
    "        X_train, X_test = data_.iloc[train_index], data_.iloc[test_index]\n",
    "        outer_sets.append([X_train, X_test])\n",
    "        \n",
    "    for test_sets in outer_sets:\n",
    "        #test_set = 0\n",
    "        k_=2\n",
    "\n",
    "        #cv_inner = KFold(n_splits=k_, shuffle=False)\n",
    "        #tscv_inner = TimeSeriesSplit(n_splits=k_,max_train_size=int(len(test_sets[0])/k_),test_size=int(len(test_sets[0])/k_))    \n",
    "        tscv_inner = TimeSeriesSplit(n_splits=k_)\n",
    "\n",
    "        X_trainv = test_sets[0]\n",
    "        #print(X_trainv)\n",
    "        X_test = test_sets[1]\n",
    "        #print(X_test)\n",
    "        #print(X_test.index)\n",
    "\n",
    "        inner_results = list()\n",
    "        inner_models = list()\n",
    "\n",
    "        x_valids = []\n",
    "        \n",
    "        for fold, (train_ix, valid_ix) in enumerate(tscv_inner.split(X_trainv)):\n",
    "            \n",
    "            X_train, X_valid = X_trainv.iloc[train_ix], X_trainv.iloc[valid_ix]\n",
    "            x_valids.append(X_valid)\n",
    "            \n",
    "            history = [x for x in X_train]\n",
    "            # make predictions\n",
    "            predictions = list()\n",
    "            for t in range(len(X_valid)):\n",
    "                model = ARIMA(history, order=arima_order)\n",
    "                model_fit = model.fit()\n",
    "                yhat = model_fit.forecast()[0]\n",
    "                predictions.append(yhat)\n",
    "                history.append(test[t])\n",
    "            # calculate out of sample error\n",
    "            error = mean_squared_error(test, predictions)\n",
    "\n",
    "            # evaluate the model\n",
    "            acc = np.mean(abs(test-yhat))\n",
    "            # store the result\n",
    "            inner_results.append(acc)\n",
    "            # report progress\n",
    "            #print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "            # summarize the estimated performance of the model\n",
    "\n",
    "        #good juncture to fork locally\n",
    "        model_scores = list()\n",
    "\n",
    "        #test inner model as ansemble\n",
    "        for m_ in range(0,len(inner_models),1):\n",
    "            m = inner_models[m_]\n",
    "            X_valid = x_valids[m_]\n",
    "\n",
    "            if(str(type(m))==\"<class 'statsmodels.tsa.statespace.sarimax.SARIMAX'>\"):\n",
    "\n",
    "                #model_fit = m.fit(disp=0)\n",
    "                model = ARIMA(history, order=arima_order)\n",
    "                model_fit = m.fit(disp=False)\n",
    "                forecasts = model_fit.predict(start=len(model_fit.fittedvalues)+1,end=len(X_test)+len(X_valid))\n",
    "\n",
    "                predict = model_fit.predict(start=(len(model_fit.fittedvalues)+len(X_valid)+1),end=(len(model_fit.fittedvalues)+len(X_valid)+len(X_test)))\n",
    "                #print(predict)\n",
    "                model_scores.append(np.mean(abs(predict)-X_test.values.ravel()))\n",
    "            \n",
    "        #average internal model results and report as outer_result which*\n",
    "    \n",
    "    return(np.mean([r[0] for r in results]))\n",
    "    \n",
    "    return([np.mean(np.abs(model_scores)),inner_models])\n",
    "    #outer_results.append(np.mean(np.abs(model_scores)))\n",
    "    #outer_models.append(inner_models)\n",
    "\n",
    "    #print('I Accuracy: %.3f (%.3f)' % (mean(inner_results), std(inner_results)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f738914-a73d-488c-b77d-371b586d47dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders = [[(1,0,1)],\n",
    "[(0,1,0)],\n",
    "[(0,2,1)],\n",
    "[(0,2,3)],\n",
    "[(2,0,1)]]\n",
    "\n",
    "intercepts = [True,False]\n",
    "\n",
    "parameters = []\n",
    "for o in orders:\n",
    "    for i in intercepts:\n",
    "        parameters.append([o,i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664aa19f-0532-4b4d-bc74-c5c2b8e96217",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = Client('192.168.3.100:8786')\n",
    "#client.restart()\n",
    "\n",
    "future = client.map(inner_arima, outer_sets)\n",
    "\n",
    "results = client.gather(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd9ebf-b08a-41e8-96f2-06bb735b4b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89667b30-c66f-4510-8f56-d83497b01d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5a3a2-673e-4cde-9980-c478cf8c2e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#forecasts = model_.predict(5)  # predict N steps into the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da778ff-2e1d-492e-8826-37f5d6746777",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = pm.auto_arima(data_, seasonal=True, m=4)\n",
    "model = SARIMAX(data_,order=model_.order,seasonal_order=model_.seasonal_order, intercept=model_.with_intercept)\n",
    "#model.fit(disp=0)\n",
    "#forecasts = model.predict(start=len(X_train)+1,end=len(X_train)+len(X_valid))\n",
    "\n",
    "model_fit = model.fit(start=0, end=len(data_),exog=data_,disp=False)\n",
    "forecasts = model_fit.predict(start=len(data_)+1, end=len(data_)+10,dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaff535-aaa6-444e-a8f0-fb19a9bf0d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f8424-ae79-4aff-a7b2-111042c242ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8bd6d7-b302-4111-a1bf-9729031630c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1abb3-2aa2-40a8-897f-5de9f90f7870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d7b00e-5d6d-49fd-b73c-28f48f5b43da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38624de8-bd41-4fa1-9cd2-81f172bad3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1315afb-a166-4bd4-9272-4504d1f5c0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_arima(outer_sets[0],results[0][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a0b436-3315-4282-bdf1-1402c7eeb7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings = []\n",
    "for i in list(matplotlib.cbook.flatten([r[1] for r in results])):\n",
    "    strings.append(str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b18b67-8f77-4475-a064-75dd7b98117c",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf43035-d81f-40a2-8bea-86e2dbbff2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505aebab-b188-4d28-b2e9-1aae8ec65945",
   "metadata": {},
   "outputs": [],
   "source": [
    "[l.order for l in list(matplotlib.cbook.flatten([r[1] for r in results]))]\n",
    "[l.seasonal_order for l in list(matplotlib.cbook.flatten([r[1] for r in results]))]\n",
    "[l for l in list(matplotlib.cbook.flatten([r[1] for r in results]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6403d984-715b-4792-8b3e-2627ebb20d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4918b980-7612-4a65-8382-a09389307a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "string_counts = []\n",
    "\n",
    "for u in np.unique(strings):\n",
    "    #print(u)\n",
    "    count = np.count_nonzero(np.array(strings)==u)\n",
    "    string_counts.append([u,count])\n",
    "    #print(np.array(strings)==u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721a35f4-1fea-474f-9a42-3def8b1a0d81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f3128-7a7b-46e3-b6e7-38caf1041013",
   "metadata": {},
   "outputs": [],
   "source": [
    "[s[0] for s in string_counts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7227039-b324-4d94-ad60-611c2fe69fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_string_counts_df = pd.DataFrame(string_counts,columns=['arima model','times occurred in nested cv']).sort_values(by='times occurred in nested cv',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f7246-06b6-4374-b3a0-b4e2df395809",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sorted_string_counts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68161c86-3a2d-4033-8c23-c8fa3f46bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_string_counts_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0622f-e27c-49c8-8a09-9f59d8162022",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_string_counts_df['arima model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261a96c-ca08-48c1-8c0b-024ba71ee423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inner_arima(outer_sets[0],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5a284-68d8-446f-a271-a12a72ff2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings==np.unique(strings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
