{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec6684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d626f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==1.2.5 pandas_datareader yfinance==0.1.62 ipywidgets pandas_market_calendars matplotlib numpy pycorrelate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655e344-79c7-4326-a116-a163805e71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import concurrent\n",
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "import yfinance as yf\n",
    "import urllib\n",
    "import urllib.request\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from finquant.portfolio import build_portfolio\n",
    "\n",
    "from ipywidgets import interactive\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pycorrelate as pyc\n",
    "import seaborn as sns\n",
    "from yahoofinancials import YahooFinancials\n",
    "\n",
    "import pandas_market_calendars as mcal\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import stats # For in-built method to get PCC\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "#import statsmodels.formula.api as sm\n",
    "import scipy.stats  as stats\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c8e1c-3d8e-4408-95cb-312ae590387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def crosscorrelation(x, y, maxlag, mode='corr'):\n",
    "\t\"\"\"\n",
    "\tCross correlation with a maximum number of lags.\n",
    "\n",
    "\t`x` and `y` must be one-dimensional numpy arrays with the same length.\n",
    "\n",
    "\tThis computes the same result as\n",
    "\t\tnumpy.correlate(x, y, mode='full')[len(a)-maxlag-1:len(a)+maxlag]\n",
    "\n",
    "\tThe return vaue has length 2*maxlag + 1.\n",
    "\t\"\"\"\n",
    "\tpy = np.pad(y.conj(), 2*maxlag, mode='constant')\n",
    "\tT = np.lib.stride_tricks.as_strided(py[2*maxlag:], shape=(2*maxlag+1, len(y) + 2*maxlag),\n",
    "\t\t\t\t   strides=(-py.strides[0], py.strides[0]))\n",
    "\tpx = np.pad(x, maxlag, mode='constant')\n",
    "\tif mode == 'dot':       # get lagged dot product\n",
    "\t\treturn T.dot(px)\n",
    "\telif mode == 'corr':    # gets Pearson correlation\n",
    "\t\treturn (T.dot(px)/px.size - (T.mean(axis=1)*px.mean())) / \\\n",
    "\t\t\t   (np.std(T, axis=1) * np.std(px))\n",
    "\n",
    "def unique(list1):\n",
    "\n",
    "    # intilize a null list\n",
    "    unique_list = []\n",
    "\n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "\n",
    "    return(unique_list)\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "        \n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n",
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6c5b3-f6e4-4531-a68a-535e3ab7457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency = output_variable.value\n",
    "frequency = \"Q\"\n",
    "\n",
    "w=52*8\n",
    "#start = datetime.datetime(2010, 1, 1)\n",
    "\n",
    "#end = datetime.datetime(2013, 1, 27)\n",
    "end_date = datetime.date.today()\n",
    "\n",
    "start_date = end_date - timedelta(weeks=w)\n",
    "\n",
    "pd.set_option('display.max_columns', None) #replace n with the number of columns you want to see completely\n",
    "pd.set_option('display.max_rows', None) #replace n with the number of rows you want to see completely\n",
    "\n",
    "#cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "print(end_date)\n",
    "print(start_date)\n",
    "\n",
    "one_week_end = end_date - 5 * pd.tseries.offsets.BDay()\n",
    "one_week_end = one_week_end.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create a calendar\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "\n",
    "# Show available calendars\n",
    "print(mcal.get_calendar_names())\n",
    "early = nyse.schedule(start_date, end_date)\n",
    "\n",
    "nstocks = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120b6d9-7f81-46e1-9ff4-d8c5df92fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"ftp://ftp.nasdaqtrader.com/symboldirectory/nasdaqtraded.txt\"\n",
    "\n",
    "urllib.request.urlretrieve(url, \"nasdaqtraded.txt\")\n",
    "urllib.request.urlretrieve(url, \"mfundslist.txt\")\n",
    "urllib.request.urlretrieve(url, \"bonds.txt\")\n",
    "\n",
    "df1 = pd.read_csv(\"nasdaqtraded.txt\", sep=\"|\")[0:-1]\n",
    "df2 = pd.read_csv(\"mfundslist.txt\", sep=\"|\")[0:-1]\n",
    "df3 = pd.read_csv(\"bonds.txt\", sep=\"|\")[0:-1]\n",
    "\n",
    "# combined = pd.concat([df1['Symbol'],df2['Symbol'],df3['Symbol']],axis=0)\n",
    "\n",
    "# process symbols for bad characters\n",
    "BAD_CHARS = [\"$\", \".\"]\n",
    "# pat = '|'.join(['({})'.format(re.escape(c)) for c in BAD_CHARS])\n",
    "# cleaned = unique(combined.replace(BAD_CHARS,'-'))\n",
    "\n",
    "# choose size\n",
    "size = nstocks\n",
    "# stocks = list(df1[\"Symbol\"].sample(n=int(size/3)))\n",
    "stocks = list(\n",
    "    df1[\"Symbol\"]\n",
    "    .replace(\".\", \"-\")\n",
    "    .replace(\"\\\\$\", \"-P\", regex=True)\n",
    "    .sample(n=int(size / 3))\n",
    ")\n",
    "mfunds = list(\n",
    "    df2[\"Symbol\"]\n",
    "    .replace(\".\", \"-\")\n",
    "    .replace(\"\\\\$\", \"-P\", regex=True)\n",
    "    .sample(n=int(size / 3))\n",
    ")\n",
    "bonds = list(\n",
    "    df3[\"Symbol\"]\n",
    "    .replace(\".\", \"-\")\n",
    "    .replace(\"\\\\$\", \"-P\", regex=True)\n",
    "    .sample(n=int(size / 3))\n",
    ")\n",
    "symbols = list(set(stocks + mfunds + bonds))  # unique(stocks + mfunds + bonds)\n",
    "# symbols = unique(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881313f8-b5dd-4481-b5b9-e4f6dcf66742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a068f4-f59f-4ccb-92af-52b1ba42b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_pre = build_portfolio(\n",
    "    names=symbols, start_date=start_date, end_date=one_week_end, data_api=\"yfinance\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504f295-39b0-4439-9dc9-54786e2d9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available calendars\n",
    "# print(mcal.get_calendar_names())\n",
    "\n",
    "vetted_symbols = list(\n",
    "    pf_pre.data.loc[\n",
    "        (np.intersect1d(list(pf_pre.data.index.strftime(\"%Y-%m-%d\")), early.index.strftime('%Y-%m-%d')))\n",
    "    ]\n",
    "    .head(-1)\n",
    "    .tail(-1)\n",
    "    .dropna(axis=1)\n",
    "    .columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Ultra-Low-Sulfur No. 2 Diesel Fuel Prices: Los Angeles (WDFUELLA)\n",
    "#US Regular All Formulations Gas Price (GASREGW)\n",
    "#Trade Weighted U.S. Dollar Index: Broad, Goods and Services (DTWEXBGS)\n",
    "\n",
    "\n",
    "etf_commodities = ['DBO','CORN', 'WEAT', 'SOYB', 'JO', 'SGG', 'BAL', 'COW', 'MOO', 'TAGS', 'KOL' ]\n",
    "#Gold, Silver, Platinum, Copper, Paladium, Aluminum, Iron, Steel\n",
    "etf_metals = ['IAU', 'SLV', 'PGM', 'JJC', 'PALL', 'JJU', 'IFUNX', 'SLX']\n",
    "#US dollar, European Euro, Japanese yen, Pound sterling, Australian dollar, Canadian dollar, Swiss franc, Chinese Yuan Renminbi, Swedish Krona, Peso, India\n",
    "#defunct: Russia: XRU, Mexico: FXM\n",
    "etf_foreign_exchanges = ['UUP','FXE','FXY','FXB','FXA','FXC','FXF','CYB', 'FXS', 'INR']\n",
    "#residential, Ishares all NAmerica\n",
    "etf_real_estate = ['REZ', 'IYR']\n",
    "#Russia, Germany, UK, Japan, China, Euro, Euro, Brazil, Latin America, Mexico, India\n",
    "etf_economies = ['ERUS','EWG','EWU','EWJ','MCHI','EZU','IEUR','EWZ','ILF','EWW','INDA']\n",
    "#Ishares Investment Grade, IShares core aggregate Investment grade, Short, Total, 1-5 Years, 5-10 Years, 10 Years, Gov/Credit\n",
    "#defunct:\n",
    "\n",
    "etf_spdr_indexes = ['XLC','XLY','XLP','XLE','XLF','XLV','XLI','XLB','XLRE','XLK','XLU']\n",
    "etf_dow_components = ['MMM','AXP','AMGN','AAPL','BA','CAT','CVX','CSCO','KO','DOW','GS','HD','HON','IBM','INTC','JNJ','JPM','MCD','MRK','MSFT','NKE','PG','CRM','TRV','UNH','VZ','V','WMT','WBA','DIS']\n",
    "\n",
    "etf_bonds = ['LQD', 'AGG', 'NEAR', 'IUSB', 'ISTB', 'IMTB', 'ILTB', 'GBF']\n",
    "etf_muni_bonds = ['MUB', 'SUB', 'MEAR']\n",
    "\n",
    "etf_treasuries = ['AGZ', 'GOVT', 'BIL', 'SHV', 'SHY', 'IEI', 'IEF', 'TLT']\n",
    "\n",
    "crypto = ['BTC-USD','ETH','RPL','BCH','EOS','LTC']\n",
    "\n",
    "#,'GOLDAMGBD228NLBM',\n",
    "FRED_Indicators = ['T10YIE','WDFUELLA','DTWEXBGS','GASREGW','DGS2','CPALTT01USQ657N','PAYEMS','IRLTLT01USM156N','MEPAINUSA672N','MABMM301USM189S','LFWA64TTUSM647S','MANMM101USA189S','MICH','UMCSENT','CSCICP03USM665S','DGS10','DTB3','DGS3MO','CASTHPI','GDPC1','CIVPART','POPTOTUSA647NWDB','MEHOINUSA672N','HOSMEDUSM052N','MORTGAGE30US','TTLHH','CSUSHPINSA','EMRATIO','CPIAUCSL','PSAVERT','LRUN64TTUSQ156S','USSTHPI','NYSTHPI','M2V','GFDEBTN','DFII10','GFDEGDQ188S','CUSR0000SEHA','ETOTALUSQ176N','ERENTUSQ176N','RECPROUSM156N','T5YIFR','BAMLHYH0A0HYM2TRIV','BAMLCC0A1AAATRIV','GVZCLS','DGS1','BAMLCC0A4BBBTRIV','VXVCLS','IC4WSA','WILLMICROCAPPR','WILLLRGCAPVAL','CFNAIDIFF','MZMSL','KCFSI','T5YIE','TOTALSA','USSLIND','AWHAETP','CES0500000003','TCU','WTB3MS','WGS3MO','TWEXB','DEXCHUS','DEXUSUK','CILACBQ158SBOG','CES4348400001','FEDFUNDS','TDSP','PERMIT','CP','PRFI','DRSFRMACBS','DRCCLACBS','DRBLACBS','DALLCIACBEP','USROA','USROE','RSAHORUSQ156S','MEFAINUSA672N','COMREPUSQ159N','HDTGPDUSQ163N','POP','NROU','FGCCSAQ027S','TEDRATE', 'VIXCLS', 'NFCI','INDPRO','LES1252881600Q','CUUR0000SEHA','LEU0252918500Q','BAA10Y','BAMLC0A0CM','BAMLH0A3HYC','BOGMBASE','DCOILBRENTEU','DCOILWTICO','DFF','DGS1MO','DGS30','DGS5','FPCPITOTLZGUSA','ICSA','INTDSRUSM193N','M1','M1V','MPRIME','PPIACO','SPCS20RSA','STLFSI2','T10Y2Y','T10Y3M','TB3MS','TREAST','UNRATE','WPU0911']\n",
    "#FRED_Indicators = [\"CPALTT01USQ657N\",\"PAYEMS\",\"IRLTLT01USM156N\",\"MABMM301USM189S\",\"LFWA64TTUSM647S\",\"MANMM101USA189S\",\"MICH\",\"UMCSENT\",\"CSCICP03USM665S\",\"DGS10\",\"DTB3\",\"DGS3MO\",\"CASTHPI\",\"GDPC1\",\"CIVPART\",\"POPTOTUSA647NWDB\",\"MEHOINUSA672N\",\"HOSMEDUSM052N\",\"MORTGAGE30US\",\"TTLHH\",\"CSUSHPINSA\",\"EMRATIO\",\"CPIAUCSL\",\"PSAVERT\",\"LRUN64TTUSQ156S\",\"USSTHPI\",\"NYSTHPI\",\"M2V\",\"GFDEBTN\",\"DFII10\",\"GFDEGDQ188S\",\"CUSR0000SEHA\",\"ETOTALUSQ176N\",\"ERENTUSQ176N\",\"RECPROUSM156N\",\"T5YIFR\",\"BAMLHYH0A0HYM2TRIV\",\"BAMLCC0A1AAATRIV\",\"GVZCLS\",\"DGS1\",\"BAMLCC0A4BBBTRIV\",\"VXVCLS\",\"IC4WSA\",\"WILLMICROCAPPR\",\"WILLLRGCAPVAL\",\"CFNAIDIFF\",\"MZMSL\",\"KCFSI\",\"T5YIE\",\"TOTALSA\",\"USSLIND\",\"AWHAETP\",\"CES0500000003\",\"TCU\",\"WTB3MS\",\"WGS3MO\",\"TWEXB\",\"DEXCHUS\",\"DEXUSUK\",\"CILACBQ158SBOG\",\"CES4348400001\",\"FEDFUNDS\",\"TDSP\",\"PERMIT\",\"GFDEGDQ188S\",\"CP\",\"PRFI\",\"DRSFRMACBS\",\"DRCCLACBS\",\"DRBLACBS\",\"DALLCIACBEP\",\"USROA\",\"USROE\",\"RSAHORUSQ156S\",\"MEFAINUSA672N\",\"COMREPUSQ159N\",\"HDTGPDUSQ163N\",\"POP\",\"NROU\",\"FGCCSAQ027S\",\"TEDRATE\", \"VIXCLS\", \"NFCI\",\"INDPRO\",\"LES1252881600Q\",\"CUUR0000SEHA\",\"LEU0252918500Q\",\"BAA10Y\",\"BAMLC0A0CM\",\"BAMLH0A3HYC\",\"BOGMBASE\",\"DCOILBRENTEU\",\"DCOILWTICO\",\"DFF\",\"DGS1MO\",\"DGS30\",\"DGS5\",\"FPCPITOTLZGUSA\",\"GOLDAMGBD228NLBM\",\"ICSA\",\"INTDSRUSM193N\",\"M1\",\"M1V\",\"MPRIME\",\"PPIACO\",\"SPCS20RSA\",\"STLFSI2\",\"T10Y2Y\",\"T10Y3M\",\"TB3MS\",\"TREAST\",\"UNRATE\",\"WPU0911\"]\n",
    "\n",
    "Indexes = ['^SP500TR', '^GSPC', 'QQQ', 'DIA', 'VTWO']\n",
    "\n",
    "ManualStocks = ['VOO','SPY']\n",
    "ManualStocks.extend(vetted_symbols)\n",
    "\n",
    "etf_indexes_and_Crypto_list = [Indexes, ManualStocks, etf_commodities, etf_metals, etf_foreign_exchanges, etf_real_estate, etf_economies, etf_bonds, etf_muni_bonds, etf_treasuries, crypto, etf_spdr_indexes, etf_dow_components]\n",
    "\n",
    "commodities = []\n",
    "for sublist in etf_indexes_and_Crypto_list:\n",
    "    for val in sublist:\n",
    "        commodities.append(val)\n",
    "\n",
    "#pool2 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "completed = []\n",
    "def dl(name):\n",
    "    subset = yf.download(name, start=start_date, end=end_date, auto_adjust=True).iloc[:, :6].dropna(axis=0, how='any')\n",
    "    subset = subset[start_date.strftime('%Y-%m-%d'):end_date.strftime('%Y-%m-%d')]\n",
    "    #sleep(4)\n",
    "    if len(subset) != 0:\n",
    "        completed.append(name)\n",
    "        return (subset)\n",
    "    \n",
    "def dl2(assets):\n",
    "    #https://webcache.googleusercontent.com/search?q=cache:Em9Ge5B9ue8J:https://stackoverflow.com/questions/62614282/is-the-yfinance-module-broken-i-keep-getting-a-jsondecodeerror+&cd=3&hl=en&ct=clnk&gl=us\n",
    "\n",
    "    yahoo_financials = YahooFinancials(assets)\n",
    "\n",
    "    data = yahoo_financials.get_historical_price_data(start_date=start_date.strftime('%Y-%m-%d'), end_date=end_date.strftime('%Y-%m-%d'), time_interval='daily')\n",
    "    return(data)\n",
    "\n",
    "\n",
    "#futures2 = [pool2.submit(dl, args) for args in commodities]\n",
    "#wait(futures2, timeout=4, return_when=ALL_COMPLETED)\n",
    "futures2 = []\n",
    "#'''\n",
    "for i in commodities:\n",
    "    futures2.append(dl(i))\n",
    "#'''\n",
    "\n",
    "'''\n",
    "ohlcv_data = dl2(commodities)\n",
    "for i in commodities:\n",
    "    subset = pd.DataFrame(ohlcv_data[i]['prices']).set_index(['formatted_date'])[['open','high','low','close','adjclose','volume']].dropna()\n",
    "    #sleep(4)\n",
    "    if len(subset) != 0:\n",
    "        completed.append(i)\n",
    "        futures2.append(subset)\n",
    "'''\n",
    "#print(futures2.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4376b7-97e2-4480-8dbe-823205bb043e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f93f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "commodities_ = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(completed)):\n",
    "    values = futures2[x]\n",
    "    values.index = pd.to_datetime(values.index)\n",
    "    values = values.resample(frequency).mean().dropna()\n",
    "    values['Symbol'] = x\n",
    "    values = values.loc[~values.index.duplicated(keep='last')]\n",
    "    values = values.reset_index()\n",
    "\n",
    "    commodities_ = pd.concat([commodities_,values], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d258d0c-001a-4565-8433-19a895e1ad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yahoofinancials\n",
    "#commodities_pvt = pd.pivot_table(commodities_, values='close', index=['formatted_date'],columns=['Symbol'])\n",
    "\n",
    "#yfinance\n",
    "commodities_pvt = pd.pivot_table(commodities_, values='Close', index=['Date'],columns=['Symbol'])\n",
    "commodities_pvt.columns = completed\n",
    "wd = os.getcwd()\n",
    "\n",
    "commodities_pvt.to_csv(re.sub('code', 'data', wd)+\"\\commodities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ae416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fred_Data(name):\n",
    "    temp = web.DataReader(str(name), 'fred', start_date, end_date)\n",
    "    temp.index = pd.to_datetime(temp.index)\n",
    "    temp = temp.resample(frequency).mean().dropna()\n",
    "    return(temp)\n",
    "\n",
    "#pool1 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "#futures1 = [pool1.submit(Fred_Data, args) for args in FRED_Indicators]\n",
    "#wait(futures1, timeout=None, return_when=ALL_COMPLETED)\n",
    "\n",
    "FRED_set = []\n",
    "FRED_completed = []\n",
    "for i in FRED_Indicators:\n",
    "    FRED_completed.append(i)\n",
    "    FRED_set.append(Fred_Data(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02687812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FRED_pvt = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(FRED_completed)):\n",
    "    values = FRED_set[x]\n",
    "    #values.index = pd.to_datetime(FRED_set[\"DATE\"])\n",
    "    values = values.resample(frequency).mean().dropna()\n",
    "    #values['Symbol'] = x\n",
    "    values = values.loc[~values.index.duplicated(keep='last')]\n",
    "    #values = values.reset_index()\n",
    "\n",
    "    FRED_pvt = pd.concat([FRED_pvt,values], axis=1)\n",
    "\n",
    "#FRED_ = pd.pivot_table(commodities_, values='Close', index=['Date'],columns=['Symbol'])\n",
    "#FRED_.to_csv(\"/mnt/distvol/FRED_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405d624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbea38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRED_pvt = pd.pivot_table(FRED_, index=['DATE'])\n",
    "FRED_pvt.to_csv(re.sub('code', 'data', wd)+\"\\FRED_pvt.csv\")\n",
    "\n",
    "#print(len(FRED_.columns))\n",
    "#print(len(FRED_))\n",
    "#FRED_pvt.columns = FRED_completed\n",
    "#FRED_pvt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRED_pvt.set_index(FRED_pvt.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set = pd.concat([FRED_pvt.set_index(FRED_pvt.index),commodities_pvt],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f4f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    combined_set = combined_set.interpolate(method='linear', limit_direction='forward', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364348f3-2789-4432-a3e9-497557d7563e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set.describe().loc['count'].index[combined_set.describe().loc['count']<(len(combined_set)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc346c-e48a-4c48-a555-56cf78db622d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecde09b-18e9-4505-b3c8-37456233619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = combined_set.describe().loc['count'].index[combined_set.describe().loc['count']<(len(combined_set)*.99)]\n",
    "print(drops)\n",
    "filtered = combined_set.columns.tolist()\n",
    "\n",
    "for d in drops:\n",
    "    #print(d)\n",
    "    filtered.remove(d)\n",
    "#filtered.remove(drops.tolist())\n",
    "#combined_set[filtered].to_csv(\"/mnt/distvol/combined_set.csv\")\n",
    "\n",
    "#drop first/last row\n",
    "all_data = combined_set[filtered]\n",
    "all_data = all_data.iloc[:-1,:]\n",
    "all_data = all_data.iloc[1:,:]\n",
    "\n",
    "#all_data.loc[:, (all_data != all_data.iloc[0]).any()] \n",
    "#*** should fix duplications\n",
    "all_data = all_data.loc[:,~all_data.columns.duplicated()]\n",
    "\n",
    "all_data.to_csv(re.sub('code', 'data', wd)+\"\\combined_set.csv\")\n",
    "#filtered\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8f8e0-62df-43c0-baf4-5134c22bdc45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547faad-34f0-46f4-b7b0-1d4b04108be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433bc12-abcf-4edf-9537-bfbc217a1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedData = all_data.reindex(early.asfreq(frequency, method='pad').index).interpolate(method='time')\n",
    "#len(truncatedData.dropna(axis=0).columns)\n",
    "#truncatedData = truncatedData.replace([np.inf, -np.inf, np.NaN], 0).interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b8125-3823-4c5c-93a3-686b031d4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(truncatedData.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f9e30-ff3b-45e1-bcc6-fd26c17eb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431541c-b8f9-44cc-b365-0922ef125647",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(truncatedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e0b47-ea38-4fa0-8b1e-21db68aff32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = truncatedData.dropna().pct_change().dropna()\n",
    "deltas = deltas.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "#deltas = (truncatedData[all_data.columns]/truncatedData[all_data.columns].shift(-1))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0d0cd-edb5-48b4-a20a-31d2a979636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23f172-ff5d-491c-af1f-a8875075e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.sum(deltas.isin([np.inf, -np.inf, np.NaN])).sort_values(kind=\"quicksort\", ascending=True)\n",
    "results[results>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673829c5-6201-4c46-b0c8-ff0a8872a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Training, Holdout = split_sequences(np.array(pd.DataFrame(truncatedData.index.strftime('%Y-%m-%d'))), 1009, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46674a8d-37f0-480c-ade2-4f2cf6b52416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = 'DGS2'\n",
    "#compare = '^SP500TR'\n",
    "#compare = 'T10Y3M'\n",
    "#compare = 'T10Y2Y'\n",
    "target = '^SP500TR'\n",
    "#target = pd.DataFrame(vetted_symbols).sample(n=1).values[0][0]\n",
    "#target = etf_metals[0]\n",
    "#target = crypto[1]\n",
    "#target = '^GSPC'\n",
    "\n",
    "pd.concat([truncatedData[compare].pct_change(),truncatedData[target].pct_change()],axis=1).dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674b397-30ba-4421-be78-87200f3adf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(deltas.index,  test_size=0.33, random_state=0, shuffle=False)\n",
    "valid, test = train_test_split(valid,  test_size=0.5, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32dfcb7-6a76-48ef-afe0-01af8158749f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a46be8-89f1-421c-aaba-43a97aa6c7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e2da9-0e53-4906-b0d4-ce5e44f7a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats # For in-built method to get PCC\n",
    "import scipy\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650927b6-968a-4cd9-90b0-c8d6f4af67fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69844396-f693-44b9-a2fa-888a4c194d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2d515-3646-42a6-bf97-04394a715eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "lagn=9\n",
    "p_threshold = .05\n",
    "threshold = .5\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "target = \"SPCS20RSA\"\n",
    "#print()\n",
    "#print(target)\n",
    "#print()\n",
    "#print(f\"target: {target}\")\n",
    "\n",
    "#sets = range(0,len(Training),252)\n",
    "#move this outside\n",
    "\n",
    "X = deltas[set(deltas.columns).difference(target)].copy()\n",
    "newX = pd.DataFrame()\n",
    "y = pd.DataFrame(deltas[target].copy())\n",
    "\n",
    "for m in X.columns:\n",
    "    lagged = pd.DataFrame()\n",
    "    newX = pd.concat([newX,X[m]],axis=1)\n",
    "    \n",
    "    for lag in range(1,lagn+1):\n",
    "        temp = pd.DataFrame(X[m].shift(lag).copy())\n",
    "        temp.columns = [m+\"_\"+str(lag)]\n",
    "        lagged = pd.concat([lagged,temp],axis=1)\n",
    "    #print(lagged)\n",
    "    newX = pd.concat([newX,lagged],axis=1)\n",
    "\n",
    "#newX = newX[set(newX.columns).difference(newX)].copy()\n",
    "#newX = newX.dropna().copy()\n",
    "#y = y.loc[newX.index]\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "kfold.get_n_splits(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c8fab-b221-4ffa-ab5b-506bb434cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "newX.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3cfc06-9712-43b0-8abb-f85cbffd5036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc807c5b-dfa8-4741-830a-c24f5fd7b433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0bd92-72e6-49f1-b8b0-d9f0fdaedf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#for m in X.columns:\n",
    "#print(m)\n",
    "#X_train = newX[newX.columns[newX.columns.str.contains(m)]].loc[train].copy()\n",
    "#X_valid = newX[newX.columns[newX.columns.str.contains(m)]].loc[valid].copy()\n",
    "X_train = newX.drop(X.columns, axis=1, inplace=False).loc[train].dropna().copy()\n",
    "X_valid = newX.drop(X.columns, axis=1, inplace=False).loc[valid].dropna().copy()\n",
    "X_test = newX.drop(X.columns, axis=1, inplace=False).loc[test].dropna().copy()\n",
    "\n",
    "y_train = y.loc[X_train.index][target].copy()\n",
    "y_valid = y.loc[X_valid.index][target].copy()\n",
    "y_test = y.loc[X_test.index][target].copy()\n",
    "\n",
    "exclude = ''\n",
    "\n",
    "sig_table = np.zeros(shape=(len(all_data.columns)))\n",
    "signs_table = np.zeros(shape=(len(all_data.columns)))\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "k_fold = KFold(n_splits=num_folds)\n",
    "train_ = []\n",
    "test_ = []\n",
    "for train_indices, test_indices in k_fold.split(X_train.index):\n",
    "    train_.append(train_indices)\n",
    "    test_.append(test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e356570-6384-4f68-b419-465e92433673",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99, svd_solver='full')\n",
    "pca.fit(X_train)\n",
    "pca.explained_variance_\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "#pca = PCA(n_components=1)\n",
    "#pca.fit(X)\n",
    "X_pca = pd.DataFrame(pca.transform(X_train))\n",
    "X_pca.index = X_train.index\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d24d0-7ac6-445a-820b-d9908d015139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4472e-d280-463a-a2fb-ff4eb29a11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from visuals import visuals as vs\n",
    "\n",
    "# Train the supervised model on the training \n",
    "model = AdaBoostRegressor().fit(pd.DataFrame(X_pca), y_train)\n",
    "\n",
    "# Extract the feature importances using .feature_importances_ \n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Plot\n",
    "vs.feature_plot(importances, pd.DataFrame(X_pca), y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd454ae9-1dda-451d-94f2-3e0cbc959bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25603e4f-6960-421d-a2db-b0d80cb4ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "sfs = sfs(lr, \n",
    "          k_features=len(X_train), \n",
    "          forward=True, \n",
    "          floating=False, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          cv=10)\n",
    "\n",
    "sfs = sfs.fit(X_train, y_train)\n",
    "fig = plot_sfs(sfs.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('Selected features:', sfs.k_feature_idx_)\n",
    "\n",
    "position = list(pd.DataFrame(sfs.subsets_).loc[\"avg_score\"]).index(pd.DataFrame(sfs.subsets_).loc[\"avg_score\"].max())\n",
    "\n",
    "print(sfs.subsets_[position]['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b7638e-c8bf-49d3-8cd8-e4a19cab593a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3d1a3-14b7-4ff4-aeed-8e97bad4d3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf63d3-5b24-4824-baa2-4d7ad79d8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedFeatures = list(sfs.subsets_[position]['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "f0552d02-5f8b-4fce-8d38-1017b4aaa495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNH_2',\n",
       " 'BAMLH0A3HYC_3',\n",
       " 'CLWT_5',\n",
       " 'CVX_8',\n",
       " 'BIL_8',\n",
       " 'CUSR0000SEHA_9',\n",
       " 'OVBC_7',\n",
       " 'PTSI_9',\n",
       " 'BAMLHYH0A0HYM2TRIV_1',\n",
       " 'XLY_3']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortedFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d3f4e2e3-d6d3-417e-8586-f66dc5a9cf27",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (11,1) and (5,10) not aligned: 1 (dim 1) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18712/3884892226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msortedFeatures\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\jupyterlab\\lib\\site-packages\\statsmodels\\regression\\linear_model.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, params, exog)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0mexog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (11,1) and (5,10) not aligned: 1 (dim 1) != 5 (dim 0)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "d837bbf6-9a1c-49c1-8e25-16392e002e39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 10)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "27874243-52a4-4750-9b6d-0c791bd0bba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 10)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "279235ac-c7c7-4a24-98ce-3a53b48f34c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:              SPCS20RSA   R-squared (uncentered):                   1.000\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              1.000\n",
      "Method:                 Least Squares   F-statistic:                              6011.\n",
      "Date:                Sat, 14 Aug 2021   Prob (F-statistic):                      0.0100\n",
      "Time:                        19:10:07   Log-Likelihood:                          92.200\n",
      "No. Observations:                  11   AIC:                                     -164.4\n",
      "Df Residuals:                       1   BIC:                                     -160.4\n",
      "Df Model:                          10                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "UNH_2                   -0.0129      0.003     -3.930      0.159      -0.055       0.029\n",
      "BAMLH0A3HYC_3            0.0094      0.002      3.982      0.157      -0.021       0.039\n",
      "CLWT_5                   0.0144      0.006      2.585      0.235      -0.056       0.085\n",
      "CVX_8                   -0.0386      0.004    -10.533      0.060      -0.085       0.008\n",
      "BIL_8                   -2.3668      1.811     -1.307      0.416     -25.383      20.650\n",
      "CUSR0000SEHA_9           1.9200      0.044     43.740      0.015       1.362       2.478\n",
      "OVBC_7                  -0.0464      0.009     -5.320      0.118      -0.157       0.064\n",
      "PTSI_9                  -0.0032      0.001     -2.226      0.269      -0.022       0.015\n",
      "BAMLHYH0A0HYM2TRIV_1    -0.0725      0.012     -5.977      0.106      -0.227       0.082\n",
      "XLY_3                    0.0006      0.003      0.172      0.892      -0.043       0.044\n",
      "==============================================================================\n",
      "Omnibus:                        1.456   Durbin-Watson:                   3.017\n",
      "Prob(Omnibus):                  0.483   Jarque-Bera (JB):                1.083\n",
      "Skew:                          -0.610   Prob(JB):                        0.582\n",
      "Kurtosis:                       2.064   Cond. No.                     8.36e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[3] The condition number is large, 8.36e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "kurtosistest only valid for n>=20 ... continuing anyway, n=11\n",
      "kurtosistest only valid for n>=20 ... continuing anyway, n=11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>SPCS20RSA</td>    <th>  R-squared (uncentered):</th>      <td>   1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   1.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   6011.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 14 Aug 2021</td> <th>  Prob (F-statistic):</th>           <td>0.0100</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:10:07</td>     <th>  Log-Likelihood:    </th>          <td>  92.200</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    11</td>      <th>  AIC:               </th>          <td>  -164.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>     1</td>      <th>  BIC:               </th>          <td>  -160.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    10</td>      <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UNH_2</th>                <td>   -0.0129</td> <td>    0.003</td> <td>   -3.930</td> <td> 0.159</td> <td>   -0.055</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BAMLH0A3HYC_3</th>        <td>    0.0094</td> <td>    0.002</td> <td>    3.982</td> <td> 0.157</td> <td>   -0.021</td> <td>    0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CLWT_5</th>               <td>    0.0144</td> <td>    0.006</td> <td>    2.585</td> <td> 0.235</td> <td>   -0.056</td> <td>    0.085</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CVX_8</th>                <td>   -0.0386</td> <td>    0.004</td> <td>  -10.533</td> <td> 0.060</td> <td>   -0.085</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BIL_8</th>                <td>   -2.3668</td> <td>    1.811</td> <td>   -1.307</td> <td> 0.416</td> <td>  -25.383</td> <td>   20.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CUSR0000SEHA_9</th>       <td>    1.9200</td> <td>    0.044</td> <td>   43.740</td> <td> 0.015</td> <td>    1.362</td> <td>    2.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OVBC_7</th>               <td>   -0.0464</td> <td>    0.009</td> <td>   -5.320</td> <td> 0.118</td> <td>   -0.157</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTSI_9</th>               <td>   -0.0032</td> <td>    0.001</td> <td>   -2.226</td> <td> 0.269</td> <td>   -0.022</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BAMLHYH0A0HYM2TRIV_1</th> <td>   -0.0725</td> <td>    0.012</td> <td>   -5.977</td> <td> 0.106</td> <td>   -0.227</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>XLY_3</th>                <td>    0.0006</td> <td>    0.003</td> <td>    0.172</td> <td> 0.892</td> <td>   -0.043</td> <td>    0.044</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.456</td> <th>  Durbin-Watson:     </th> <td>   3.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.483</td> <th>  Jarque-Bera (JB):  </th> <td>   1.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.610</td> <th>  Prob(JB):          </th> <td>   0.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.064</td> <th>  Cond. No.          </th> <td>8.36e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[3] The condition number is large, 8.36e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:              SPCS20RSA   R-squared (uncentered):                   1.000\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              1.000\n",
       "Method:                 Least Squares   F-statistic:                              6011.\n",
       "Date:                Sat, 14 Aug 2021   Prob (F-statistic):                      0.0100\n",
       "Time:                        19:10:07   Log-Likelihood:                          92.200\n",
       "No. Observations:                  11   AIC:                                     -164.4\n",
       "Df Residuals:                       1   BIC:                                     -160.4\n",
       "Df Model:                          10                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "UNH_2                   -0.0129      0.003     -3.930      0.159      -0.055       0.029\n",
       "BAMLH0A3HYC_3            0.0094      0.002      3.982      0.157      -0.021       0.039\n",
       "CLWT_5                   0.0144      0.006      2.585      0.235      -0.056       0.085\n",
       "CVX_8                   -0.0386      0.004    -10.533      0.060      -0.085       0.008\n",
       "BIL_8                   -2.3668      1.811     -1.307      0.416     -25.383      20.650\n",
       "CUSR0000SEHA_9           1.9200      0.044     43.740      0.015       1.362       2.478\n",
       "OVBC_7                  -0.0464      0.009     -5.320      0.118      -0.157       0.064\n",
       "PTSI_9                  -0.0032      0.001     -2.226      0.269      -0.022       0.015\n",
       "BAMLHYH0A0HYM2TRIV_1    -0.0725      0.012     -5.977      0.106      -0.227       0.082\n",
       "XLY_3                    0.0006      0.003      0.172      0.892      -0.043       0.044\n",
       "==============================================================================\n",
       "Omnibus:                        1.456   Durbin-Watson:                   3.017\n",
       "Prob(Omnibus):                  0.483   Jarque-Bera (JB):                1.083\n",
       "Skew:                          -0.610   Prob(JB):                        0.582\n",
       "Kurtosis:                       2.064   Cond. No.                     8.36e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[3] The condition number is large, 8.36e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.OLS(y_train,X_train[sortedFeatures])\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "reg = LinearRegression().fit(X_train[sortedFeatures], y_train)\n",
    "#reg.score(X, y)\n",
    "\n",
    "#reg.coef_\n",
    "\n",
    "#reg.intercept_\n",
    "\n",
    "#import statsmodels as ssm\n",
    "X=sm.add_constant(X_train[sortedFeatures])        #to add constant value in the model\n",
    "model= sm.OLS(y_train,X_train[sortedFeatures]).fit()         #fitting the model\n",
    "summary = model.summary()      #summary of the model\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "d86d4f26-2412-4111-af27-72f788db66bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6784725a-c17d-4c32-ad0e-07e30a33d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4106903005235912\n",
      "96.3468657063521\n",
      "65.79284309103612\n"
     ]
    }
   ],
   "source": [
    "print(MAPE(y_train,model.predict(X_train[sortedFeatures])))\n",
    "print(MAPE(y_valid,model.predict(X_valid[sortedFeatures])))\n",
    "print(MAPE(y_test,model.predict(X_test[sortedFeatures])))\n",
    "#y_valid - \n",
    "#y_test - model.predict(X_test[sortedFeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "f9a74108-51f2-4b31-90fc-6920143c0325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x23fe91f7490>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.scatter(y_train, model.predict(X_train[sortedFeatures]))\n",
    "plt.scatter(y_valid, model.predict(X_valid[sortedFeatures]))\n",
    "plt.scatter(y_test, model.predict(X_test[sortedFeatures]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cc9d7-ab49-4cd4-874d-9865758a9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "lagn=9\n",
    "p_threshold = .05\n",
    "threshold = .5\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "target = \"SPCS20RSA\"\n",
    "#print()\n",
    "#print(target)\n",
    "#print()\n",
    "#print(f\"target: {target}\")\n",
    "\n",
    "#sets = range(0,len(Training),252)\n",
    "#move this outside\n",
    "X_train = deltas.loc[train][set(deltas.columns).difference(target)].copy()\n",
    "X_valid = deltas.loc[test][set(deltas.columns).difference(target)].copy()\n",
    "y_train = deltas.loc[train][target].copy()\n",
    "y_valid = deltas.loc[test][target].copy()\n",
    "\n",
    "#X_train = deltas.loc[train][X_train.columns[~X_train.columns.isin([target])]].copy()\n",
    "#X_valid = deltas.loc[test][X_train.columns[~X_train.columns.isin([target])]].copy()\n",
    "#y_train = deltas.loc[train][target].copy()\n",
    "#y_valid = deltas.loc[test][target].copy()\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "kfold.get_n_splits(X_train)\n",
    "\n",
    "for m in X_train.columns:\n",
    "    #print(m)\n",
    "\n",
    "    corrs = []\n",
    "    ps = []\n",
    "    lags = []\n",
    "\n",
    "    sig_table = np.zeros(shape=(2))\n",
    "    signs_table = np.zeros(shape=(2))\n",
    "\n",
    "    sets = np.zeros(shape=(num_folds,lagn))\n",
    "\n",
    "    iterator = 0\n",
    "\n",
    "    for train_index, test_index in kfold.split(X_train):\n",
    "\n",
    "        subsetX = X_train.iloc[train_index]\n",
    "        subsetY = y_train.iloc[train_index]\n",
    "\n",
    "        #skip y and states\n",
    "\n",
    "        n=len(subsetX)\n",
    "\n",
    "        temp = pd.concat([subsetX[m].shift((lag-lagn)[0]),subsetY], axis=1).dropna()\n",
    "\n",
    "        dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "\n",
    "        chosen = pd.DataFrame()\n",
    "\n",
    "        #train\n",
    "        setc = crosscorrelation(np.array(temp[m]),np.array(temp.iloc[:,1]), lagn)\n",
    "        p_values = pd.DataFrame(2*dist.cdf(-abs(setc))).T\n",
    "\n",
    "        fields = np.argwhere(np.array(p_values)[0] <= p_threshold)\n",
    "\n",
    "        #print(fields[fields>lagn+1]-lagn-1)\n",
    "        #print(setc[fields[fields>lagn+1]])\n",
    "\n",
    "        #sets[iterator] = (np.where(p_values <= p_threshold, True, 0)*setc)[0][lagn+1:]\n",
    "        sets[iterator] = (np.array(p_values)*setc)[0][lagn+1:]             \n",
    "\n",
    "        iterator = iterator + 1\n",
    "\n",
    "    csets_avg = np.sum(sets, axis=0)/num_folds       \n",
    "\n",
    "    lag = pd.DataFrame(abs(csets_avg)).idxmax()\n",
    "    #print(f\"correlation: {setc[lag]}\")\n",
    "\n",
    "    #pearson_coef, p_value = stats.pearsonr(np.array(temp.iloc[:,0]),np.array(temp.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "    corrs.append(csets_avg[lag])\n",
    "    p_value = (2*dist.cdf(-abs(csets_avg[lag])))\n",
    "    ps.append(p_value)\n",
    "    lags.append(lag)    \n",
    "\n",
    "    print(p_value)\n",
    "    if (p_value < .05):\n",
    "        for p in range(0,len(sets)):\n",
    "            plt.plot(sets[p])   \n",
    "        plt.show()\n",
    "\n",
    "        print(target)\n",
    "        print(m)\n",
    "        #print(i)\n",
    "        #print(f\"lag: {lag-lagn}\")\n",
    "        #print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results\n",
    "        temp1 = pd.DataFrame([target, m,(lag-lagn)[0],pearson_coef]).T\n",
    "        temp1.columns = [\"target\",\"name\",\"lag\",\"pearson\"]\n",
    "\n",
    "        #p_values = pd.DataFrame(2*dist.cdf(-abs(temp.corr()[target]))).T\n",
    "        #p_values.columns = list(temp.columns)\n",
    "\n",
    "        #if(p_values[p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()]<=p_threshold):\n",
    "        #winners = p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()\n",
    "        #winners = m\n",
    "\n",
    "        #sig_table = (sig_table + np.where(temp.columns.isin([winners]),1,0)).copy()\n",
    "        #print(sig_table)\n",
    "        #signs_table[temp.columns.get_indexer([winners])]+=np.where(temp.corr()[target][winners]<0,-1,1)                 \n",
    "        #chosen = pd.concat([temp1,chosen],axis=0)\n",
    "        chosen.append(m)\n",
    "\n",
    "        c_threshold = dist.ppf(.05)\n",
    "        plt.plot(np.sum(sets, axis=0)/num_folds)\n",
    "        plt.axhline(y = 0, color = 'r', linestyle = '-')\n",
    "        plt.axhline(y = c_threshold, color = 'y', linestyle = '-')\n",
    "        plt.axhline(y = abs(c_threshold), color = 'y', linestyle = '-')\n",
    "\n",
    "        plt.show()\n",
    "        x=range(0,lagn)\n",
    "        plt.stackplot(x,sets[0],sets[1],sets[2],sets[3],sets[4], labels=['A','B','C','D','E'])\n",
    "        plt.axhline(y = 0, color = 'r', linestyle = '-')\n",
    "        plt.axhline(y = c_threshold, color = 'y', linestyle = '-')\n",
    "        plt.axhline(y = abs(c_threshold), color = 'y', linestyle = '-')        \n",
    "        plt.show()\n",
    "\n",
    "    #significance = pd.DataFrame(sig_table).T\n",
    "    #significance.columns = list(temp.columns)\n",
    "    #print(significance)\n",
    "\n",
    "    #sign = pd.DataFrame(signs_table).T\n",
    "    #sign.columns = list(temp.columns)\n",
    "\n",
    "    #purity = abs((sign/num_folds)*(sign/significance)).T.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "    #print(purity)\n",
    "\n",
    "    #ichosen = list(purity.T.columns.values[np.array(purity.T>=threshold).reshape(len(temp.columns,))])\n",
    "    #print(ichosen)\n",
    "    #chosen.append(ichosen)\n",
    "\n",
    "    #print(chosen)\n",
    "\n",
    "    #print(lags)\n",
    "\n",
    "    #print(m)\n",
    "    #print(ps)          \n",
    "\n",
    "    for i in range(0,len(chosen)):\n",
    "        values = chosen.reset_index().iloc[i]\n",
    "        name = values['name']\n",
    "        target = values['target']\n",
    "        lag = values['lag']\n",
    "        #print(lag)\n",
    "        aggregate = pd.DataFrame()\n",
    "\n",
    "        #test\n",
    "        innerSet = pd.concat([X_valid[name].shift(lag),y_valid],axis=1).dropna()\n",
    "\n",
    "        for p in range(0,len(innerSet)):     \n",
    "            #print(innerSet.iloc[p][name] )\n",
    "            if(innerSet.iloc[p][name] < 0):\n",
    "                d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),innerSet.iloc[p][target], np.nan, 'l'])\n",
    "                #print(\"lower\")\n",
    "            elif (innerSet.iloc[p][name] > 0):\n",
    "                d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, innerSet.iloc[p][target], 'u'])\n",
    "                #print(\"upper\")\n",
    "            else:\n",
    "                d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, np.nan, np.nan])\n",
    "\n",
    "            aggregate = pd.concat([d.T,aggregate],axis=0)\n",
    "        #print(aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1])\n",
    "\n",
    "        aggregate.columns = \"Date\",\"l\",\"u\",\"class\"\n",
    "\n",
    "        pearson_coef, p_value = stats.pearsonr(np.array(innerSet.iloc[:,0]),np.array(innerSet.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "        #print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {innerSet.corr().iloc[0][1]}\")\n",
    "        if p_value < .05 and (values['pearson']*pearson_coef) > 0:\n",
    "\n",
    "                newData = pd.concat([pd.DataFrame(innerSet[target]).set_index(innerSet[target].index.strftime('%Y-%m-%d')),aggregate.set_index(\"Date\")],axis=1).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "                if newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['l'] or newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['u']:\n",
    "                    print(f\"target: {target}\")\n",
    "                    print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {pearson_coef}\", f\"p-value: {p_value}\")\n",
    "                    print(pd.DataFrame(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]).T)\n",
    "\n",
    "                    x_ticks = newData.index[np.arange(0, len(newData.index), 200)]\n",
    "\n",
    "                    plt.plot(newData[[target,\"l\",\"u\"]].cumsum())\n",
    "                    plt.legend(loc='upper left', fancybox=True, ncol=5, labels=[target,\"l\",\"u\"])\n",
    "                    #plt.legend(loc=\"upper left\",fontsize=8)\n",
    "\n",
    "                    plt.xticks(x_ticks, rotation = 45)\n",
    "                    plt.show()\n",
    "\n",
    "                    temp1 = pd.DataFrame([target, name, pearson_coef, p_value, lag, max(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][['l','u']]), newData[[target]].cumsum().iloc[-1][target] ]).T\n",
    "                    final = pd.concat([temp1,final],axis=0)\n",
    "\n",
    "final.columns = [\"target\",\"correlate\",\"pearson\",\"p-value\",\"lag\",\"TCR\",\"holdTCR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed0215-606c-4362-8e82-72228d3284ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de683ae-f0a3-4422-809b-d1ff35ffef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "lagn=1\n",
    "p_threshold = .05\n",
    "threshold = .5\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "for target in set(deltas.columns) & set(vetted_symbols):\n",
    "    #print()\n",
    "    #print(target)\n",
    "    #print()\n",
    "    #print(f\"target: {target}\")\n",
    "    \n",
    "    #sets = range(0,len(Training),252)\n",
    "    #move this outside\n",
    "    X_train = deltas.loc[train][X_train.columns[~X_train.columns.isin([target])]].copy()\n",
    "    X_valid = deltas.loc[test][X_train.columns[~X_train.columns.isin([target])]].copy()\n",
    "    y_train = deltas.loc[train][target].copy()\n",
    "    y_valid = deltas.loc[test][target].copy()\n",
    "    \n",
    "    kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "    kfold.get_n_splits(X_train)\n",
    "\n",
    "    for m in X_train.columns:\n",
    "        #print(m)\n",
    "        \n",
    "        corrs = []\n",
    "        ps = []\n",
    "        lags = []\n",
    "\n",
    "        sig_table = np.zeros(shape=(2))\n",
    "        signs_table = np.zeros(shape=(2))\n",
    "\n",
    "        sets = np.zeros(shape=(num_folds,lagn))\n",
    "        \n",
    "        iterator = 0\n",
    "        \n",
    "        for train_index, test_index in kfold.split(X_train):\n",
    "\n",
    "            subsetX = X_train.iloc[train_index]\n",
    "            subsetY = y_train.iloc[train_index]\n",
    "\n",
    "            #skip y and states\n",
    "\n",
    "            n=len(subset)\n",
    "            \n",
    "            temp = pd.concat([subsetX[m].shift((lag-lagn)[0]),subsetY], axis=1).dropna()\n",
    "\n",
    "            dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "\n",
    "            chosen = pd.DataFrame()\n",
    "\n",
    "            #train\n",
    "            setc = crosscorrelation(np.array(temp[m]),np.array(temp.iloc[:,1]), lagn)\n",
    "            p_values = pd.DataFrame(2*dist.cdf(-abs(setc))).T\n",
    "            \n",
    "            fields = np.argwhere(np.array(p_values)[0] <= p_threshold)\n",
    "           \n",
    "            #print(fields[fields>lagn+1]-lagn-1)\n",
    "            #print(setc[fields[fields>lagn+1]])\n",
    "            \n",
    "            #sets[iterator] = (np.where(p_values <= p_threshold, True, 0)*setc)[0][lagn+1:]\n",
    "            sets[iterator] = (np.array(p_values)*setc)[0][lagn+1:]             \n",
    "            \n",
    "            iterator = iterator + 1\n",
    "        \n",
    "        csets_avg = np.sum(sets, axis=0)/num_folds       \n",
    "        \n",
    "        lag = pd.DataFrame(abs(csets_avg)).idxmax()\n",
    "        #print(f\"correlation: {setc[lag]}\")\n",
    "\n",
    "        #pearson_coef, p_value = stats.pearsonr(np.array(temp.iloc[:,0]),np.array(temp.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "        corrs.append(csets_avg[lag])\n",
    "        p_value = (2*dist.cdf(-abs(csets_avg[lag])))\n",
    "        ps.append(p_value)\n",
    "        lags.append(lag)    \n",
    "\n",
    "        #print(p_value)\n",
    "        if (p_value < .05):\n",
    "            for p in range(0,len(sets)):\n",
    "                plt.plot(sets[p])   \n",
    "            plt.show()\n",
    "            \n",
    "            print(target)\n",
    "            print(m)\n",
    "            #print(i)\n",
    "            #print(f\"lag: {lag-lagn}\")\n",
    "            #print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results\n",
    "            temp1 = pd.DataFrame([target, m,(lag-lagn)[0],pearson_coef]).T\n",
    "            temp1.columns = [\"target\",\"name\",\"lag\",\"pearson\"]\n",
    "\n",
    "            #p_values = pd.DataFrame(2*dist.cdf(-abs(temp.corr()[target]))).T\n",
    "            #p_values.columns = list(temp.columns)\n",
    "\n",
    "            #if(p_values[p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()]<=p_threshold):\n",
    "            #winners = p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()\n",
    "            winners = m\n",
    "\n",
    "            #sig_table = (sig_table + np.where(temp.columns.isin([winners]),1,0)).copy()\n",
    "            #print(sig_table)\n",
    "            #signs_table[temp.columns.get_indexer([winners])]+=np.where(temp.corr()[target][winners]<0,-1,1)                 \n",
    "            #chosen = pd.concat([temp1,chosen],axis=0)\n",
    "            chosen.append(m)\n",
    "\n",
    "            c_threshold = dist.ppf(.05)\n",
    "            plt.plot(np.sum(sets, axis=0)/num_folds)\n",
    "            plt.axhline(y = 0, color = 'r', linestyle = '-')\n",
    "            plt.axhline(y = c_threshold, color = 'y', linestyle = '-')\n",
    "            plt.axhline(y = abs(c_threshold), color = 'y', linestyle = '-')\n",
    "\n",
    "            plt.show()\n",
    "            x=range(0,lagn)\n",
    "            plt.stackplot(x,sets[0],sets[1],sets[2],sets[3],sets[4], labels=['A','B','C','D','E'])\n",
    "            plt.axhline(y = 0, color = 'r', linestyle = '-')\n",
    "            plt.axhline(y = c_threshold, color = 'y', linestyle = '-')\n",
    "            plt.axhline(y = abs(c_threshold), color = 'y', linestyle = '-')        \n",
    "            plt.show()\n",
    "\n",
    "        #significance = pd.DataFrame(sig_table).T\n",
    "        #significance.columns = list(temp.columns)\n",
    "        #print(significance)\n",
    "\n",
    "        #sign = pd.DataFrame(signs_table).T\n",
    "        #sign.columns = list(temp.columns)\n",
    "\n",
    "        #purity = abs((sign/num_folds)*(sign/significance)).T.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "        #print(purity)\n",
    "\n",
    "        #ichosen = list(purity.T.columns.values[np.array(purity.T>=threshold).reshape(len(temp.columns,))])\n",
    "        #print(ichosen)\n",
    "        #chosen.append(ichosen)\n",
    "        \n",
    "        #print(chosen)\n",
    "        \n",
    "        #print(lags)\n",
    "        \n",
    "        #print(m)\n",
    "        #print(ps)          \n",
    "        \n",
    "        for i in range(0,len(chosen)):\n",
    "            values = chosen.reset_index().iloc[i]\n",
    "            name = values['name']\n",
    "            target = values['target']\n",
    "            lag = values['lag']\n",
    "            #print(lag)\n",
    "            aggregate = pd.DataFrame()\n",
    "\n",
    "            #test\n",
    "            innerSet = pd.concat([X_valid[name].shift(lag),y_valid],axis=1).dropna()\n",
    "\n",
    "            for p in range(0,len(innerSet)):     \n",
    "                #print(innerSet.iloc[p][name] )\n",
    "                if(innerSet.iloc[p][name] < 0):\n",
    "                    d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),innerSet.iloc[p][target], np.nan, 'l'])\n",
    "                    #print(\"lower\")\n",
    "                elif (innerSet.iloc[p][name] > 0):\n",
    "                    d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, innerSet.iloc[p][target], 'u'])\n",
    "                    #print(\"upper\")\n",
    "                else:\n",
    "                    d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, np.nan, np.nan])\n",
    "\n",
    "                aggregate = pd.concat([d.T,aggregate],axis=0)\n",
    "            #print(aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1])\n",
    "\n",
    "            aggregate.columns = \"Date\",\"l\",\"u\",\"class\"\n",
    "\n",
    "            pearson_coef, p_value = stats.pearsonr(np.array(innerSet.iloc[:,0]),np.array(innerSet.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "            #print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {innerSet.corr().iloc[0][1]}\")\n",
    "            if p_value < .05 and (values['pearson']*pearson_coef) > 0:\n",
    "\n",
    "                    newData = pd.concat([pd.DataFrame(innerSet[target]).set_index(innerSet[target].index.strftime('%Y-%m-%d')),aggregate.set_index(\"Date\")],axis=1).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "                    if newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['l'] or newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['u']:\n",
    "                        print(f\"target: {target}\")\n",
    "                        print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {pearson_coef}\", f\"p-value: {p_value}\")\n",
    "                        print(pd.DataFrame(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]).T)\n",
    "\n",
    "                        x_ticks = newData.index[np.arange(0, len(newData.index), 200)]\n",
    "\n",
    "                        plt.plot(newData[[target,\"l\",\"u\"]].cumsum())\n",
    "                        plt.legend(loc='upper left', fancybox=True, ncol=5, labels=[target,\"l\",\"u\"])\n",
    "                        #plt.legend(loc=\"upper left\",fontsize=8)\n",
    "\n",
    "                        plt.xticks(x_ticks, rotation = 45)\n",
    "                        plt.show()\n",
    "\n",
    "                        temp1 = pd.DataFrame([target, name, pearson_coef, p_value, lag, max(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][['l','u']]), newData[[target]].cumsum().iloc[-1][target] ]).T\n",
    "                        final = pd.concat([temp1,final],axis=0)\n",
    "\n",
    "final.columns = [\"target\",\"correlate\",\"pearson\",\"p-value\",\"lag\",\"TCR\",\"holdTCR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edaae29-4918-4d61-bcb6-b2eeedbaae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100c95c-3b55-450a-b919-8f36936340c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c5f0c-8226-4c96-b684-174c03d4b5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530810c5-fa4b-457c-9d58-dfe7925b3a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8ec73-994c-4c85-b928-52e9c9f63cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(final)):\n",
    "    values = final.reset_index().iloc[i]\n",
    "    name = values['correlate']\n",
    "    target = values['target']\n",
    "    lag = values['lag']\n",
    "    #print(lag)\n",
    "    aggregate = pd.DataFrame()\n",
    "\n",
    "    X_test = deltas.loc[test][set(deltas.columns).difference(target)]\n",
    "    y_test = deltas.loc[test][target]\n",
    "    \n",
    "    #test\n",
    "    innerSet = pd.concat([X_test[name].shift(lag),y_test],axis=1).dropna()\n",
    "\n",
    "    for p in range(0,len(innerSet)):     \n",
    "        #print(innerSet.iloc[p][name] )\n",
    "        if(innerSet.iloc[p][name] < 0):\n",
    "            d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),innerSet.iloc[p][target], np.nan, 'l'])\n",
    "            #print(\"lower\")\n",
    "        elif (innerSet.iloc[p][name] > 0):\n",
    "            d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, innerSet.iloc[p][target], 'u'])\n",
    "            #print(\"upper\")\n",
    "        else:\n",
    "            d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, np.nan, np.nan])\n",
    "\n",
    "        aggregate = pd.concat([d.T,aggregate],axis=0)\n",
    "    #print(aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1])\n",
    "\n",
    "    aggregate.columns = \"Date\",\"l\",\"u\",\"class\"\n",
    "\n",
    "    pearson_coef, p_value = stats.pearsonr(np.array(innerSet.iloc[:,0]),np.array(innerSet.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "    #print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {innerSet.corr().iloc[0][1]}\")\n",
    "    if p_value < .05:\n",
    "\n",
    "            newData = pd.concat([pd.DataFrame(innerSet[target]).set_index(innerSet[target].index.strftime('%Y-%m-%d')),aggregate.set_index(\"Date\")],axis=1).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "            if newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['l'] or newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['u']:\n",
    "                print(f\"target: {target}\")\n",
    "                print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {pearson_coef}\", f\"p-value: {p_value}\")\n",
    "                print(pd.DataFrame(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]).T)\n",
    "\n",
    "                x_ticks = newData.index[np.arange(0, len(newData.index), 200)]\n",
    "\n",
    "                plt.plot(newData[[target,\"l\",\"u\"]].cumsum())\n",
    "                plt.legend(loc='upper left', fancybox=True, ncol=5, labels=[target,\"l\",\"u\"])\n",
    "                #plt.legend(loc=\"upper left\",fontsize=8)\n",
    "\n",
    "                plt.xticks(x_ticks, rotation = 45)\n",
    "                plt.show()\n",
    "\n",
    "                temp1 = pd.DataFrame([target, name, pearson_coef, p_value, lag, max(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][['l','u']]), newData[[target]].cumsum().iloc[-1][target] ]).T\n",
    "                results2 = pd.concat([temp1,results2],axis=0)\n",
    "                \n",
    "results2.columns = [\"target\",\"correlate\",\"pearson\",\"p-value\",\"lag\",\"TCR\",\"holdTCR\"]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7c793-e071-420b-aa9b-f6b7e08f2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4f0c4-ad8a-4291-b988-9a1bbcc9dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afbd82-67be-4636-acc6-9e88ef8761df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([final['pearson'],results2['pearson']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cd9f0-a1c1-4b62-bbfb-3a60f28a9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([final['pearson']*results2['pearson']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b5a42-8ce8-49d3-8324-b706b77780e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate = pd.DataFrame()\n",
    "\n",
    "for s in Training:\n",
    "    #print(s)\n",
    "    set_dates = s\n",
    "    #print(set_dates[1])\n",
    "    #print(set_dates[-1])\n",
    "    \n",
    "    #rate of change compare\n",
    "    filtered2 =  pd.concat([truncatedData.loc[[i[0] for i in set_dates]][compare],truncatedData.loc[[i[0] for i in set_dates]][target]],axis=1).pct_change().dropna().replace([np.inf, -np.inf, np.NaN], 0)\n",
    "    #quantiles2 = filtered2[compare].quantile(q=[0, .25, .5, .75, 1], interpolation='linear')\n",
    "\n",
    "    #prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    #colors = cycle(prop_cycle.by_key()['color'])\n",
    "    \n",
    "    #subset, Holdout = split_sequences(np.array(pd.DataFrame(filtered2.index.strftime('%Y-%m-%d'))), 126, 0)\n",
    "    \n",
    "    #for i in subset:\n",
    "        \n",
    "    #quantiles = pd.DataFrame(filtered2.iloc[0:-2][compare].quantile([0,.5,1]),columns=['min','median','max'])\n",
    "    #np.percentile((filtered2.iloc[0:-2][compare]),50)\n",
    "    \n",
    "    t = pd.DataFrame(filtered2.iloc[0:-3][compare].quantile([0,.5,1])).T\n",
    "    t.columns = ['min','median','max']\n",
    "    quantiles = t.reset_index(drop=True)\n",
    "\n",
    "    #lower = filtered2.iloc[0:-1][(filtered2.iloc[0:-2][compare]<=quantile)].index\n",
    "    #upper = ~filtered2.iloc[0:-2].index.isin(lower)\n",
    "\n",
    "\n",
    "\n",
    "    #my_dpi = 100\n",
    "    #fig, axes = plt.subplots(figsize=(12, 4),ncols=3, nrows=1)\n",
    "    #ax1, ax2, ax3 = axes.ravel()\n",
    "    #sns.set(style=\"ticks\")\n",
    "    #sns.despine(fig=fig)\n",
    "\n",
    "    #dataframe = filtered2.loc[dates]\n",
    "    #returns = dataframe[target].dropna()\n",
    "\n",
    "    #l = np.where(filtered2.iloc[0:-2][compare] <= quantile, filtered2.iloc[-1][target], 0)\n",
    "    #u = np.where(filtered2.iloc[upper][compare] > quantile, filtered2.iloc[-1][target], 0)\n",
    "    if((filtered2.iloc[-2][compare] <= quantiles['median'][0])):\n",
    "        d = pd.DataFrame([filtered2.iloc[-1][target], np.nan, 'l'])\n",
    "    else:\n",
    "        d = pd.DataFrame([np.nan, filtered2.iloc[-1][target], 'u'])\n",
    "    #d = pd.concat([pd.DataFrame(l.tolist()),pd.DataFrame(u.tolist())],axis=1)\n",
    "    #print(len(d))\n",
    "    #print(d)\n",
    "    \n",
    "    #print(pd.concat([d.T, quantiles.T.reset_index(drop=True)],axis=1))\n",
    "    #aggregate = pd.concat([d.T, quantiles.T.reset_index(drop=True), aggregate],axis=0)\n",
    "    aggregate = pd.concat([pd.concat([d.T, quantiles],axis=1),aggregate],axis=0)\n",
    "    #print(aggregate)\n",
    "    #print(len(aggregate))\n",
    "    #print(aggregate)\n",
    "    #d.index = filtered2.iloc[-1].name.strftime('%Y-%m-%d')\n",
    "   \n",
    "    #sns.regplot(x=compare, y=target, data=dataframe, ax=ax1)\n",
    "\n",
    "    #sns.violinplot(x=dataframe[compare].dropna(),color=next(colors), ax=ax2)\n",
    "\n",
    "    #sns.vioinplot(x=returns,color=next(colors), ax=ax3) \n",
    "    #plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9982434-a0db-4230-803b-0c250ef3c9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82770c63-0235-4afa-9075-addb7841d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Training)\n",
    "\n",
    "aggregate.columns = ['l','u','class','min','median','max']\n",
    "\n",
    "dates = []\n",
    "for item in Training:\n",
    "    last = item[-1]\n",
    "    dates.append(last[0])\n",
    "    \n",
    "aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1]\n",
    "\n",
    "aggregate.index=dates\n",
    "\n",
    "#print(aggregate.cumsum().iloc[-1])\n",
    "#aggregate.reset_index()\n",
    "#ax = sns.regplot(x=aggregate.columns[1], y='index', data=aggregate.reset_index())\n",
    "\n",
    "x_ticks = aggregate.index[np.arange(0, len(aggregate.index), 200)]\n",
    "\n",
    "plt.plot(aggregate.loc[:,['l']].replace([np.inf, -np.inf, np.NaN], 0).cumsum())\n",
    "\n",
    "plt.xticks(x_ticks, rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb49747-11d0-4e27-9d16-c3e4234164c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a51829-f0e8-4c01-8916-2c2deb6d496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = pd.concat([truncatedData[compare].pct_change(),truncatedData[target]],axis=1).loc[dates]\n",
    "temp2 = pd.concat([truncatedData[compare].pct_change(),truncatedData[target].pct_change()],axis=1).loc[dates]\n",
    "temp1.index = temp1.index.copy().strftime('%Y-%m-%d')\n",
    "temp2.index = temp2.index.copy().strftime('%Y-%m-%d')\n",
    "temp = pd.concat([temp1,temp2,aggregate],axis=1)\n",
    "newNames = [compare,target,compare+\"_pct_change\",target+\"_pct_change\"]\n",
    "newNames.extend(temp.columns[4:10])\n",
    "temp.columns = newNames\n",
    "\n",
    "temp.to_csv('../data/processed/output.csv', index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e5e50-2826-47ee-8223-b8daa2f203fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#scores = np.where(temp[compare] > 1, 1, 0)\n",
    "\n",
    "#idk why this library uses 2, 1 vs 1 and 0\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np.where(temp[target+\"_pct_change\"] > 0, 2, 1), np.array(temp[compare+\"_pct_change\"].shift(-1)) , pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa15229-dd40-409c-86c4-094143a72967",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_roc_curve(clf, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3179b-a4d3-46e6-9553-a3763ae8cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "#plt.plot(fpr,tpr, label='AUC = ' + str(round(roc_auc_score(y,m.oob_decision_function_[:,1]), 2)))\n",
    "#plt.legend(loc='lower right')\n",
    "\n",
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "bc = BinaryClassification(np.where(temp[target+\"_pct_change\"] > 0, 1, 0), np.array(temp[compare+\"_pct_change\"]), labels=[\"Class 1\", \"Class 2\"])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da249f-be20-4b24-b594-9ed3612fd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"optimal cutoff\")\n",
    "#https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "Find_Optimal_Cutoff(np.where(temp[target+\"_pct_change\"] > 0, 1, 0), np.array(temp[compare+\"_pct_change\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e19fe4-ed2b-464a-b0a2-08536a924dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import DataGenerator, KneeLocator\n",
    "kneedle = KneeLocator(fpr, tpr, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "#kneedle.plot_knee_normalized()\n",
    "kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf2a1e-3f0a-49de-844d-dca3c37f787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c724826-6c51-4e93-827e-c55cc83ab675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db525f5-aeb2-45fd-934b-efb782ecf9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15badd1f-eab0-411a-aaf8-5ba8efe5387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415802f-c6dc-45b0-a604-a0439104ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(aggregate[aggregate['bifur']=='l'].iloc[:,0].cumsum(),  truncatedData[target].pct_change().loc[aggregate[aggregate['bifur']=='l'].iloc[:,0].index.tolist()])\n",
    "plt.show()\n",
    "aggregate[aggregate['bifur']=='l'].iloc[:,0].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b50107-1e96-4169-abd4-97efb6203f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(aggregate[aggregate['bifur']=='u'].iloc[:,1].cumsum(),  truncatedData[target].pct_change().loc[aggregate[aggregate['bifur']=='u'].iloc[:,1].index.tolist()])\n",
    "plt.show()\n",
    "aggregate[aggregate['bifur']=='u'].iloc[:,1].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23aeba-1baf-43ba-8ed1-1f886304456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#252 trading days a year\n",
    "#30 days = 21\n",
    "#60 = 42\n",
    "#90 = 63\n",
    "\n",
    "#return = current - prior / prior\n",
    "\n",
    "#for i in range(1,63): #[1,21,42,63]\n",
    "for i in [1,21,42,63,84]: #[1,21,42,84]\n",
    "    print(i)\n",
    "    rate_of_change = (truncatedData[compare]-truncatedData[compare].shift(i))/truncatedData[compare].shift(i)\n",
    "    \n",
    "    newDF = pd.concat([rate_of_change,truncatedData[target].pct_change()],axis=1).dropna()\n",
    "\n",
    "    set1 = newDF[compare]\n",
    "    set2 = newDF[target]\n",
    "    \n",
    "    lags = range(0,85) #[0,21,42,63]\n",
    "    mcorrs_ = []\n",
    "    mlags = []\n",
    "    for j in lags:\n",
    "        \n",
    "        newSet = pd.concat([set1.shift(j),set2],axis=1).dropna()\n",
    "      \n",
    "        mcorrs_.append(np.array(newSet.corr())[1,0])\n",
    "        \n",
    "    plt.plot(mcorrs_)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d193fa-397f-4061-909e-5086d2087334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([(truncatedData[compare]-truncatedData[compare].shift(1))/truncatedData[compare].shift(1),truncatedData[target].pct_change().shift(0)],axis=1).dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0985e2-7c25-4c96-bb60-b9dcb8e5148e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a5775-b45a-4420-9eb5-56f125f350b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter((truncatedData[compare]-truncatedData[compare].shift(1))/truncatedData[compare].shift(1),truncatedData[target].pct_change().shift(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031f472-f7f1-4d61-9002-d2f9c109f327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.matshow(\n",
    "df = combined_set.loc[combined_set.index>=start_date.strftime('%Y-%m-%d')]\n",
    "\n",
    "r_ = df.corr()\n",
    "\n",
    "filter = r_[compare]\n",
    "                       \n",
    "filter = filter[filter<1]\n",
    "filter = filter.sort_values(kind=\"quicksort\", ascending=True)\n",
    "print(filter.head(10))\n",
    "print(filter.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a40b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
