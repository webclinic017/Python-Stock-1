{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec6684d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d626f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas==1.2.5 pandas_datareader yfinance==0.1.62 ipywidgets pandas_market_calendars matplotlib numpy pycorrelate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8655e344-79c7-4326-a116-a163805e71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import concurrent\n",
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "import yfinance as yf\n",
    "import urllib\n",
    "import urllib.request\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from finquant.portfolio import build_portfolio\n",
    "\n",
    "from ipywidgets import interactive\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pycorrelate as pyc\n",
    "import seaborn as sns\n",
    "from yahoofinancials import YahooFinancials\n",
    "\n",
    "import pandas_market_calendars as mcal\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import stats # For in-built method to get PCC\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "#import statsmodels.formula.api as sm\n",
    "import scipy.stats  as stats\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c8e1c-3d8e-4408-95cb-312ae590387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def crosscorrelation(x, y, maxlag, mode='corr'):\n",
    "\t\"\"\"\n",
    "\tCross correlation with a maximum number of lags.\n",
    "\n",
    "\t`x` and `y` must be one-dimensional numpy arrays with the same length.\n",
    "\n",
    "\tThis computes the same result as\n",
    "\t\tnumpy.correlate(x, y, mode='full')[len(a)-maxlag-1:len(a)+maxlag]\n",
    "\n",
    "\tThe return vaue has length 2*maxlag + 1.\n",
    "\t\"\"\"\n",
    "\tpy = np.pad(y.conj(), 2*maxlag, mode='constant')\n",
    "\tT = np.lib.stride_tricks.as_strided(py[2*maxlag:], shape=(2*maxlag+1, len(y) + 2*maxlag),\n",
    "\t\t\t\t   strides=(-py.strides[0], py.strides[0]))\n",
    "\tpx = np.pad(x, maxlag, mode='constant')\n",
    "\tif mode == 'dot':       # get lagged dot product\n",
    "\t\treturn T.dot(px)\n",
    "\telif mode == 'corr':    # gets Pearson correlation\n",
    "\t\treturn (T.dot(px)/px.size - (T.mean(axis=1)*px.mean())) / \\\n",
    "\t\t\t   (np.std(T, axis=1) * np.std(px))\n",
    "\n",
    "def unique(list1):\n",
    "\n",
    "    # intilize a null list\n",
    "    unique_list = []\n",
    "\n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "\n",
    "    return(unique_list)\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "        \n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6c5b3-f6e4-4531-a68a-535e3ab7457f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#frequency = output_variable.value\n",
    "frequency = \"D\"\n",
    "\n",
    "w=52*8\n",
    "#start = datetime.datetime(2010, 1, 1)\n",
    "\n",
    "#end = datetime.datetime(2013, 1, 27)\n",
    "end_date = datetime.date.today()\n",
    "\n",
    "start_date = end_date - timedelta(weeks=w)\n",
    "\n",
    "pd.set_option('display.max_columns', None) #replace n with the number of columns you want to see completely\n",
    "pd.set_option('display.max_rows', None) #replace n with the number of rows you want to see completely\n",
    "\n",
    "#cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "print(end_date)\n",
    "print(start_date)\n",
    "\n",
    "one_week_end = end_date - 5 * pd.tseries.offsets.BDay()\n",
    "one_week_end = one_week_end.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create a calendar\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "\n",
    "# Show available calendars\n",
    "print(mcal.get_calendar_names())\n",
    "early = nyse.schedule(start_date, end_date)\n",
    "\n",
    "nstocks = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7120b6d9-7f81-46e1-9ff4-d8c5df92fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"ftp://ftp.nasdaqtrader.com/symboldirectory/nasdaqtraded.txt\"\n",
    "\n",
    "urllib.request.urlretrieve(url, \"nasdaqtraded.txt\")\n",
    "urllib.request.urlretrieve(url, \"mfundslist.txt\")\n",
    "urllib.request.urlretrieve(url, \"bonds.txt\")\n",
    "\n",
    "df1 = pd.read_csv(\"nasdaqtraded.txt\", sep=\"|\")[0:-1]\n",
    "df2 = pd.read_csv(\"mfundslist.txt\", sep=\"|\")[0:-1]\n",
    "df3 = pd.read_csv(\"bonds.txt\", sep=\"|\")[0:-1]\n",
    "\n",
    "# combined = pd.concat([df1['Symbol'],df2['Symbol'],df3['Symbol']],axis=0)\n",
    "\n",
    "# process symbols for bad characters\n",
    "BAD_CHARS = [\"$\", \".\"]\n",
    "# pat = '|'.join(['({})'.format(re.escape(c)) for c in BAD_CHARS])\n",
    "# cleaned = unique(combined.replace(BAD_CHARS,'-'))\n",
    "\n",
    "# choose size\n",
    "size = nstocks\n",
    "# stocks = list(df1[\"Symbol\"].sample(n=int(size/3)))\n",
    "stocks = list(\n",
    "    df1[\"Symbol\"]\n",
    "    .replace(\".\", \"-\")\n",
    "    .replace(\"\\\\$\", \"-P\", regex=True)\n",
    "    .sample(n=int(size / 3))\n",
    ")\n",
    "mfunds = list(\n",
    "    df2[\"Symbol\"]\n",
    "    .replace(\".\", \"-\")\n",
    "    .replace(\"\\\\$\", \"-P\", regex=True)\n",
    "    .sample(n=int(size / 3))\n",
    ")\n",
    "bonds = list(\n",
    "    df3[\"Symbol\"]\n",
    "    .replace(\".\", \"-\")\n",
    "    .replace(\"\\\\$\", \"-P\", regex=True)\n",
    "    .sample(n=int(size / 3))\n",
    ")\n",
    "symbols = list(set(stocks + mfunds + bonds))  # unique(stocks + mfunds + bonds)\n",
    "# symbols = unique(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881313f8-b5dd-4481-b5b9-e4f6dcf66742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a068f4-f59f-4ccb-92af-52b1ba42b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_pre = build_portfolio(\n",
    "    names=symbols, start_date=start_date, end_date=one_week_end, data_api=\"yfinance\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504f295-39b0-4439-9dc9-54786e2d9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available calendars\n",
    "# print(mcal.get_calendar_names())\n",
    "\n",
    "vetted_symbols = list(\n",
    "    pf_pre.data.loc[\n",
    "        (np.intersect1d(list(pf_pre.data.index.strftime(\"%Y-%m-%d\")), early.index.strftime('%Y-%m-%d')))\n",
    "    ]\n",
    "    .head(-1)\n",
    "    .tail(-1)\n",
    "    .dropna(axis=1)\n",
    "    .columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Ultra-Low-Sulfur No. 2 Diesel Fuel Prices: Los Angeles (WDFUELLA)\n",
    "#US Regular All Formulations Gas Price (GASREGW)\n",
    "#Trade Weighted U.S. Dollar Index: Broad, Goods and Services (DTWEXBGS)\n",
    "\n",
    "\n",
    "etf_commodities = ['DBO','CORN', 'WEAT', 'SOYB', 'JO', 'SGG', 'BAL', 'COW', 'MOO', 'TAGS', 'KOL' ]\n",
    "#Gold, Silver, Platinum, Copper, Paladium, Aluminum, Iron, Steel\n",
    "etf_metals = ['IAU', 'SLV', 'PGM', 'JJC', 'PALL', 'JJU', 'IFUNX', 'SLX']\n",
    "#US dollar, European Euro, Japanese yen, Pound sterling, Australian dollar, Canadian dollar, Swiss franc, Chinese Yuan Renminbi, Swedish Krona, Peso, India\n",
    "#defunct: Russia: XRU, Mexico: FXM\n",
    "etf_foreign_exchanges = ['UUP','FXE','FXY','FXB','FXA','FXC','FXF','CYB', 'FXS', 'INR']\n",
    "#residential, Ishares all NAmerica\n",
    "etf_real_estate = ['REZ', 'IYR']\n",
    "#Russia, Germany, UK, Japan, China, Euro, Euro, Brazil, Latin America, Mexico, India\n",
    "etf_economies = ['ERUS','EWG','EWU','EWJ','MCHI','EZU','IEUR','EWZ','ILF','EWW','INDA']\n",
    "#Ishares Investment Grade, IShares core aggregate Investment grade, Short, Total, 1-5 Years, 5-10 Years, 10 Years, Gov/Credit\n",
    "#defunct:\n",
    "\n",
    "etf_spdr_indexes = ['XLC','XLY','XLP','XLE','XLF','XLV','XLI','XLB','XLRE','XLK','XLU']\n",
    "etf_dow_components = ['MMM','AXP','AMGN','AAPL','BA','CAT','CVX','CSCO','KO','DOW','GS','HD','HON','IBM','INTC','JNJ','JPM','MCD','MRK','MSFT','NKE','PG','CRM','TRV','UNH','VZ','V','WMT','WBA','DIS']\n",
    "\n",
    "etf_bonds = ['LQD', 'AGG', 'NEAR', 'IUSB', 'ISTB', 'IMTB', 'ILTB', 'GBF']\n",
    "etf_muni_bonds = ['MUB', 'SUB', 'MEAR']\n",
    "\n",
    "etf_treasuries = ['AGZ', 'GOVT', 'BIL', 'SHV', 'SHY', 'IEI', 'IEF', 'TLT']\n",
    "\n",
    "crypto = ['BTC-USD','ETH','RPL','BCH','EOS','LTC']\n",
    "\n",
    "#,'GOLDAMGBD228NLBM',\n",
    "FRED_Indicators = ['T10YIE','WDFUELLA','DTWEXBGS','GASREGW','DGS2','CPALTT01USQ657N','PAYEMS','IRLTLT01USM156N','MABMM301USM189S','LFWA64TTUSM647S','MANMM101USA189S','MICH','UMCSENT','CSCICP03USM665S','DGS10','DTB3','DGS3MO','CASTHPI','GDPC1','CIVPART','POPTOTUSA647NWDB','MEHOINUSA672N','HOSMEDUSM052N','MORTGAGE30US','TTLHH','CSUSHPINSA','EMRATIO','CPIAUCSL','PSAVERT','LRUN64TTUSQ156S','USSTHPI','NYSTHPI','M2V','GFDEBTN','DFII10','GFDEGDQ188S','CUSR0000SEHA','ETOTALUSQ176N','ERENTUSQ176N','RECPROUSM156N','T5YIFR','BAMLHYH0A0HYM2TRIV','BAMLCC0A1AAATRIV','GVZCLS','DGS1','BAMLCC0A4BBBTRIV','VXVCLS','IC4WSA','WILLMICROCAPPR','WILLLRGCAPVAL','CFNAIDIFF','MZMSL','KCFSI','T5YIE','TOTALSA','USSLIND','AWHAETP','CES0500000003','TCU','WTB3MS','WGS3MO','TWEXB','DEXCHUS','DEXUSUK','CILACBQ158SBOG','CES4348400001','FEDFUNDS','TDSP','PERMIT','CP','PRFI','DRSFRMACBS','DRCCLACBS','DRBLACBS','DALLCIACBEP','USROA','USROE','RSAHORUSQ156S','MEFAINUSA672N','COMREPUSQ159N','HDTGPDUSQ163N','POP','NROU','FGCCSAQ027S','TEDRATE', 'VIXCLS', 'NFCI','INDPRO','LES1252881600Q','CUUR0000SEHA','LEU0252918500Q','BAA10Y','BAMLC0A0CM','BAMLH0A3HYC','BOGMBASE','DCOILBRENTEU','DCOILWTICO','DFF','DGS1MO','DGS30','DGS5','FPCPITOTLZGUSA','ICSA','INTDSRUSM193N','M1','M1V','MPRIME','PPIACO','SPCS20RSA','STLFSI2','T10Y2Y','T10Y3M','TB3MS','TREAST','UNRATE','WPU0911']\n",
    "#FRED_Indicators = [\"CPALTT01USQ657N\",\"PAYEMS\",\"IRLTLT01USM156N\",\"MABMM301USM189S\",\"LFWA64TTUSM647S\",\"MANMM101USA189S\",\"MICH\",\"UMCSENT\",\"CSCICP03USM665S\",\"DGS10\",\"DTB3\",\"DGS3MO\",\"CASTHPI\",\"GDPC1\",\"CIVPART\",\"POPTOTUSA647NWDB\",\"MEHOINUSA672N\",\"HOSMEDUSM052N\",\"MORTGAGE30US\",\"TTLHH\",\"CSUSHPINSA\",\"EMRATIO\",\"CPIAUCSL\",\"PSAVERT\",\"LRUN64TTUSQ156S\",\"USSTHPI\",\"NYSTHPI\",\"M2V\",\"GFDEBTN\",\"DFII10\",\"GFDEGDQ188S\",\"CUSR0000SEHA\",\"ETOTALUSQ176N\",\"ERENTUSQ176N\",\"RECPROUSM156N\",\"T5YIFR\",\"BAMLHYH0A0HYM2TRIV\",\"BAMLCC0A1AAATRIV\",\"GVZCLS\",\"DGS1\",\"BAMLCC0A4BBBTRIV\",\"VXVCLS\",\"IC4WSA\",\"WILLMICROCAPPR\",\"WILLLRGCAPVAL\",\"CFNAIDIFF\",\"MZMSL\",\"KCFSI\",\"T5YIE\",\"TOTALSA\",\"USSLIND\",\"AWHAETP\",\"CES0500000003\",\"TCU\",\"WTB3MS\",\"WGS3MO\",\"TWEXB\",\"DEXCHUS\",\"DEXUSUK\",\"CILACBQ158SBOG\",\"CES4348400001\",\"FEDFUNDS\",\"TDSP\",\"PERMIT\",\"GFDEGDQ188S\",\"CP\",\"PRFI\",\"DRSFRMACBS\",\"DRCCLACBS\",\"DRBLACBS\",\"DALLCIACBEP\",\"USROA\",\"USROE\",\"RSAHORUSQ156S\",\"MEFAINUSA672N\",\"COMREPUSQ159N\",\"HDTGPDUSQ163N\",\"POP\",\"NROU\",\"FGCCSAQ027S\",\"TEDRATE\", \"VIXCLS\", \"NFCI\",\"INDPRO\",\"LES1252881600Q\",\"CUUR0000SEHA\",\"LEU0252918500Q\",\"BAA10Y\",\"BAMLC0A0CM\",\"BAMLH0A3HYC\",\"BOGMBASE\",\"DCOILBRENTEU\",\"DCOILWTICO\",\"DFF\",\"DGS1MO\",\"DGS30\",\"DGS5\",\"FPCPITOTLZGUSA\",\"GOLDAMGBD228NLBM\",\"ICSA\",\"INTDSRUSM193N\",\"M1\",\"M1V\",\"MPRIME\",\"PPIACO\",\"SPCS20RSA\",\"STLFSI2\",\"T10Y2Y\",\"T10Y3M\",\"TB3MS\",\"TREAST\",\"UNRATE\",\"WPU0911\"]\n",
    "\n",
    "Indexes = ['^SP500TR', '^GSPC', 'QQQ', 'DIA', 'VTWO']\n",
    "\n",
    "ManualStocks = ['VOO','SPY']\n",
    "ManualStocks.extend(vetted_symbols)\n",
    "\n",
    "etf_indexes_and_Crypto_list = [Indexes, ManualStocks, etf_commodities, etf_metals, etf_foreign_exchanges, etf_real_estate, etf_economies, etf_bonds, etf_muni_bonds, etf_treasuries, crypto, etf_spdr_indexes, etf_dow_components]\n",
    "\n",
    "commodities = []\n",
    "for sublist in etf_indexes_and_Crypto_list:\n",
    "    for val in sublist:\n",
    "        commodities.append(val)\n",
    "\n",
    "#pool2 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "completed = []\n",
    "def dl(name):\n",
    "    subset = yf.download(name, start=start_date, end=end_date, auto_adjust=True).iloc[:, :6].dropna(axis=0, how='any')\n",
    "    subset = subset[start_date.strftime('%Y-%m-%d'):end_date.strftime('%Y-%m-%d')]\n",
    "    #sleep(4)\n",
    "    if len(subset) != 0:\n",
    "        completed.append(name)\n",
    "        return (subset)\n",
    "    \n",
    "def dl2(assets):\n",
    "    #https://webcache.googleusercontent.com/search?q=cache:Em9Ge5B9ue8J:https://stackoverflow.com/questions/62614282/is-the-yfinance-module-broken-i-keep-getting-a-jsondecodeerror+&cd=3&hl=en&ct=clnk&gl=us\n",
    "\n",
    "    yahoo_financials = YahooFinancials(assets)\n",
    "\n",
    "    data = yahoo_financials.get_historical_price_data(start_date=start_date.strftime('%Y-%m-%d'), end_date=end_date.strftime('%Y-%m-%d'), time_interval='daily')\n",
    "    return(data)\n",
    "\n",
    "\n",
    "#futures2 = [pool2.submit(dl, args) for args in commodities]\n",
    "#wait(futures2, timeout=4, return_when=ALL_COMPLETED)\n",
    "futures2 = []\n",
    "#'''\n",
    "for i in commodities:\n",
    "    futures2.append(dl(i))\n",
    "#'''\n",
    "\n",
    "'''\n",
    "ohlcv_data = dl2(commodities)\n",
    "for i in commodities:\n",
    "    subset = pd.DataFrame(ohlcv_data[i]['prices']).set_index(['formatted_date'])[['open','high','low','close','adjclose','volume']].dropna()\n",
    "    #sleep(4)\n",
    "    if len(subset) != 0:\n",
    "        completed.append(i)\n",
    "        futures2.append(subset)\n",
    "'''\n",
    "#print(futures2.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4376b7-97e2-4480-8dbe-823205bb043e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f93f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "commodities_ = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(completed)):\n",
    "    values = futures2[x]\n",
    "    values.index = pd.to_datetime(values.index)\n",
    "    values = values.resample(frequency).mean().dropna()\n",
    "    values['Symbol'] = x\n",
    "    values = values.loc[~values.index.duplicated(keep='last')]\n",
    "    values = values.reset_index()\n",
    "\n",
    "    commodities_ = pd.concat([commodities_,values], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d258d0c-001a-4565-8433-19a895e1ad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yahoofinancials\n",
    "#commodities_pvt = pd.pivot_table(commodities_, values='close', index=['formatted_date'],columns=['Symbol'])\n",
    "\n",
    "#yfinance\n",
    "commodities_pvt = pd.pivot_table(commodities_, values='Close', index=['Date'],columns=['Symbol'])\n",
    "commodities_pvt.columns = completed\n",
    "wd = os.getcwd()\n",
    "\n",
    "commodities_pvt.to_csv(re.sub('code', 'data', wd)+\"\\commodities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ae416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fred_Data(name):\n",
    "    temp = web.DataReader(str(name), 'fred', start_date, end_date)\n",
    "    temp.index = pd.to_datetime(temp.index)\n",
    "    temp = temp.resample(frequency).mean().dropna()\n",
    "    return(temp)\n",
    "\n",
    "#pool1 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "#futures1 = [pool1.submit(Fred_Data, args) for args in FRED_Indicators]\n",
    "#wait(futures1, timeout=None, return_when=ALL_COMPLETED)\n",
    "\n",
    "FRED_set = []\n",
    "FRED_completed = []\n",
    "for i in FRED_Indicators:\n",
    "    FRED_completed.append(i)\n",
    "    FRED_set.append(Fred_Data(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02687812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FRED_pvt = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(FRED_completed)):\n",
    "    values = FRED_set[x]\n",
    "    #values.index = pd.to_datetime(FRED_set[\"DATE\"])\n",
    "    values = values.resample(frequency).mean().dropna()\n",
    "    #values['Symbol'] = x\n",
    "    values = values.loc[~values.index.duplicated(keep='last')]\n",
    "    #values = values.reset_index()\n",
    "\n",
    "    FRED_pvt = pd.concat([FRED_pvt,values], axis=1)\n",
    "\n",
    "#FRED_ = pd.pivot_table(commodities_, values='Close', index=['Date'],columns=['Symbol'])\n",
    "#FRED_.to_csv(\"/mnt/distvol/FRED_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405d624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbea38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRED_pvt = pd.pivot_table(FRED_, index=['DATE'])\n",
    "FRED_pvt.to_csv(re.sub('code', 'data', wd)+\"\\FRED_pvt.csv\")\n",
    "\n",
    "#print(len(FRED_.columns))\n",
    "#print(len(FRED_))\n",
    "#FRED_pvt.columns = FRED_completed\n",
    "#FRED_pvt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRED_pvt.set_index(FRED_pvt.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set = pd.concat([FRED_pvt.set_index(FRED_pvt.index),commodities_pvt],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f4f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    combined_set = combined_set.interpolate(method='linear', limit_direction='forward', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364348f3-2789-4432-a3e9-497557d7563e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set.describe().loc['count'].index[combined_set.describe().loc['count']<(len(combined_set)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc346c-e48a-4c48-a555-56cf78db622d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecde09b-18e9-4505-b3c8-37456233619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = combined_set.describe().loc['count'].index[combined_set.describe().loc['count']<(len(combined_set)*.99)]\n",
    "print(drops)\n",
    "filtered = combined_set.columns.tolist()\n",
    "\n",
    "for d in drops:\n",
    "    #print(d)\n",
    "    filtered.remove(d)\n",
    "#filtered.remove(drops.tolist())\n",
    "#combined_set[filtered].to_csv(\"/mnt/distvol/combined_set.csv\")\n",
    "\n",
    "#drop first/last row\n",
    "all_data = combined_set[filtered]\n",
    "all_data = all_data.iloc[:-1,:]\n",
    "all_data = all_data.iloc[1:,:]\n",
    "\n",
    "#all_data.loc[:, (all_data != all_data.iloc[0]).any()] \n",
    "#*** should fix duplications\n",
    "all_data = all_data.loc[:,~all_data.columns.duplicated()]\n",
    "\n",
    "all_data.to_csv(re.sub('code', 'data', wd)+\"\\combined_set.csv\")\n",
    "#filtered\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8f8e0-62df-43c0-baf4-5134c22bdc45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547faad-34f0-46f4-b7b0-1d4b04108be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61b34f4-63f8-4593-aa39-292dfaafc6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedData = all_data.reindex(early.index).interpolate(method='time')\n",
    "#len(truncatedData.dropna(axis=0).columns)\n",
    "#truncatedData = truncatedData.replace([np.inf, -np.inf, np.NaN], 0).interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b8125-3823-4c5c-93a3-686b031d4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(truncatedData.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f9e30-ff3b-45e1-bcc6-fd26c17eb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431541c-b8f9-44cc-b365-0922ef125647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e0b47-ea38-4fa0-8b1e-21db68aff32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = truncatedData.dropna().pct_change().dropna()\n",
    "deltas = deltas.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "#deltas = (truncatedData[all_data.columns]/truncatedData[all_data.columns].shift(-1))-1\n",
    "len(deltas.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0d0cd-edb5-48b4-a20a-31d2a979636a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23f172-ff5d-491c-af1f-a8875075e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.sum(deltas.isin([np.inf, -np.inf, np.NaN])).sort_values(kind=\"quicksort\", ascending=True)\n",
    "results[results>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673829c5-6201-4c46-b0c8-ff0a8872a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Training, Holdout = split_sequences(np.array(pd.DataFrame(truncatedData.index.strftime('%Y-%m-%d'))), 1009, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46674a8d-37f0-480c-ade2-4f2cf6b52416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = 'DGS2'\n",
    "#compare = '^SP500TR'\n",
    "#compare = 'T10Y3M'\n",
    "#compare = 'T10Y2Y'\n",
    "target = '^SP500TR'\n",
    "#target = pd.DataFrame(vetted_symbols).sample(n=1).values[0][0]\n",
    "#target = etf_metals[0]\n",
    "#target = crypto[1]\n",
    "#target = '^GSPC'\n",
    "\n",
    "pd.concat([truncatedData[compare].pct_change(),truncatedData[target].pct_change()],axis=1).dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674b397-30ba-4421-be78-87200f3adf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = train_test_split(deltas.index,  test_size=0.33, random_state=0, shuffle=False)\n",
    "valid, test = train_test_split(valid,  test_size=0.5, random_state=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32dfcb7-6a76-48ef-afe0-01af8158749f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a46be8-89f1-421c-aaba-43a97aa6c7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e2da9-0e53-4906-b0d4-ce5e44f7a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats # For in-built method to get PCC\n",
    "import scipy\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650927b6-968a-4cd9-90b0-c8d6f4af67fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69844396-f693-44b9-a2fa-888a4c194d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2d515-3646-42a6-bf97-04394a715eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25603e4f-6960-421d-a2db-b0d80cb4ad80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cc9d7-ab49-4cd4-874d-9865758a9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "lagn=63\n",
    "p_threshold = .05\n",
    "threshold = .5\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "for target in set(deltas.columns) & set(vetted_symbols):\n",
    "    #print(f\"target: {target}\")\n",
    "    \n",
    "    #sets = range(0,len(Training),252)\n",
    "    #move this outside\n",
    "    X_train = deltas.loc[train][set(deltas.columns).difference(target)].copy()\n",
    "    X_valid = deltas.loc[test][set(deltas.columns).difference(target)].copy()\n",
    "    y_train = deltas.loc[train][target].copy()\n",
    "    y_valid = deltas.loc[test][target].copy()\n",
    "    \n",
    "    kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "    kfold.get_n_splits(X_train)\n",
    "\n",
    "    for m in X_train.columns:\n",
    "        \n",
    "        corrs = []\n",
    "        ps = []\n",
    "        lags = []\n",
    "\n",
    "        sig_table = np.zeros(shape=(2))\n",
    "        signs_table = np.zeros(shape=(2))\n",
    "\n",
    "        sets = np.zeros(shape=(num_folds,lagn))\n",
    "        \n",
    "        iterator = 0\n",
    "        \n",
    "        for train_index, test_index in kfold.split(X_train):\n",
    "\n",
    "            subsetX = X_train.iloc[train_index]\n",
    "            subsetY = y_train.iloc[train_index]\n",
    "\n",
    "            #skip y and states\n",
    "\n",
    "            n=len(subset)\n",
    "            \n",
    "            temp = pd.concat([subsetX[m].shift((lag-lagn)[0]),subsetY], axis=1).dropna()\n",
    "\n",
    "            dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "\n",
    "            chosen = pd.DataFrame()\n",
    "\n",
    "            #train\n",
    "            setc = crosscorrelation(np.array(temp[m]),np.array(temp.iloc[:,1]), lagn)\n",
    "            p_values = pd.DataFrame(2*dist.cdf(-abs(setc))).T\n",
    "            \n",
    "            fields = np.argwhere(np.array(p_values)[0] <= p_threshold)\n",
    "            print(fields[fields>lagn+1]-lagn-1)\n",
    "            print(setc[fields[fields>lagn+1]])\n",
    "            \n",
    "            sets[iterator] = (np.where(p_values <= p_threshold, True, 0)*setc)[0][lagn+1:]\n",
    "            #plt.plot((np.where(p_values <= p_threshold, True, 0)*setc)[0][lagn+1:])\n",
    "            \n",
    "            lag = pd.DataFrame(abs(setc[lagn+1:])).idxmax()+lagn\n",
    "            #print(f\"correlation: {setc[lag]}\")\n",
    "            \n",
    "            pearson_coef, p_value = stats.pearsonr(np.array(temp.iloc[:,0]),np.array(temp.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "            corrs.append(pearson_coef)\n",
    "            ps.append(p_value)\n",
    "            lags.append(lag-lagn)        \n",
    "            \n",
    "            if (p_value < .05) and ((lag-lagn)[0] < 0):\n",
    "                #print(i)\n",
    "                #print(f\"lag: {lag-lagn}\")\n",
    "                #print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results\n",
    "                temp1 = pd.DataFrame([target, m,(lag-lagn)[0],pearson_coef]).T\n",
    "                temp1.columns = [\"target\",\"name\",\"lag\",\"pearson\"]\n",
    "\n",
    "                #p_values = pd.DataFrame(2*dist.cdf(-abs(temp.corr()[target]))).T\n",
    "                #p_values.columns = list(temp.columns)\n",
    "\n",
    "                #if(p_values[p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()]<=p_threshold):\n",
    "                #winners = p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()\n",
    "                winners = m\n",
    "\n",
    "                sig_table = (sig_table + np.where(temp.columns.isin([winners]),1,0)).copy()\n",
    "                #print(sig_table)\n",
    "                signs_table[temp.columns.get_indexer([winners])]+=np.where(temp.corr()[target][winners]<0,-1,1)                 \n",
    "                #chosen = pd.concat([temp1,chosen],axis=0)\n",
    "                \n",
    "            significance = pd.DataFrame(sig_table).T\n",
    "            significance.columns = list(temp.columns)\n",
    "            #print(significance)\n",
    "\n",
    "            sign = pd.DataFrame(signs_table).T\n",
    "            sign.columns = list(temp.columns)\n",
    "\n",
    "            purity = abs((sign/num_folds)*(sign/significance)).T.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "            #print(purity)\n",
    "\n",
    "            ichosen = list(purity.T.columns.values[np.array(purity.T>=threshold).reshape(len(temp.columns,))])\n",
    "            #print(ichosen)\n",
    "            chosen.append(ichosen)\n",
    "            \n",
    "            iterator = iterator + 1\n",
    "            \n",
    "        x=range(0,lagn)\n",
    "        plt.stackplot(x,sets[0],sets[1],sets[2],sets[3],sets[4], labels=['A','B','C','D','E'])\n",
    "        plt.show()\n",
    "        #print(chosen)\n",
    "        \n",
    "        print(lags)\n",
    "        #print(m)\n",
    "        #print(ps)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed0215-606c-4362-8e82-72228d3284ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de683ae-f0a3-4422-809b-d1ff35ffef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "lagn=63\n",
    "p_threshold = .05\n",
    "threshold = .5\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "for target in set(deltas.columns) & set(vetted_symbols):\n",
    "    #print(f\"target: {target}\")\n",
    "    \n",
    "    #sets = range(0,len(Training),252)\n",
    "    #move this outside\n",
    "    X_train = deltas.loc[train][set(deltas.columns).difference(target)].copy()\n",
    "    X_valid = deltas.loc[test][set(deltas.columns).difference(target)].copy()\n",
    "    y_train = deltas.loc[train][target].copy()\n",
    "    y_valid = deltas.loc[test][target].copy()\n",
    "    \n",
    "    kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "    kfold.get_n_splits(X_train)\n",
    "\n",
    "    for m in X_train.columns:\n",
    "        \n",
    "        corrs = []\n",
    "        ps = []\n",
    "        lags = []\n",
    "\n",
    "        sig_table = np.zeros(shape=(2))\n",
    "        signs_table = np.zeros(shape=(2))\n",
    "\n",
    "        sets = np.zeros(shape=(num_folds,lagn))\n",
    "        \n",
    "        iterator = 0\n",
    "        \n",
    "        for train_index, test_index in kfold.split(X_train):\n",
    "\n",
    "            subsetX = X_train.iloc[train_index]\n",
    "            subsetY = y_train.iloc[train_index]\n",
    "\n",
    "            #skip y and states\n",
    "\n",
    "            n=len(subset)\n",
    "            \n",
    "            temp = pd.concat([subsetX[m].shift((lag-lagn)[0]),subsetY], axis=1).dropna()\n",
    "\n",
    "            dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "\n",
    "            chosen = pd.DataFrame()\n",
    "\n",
    "            #train\n",
    "            setc = crosscorrelation(np.array(temp[m]),np.array(temp.iloc[:,1]), lagn)\n",
    "            p_values = pd.DataFrame(2*dist.cdf(-abs(setc))).T\n",
    "            \n",
    "            fields = np.argwhere(np.array(p_values)[0] <= p_threshold)\n",
    "            print(fields[fields>lagn+1]-lagn-1)\n",
    "            print(setc[fields[fields>lagn+1]])\n",
    "            \n",
    "            sets[iterator] = (np.where(p_values <= p_threshold, True, 0)*setc)[0][lagn+1:]\n",
    "            #plt.plot((np.where(p_values <= p_threshold, True, 0)*setc)[0][lagn+1:])\n",
    "            \n",
    "            lag = pd.DataFrame(abs(setc[lagn+1:])).idxmax()+lagn\n",
    "            #print(f\"correlation: {setc[lag]}\")\n",
    "            \n",
    "            pearson_coef, p_value = stats.pearsonr(np.array(temp.iloc[:,0]),np.array(temp.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "            corrs.append(pearson_coef)\n",
    "            ps.append(p_value)\n",
    "            lags.append(lag-lagn)        \n",
    "            \n",
    "            if (p_value < .05) and ((lag-lagn)[0] < 0):\n",
    "                #print(i)\n",
    "                #print(f\"lag: {lag-lagn}\")\n",
    "                #print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results\n",
    "                temp1 = pd.DataFrame([target, m,(lag-lagn)[0],pearson_coef]).T\n",
    "                temp1.columns = [\"target\",\"name\",\"lag\",\"pearson\"]\n",
    "\n",
    "                #p_values = pd.DataFrame(2*dist.cdf(-abs(temp.corr()[target]))).T\n",
    "                #p_values.columns = list(temp.columns)\n",
    "\n",
    "                #if(p_values[p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()]<=p_threshold):\n",
    "                #winners = p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()\n",
    "                winners = m\n",
    "\n",
    "                sig_table = (sig_table + np.where(temp.columns.isin([winners]),1,0)).copy()\n",
    "                #print(sig_table)\n",
    "                signs_table[temp.columns.get_indexer([winners])]+=np.where(temp.corr()[target][winners]<0,-1,1)                 \n",
    "                #chosen = pd.concat([temp1,chosen],axis=0)\n",
    "                \n",
    "            significance = pd.DataFrame(sig_table).T\n",
    "            significance.columns = list(temp.columns)\n",
    "            #print(significance)\n",
    "\n",
    "            sign = pd.DataFrame(signs_table).T\n",
    "            sign.columns = list(temp.columns)\n",
    "\n",
    "            purity = abs((sign/num_folds)*(sign/significance)).T.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "            #print(purity)\n",
    "\n",
    "            ichosen = list(purity.T.columns.values[np.array(purity.T>=threshold).reshape(len(temp.columns,))])\n",
    "            #print(ichosen)\n",
    "            chosen.append(ichosen)\n",
    "            \n",
    "            iterator = iterator + 1\n",
    "            \n",
    "        x=range(0,lagn)\n",
    "        plt.stackplot(x,sets[0],sets[1],sets[2],sets[3],sets[4], labels=['A','B','C','D','E'])\n",
    "        plt.show()\n",
    "        #print(chosen)\n",
    "        \n",
    "        print(lags)\n",
    "        #print(m)\n",
    "        #print(ps)            \n",
    "        \n",
    "        for i in range(0,len(chosen)):\n",
    "            values = chosen.reset_index().iloc[i]\n",
    "            name = values['name']\n",
    "            target = values['target']\n",
    "            lag = values['lag']\n",
    "            #print(lag)\n",
    "            aggregate = pd.DataFrame()\n",
    "\n",
    "            #test\n",
    "            innerSet = pd.concat([X_valid[name].shift(lag),y_valid],axis=1).dropna()\n",
    "\n",
    "            for p in range(0,len(innerSet)):     \n",
    "                #print(innerSet.iloc[p][name] )\n",
    "                if(innerSet.iloc[p][name] < 0):\n",
    "                    d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),innerSet.iloc[p][target], np.nan, 'l'])\n",
    "                    #print(\"lower\")\n",
    "                elif (innerSet.iloc[p][name] > 0):\n",
    "                    d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, innerSet.iloc[p][target], 'u'])\n",
    "                    #print(\"upper\")\n",
    "                else:\n",
    "                    d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, np.nan, np.nan])\n",
    "\n",
    "                aggregate = pd.concat([d.T,aggregate],axis=0)\n",
    "            #print(aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1])\n",
    "\n",
    "            aggregate.columns = \"Date\",\"l\",\"u\",\"class\"\n",
    "\n",
    "            pearson_coef, p_value = stats.pearsonr(np.array(innerSet.iloc[:,0]),np.array(innerSet.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "            #print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {innerSet.corr().iloc[0][1]}\")\n",
    "            if p_value < .05 and (values['pearson']*pearson_coef) > 0:\n",
    "\n",
    "                    newData = pd.concat([pd.DataFrame(innerSet[target]).set_index(innerSet[target].index.strftime('%Y-%m-%d')),aggregate.set_index(\"Date\")],axis=1).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "                    if newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['l'] or newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['u']:\n",
    "                        print(f\"target: {target}\")\n",
    "                        print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {pearson_coef}\", f\"p-value: {p_value}\")\n",
    "                        print(pd.DataFrame(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]).T)\n",
    "\n",
    "                        x_ticks = newData.index[np.arange(0, len(newData.index), 200)]\n",
    "\n",
    "                        plt.plot(newData[[target,\"l\",\"u\"]].cumsum())\n",
    "                        plt.legend(loc='upper left', fancybox=True, ncol=5, labels=[target,\"l\",\"u\"])\n",
    "                        #plt.legend(loc=\"upper left\",fontsize=8)\n",
    "\n",
    "                        plt.xticks(x_ticks, rotation = 45)\n",
    "                        plt.show()\n",
    "\n",
    "                        temp1 = pd.DataFrame([target, name, pearson_coef, p_value, lag, max(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][['l','u']]), newData[[target]].cumsum().iloc[-1][target] ]).T\n",
    "                        final = pd.concat([temp1,final],axis=0)\n",
    "\n",
    "final.columns = [\"target\",\"correlate\",\"pearson\",\"p-value\",\"lag\",\"TCR\",\"holdTCR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edaae29-4918-4d61-bcb6-b2eeedbaae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100c95c-3b55-450a-b919-8f36936340c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c5f0c-8226-4c96-b684-174c03d4b5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530810c5-fa4b-457c-9d58-dfe7925b3a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8ec73-994c-4c85-b928-52e9c9f63cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(final)):\n",
    "    values = final.reset_index().iloc[i]\n",
    "    name = values['correlate']\n",
    "    target = values['target']\n",
    "    lag = values['lag']\n",
    "    #print(lag)\n",
    "    aggregate = pd.DataFrame()\n",
    "\n",
    "    X_test = deltas.loc[test][set(deltas.columns).difference(target)]\n",
    "    y_test = deltas.loc[test][target]\n",
    "    \n",
    "    #test\n",
    "    innerSet = pd.concat([X_test[name].shift(lag),y_test],axis=1).dropna()\n",
    "\n",
    "    for p in range(0,len(innerSet)):     \n",
    "        #print(innerSet.iloc[p][name] )\n",
    "        if(innerSet.iloc[p][name] < 0):\n",
    "            d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),innerSet.iloc[p][target], np.nan, 'l'])\n",
    "            #print(\"lower\")\n",
    "        elif (innerSet.iloc[p][name] > 0):\n",
    "            d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, innerSet.iloc[p][target], 'u'])\n",
    "            #print(\"upper\")\n",
    "        else:\n",
    "            d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, np.nan, np.nan])\n",
    "\n",
    "        aggregate = pd.concat([d.T,aggregate],axis=0)\n",
    "    #print(aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1])\n",
    "\n",
    "    aggregate.columns = \"Date\",\"l\",\"u\",\"class\"\n",
    "\n",
    "    pearson_coef, p_value = stats.pearsonr(np.array(innerSet.iloc[:,0]),np.array(innerSet.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "    #print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {innerSet.corr().iloc[0][1]}\")\n",
    "    if p_value < .05:\n",
    "\n",
    "            newData = pd.concat([pd.DataFrame(innerSet[target]).set_index(innerSet[target].index.strftime('%Y-%m-%d')),aggregate.set_index(\"Date\")],axis=1).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "            if newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['l'] or newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['u']:\n",
    "                print(f\"target: {target}\")\n",
    "                print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {pearson_coef}\", f\"p-value: {p_value}\")\n",
    "                print(pd.DataFrame(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]).T)\n",
    "\n",
    "                x_ticks = newData.index[np.arange(0, len(newData.index), 200)]\n",
    "\n",
    "                plt.plot(newData[[target,\"l\",\"u\"]].cumsum())\n",
    "                plt.legend(loc='upper left', fancybox=True, ncol=5, labels=[target,\"l\",\"u\"])\n",
    "                #plt.legend(loc=\"upper left\",fontsize=8)\n",
    "\n",
    "                plt.xticks(x_ticks, rotation = 45)\n",
    "                plt.show()\n",
    "\n",
    "                temp1 = pd.DataFrame([target, name, pearson_coef, p_value, lag, max(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][['l','u']]), newData[[target]].cumsum().iloc[-1][target] ]).T\n",
    "                results2 = pd.concat([temp1,results2],axis=0)\n",
    "                \n",
    "results2.columns = [\"target\",\"correlate\",\"pearson\",\"p-value\",\"lag\",\"TCR\",\"holdTCR\"]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7c793-e071-420b-aa9b-f6b7e08f2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4f0c4-ad8a-4291-b988-9a1bbcc9dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afbd82-67be-4636-acc6-9e88ef8761df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([final['pearson'],results2['pearson']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cd9f0-a1c1-4b62-bbfb-3a60f28a9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([final['pearson']*results2['pearson']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b5a42-8ce8-49d3-8324-b706b77780e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate = pd.DataFrame()\n",
    "\n",
    "for s in Training:\n",
    "    #print(s)\n",
    "    set_dates = s\n",
    "    #print(set_dates[1])\n",
    "    #print(set_dates[-1])\n",
    "    \n",
    "    #rate of change compare\n",
    "    filtered2 =  pd.concat([truncatedData.loc[[i[0] for i in set_dates]][compare],truncatedData.loc[[i[0] for i in set_dates]][target]],axis=1).pct_change().dropna().replace([np.inf, -np.inf, np.NaN], 0)\n",
    "    #quantiles2 = filtered2[compare].quantile(q=[0, .25, .5, .75, 1], interpolation='linear')\n",
    "\n",
    "    #prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    #colors = cycle(prop_cycle.by_key()['color'])\n",
    "    \n",
    "    #subset, Holdout = split_sequences(np.array(pd.DataFrame(filtered2.index.strftime('%Y-%m-%d'))), 126, 0)\n",
    "    \n",
    "    #for i in subset:\n",
    "        \n",
    "    #quantiles = pd.DataFrame(filtered2.iloc[0:-2][compare].quantile([0,.5,1]),columns=['min','median','max'])\n",
    "    #np.percentile((filtered2.iloc[0:-2][compare]),50)\n",
    "    \n",
    "    t = pd.DataFrame(filtered2.iloc[0:-3][compare].quantile([0,.5,1])).T\n",
    "    t.columns = ['min','median','max']\n",
    "    quantiles = t.reset_index(drop=True)\n",
    "\n",
    "    #lower = filtered2.iloc[0:-1][(filtered2.iloc[0:-2][compare]<=quantile)].index\n",
    "    #upper = ~filtered2.iloc[0:-2].index.isin(lower)\n",
    "\n",
    "\n",
    "\n",
    "    #my_dpi = 100\n",
    "    #fig, axes = plt.subplots(figsize=(12, 4),ncols=3, nrows=1)\n",
    "    #ax1, ax2, ax3 = axes.ravel()\n",
    "    #sns.set(style=\"ticks\")\n",
    "    #sns.despine(fig=fig)\n",
    "\n",
    "    #dataframe = filtered2.loc[dates]\n",
    "    #returns = dataframe[target].dropna()\n",
    "\n",
    "    #l = np.where(filtered2.iloc[0:-2][compare] <= quantile, filtered2.iloc[-1][target], 0)\n",
    "    #u = np.where(filtered2.iloc[upper][compare] > quantile, filtered2.iloc[-1][target], 0)\n",
    "    if((filtered2.iloc[-2][compare] <= quantiles['median'][0])):\n",
    "        d = pd.DataFrame([filtered2.iloc[-1][target], np.nan, 'l'])\n",
    "    else:\n",
    "        d = pd.DataFrame([np.nan, filtered2.iloc[-1][target], 'u'])\n",
    "    #d = pd.concat([pd.DataFrame(l.tolist()),pd.DataFrame(u.tolist())],axis=1)\n",
    "    #print(len(d))\n",
    "    #print(d)\n",
    "    \n",
    "    #print(pd.concat([d.T, quantiles.T.reset_index(drop=True)],axis=1))\n",
    "    #aggregate = pd.concat([d.T, quantiles.T.reset_index(drop=True), aggregate],axis=0)\n",
    "    aggregate = pd.concat([pd.concat([d.T, quantiles],axis=1),aggregate],axis=0)\n",
    "    #print(aggregate)\n",
    "    #print(len(aggregate))\n",
    "    #print(aggregate)\n",
    "    #d.index = filtered2.iloc[-1].name.strftime('%Y-%m-%d')\n",
    "   \n",
    "    #sns.regplot(x=compare, y=target, data=dataframe, ax=ax1)\n",
    "\n",
    "    #sns.violinplot(x=dataframe[compare].dropna(),color=next(colors), ax=ax2)\n",
    "\n",
    "    #sns.vioinplot(x=returns,color=next(colors), ax=ax3) \n",
    "    #plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9982434-a0db-4230-803b-0c250ef3c9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82770c63-0235-4afa-9075-addb7841d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Training)\n",
    "\n",
    "aggregate.columns = ['l','u','class','min','median','max']\n",
    "\n",
    "dates = []\n",
    "for item in Training:\n",
    "    last = item[-1]\n",
    "    dates.append(last[0])\n",
    "    \n",
    "aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1]\n",
    "\n",
    "aggregate.index=dates\n",
    "\n",
    "#print(aggregate.cumsum().iloc[-1])\n",
    "#aggregate.reset_index()\n",
    "#ax = sns.regplot(x=aggregate.columns[1], y='index', data=aggregate.reset_index())\n",
    "\n",
    "x_ticks = aggregate.index[np.arange(0, len(aggregate.index), 200)]\n",
    "\n",
    "plt.plot(aggregate.loc[:,['l']].replace([np.inf, -np.inf, np.NaN], 0).cumsum())\n",
    "\n",
    "plt.xticks(x_ticks, rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb49747-11d0-4e27-9d16-c3e4234164c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a51829-f0e8-4c01-8916-2c2deb6d496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = pd.concat([truncatedData[compare].pct_change(),truncatedData[target]],axis=1).loc[dates]\n",
    "temp2 = pd.concat([truncatedData[compare].pct_change(),truncatedData[target].pct_change()],axis=1).loc[dates]\n",
    "temp1.index = temp1.index.copy().strftime('%Y-%m-%d')\n",
    "temp2.index = temp2.index.copy().strftime('%Y-%m-%d')\n",
    "temp = pd.concat([temp1,temp2,aggregate],axis=1)\n",
    "newNames = [compare,target,compare+\"_pct_change\",target+\"_pct_change\"]\n",
    "newNames.extend(temp.columns[4:10])\n",
    "temp.columns = newNames\n",
    "\n",
    "temp.to_csv('../data/processed/output.csv', index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e5e50-2826-47ee-8223-b8daa2f203fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#scores = np.where(temp[compare] > 1, 1, 0)\n",
    "\n",
    "#idk why this library uses 2, 1 vs 1 and 0\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np.where(temp[target+\"_pct_change\"] > 0, 2, 1), np.array(temp[compare+\"_pct_change\"].shift(-1)) , pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa15229-dd40-409c-86c4-094143a72967",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_roc_curve(clf, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3179b-a4d3-46e6-9553-a3763ae8cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "#plt.plot(fpr,tpr, label='AUC = ' + str(round(roc_auc_score(y,m.oob_decision_function_[:,1]), 2)))\n",
    "#plt.legend(loc='lower right')\n",
    "\n",
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "bc = BinaryClassification(np.where(temp[target+\"_pct_change\"] > 0, 1, 0), np.array(temp[compare+\"_pct_change\"]), labels=[\"Class 1\", \"Class 2\"])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da249f-be20-4b24-b594-9ed3612fd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"optimal cutoff\")\n",
    "#https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "Find_Optimal_Cutoff(np.where(temp[target+\"_pct_change\"] > 0, 1, 0), np.array(temp[compare+\"_pct_change\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e19fe4-ed2b-464a-b0a2-08536a924dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import DataGenerator, KneeLocator\n",
    "kneedle = KneeLocator(fpr, tpr, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "#kneedle.plot_knee_normalized()\n",
    "kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf2a1e-3f0a-49de-844d-dca3c37f787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c724826-6c51-4e93-827e-c55cc83ab675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db525f5-aeb2-45fd-934b-efb782ecf9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15badd1f-eab0-411a-aaf8-5ba8efe5387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415802f-c6dc-45b0-a604-a0439104ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(aggregate[aggregate['bifur']=='l'].iloc[:,0].cumsum(),  truncatedData[target].pct_change().loc[aggregate[aggregate['bifur']=='l'].iloc[:,0].index.tolist()])\n",
    "plt.show()\n",
    "aggregate[aggregate['bifur']=='l'].iloc[:,0].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b50107-1e96-4169-abd4-97efb6203f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(aggregate[aggregate['bifur']=='u'].iloc[:,1].cumsum(),  truncatedData[target].pct_change().loc[aggregate[aggregate['bifur']=='u'].iloc[:,1].index.tolist()])\n",
    "plt.show()\n",
    "aggregate[aggregate['bifur']=='u'].iloc[:,1].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23aeba-1baf-43ba-8ed1-1f886304456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#252 trading days a year\n",
    "#30 days = 21\n",
    "#60 = 42\n",
    "#90 = 63\n",
    "\n",
    "#return = current - prior / prior\n",
    "\n",
    "#for i in range(1,63): #[1,21,42,63]\n",
    "for i in [1,21,42,63,84]: #[1,21,42,84]\n",
    "    print(i)\n",
    "    rate_of_change = (truncatedData[compare]-truncatedData[compare].shift(i))/truncatedData[compare].shift(i)\n",
    "    \n",
    "    newDF = pd.concat([rate_of_change,truncatedData[target].pct_change()],axis=1).dropna()\n",
    "\n",
    "    set1 = newDF[compare]\n",
    "    set2 = newDF[target]\n",
    "    \n",
    "    lags = range(0,85) #[0,21,42,63]\n",
    "    mcorrs_ = []\n",
    "    mlags = []\n",
    "    for j in lags:\n",
    "        \n",
    "        newSet = pd.concat([set1.shift(j),set2],axis=1).dropna()\n",
    "      \n",
    "        mcorrs_.append(np.array(newSet.corr())[1,0])\n",
    "        \n",
    "    plt.plot(mcorrs_)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d193fa-397f-4061-909e-5086d2087334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([(truncatedData[compare]-truncatedData[compare].shift(1))/truncatedData[compare].shift(1),truncatedData[target].pct_change().shift(0)],axis=1).dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0985e2-7c25-4c96-bb60-b9dcb8e5148e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a5775-b45a-4420-9eb5-56f125f350b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter((truncatedData[compare]-truncatedData[compare].shift(1))/truncatedData[compare].shift(1),truncatedData[target].pct_change().shift(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031f472-f7f1-4d61-9002-d2f9c109f327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.matshow(\n",
    "df = combined_set.loc[combined_set.index>=start_date.strftime('%Y-%m-%d')]\n",
    "\n",
    "r_ = df.corr()\n",
    "\n",
    "filter = r_[compare]\n",
    "                       \n",
    "filter = filter[filter<1]\n",
    "filter = filter.sort_values(kind=\"quicksort\", ascending=True)\n",
    "print(filter.head(10))\n",
    "print(filter.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a40b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
