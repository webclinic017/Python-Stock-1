{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2ec6684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "08d626f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: pandas_datareader in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: yfinance==0.1.62 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.1.62)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (7.6.5)\n",
      "Requirement already satisfied: pandas_market_calendars in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.4.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.20.3)\n",
      "Requirement already satisfied: pycorrelate in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas==1.2.5) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas==1.2.5) (2.8.2)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from yfinance==0.1.62) (2.26.0)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from yfinance==0.1.62) (0.0.9)\n",
      "Requirement already satisfied: lxml>=4.5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from yfinance==0.1.62) (4.6.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (7.27.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (6.4.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: exchange-calendars>=3.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas_market_calendars) (3.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (8.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numba in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pycorrelate) (0.54.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pyluach in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (1.3.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (0.11.1)\n",
      "Requirement already satisfied: korean_lunar_calendar in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from exchange-calendars>=3.3->pandas_market_calendars) (0.2.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (1.4.3)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (7.0.3)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (57.4.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (3.0.20)\n",
      "Requirement already satisfied: backcall in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ipython>=4.0.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (4.8.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (1.5.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (22.3.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets) (301)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->yfinance==0.1.62) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->yfinance==0.1.62) (2.0.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->yfinance==0.1.62) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->yfinance==0.1.62) (3.2)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.4)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.1.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.1.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.11.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: pywinpty>=1.1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.4)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.6)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: bleach in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: testpath in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.0)\n",
      "Requirement already satisfied: llvmlite<0.38,>=0.37.0rc1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from numba->pycorrelate) (0.37.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.2.5 pandas_datareader yfinance==0.1.62 ipywidgets pandas_market_calendars matplotlib numpy pycorrelate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8655e344-79c7-4326-a116-a163805e71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import concurrent\n",
    "import pandas_datareader.data as web\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import concurrent.futures\n",
    "from concurrent.futures import wait, ALL_COMPLETED\n",
    "import yfinance as yf\n",
    "import urllib\n",
    "import urllib.request\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from finquant.portfolio import build_portfolio\n",
    "\n",
    "from ipywidgets import interactive\n",
    "import numpy as np\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pycorrelate as pyc\n",
    "import seaborn as sns\n",
    "from yahoofinancials import YahooFinancials\n",
    "\n",
    "import pandas_market_calendars as mcal\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy import stats # For in-built method to get PCC\n",
    "from scipy.ndimage.interpolation import shift\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "#import statsmodels.formula.api as sm\n",
    "import scipy.stats  as stats\n",
    "from itertools import cycle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "de3c8e1c-3d8e-4408-95cb-312ae590387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out\n",
    "        # check if we are beyond the dataset\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix:out_end_ix, :]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def crosscorrelation(x, y, maxlag, mode='corr'):\n",
    "\t\"\"\"\n",
    "\tCross correlation with a maximum number of lags.\n",
    "\n",
    "\t`x` and `y` must be one-dimensional numpy arrays with the same length.\n",
    "\n",
    "\tThis computes the same result as\n",
    "\t\tnumpy.correlate(x, y, mode='full')[len(a)-maxlag-1:len(a)+maxlag]\n",
    "\n",
    "\tThe return vaue has length 2*maxlag + 1.\n",
    "\t\"\"\"\n",
    "\tpy = np.pad(y.conj(), 2*maxlag, mode='constant')\n",
    "\tT = np.lib.stride_tricks.as_strided(py[2*maxlag:], shape=(2*maxlag+1, len(y) + 2*maxlag),\n",
    "\t\t\t\t   strides=(-py.strides[0], py.strides[0]))\n",
    "\tpx = np.pad(x, maxlag, mode='constant')\n",
    "\tif mode == 'dot':       # get lagged dot product\n",
    "\t\treturn T.dot(px)\n",
    "\telif mode == 'corr':    # gets Pearson correlation\n",
    "\t\treturn (T.dot(px)/px.size - (T.mean(axis=1)*px.mean())) / \\\n",
    "\t\t\t   (np.std(T, axis=1) * np.std(px))\n",
    "\n",
    "def unique(list1):\n",
    "\n",
    "    # intilize a null list\n",
    "    unique_list = []\n",
    "\n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "\n",
    "    return(unique_list)\n",
    "\n",
    "def Find_Optimal_Cutoff(target, predicted):\n",
    "    \"\"\" Find the optimal probability cutoff point for a classification model related to event rate\n",
    "    Parameters\n",
    "    ----------\n",
    "    target : Matrix with dependent or target data, where rows are observations\n",
    "\n",
    "    predicted : Matrix with predicted data, where rows are observations\n",
    "\n",
    "    Returns\n",
    "    -------     \n",
    "    list type, with optimal cutoff value\n",
    "        \n",
    "    \"\"\"\n",
    "    fpr, tpr, threshold = roc_curve(target, predicted)\n",
    "    i = np.arange(len(tpr)) \n",
    "    roc = pd.DataFrame({'tf' : pd.Series(tpr-(1-fpr), index=i), 'threshold' : pd.Series(threshold, index=i)})\n",
    "    roc_t = roc.iloc[(roc.tf-0).abs().argsort()[:1]]\n",
    "\n",
    "    return list(roc_t['threshold']) \n",
    "\n",
    "def MAPE(Y_actual,Y_Predicted):\n",
    "    mape = np.mean(np.abs((Y_actual - Y_Predicted)/Y_actual))*100\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "45e6c5b3-f6e4-4531-a68a-535e3ab7457f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-19\n",
      "1999-12-17\n",
      "['ASX', 'BMF', 'CFE', 'CBOE_Futures', 'CBOE_Equity_Options', 'CBOE_Index_Options', 'CME_Equity', 'CBOT_Equity', 'CME_Agriculture', 'CBOT_Agriculture', 'COMEX_Agriculture', 'NYMEX_Agriculture', 'CME_Rate', 'CBOT_Rate', 'CME_InterestRate', 'CBOT_InterestRate', 'CME_Bond', 'CBOT_Bond', 'EUREX', 'HKEX', 'ICE', 'ICEUS', 'NYFE', 'JPX', 'LSE', 'NYSE', 'stock', 'NASDAQ', 'BATS', 'DJIA', 'DOW', 'OSE', 'SIX', 'SSE', 'TSX', 'TSXV', 'BSE', 'TASE', 'AIXK', 'ASEX', 'BVMF', 'CMES', 'IEPA', 'XAMS', 'XASX', 'XBKK', 'XBOG', 'XBOM', 'XBRU', 'XBSE', 'XBUD', 'XBUE', 'XCBF', 'XCSE', 'XDUB', 'XFRA', 'XETR', 'XHEL', 'XHKG', 'XICE', 'XIDX', 'XIST', 'XJSE', 'XKAR', 'XKLS', 'XKRX', 'XLIM', 'XLIS', 'XLON', 'XMAD', 'XMEX', 'XMIL', 'XMOS', 'XNYS', 'XNZE', 'XOSL', 'XPAR', 'XPHS', 'XPRA', 'XSES', 'XSGO', 'XSHG', 'XSTO', 'XSWX', 'XTAE', 'XTAI', 'XTKS', 'XTSE', 'XWAR', 'XWBO', 'us_futures', '24/7', '24/5']\n"
     ]
    }
   ],
   "source": [
    "#frequency = output_variable.value\n",
    "frequency = \"Q\"\n",
    "\n",
    "w=52*22\n",
    "#start = datetime.datetime(2010, 1, 1)\n",
    "\n",
    "#end = datetime.datetime(2013, 1, 27)\n",
    "end_date = datetime.date.today()\n",
    "\n",
    "start_date = end_date - timedelta(weeks=w)\n",
    "\n",
    "pd.set_option('display.max_columns', None) #replace n with the number of columns you want to see completely\n",
    "pd.set_option('display.max_rows', None) #replace n with the number of rows you want to see completely\n",
    "\n",
    "#cores = int(len(os.sched_getaffinity(0)))\n",
    "\n",
    "print(end_date)\n",
    "print(start_date)\n",
    "\n",
    "one_week_end = end_date - 5 * pd.tseries.offsets.BDay()\n",
    "one_week_end = one_week_end.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Create a calendar\n",
    "nyse = mcal.get_calendar('NYSE')\n",
    "\n",
    "# Show available calendars\n",
    "print(mcal.get_calendar_names())\n",
    "early = nyse.schedule(start_date, end_date)\n",
    "\n",
    "nstocks = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7120b6d9-7f81-46e1-9ff4-d8c5df92fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"ftp://ftp.nasdaqtrader.com/symboldirectory/nasdaqtraded.txt\"\n",
    "\n",
    "urllib.request.urlretrieve(url, \"nasdaqtraded.txt\")\n",
    "urllib.request.urlretrieve(url, \"mfundslist.txt\")\n",
    "urllib.request.urlretrieve(url, \"bonds.txt\")\n",
    "\n",
    "df1 = pd.read_csv(\"nasdaqtraded.txt\", sep=\"|\")[0:-1]\n",
    "df2 = pd.read_csv(\"mfundslist.txt\", sep=\"|\")[0:-1]\n",
    "df3 = pd.read_csv(\"bonds.txt\", sep=\"|\")[0:-1]\n",
    "\n",
    "# combined = pd.concat([df1['Symbol'],df2['Symbol'],df3['Symbol']],axis=0)\n",
    "\n",
    "# process symbols for bad characters\n",
    "BAD_CHARS = [\"$\", \".\"]\n",
    "# pat = '|'.join(['({})'.format(re.escape(c)) for c in BAD_CHARS])\n",
    "# cleaned = unique(combined.replace(BAD_CHARS,'-'))\n",
    "\n",
    "# choose size\n",
    "size = nstocks\n",
    "# stocks = list(df1[\"Symbol\"].sample(n=int(size/3)))\n",
    "stocks = list(\n",
    "    df1[\"Symbol\"]\n",
    "    .replace(\".\", \"-\")\n",
    "    .replace(\"\\\\$\", \"-P\", regex=True)\n",
    "    .sample(n=int(size / 3))\n",
    ")\n",
    "mfunds = list(\n",
    "    df2[\"Symbol\"]\n",
    "    .replace(\".\", \"-\")\n",
    "    .replace(\"\\\\$\", \"-P\", regex=True)\n",
    "    .sample(n=int(size / 3))\n",
    ")\n",
    "bonds = list(\n",
    "    df3[\"Symbol\"]\n",
    "    .replace(\".\", \"-\")\n",
    "    .replace(\"\\\\$\", \"-P\", regex=True)\n",
    "    .sample(n=int(size / 3))\n",
    ")\n",
    "symbols = list(set(stocks + mfunds + bonds))  # unique(stocks + mfunds + bonds)\n",
    "# symbols = unique(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881313f8-b5dd-4481-b5b9-e4f6dcf66742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a068f4-f59f-4ccb-92af-52b1ba42b6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[**********************62%*****                  ]  183 of 297 completed"
     ]
    }
   ],
   "source": [
    "pf_pre = build_portfolio(\n",
    "    names=symbols, start_date=start_date, end_date=one_week_end, data_api=\"yfinance\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1504f295-39b0-4439-9dc9-54786e2d9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show available calendars\n",
    "# print(mcal.get_calendar_names())\n",
    "\n",
    "vetted_symbols = list(\n",
    "    pf_pre.data.loc[\n",
    "        (np.intersect1d(list(pf_pre.data.index.strftime(\"%Y-%m-%d\")), early.index.strftime('%Y-%m-%d')))\n",
    "    ]\n",
    "    .head(-1)\n",
    "    .tail(-1)\n",
    "    .dropna(axis=1)\n",
    "    .columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec4b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Ultra-Low-Sulfur No. 2 Diesel Fuel Prices: Los Angeles (WDFUELLA)\n",
    "#US Regular All Formulations Gas Price (GASREGW)\n",
    "#Trade Weighted U.S. Dollar Index: Broad, Goods and Services (DTWEXBGS)\n",
    "\n",
    "\n",
    "etf_commodities = ['DBO','CORN', 'WEAT', 'SOYB', 'JO', 'SGG', 'BAL', 'COW', 'MOO', 'TAGS', 'KOL' ]\n",
    "#Gold, Silver, Platinum, Copper, Paladium, Aluminum, Iron, Steel\n",
    "etf_metals = ['IAU', 'SLV', 'PGM', 'JJC', 'PALL', 'JJU', 'IFUNX', 'SLX']\n",
    "#US dollar, European Euro, Japanese yen, Pound sterling, Australian dollar, Canadian dollar, Swiss franc, Chinese Yuan Renminbi, Swedish Krona, Peso, India\n",
    "#defunct: Russia: XRU, Mexico: FXM\n",
    "etf_foreign_exchanges = ['UUP','FXE','FXY','FXB','FXA','FXC','FXF','CYB', 'FXS', 'INR']\n",
    "#residential, Ishares all NAmerica\n",
    "etf_real_estate = ['REZ', 'IYR']\n",
    "#Russia, Germany, UK, Japan, China, Euro, Euro, Brazil, Latin America, Mexico, India\n",
    "etf_economies = ['ERUS','EWG','EWU','EWJ','MCHI','EZU','IEUR','EWZ','ILF','EWW','INDA']\n",
    "#Ishares Investment Grade, IShares core aggregate Investment grade, Short, Total, 1-5 Years, 5-10 Years, 10 Years, Gov/Credit\n",
    "#defunct:\n",
    "\n",
    "etf_spdr_indexes = ['XLC','XLY','XLP','XLE','XLF','XLV','XLI','XLB','XLRE','XLK','XLU']\n",
    "etf_dow_components = ['MMM','AXP','AMGN','AAPL','BA','CAT','CVX','CSCO','KO','DOW','GS','HD','HON','IBM','INTC','JNJ','JPM','MCD','MRK','MSFT','NKE','PG','CRM','TRV','UNH','VZ','V','WMT','WBA','DIS']\n",
    "\n",
    "etf_bonds = ['LQD', 'AGG', 'NEAR', 'IUSB', 'ISTB', 'IMTB', 'ILTB', 'GBF']\n",
    "etf_muni_bonds = ['MUB', 'SUB', 'MEAR']\n",
    "\n",
    "etf_treasuries = ['AGZ', 'GOVT', 'BIL', 'SHV', 'SHY', 'IEI', 'IEF', 'TLT']\n",
    "\n",
    "crypto = ['BTC-USD','ETH','RPL','BCH','EOS','LTC']\n",
    "\n",
    "#,'GOLDAMGBD228NLBM',\n",
    "FRED_Indicators = ['T10YIE','WDFUELLA','DTWEXBGS','GASREGW','DGS2','CPALTT01USQ657N','PAYEMS','MSPUS','ASPUS','IRLTLT01USM156N','MEPAINUSA672N','MABMM301USM189S','LFWA64TTUSM647S','MANMM101USA189S','MICH','UMCSENT','CSCICP03USM665S','DGS10','DTB3','DGS3MO','CASTHPI','GDPC1','CIVPART','POPTOTUSA647NWDB','MEHOINUSA672N','HOSMEDUSM052N','MORTGAGE30US','TTLHH','CSUSHPINSA','EMRATIO','CPIAUCSL','PSAVERT','LRUN64TTUSQ156S','USSTHPI','NYSTHPI','M2V','GFDEBTN','DFII10','GFDEGDQ188S','CUSR0000SEHA','ETOTALUSQ176N','ERENTUSQ176N','RECPROUSM156N','T5YIFR','BAMLHYH0A0HYM2TRIV','BAMLCC0A1AAATRIV','GVZCLS','DGS1','BAMLCC0A4BBBTRIV','VXVCLS','IC4WSA','WILLMICROCAPPR','WILLLRGCAPVAL','CFNAIDIFF','MZMSL','KCFSI','T5YIE','TOTALSA','USSLIND','AWHAETP','CES0500000003','TCU','WTB3MS','WGS3MO','TWEXB','DEXCHUS','DEXUSUK','CILACBQ158SBOG','CES4348400001','FEDFUNDS','TDSP','PERMIT','CP','PRFI','DRSFRMACBS','DRCCLACBS','DRBLACBS','DALLCIACBEP','USROA','USROE','RSAHORUSQ156S','MEFAINUSA672N','COMREPUSQ159N','HDTGPDUSQ163N','POP','NROU','FGCCSAQ027S','TEDRATE', 'VIXCLS', 'NFCI','INDPRO','LES1252881600Q','CUUR0000SEHA','LEU0252918500Q','BAA10Y','BAMLC0A0CM','BAMLH0A3HYC','BOGMBASE','DCOILBRENTEU','DCOILWTICO','DFF','DGS1MO','DGS30','DGS5','FPCPITOTLZGUSA','ICSA','INTDSRUSM193N','M1','M1V','MPRIME','PPIACO','SPCS20RSA','STLFSI2','T10Y2Y','T10Y3M','TB3MS','TREAST','UNRATE','WPU0911']\n",
    "#FRED_Indicators = [\"CPALTT01USQ657N\",\"PAYEMS\",\"IRLTLT01USM156N\",\"MABMM301USM189S\",\"LFWA64TTUSM647S\",\"MANMM101USA189S\",\"MICH\",\"UMCSENT\",\"CSCICP03USM665S\",\"DGS10\",\"DTB3\",\"DGS3MO\",\"CASTHPI\",\"GDPC1\",\"CIVPART\",\"POPTOTUSA647NWDB\",\"MEHOINUSA672N\",\"HOSMEDUSM052N\",\"MORTGAGE30US\",\"TTLHH\",\"CSUSHPINSA\",\"EMRATIO\",\"CPIAUCSL\",\"PSAVERT\",\"LRUN64TTUSQ156S\",\"USSTHPI\",\"NYSTHPI\",\"M2V\",\"GFDEBTN\",\"DFII10\",\"GFDEGDQ188S\",\"CUSR0000SEHA\",\"ETOTALUSQ176N\",\"ERENTUSQ176N\",\"RECPROUSM156N\",\"T5YIFR\",\"BAMLHYH0A0HYM2TRIV\",\"BAMLCC0A1AAATRIV\",\"GVZCLS\",\"DGS1\",\"BAMLCC0A4BBBTRIV\",\"VXVCLS\",\"IC4WSA\",\"WILLMICROCAPPR\",\"WILLLRGCAPVAL\",\"CFNAIDIFF\",\"MZMSL\",\"KCFSI\",\"T5YIE\",\"TOTALSA\",\"USSLIND\",\"AWHAETP\",\"CES0500000003\",\"TCU\",\"WTB3MS\",\"WGS3MO\",\"TWEXB\",\"DEXCHUS\",\"DEXUSUK\",\"CILACBQ158SBOG\",\"CES4348400001\",\"FEDFUNDS\",\"TDSP\",\"PERMIT\",\"GFDEGDQ188S\",\"CP\",\"PRFI\",\"DRSFRMACBS\",\"DRCCLACBS\",\"DRBLACBS\",\"DALLCIACBEP\",\"USROA\",\"USROE\",\"RSAHORUSQ156S\",\"MEFAINUSA672N\",\"COMREPUSQ159N\",\"HDTGPDUSQ163N\",\"POP\",\"NROU\",\"FGCCSAQ027S\",\"TEDRATE\", \"VIXCLS\", \"NFCI\",\"INDPRO\",\"LES1252881600Q\",\"CUUR0000SEHA\",\"LEU0252918500Q\",\"BAA10Y\",\"BAMLC0A0CM\",\"BAMLH0A3HYC\",\"BOGMBASE\",\"DCOILBRENTEU\",\"DCOILWTICO\",\"DFF\",\"DGS1MO\",\"DGS30\",\"DGS5\",\"FPCPITOTLZGUSA\",\"GOLDAMGBD228NLBM\",\"ICSA\",\"INTDSRUSM193N\",\"M1\",\"M1V\",\"MPRIME\",\"PPIACO\",\"SPCS20RSA\",\"STLFSI2\",\"T10Y2Y\",\"T10Y3M\",\"TB3MS\",\"TREAST\",\"UNRATE\",\"WPU0911\"]\n",
    "\n",
    "Indexes = ['^SP500TR', '^GSPC', 'QQQ', 'DIA', 'VTWO']\n",
    "\n",
    "ManualStocks = ['VOO','SPY']\n",
    "ManualStocks.extend(vetted_symbols)\n",
    "\n",
    "etf_indexes_and_Crypto_list = [Indexes, ManualStocks, etf_commodities, etf_metals, etf_foreign_exchanges, etf_real_estate, etf_economies, etf_bonds, etf_muni_bonds, etf_treasuries, crypto, etf_spdr_indexes, etf_dow_components]\n",
    "\n",
    "commodities = []\n",
    "for sublist in etf_indexes_and_Crypto_list:\n",
    "    for val in sublist:\n",
    "        commodities.append(val)\n",
    "\n",
    "#pool2 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "completed = []\n",
    "def dl(name):\n",
    "    subset = yf.download(name, start=start_date, end=end_date, auto_adjust=True).iloc[:, :6].dropna(axis=0, how='any')\n",
    "    subset = subset[start_date.strftime('%Y-%m-%d'):end_date.strftime('%Y-%m-%d')]\n",
    "    #sleep(4)\n",
    "    if len(subset) != 0:\n",
    "        completed.append(name)\n",
    "        return (subset)\n",
    "    \n",
    "def dl2(assets):\n",
    "    #https://webcache.googleusercontent.com/search?q=cache:Em9Ge5B9ue8J:https://stackoverflow.com/questions/62614282/is-the-yfinance-module-broken-i-keep-getting-a-jsondecodeerror+&cd=3&hl=en&ct=clnk&gl=us\n",
    "\n",
    "    yahoo_financials = YahooFinancials(assets)\n",
    "\n",
    "    data = yahoo_financials.get_historical_price_data(start_date=start_date.strftime('%Y-%m-%d'), end_date=end_date.strftime('%Y-%m-%d'), time_interval='daily')\n",
    "    return(data)\n",
    "\n",
    "\n",
    "#futures2 = [pool2.submit(dl, args) for args in commodities]\n",
    "#wait(futures2, timeout=4, return_when=ALL_COMPLETED)\n",
    "futures2 = []\n",
    "#'''\n",
    "for i in commodities:\n",
    "    futures2.append(dl(i))\n",
    "#'''\n",
    "\n",
    "'''\n",
    "ohlcv_data = dl2(commodities)\n",
    "for i in commodities:\n",
    "    subset = pd.DataFrame(ohlcv_data[i]['prices']).set_index(['formatted_date'])[['open','high','low','close','adjclose','volume']].dropna()\n",
    "    #sleep(4)\n",
    "    if len(subset) != 0:\n",
    "        completed.append(i)\n",
    "        futures2.append(subset)\n",
    "'''\n",
    "#print(futures2.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4376b7-97e2-4480-8dbe-823205bb043e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(type(futures2[31]) == type(None)):\n",
    "    print(\"None\")\n",
    "else:\n",
    "    print(\"Not\")\n",
    "    \n",
    "type(futures2[31])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f93f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "commodities_ = pd.DataFrame()\n",
    "\n",
    "#commodities_includes = []\n",
    "names = []\n",
    "\n",
    "#completed_2 = []\n",
    "\n",
    "for x in range(0,len(completed)):\n",
    "    values = futures2[x]\n",
    "    \n",
    "    if(type(values) == type(None)):\n",
    "        #commodities_includes.append(False)\n",
    "        print(\"None\")\n",
    "    else:\n",
    "        #print(\"Not\")\n",
    "        #commodities_includes.append(True)\n",
    "        values.index = pd.to_datetime(values.index)\n",
    "        values = values.resample(frequency).mean().dropna()\n",
    "        values['Symbol'] = x\n",
    "        values = values.loc[~values.index.duplicated(keep='last')]\n",
    "        values = values.reset_index()\n",
    "        names.append(completed[x])\n",
    "\n",
    "        commodities_ = pd.concat([commodities_,values], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf121d-4c92-4efe-9dd6-a86daa8681c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024d7e15-207d-46d9-8d7b-dc7e06c32ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#type(commodities_includes)\n",
    "\n",
    "#np.where(type(commodities_includes) == type(None), False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df69eb-feab-4fe4-89bc-db8dfdfa074d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d258d0c-001a-4565-8433-19a895e1ad7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff3aa61-f820-46e0-8b6a-2f79534d1fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(commodities_, values='Close', index=['Date'],columns=['Symbol']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yahoofinancials\n",
    "#commodities_pvt = pd.pivot_table(commodities_, values='close', index=['formatted_date'],columns=['Symbol'])\n",
    "\n",
    "#yfinance\n",
    "commodities_pvt = pd.pivot_table(commodities_, values='Close', index=['Date'],columns=['Symbol'])\n",
    "commodities_pvt.columns = names\n",
    "wd = os.getcwd()\n",
    "\n",
    "commodities_pvt.to_csv(re.sub('code', 'data', wd)+\"\\commodities.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8ae416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acd6c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fred_Data(name):\n",
    "    temp = web.DataReader(str(name), 'fred', start_date, end_date)\n",
    "    temp.index = pd.to_datetime(temp.index)\n",
    "    temp = temp.resample(frequency).mean().dropna()\n",
    "    return(temp)\n",
    "\n",
    "#pool1 = concurrent.futures.ProcessPoolExecutor(cores)\n",
    "\n",
    "#futures1 = [pool1.submit(Fred_Data, args) for args in FRED_Indicators]\n",
    "#wait(futures1, timeout=None, return_when=ALL_COMPLETED)\n",
    "\n",
    "FRED_set = []\n",
    "FRED_completed = []\n",
    "for i in FRED_Indicators:\n",
    "    FRED_completed.append(i)\n",
    "    FRED_set.append(Fred_Data(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02687812",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "FRED_pvt = pd.DataFrame()\n",
    "\n",
    "for x in range(0,len(FRED_completed)):\n",
    "    values = FRED_set[x]\n",
    "    #values.index = pd.to_datetime(FRED_set[\"DATE\"])\n",
    "    values = values.resample(frequency).mean().dropna()\n",
    "    #values['Symbol'] = x\n",
    "    values = values.loc[~values.index.duplicated(keep='last')]\n",
    "    #values = values.reset_index()\n",
    "\n",
    "    FRED_pvt = pd.concat([FRED_pvt,values], axis=1)\n",
    "\n",
    "#FRED_ = pd.pivot_table(commodities_, values='Close', index=['Date'],columns=['Symbol'])\n",
    "#FRED_.to_csv(\"/mnt/distvol/FRED_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d405d624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbea38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRED_pvt = pd.pivot_table(FRED_, index=['DATE'])\n",
    "FRED_pvt.to_csv(re.sub('code', 'data', wd)+\"\\FRED_pvt.csv\")\n",
    "\n",
    "#print(len(FRED_.columns))\n",
    "#print(len(FRED_))\n",
    "#FRED_pvt.columns = FRED_completed\n",
    "#FRED_pvt.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FRED_pvt.set_index(FRED_pvt.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e41c6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set = pd.concat([FRED_pvt.set_index(FRED_pvt.index),commodities_pvt],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f4f4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    combined_set = combined_set.interpolate(method='linear', limit_direction='forward', axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364348f3-2789-4432-a3e9-497557d7563e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80cd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_set.describe().loc['count'].index[combined_set.describe().loc['count']<(len(combined_set)-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fc346c-e48a-4c48-a555-56cf78db622d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecde09b-18e9-4505-b3c8-37456233619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacfb786",
   "metadata": {},
   "outputs": [],
   "source": [
    "drops = combined_set.describe().loc['count'].index[combined_set.describe().loc['count']<(len(combined_set)*.90)]\n",
    "print(drops)\n",
    "filtered = combined_set.columns.tolist()\n",
    "\n",
    "for d in drops:\n",
    "    #print(d)\n",
    "    filtered.remove(d)\n",
    "#filtered.remove(drops.tolist())\n",
    "#combined_set[filtered].to_csv(\"/mnt/distvol/combined_set.csv\")\n",
    "\n",
    "#drop first/last row\n",
    "all_data = combined_set[filtered]\n",
    "all_data = all_data.iloc[:-1,:]\n",
    "all_data = all_data.iloc[1:,:]\n",
    "\n",
    "#all_data.loc[:, (all_data != all_data.iloc[0]).any()] \n",
    "#*** should fix duplications\n",
    "all_data = all_data.loc[:,~all_data.columns.duplicated()]\n",
    "\n",
    "all_data.to_csv(re.sub('code', 'data', wd)+\"\\combined_set.csv\",index=True, index_label='Date')\n",
    "#filtered\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a8f8e0-62df-43c0-baf4-5134c22bdc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3547faad-34f0-46f4-b7b0-1d4b04108be8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e433bc12-abcf-4edf-9537-bfbc217a1010",
   "metadata": {},
   "outputs": [],
   "source": [
    "truncatedData = all_data.reindex(early.asfreq(frequency, method='pad').index).interpolate(method='time')\n",
    "#len(truncatedData.dropna(axis=0).columns)\n",
    "#truncatedData = truncatedData.replace([np.inf, -np.inf, np.NaN], 0).interpolate(method='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721b8125-3823-4c5c-93a3-686b031d4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(truncatedData.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f9e30-ff3b-45e1-bcc6-fd26c17eb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a431541c-b8f9-44cc-b365-0922ef125647",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(truncatedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e0b47-ea38-4fa0-8b1e-21db68aff32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = truncatedData.dropna().pct_change().dropna()\n",
    "deltas = deltas.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "#deltas = (truncatedData[all_data.columns]/truncatedData[all_data.columns].shift(-1))-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53a99e7-4557-4107-917f-fcc80ee58e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01dce52-f1c6-4cd4-9853-227922f425c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6239637-e01a-4751-8059-567cc1b877a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a0d0cd-edb5-48b4-a20a-31d2a979636a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc23f172-ff5d-491c-af1f-a8875075e1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.sum(deltas.isin([np.inf, -np.inf, np.NaN])).sort_values(kind=\"quicksort\", ascending=True)\n",
    "results[results>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673829c5-6201-4c46-b0c8-ff0a8872a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare = 'SPY'\n",
    "compare = '^SP500TR'\n",
    "#compare = 'T10Y3M'\n",
    "#compare = 'T10Y2Y'\n",
    "target = \"MSPUS\"\n",
    "\n",
    "#why did I do this?, to zero it out\n",
    "#deltas[target] = deltas[target].diff(1).copy()\n",
    "\n",
    "deltas = deltas.dropna().copy()\n",
    "#target = '^SP500TR'\n",
    "#target = pd.DataFrame(vetted_symbols).sample(n=1).values[0][0]\n",
    "#target = etf_metals[0]\n",
    "#target = crypto[1]\n",
    "#target = '^GSPC'\n",
    "\n",
    "pd.concat([truncatedData[compare].pct_change(),truncatedData[target].pct_change()],axis=1).dropna().corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bf36aa-4b10-4739-8a32-c23a0c321e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(deltas[target].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09202c04-4577-475d-b1f5-ab9fb9b52451",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(deltas[compare].cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ae7d0-93f7-449f-8a18-94963576a4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pd.concat([deltas[compare].cumsum(),deltas[target].cumsum()],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "46674a8d-37f0-480c-ade2-4f2cf6b52416",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Training, Holdout = split_sequences(np.array(pd.DataFrame(deltas.index.strftime('%Y-%m-%d'))), 1009, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f32a3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674b397-30ba-4421-be78-87200f3adf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, valid = train_test_split(deltas.index,  test_size=0.3, random_state=0, shuffle=False)\n",
    "#valid, test = train_test_split(valid,  test_size=0.5, random_state=0, shuffle=False)\n",
    "\n",
    "train, valid = train_test_split(deltas.index,  test_size=0.3, random_state=0, shuffle=True)\n",
    "valid, test = train_test_split(valid,  test_size=0.5, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32dfcb7-6a76-48ef-afe0-01af8158749f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a46be8-89f1-421c-aaba-43a97aa6c7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443e2da9-0e53-4906-b0d4-ce5e44f7a626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from scipy import stats # For in-built method to get PCC\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650927b6-968a-4cd9-90b0-c8d6f4af67fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69844396-f693-44b9-a2fa-888a4c194d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f2d515-3646-42a6-bf97-04394a715eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "lagn=9\n",
    "p_threshold = .05\n",
    "threshold = .5\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "#target = '^SP500TR'\n",
    "#print()\n",
    "#print(target)\n",
    "#print()\n",
    "#print(f\"target: {target}\")\n",
    "\n",
    "#sets = range(0,len(Training),252)\n",
    "#move this outside\n",
    "\n",
    "X = deltas[set(deltas.columns).difference(target)].copy()\n",
    "newX = pd.DataFrame()\n",
    "y = pd.DataFrame(deltas[target].copy())\n",
    "\n",
    "for m in X.columns:\n",
    "    lagged = pd.DataFrame()\n",
    "    newX = pd.concat([newX,X[m]],axis=1)\n",
    "    \n",
    "    for lag in range(1,lagn+1):\n",
    "        temp = pd.DataFrame(X[m].shift(lag).copy())\n",
    "        temp.columns = [m+\"_\"+str(lag)]\n",
    "        lagged = pd.concat([lagged,temp],axis=1)\n",
    "    #print(lagged)\n",
    "    newX = pd.concat([newX,lagged],axis=1)\n",
    "\n",
    "#newX = newX[set(newX.columns).difference(newX)].copy()\n",
    "#newX = newX.dropna().copy()\n",
    "#y = y.loc[newX.index]\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "kfold.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c8fab-b221-4ffa-ab5b-506bb434cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "newX.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3cfc06-9712-43b0-8abb-f85cbffd5036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc807c5b-dfa8-4741-830a-c24f5fd7b433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0bd92-72e6-49f1-b8b0-d9f0fdaedf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#for m in X.columns:\n",
    "#print(m)\n",
    "#X_train = newX[newX.columns[newX.columns.str.contains(m)]].loc[train].copy()\n",
    "#X_valid = newX[newX.columns[newX.columns.str.contains(m)]].loc[valid].copy()\n",
    "X_train = newX.drop(X.columns, axis=1, inplace=False).loc[train].dropna().copy()\n",
    "X_valid = newX.drop(X.columns, axis=1, inplace=False).loc[valid].dropna().copy()\n",
    "X_test = newX.drop(X.columns, axis=1, inplace=False).loc[test].dropna().copy()\n",
    "\n",
    "y_train = y.loc[X_train.index][target].copy()\n",
    "y_valid = y.loc[X_valid.index][target].copy()\n",
    "y_test = y.loc[X_test.index][target].copy()\n",
    "\n",
    "exclude = ''\n",
    "\n",
    "sig_table = np.zeros(shape=(len(all_data.columns)))\n",
    "signs_table = np.zeros(shape=(len(all_data.columns)))\n",
    "\n",
    "#this is for internal cross validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "k_fold = KFold(n_splits=num_folds)\n",
    "train_ = []\n",
    "test_ = []\n",
    "for train_indices, test_indices in k_fold.split(X_train.index):\n",
    "    train_.append(train_indices)\n",
    "    test_.append(test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e356570-6384-4f68-b419-465e92433673",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.99, svd_solver='full')\n",
    "pca.fit(X_train)\n",
    "pca.explained_variance_\n",
    "print(pca.explained_variance_ratio_.cumsum())\n",
    "\n",
    "#pca = PCA(n_components=1)\n",
    "#pca.fit(X)\n",
    "X_pca = pd.DataFrame(pca.transform(X_train))\n",
    "X_pca.index = X_train.index\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d24d0-7ac6-445a-820b-d9908d015139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4472e-d280-463a-a2fb-ff4eb29a11bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from visuals import visuals as vs\n",
    "\n",
    "# Train the supervised model on the training \n",
    "model = AdaBoostRegressor().fit(pd.DataFrame(X_pca), y_train)\n",
    "\n",
    "# Extract the feature importances using .feature_importances_ \n",
    "importances = model.feature_importances_\n",
    "\n",
    "# Plot\n",
    "vs.feature_plot(importances, pd.DataFrame(X_pca), y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd454ae9-1dda-451d-94f2-3e0cbc959bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25603e4f-6960-421d-a2db-b0d80cb4ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as sffs\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "#lr = LinearRegression()\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "sffs1 = sffs(lr, \n",
    "          k_features=len(X_train)+1, \n",
    "          forward=True, \n",
    "          floating=True, \n",
    "          scoring='neg_mean_squared_error',\n",
    "          #scoring='accuracy',\n",
    "          n_jobs=-1,\n",
    "          cv=5)\n",
    "\n",
    "y_ = pd.DataFrame(np.where(y_train>0,1,0)))\n",
    "sffs1 = sffs1.fit(X_train, pd.DataFrame(y_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b7638e-c8bf-49d3-8cd8-e4a19cab593a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_sfs(sffs1.get_metric_dict(), kind='std_err')\n",
    "\n",
    "plt.title('Sequential Forward Selection (w. StdErr)')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "print('Selected features:', sffs1.k_feature_idx_)\n",
    "\n",
    "position = list(pd.DataFrame(sffs1.subsets_).loc[\"avg_score\"]).index(pd.DataFrame(sffs1.subsets_).loc[\"avg_score\"].max())\n",
    "\n",
    "print(sffs1.subsets_[position]['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628f9b91-c655-4dc0-9dfe-8a3d4b38f935",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_CV.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3d1a3-14b7-4ff4-aeed-8e97bad4d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(pd.DataFrame(sffs1.subsets_).loc['feature_names'].values)\n",
    "\n",
    "#feature_idx = pd.DataFrame(sfbs1.subsets_).loc['feature_idx'].tolist()\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import ElasticNet \n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "\n",
    "\n",
    "CV_results = pd.DataFrame()#[]#np.zeros(shape=(len(features),5))\n",
    "\n",
    "for f in features:\n",
    "\n",
    "    print(f)\n",
    "    cv = RepeatedKFold(n_splits=5, n_repeats=1, random_state=1, )\n",
    "    ratios = np.arange(0, 1, 0.05)\n",
    "    alphas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0.0, 1.0, 10.0, 100.0]\n",
    "\n",
    "    EN_CV = LogisticRegressionCV(l1_ratios=ratios, cv=cv, random_state=0, penalty='l2', n_jobs=-1)#.fit(X, y)\n",
    "    #EN_CV = ElasticNetCV(l1_ratio=ratios, alphas=alphas, cv=cv, n_jobs=-1)\n",
    "    # fit model\n",
    "\n",
    "    X_subset = pd.DataFrame(X_train[list(np.asarray(f))])\n",
    "    #y_ = pd.DataFrame(y_train)\n",
    "    y_ = pd.DataFrame(np.where(y_train>0,1,0))\n",
    "    EN_CV.fit(X_train, y_)\n",
    "    \n",
    "    \n",
    "    #print('alpha: %f' % EN_CV.alpha_)\n",
    "    #print('l1_ratio_: %f' % EN_CV.l1_ratio_)\n",
    "    \n",
    "    # evaluate model\n",
    "    scores = cross_val_score(EN_CV, X_subset, y_, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)\n",
    "    # force scores to be positive\n",
    "    #scores = absolute(scores)\n",
    "    #print('Mean MAE: %.3f (%.3f)' % (mean(scores[~np.isnan(scores)]), std(scores[~np.isnan(scores)])))\n",
    "    \n",
    "    #temp = pd.concat([pd.DataFrame({\"features\": [np.array(f)]}),pd.DataFrame(np.array(mean(scores[~np.isnan(scores)])).reshape(-1,1)),pd.DataFrame(np.array(std(scores[~np.isnan(scores)])).reshape(-1,1)),pd.DataFrame(np.array(EN_CV.alpha_).reshape(-1,1)),pd.DataFrame(np.array(EN_CV.l1_ratio_).reshape(-1,1))],axis=1)\n",
    "    #logistic\n",
    "    temp = pd.concat([pd.DataFrame({\"features\": [np.array(f)]}),pd.DataFrame(np.array(mean(scores[~np.isnan(scores)])).reshape(-1,1)),pd.DataFrame(np.array(std(scores[~np.isnan(scores)])).reshape(-1,1)),pd.DataFrame(np.array(EN_CV.l1_ratio_).reshape(-1,1))],axis=1)\n",
    "    \n",
    "    CV_results = pd.concat([CV_results,temp],axis=0)\n",
    "                      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2618b5d-ba16-4e12-95fe-f64254643be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedFeatures = list(np.array(pd.DataFrame(sffs1.subsets_).loc['feature_names'])[position])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b8ff3-f9dd-4f51-80cf-232576599d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CV_results.columns = ['features','mean error','std','alpha','lambda']\n",
    "#logistic\n",
    "CV_results.columns = ['features','mean error','std','lambda']\n",
    "CV_results.index = np.array(range(0,len(features)))#range(1,len(features)+1)\n",
    "plt.plot(CV_results['mean error'])\n",
    "plt.show()\n",
    "\n",
    "best = CV_results.iloc[CV_results['mean error'].idxmin()]\n",
    "print(best)\n",
    "\n",
    "parse = CV_results[CV_results['mean error']<=(np.min(CV_results['mean error'])+np.std(CV_results['mean error']))].iloc[0]\n",
    "print(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64e422-8503-4956-8918-52e0583af64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model3.predict(X_test[parse['features']]))\n",
    "print(np.array(np.where(y_test>0,1,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125f5b9-f950-4d72-ba90-e138bd6bd53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.concat([pd.DataFrame(np.where(y_valid<0,-1,1)),pd.DataFrame(model3.predict_proba(X_valid[parse['features']])).loc[:,1]],axis=1),pd.concat([pd.DataFrame(np.where(y_test<0,-1,1)),pd.DataFrame(model3.predict_proba(X_test[parse['features']])).loc[:,1]],axis=1)],axis=0)\n",
    "#pd.DataFrame(model3.predict_proba(X_train[parse['features']])).loc[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90372725-5cf0-40c7-b5a5-6c70411e01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LogisticRegression(l1_ratio=parse['lambda'])\n",
    "model3.fit(X_train[parse['features']],y_)\n",
    "#print(MAPE(np.array(y_), model3.predict(X_train[parse['features']])))\n",
    "print(mean(np.where([i[0] for i in np.where(y_==0,-1,1)]*np.where(model3.predict(X_train[parse['features']])==0,-1,1)<0,0,1)))\n",
    "print(mean(np.where(np.where(y_valid<0,-1,1)*np.where(model3.predict(X_valid[parse['features']])==0,-1,1)<0,0,1)))\n",
    "print(mean(np.where(np.where(y_test<0,-1,1)*np.where(model3.predict(X_test[parse['features']])==0,-1,1)<0,0,1)))\n",
    "\n",
    "pd.concat([pd.DataFrame(np.where(y_valid<0,-1,1)),pd.DataFrame(model3.predict(X_valid[parse['features']]))],axis=1)\n",
    "#print(MAPE(np.array(y_), model3.predict(X_train[parse['features']])))\n",
    "#print(MAPE(np.array(np.where(y_valid>0,1,0)), model3.predict(X_valid[parse['features']])))\n",
    "#print(MAPE(np.array(np.where(y_test>0,1,0)), model3.predict(X_test[parse['features']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96af8ead-297e-4368-85ed-c9c3dc9bc178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model0 = LinearRegression()\n",
    "model1 = ElasticNet(alpha=parse['alpha'], l1_ratio=parse['lambda'])\n",
    "model2 = ElasticNet(alpha=best['alpha'], l1_ratio=best['lambda'])\n",
    "\n",
    "\n",
    "model0.fit(X_train[sortedFeatures],y_train)\n",
    "model1.fit(X_train[parse['features']],y_train)\n",
    "model2.fit(X_train[best['features']],y_train)\n",
    "\n",
    "#linear\n",
    "#parse\n",
    "print(sortedFeatures)\n",
    "#print(\"EN parse: \" + str(mean_squared_error(y_valid, model1.predict(X_valid[parse['features']]))))\n",
    "print(MAPE(y_train, model0.predict(X_train[sortedFeatures])))\n",
    "print(MAPE(y_valid, model0.predict(X_valid[sortedFeatures])))\n",
    "print(MAPE(y_test, model0.predict(X_test[sortedFeatures])))\n",
    "\n",
    "\n",
    "#parse\n",
    "print(parse['features'])\n",
    "#print(\"EN parse: \" + str(mean_squared_error(y_valid, model1.predict(X_valid[parse['features']]))))\n",
    "print(MAPE(y_train,model1.predict(X_train[parse['features']])))\n",
    "print(MAPE(y_valid, model1.predict(X_valid[parse['features']])))\n",
    "print(MAPE(y_test, model1.predict(X_test[parse['features']])))\n",
    "\n",
    "#best\n",
    "#print(\"EN best: \" + str(mean_squared_error(y_valid, model2.predict(X_valid[best['features']]))))\n",
    "print(best['features'])\n",
    "print(MAPE(y_train,model2.predict(X_train[best['features']])))\n",
    "print(MAPE(y_valid, model2.predict(X_valid[best['features']])))\n",
    "print(MAPE(y_test, model2.predict(X_test[best['features']])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bf63d3-5b24-4824-baa2-4d7ad79d8e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0552d02-5f8b-4fce-8d38-1017b4aaa495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f4e2e3-d6d3-417e-8586-f66dc5a9cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ''\n",
    "\n",
    "sig_table = np.zeros(shape=(len(sortedFeatures)))\n",
    "signs_table = np.zeros(shape=(len(sortedFeatures)))\n",
    "\n",
    "p_threshold = .05\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "k_fold = KFold(n_splits=num_folds)\n",
    "train_ = []\n",
    "test_ = []\n",
    "for train_indices, test_indices in k_fold.split(X_train.index):\n",
    "    train_.append(train_indices)\n",
    "    test_.append(test_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e7b745-dfb9-4beb-9ad2-b33dceb4fdc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837bbf6-9a1c-49c1-8e25-16392e002e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "\n",
    "sig_table = np.zeros(len(X_train[sortedFeatures].columns))\n",
    "signs_table = np.zeros(len(X_train[sortedFeatures].columns))\n",
    "significance = np.zeros(len(X_train[sortedFeatures].columns))\n",
    "sign = np.zeros(len(X_train[sortedFeatures].columns))\n",
    "purity = np.zeros(len(X_train[sortedFeatures].columns))\n",
    "\n",
    "for it in range(0,len(train_)):\n",
    "    max_pvalue = 1\n",
    "    train_index = train_[it]\n",
    "    test_index = test_[it]\n",
    "    #display(all_data.iloc[test_index].describe())\n",
    "    \n",
    "    subset = pd.concat([X_train[sortedFeatures].iloc[train_index].loc[:, ~X_train[sortedFeatures].columns.isin([exclude])],y_train],axis=1)\n",
    "    \n",
    "    #skip y and states\n",
    "    set_ = subset.loc[:, ~subset.columns.isin([target])].columns.tolist()\n",
    "    \n",
    "    n=len(subset)\n",
    "    \n",
    "    while(max_pvalue>=.05):\n",
    "\n",
    "        dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "        p_values = pd.DataFrame(2*dist.cdf(-abs(subset.pcorr()[target]))).T\n",
    "        p_values.columns = list(subset.columns)\n",
    "        \n",
    "        max_pname = p_values.idxmax(axis=1)[0]\n",
    "        max_pvalue = p_values[max_pname].values[0]\n",
    "        \n",
    "        if (max_pvalue > .05):\n",
    "\n",
    "            set_.remove(max_pname)\n",
    "            temp = [target]\n",
    "            temp.extend(set_)\n",
    "            subset = subset[temp]\n",
    "    \n",
    "    winners = p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()\n",
    "    sig_table = (sig_table + np.where(X_train[sortedFeatures].columns.isin(winners),1,0)).copy()\n",
    "    signs_table[X_train[sortedFeatures].columns.get_indexer(winners)]+=np.where(subset.pcorr()[target][winners]<0,-1,1)\n",
    "    \n",
    "significance = pd.DataFrame(sig_table).T\n",
    "significance.columns = list(X_train[sortedFeatures].columns)\n",
    "display(significance)\n",
    "\n",
    "sign = pd.DataFrame(signs_table).T\n",
    "sign.columns = list(X_train[sortedFeatures].columns)\n",
    "display(sign)\n",
    "\n",
    "purity = abs((sign/num_folds)*(sign/significance)).T.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "display(purity.T)\n",
    "\n",
    "threshold = .5\n",
    "\n",
    "chosen = list(purity.T.columns.values[np.array(purity.T>threshold).reshape(len(X_train[sortedFeatures].columns,))])\n",
    "display(chosen)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27874243-52a4-4750-9b6d-0c791bd0bba7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279235ac-c7c7-4a24-98ce-3a53b48f34c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from zca import zca\n",
    "\n",
    "zca = zca.ZCA()\n",
    "#chosen = sortedFeatures\n",
    "#chosen = parse['features']\n",
    "chosen = best['features']\n",
    "\n",
    "data_zca = zca.fit_transform(X_train[chosen])\n",
    "\n",
    "#zca.fit(X_train[chosen])\n",
    "\n",
    "#data_zca = zca.transform(X_train[chosen])\n",
    "\n",
    "model = sm.OLS(y_train,X_train[chosen])\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "reg = LinearRegression().fit(X_train[chosen], y_train)\n",
    "#reg.score(X, y)\n",
    "\n",
    "#reg.coef_\n",
    "\n",
    "#reg.intercept_\n",
    "\n",
    "#import statsmodels as ssm\n",
    "#X=sm.add_constant(X_train[sortedFeatures])        #to add constant value in the model\n",
    "model= sm.OLS(y_train,X_train[chosen]).fit()         #fitting the model\n",
    "summary = model.summary()      #summary of the model\n",
    "display(summary)\n",
    "print(MAPE(y_train,model.predict(X_train[chosen])))\n",
    "print(MAPE(y_valid,model.predict(X_valid[chosen])))\n",
    "print(MAPE(y_test,model.predict(X_test[chosen])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b32f42-f2e7-41c4-bfae-370ec4c200e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parse['alpha'], parse['lambda'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b35b5d-64f3-4525-91e6-2b1031189eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d4f26-2412-4111-af27-72f788db66bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.stats.proportion as smp\n",
    "\n",
    "correct = np.where(pd.concat([y_valid*model2.predict(X_valid[chosen]),y_test*model2.predict(X_test[chosen])],axis=0) > 0, 1 ,0)\n",
    "\n",
    "ci_low, ci_upp = smp.proportion_confint(sum(correct), len(correct), alpha=0.05, method='normal')\n",
    "\n",
    "print(ci_low)\n",
    "print(ci_upp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6784725a-c17d-4c32-ad0e-07e30a33d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a74108-51f2-4b31-90fc-6920143c0325",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.scatter(y_train, model.predict(X_train[sortedFeatures]))\n",
    "plt.scatter(y_valid, model.predict(X_valid[sortedFeatures]))\n",
    "plt.scatter(y_test, model.predict(X_test[sortedFeatures]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1cc9d7-ab49-4cd4-874d-9865758a9ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "lagn=9\n",
    "p_threshold = .05\n",
    "threshold = .5\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "target = \"SPCS20RSA\"\n",
    "#print()\n",
    "#print(target)\n",
    "#print()\n",
    "#print(f\"target: {target}\")\n",
    "\n",
    "#sets = range(0,len(Training),252)\n",
    "#move this outside\n",
    "X_train = deltas.loc[train][set(deltas.columns).difference(target)].copy()\n",
    "X_valid = deltas.loc[test][set(deltas.columns).difference(target)].copy()\n",
    "y_train = deltas.loc[train][target].copy()\n",
    "y_valid = deltas.loc[test][target].copy()\n",
    "\n",
    "#X_train = deltas.loc[train][X_train.columns[~X_train.columns.isin([target])]].copy()\n",
    "#X_valid = deltas.loc[test][X_train.columns[~X_train.columns.isin([target])]].copy()\n",
    "#y_train = deltas.loc[train][target].copy()\n",
    "#y_valid = deltas.loc[test][target].copy()\n",
    "\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "kfold.get_n_splits(X_train)\n",
    "\n",
    "for m in X_train.columns:\n",
    "    #print(m)\n",
    "\n",
    "    corrs = []\n",
    "    ps = []\n",
    "    lags = []\n",
    "\n",
    "    sig_table = np.zeros(shape=(2))\n",
    "    signs_table = np.zeros(shape=(2))\n",
    "\n",
    "    sets = np.zeros(shape=(num_folds,lagn))\n",
    "\n",
    "    iterator = 0\n",
    "\n",
    "    for train_index, test_index in kfold.split(X_train):\n",
    "\n",
    "        subsetX = X_train.iloc[train_index]\n",
    "        subsetY = y_train.iloc[train_index]\n",
    "\n",
    "        #skip y and states\n",
    "\n",
    "        n=len(subsetX)\n",
    "\n",
    "        temp = pd.concat([subsetX[m].shift((lag-lagn)[0]),subsetY], axis=1).dropna()\n",
    "\n",
    "        dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "\n",
    "        chosen = pd.DataFrame()\n",
    "\n",
    "        #train\n",
    "        setc = crosscorrelation(np.array(temp[m]),np.array(temp.iloc[:,1]), lagn)\n",
    "        p_values = pd.DataFrame(2*dist.cdf(-abs(setc))).T\n",
    "\n",
    "        fields = np.argwhere(np.array(p_values)[0] <= p_threshold)\n",
    "\n",
    "        #print(fields[fields>lagn+1]-lagn-1)\n",
    "        #print(setc[fields[fields>lagn+1]])\n",
    "\n",
    "        #sets[iterator] = (np.where(p_values <= p_threshold, True, 0)*setc)[0][lagn+1:]\n",
    "        sets[iterator] = (np.array(p_values)*setc)[0][lagn+1:]             \n",
    "\n",
    "        iterator = iterator + 1\n",
    "\n",
    "    csets_avg = np.sum(sets, axis=0)/num_folds       \n",
    "\n",
    "    lag = pd.DataFrame(abs(csets_avg)).idxmax()\n",
    "    #print(f\"correlation: {setc[lag]}\")\n",
    "\n",
    "    #pearson_coef, p_value = stats.pearsonr(np.array(temp.iloc[:,0]),np.array(temp.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "    corrs.append(csets_avg[lag])\n",
    "    p_value = (2*dist.cdf(-abs(csets_avg[lag])))\n",
    "    ps.append(p_value)\n",
    "    lags.append(lag)    \n",
    "\n",
    "    print(p_value)\n",
    "    if (p_value < .05):\n",
    "        for p in range(0,len(sets)):\n",
    "            plt.plot(sets[p])   \n",
    "        plt.show()\n",
    "\n",
    "        print(target)\n",
    "        print(m)\n",
    "        #print(i)\n",
    "        #print(f\"lag: {lag-lagn}\")\n",
    "        #print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results\n",
    "        temp1 = pd.DataFrame([target, m,(lag-lagn)[0],pearson_coef]).T\n",
    "        temp1.columns = [\"target\",\"name\",\"lag\",\"pearson\"]\n",
    "\n",
    "        #p_values = pd.DataFrame(2*dist.cdf(-abs(temp.corr()[target]))).T\n",
    "        #p_values.columns = list(temp.columns)\n",
    "\n",
    "        #if(p_values[p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()]<=p_threshold):\n",
    "        #winners = p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()\n",
    "        #winners = m\n",
    "\n",
    "        #sig_table = (sig_table + np.where(temp.columns.isin([winners]),1,0)).copy()\n",
    "        #print(sig_table)\n",
    "        #signs_table[temp.columns.get_indexer([winners])]+=np.where(temp.corr()[target][winners]<0,-1,1)                 \n",
    "        #chosen = pd.concat([temp1,chosen],axis=0)\n",
    "        chosen.append(m)\n",
    "\n",
    "        c_threshold = dist.ppf(.05)\n",
    "        plt.plot(np.sum(sets, axis=0)/num_folds)\n",
    "        plt.axhline(y = 0, color = 'r', linestyle = '-')\n",
    "        plt.axhline(y = c_threshold, color = 'y', linestyle = '-')\n",
    "        plt.axhline(y = abs(c_threshold), color = 'y', linestyle = '-')\n",
    "\n",
    "        plt.show()\n",
    "        x=range(0,lagn)\n",
    "        plt.stackplot(x,sets[0],sets[1],sets[2],sets[3],sets[4], labels=['A','B','C','D','E'])\n",
    "        plt.axhline(y = 0, color = 'r', linestyle = '-')\n",
    "        plt.axhline(y = c_threshold, color = 'y', linestyle = '-')\n",
    "        plt.axhline(y = abs(c_threshold), color = 'y', linestyle = '-')        \n",
    "        plt.show()\n",
    "\n",
    "    #significance = pd.DataFrame(sig_table).T\n",
    "    #significance.columns = list(temp.columns)\n",
    "    #print(significance)\n",
    "\n",
    "    #sign = pd.DataFrame(signs_table).T\n",
    "    #sign.columns = list(temp.columns)\n",
    "\n",
    "    #purity = abs((sign/num_folds)*(sign/significance)).T.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "    #print(purity)\n",
    "\n",
    "    #ichosen = list(purity.T.columns.values[np.array(purity.T>=threshold).reshape(len(temp.columns,))])\n",
    "    #print(ichosen)\n",
    "    #chosen.append(ichosen)\n",
    "\n",
    "    #print(chosen)\n",
    "\n",
    "    #print(lags)\n",
    "\n",
    "    #print(m)\n",
    "    #print(ps)          \n",
    "\n",
    "    for i in range(0,len(chosen)):\n",
    "        values = chosen.reset_index().iloc[i]\n",
    "        name = values['name']\n",
    "        target = values['target']\n",
    "        lag = values['lag']\n",
    "        #print(lag)\n",
    "        aggregate = pd.DataFrame()\n",
    "\n",
    "        #test\n",
    "        innerSet = pd.concat([X_valid[name].shift(lag),y_valid],axis=1).dropna()\n",
    "\n",
    "        for p in range(0,len(innerSet)):     \n",
    "            #print(innerSet.iloc[p][name] )\n",
    "            if(innerSet.iloc[p][name] < 0):\n",
    "                d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),innerSet.iloc[p][target], np.nan, 'l'])\n",
    "                #print(\"lower\")\n",
    "            elif (innerSet.iloc[p][name] > 0):\n",
    "                d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, innerSet.iloc[p][target], 'u'])\n",
    "                #print(\"upper\")\n",
    "            else:\n",
    "                d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, np.nan, np.nan])\n",
    "\n",
    "            aggregate = pd.concat([d.T,aggregate],axis=0)\n",
    "        #print(aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1])\n",
    "\n",
    "        aggregate.columns = \"Date\",\"l\",\"u\",\"class\"\n",
    "\n",
    "        pearson_coef, p_value = stats.pearsonr(np.array(innerSet.iloc[:,0]),np.array(innerSet.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "        #print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {innerSet.corr().iloc[0][1]}\")\n",
    "        if p_value < .05 and (values['pearson']*pearson_coef) > 0:\n",
    "\n",
    "                newData = pd.concat([pd.DataFrame(innerSet[target]).set_index(innerSet[target].index.strftime('%Y-%m-%d')),aggregate.set_index(\"Date\")],axis=1).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "                if newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['l'] or newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['u']:\n",
    "                    print(f\"target: {target}\")\n",
    "                    print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {pearson_coef}\", f\"p-value: {p_value}\")\n",
    "                    print(pd.DataFrame(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]).T)\n",
    "\n",
    "                    x_ticks = newData.index[np.arange(0, len(newData.index), 200)]\n",
    "\n",
    "                    plt.plot(newData[[target,\"l\",\"u\"]].cumsum())\n",
    "                    plt.legend(loc='upper left', fancybox=True, ncol=5, labels=[target,\"l\",\"u\"])\n",
    "                    #plt.legend(loc=\"upper left\",fontsize=8)\n",
    "\n",
    "                    plt.xticks(x_ticks, rotation = 45)\n",
    "                    plt.show()\n",
    "\n",
    "                    temp1 = pd.DataFrame([target, name, pearson_coef, p_value, lag, max(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][['l','u']]), newData[[target]].cumsum().iloc[-1][target] ]).T\n",
    "                    final = pd.concat([temp1,final],axis=0)\n",
    "\n",
    "final.columns = [\"target\",\"correlate\",\"pearson\",\"p-value\",\"lag\",\"TCR\",\"holdTCR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ed0215-606c-4362-8e82-72228d3284ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de683ae-f0a3-4422-809b-d1ff35ffef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "lagn=1\n",
    "p_threshold = .05\n",
    "threshold = .5\n",
    "\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "\n",
    "final = pd.DataFrame()\n",
    "\n",
    "for target in set(deltas.columns) & set(vetted_symbols):\n",
    "    #print()\n",
    "    #print(target)\n",
    "    #print()\n",
    "    #print(f\"target: {target}\")\n",
    "    \n",
    "    #sets = range(0,len(Training),252)\n",
    "    #move this outside\n",
    "    X_train = deltas.loc[train][X_train.columns[~X_train.columns.isin([target])]].copy()\n",
    "    X_valid = deltas.loc[test][X_train.columns[~X_train.columns.isin([target])]].copy()\n",
    "    y_train = deltas.loc[train][target].copy()\n",
    "    y_valid = deltas.loc[test][target].copy()\n",
    "    \n",
    "    kfold = KFold(n_splits=num_folds, shuffle=False)\n",
    "    kfold.get_n_splits(X_train)\n",
    "\n",
    "    for m in X_train.columns:\n",
    "        #print(m)\n",
    "        \n",
    "        corrs = []\n",
    "        ps = []\n",
    "        lags = []\n",
    "\n",
    "        sig_table = np.zeros(shape=(2))\n",
    "        signs_table = np.zeros(shape=(2))\n",
    "\n",
    "        sets = np.zeros(shape=(num_folds,lagn))\n",
    "        \n",
    "        iterator = 0\n",
    "        \n",
    "        for train_index, test_index in kfold.split(X_train):\n",
    "\n",
    "            subsetX = X_train.iloc[train_index]\n",
    "            subsetY = y_train.iloc[train_index]\n",
    "\n",
    "            #skip y and states\n",
    "\n",
    "            n=len(subset)\n",
    "            \n",
    "            temp = pd.concat([subsetX[m].shift((lag-lagn)[0]),subsetY], axis=1).dropna()\n",
    "\n",
    "            dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
    "\n",
    "            chosen = pd.DataFrame()\n",
    "\n",
    "            #train\n",
    "            setc = crosscorrelation(np.array(temp[m]),np.array(temp.iloc[:,1]), lagn)\n",
    "            p_values = pd.DataFrame(2*dist.cdf(-abs(setc))).T\n",
    "            \n",
    "            fields = np.argwhere(np.array(p_values)[0] <= p_threshold)\n",
    "           \n",
    "            #print(fields[fields>lagn+1]-lagn-1)\n",
    "            #print(setc[fields[fields>lagn+1]])\n",
    "            \n",
    "            #sets[iterator] = (np.where(p_values <= p_threshold, True, 0)*setc)[0][lagn+1:]\n",
    "            sets[iterator] = (np.array(p_values)*setc)[0][lagn+1:]             \n",
    "            \n",
    "            iterator = iterator + 1\n",
    "        \n",
    "        csets_avg = np.sum(sets, axis=0)/num_folds       \n",
    "        \n",
    "        lag = pd.DataFrame(abs(csets_avg)).idxmax()\n",
    "        #print(f\"correlation: {setc[lag]}\")\n",
    "\n",
    "        #pearson_coef, p_value = stats.pearsonr(np.array(temp.iloc[:,0]),np.array(temp.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "        corrs.append(csets_avg[lag])\n",
    "        p_value = (2*dist.cdf(-abs(csets_avg[lag])))\n",
    "        ps.append(p_value)\n",
    "        lags.append(lag)    \n",
    "\n",
    "        #print(p_value)\n",
    "        if (p_value < .05):\n",
    "            for p in range(0,len(sets)):\n",
    "                plt.plot(sets[p])   \n",
    "            plt.show()\n",
    "            \n",
    "            print(target)\n",
    "            print(m)\n",
    "            #print(i)\n",
    "            #print(f\"lag: {lag-lagn}\")\n",
    "            #print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results\n",
    "            temp1 = pd.DataFrame([target, m,(lag-lagn)[0],pearson_coef]).T\n",
    "            temp1.columns = [\"target\",\"name\",\"lag\",\"pearson\"]\n",
    "\n",
    "            #p_values = pd.DataFrame(2*dist.cdf(-abs(temp.corr()[target]))).T\n",
    "            #p_values.columns = list(temp.columns)\n",
    "\n",
    "            #if(p_values[p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()]<=p_threshold):\n",
    "            #winners = p_values.loc[:, ~p_values.columns.isin([target])].columns.tolist()\n",
    "            winners = m\n",
    "\n",
    "            #sig_table = (sig_table + np.where(temp.columns.isin([winners]),1,0)).copy()\n",
    "            #print(sig_table)\n",
    "            #signs_table[temp.columns.get_indexer([winners])]+=np.where(temp.corr()[target][winners]<0,-1,1)                 \n",
    "            #chosen = pd.concat([temp1,chosen],axis=0)\n",
    "            chosen.append(m)\n",
    "\n",
    "            c_threshold = dist.ppf(.05)\n",
    "            plt.plot(np.sum(sets, axis=0)/num_folds)\n",
    "            plt.axhline(y = 0, color = 'r', linestyle = '-')\n",
    "            plt.axhline(y = c_threshold, color = 'y', linestyle = '-')\n",
    "            plt.axhline(y = abs(c_threshold), color = 'y', linestyle = '-')\n",
    "\n",
    "            plt.show()\n",
    "            x=range(0,lagn)\n",
    "            plt.stackplot(x,sets[0],sets[1],sets[2],sets[3],sets[4], labels=['A','B','C','D','E'])\n",
    "            plt.axhline(y = 0, color = 'r', linestyle = '-')\n",
    "            plt.axhline(y = c_threshold, color = 'y', linestyle = '-')\n",
    "            plt.axhline(y = abs(c_threshold), color = 'y', linestyle = '-')        \n",
    "            plt.show()\n",
    "\n",
    "        #significance = pd.DataFrame(sig_table).T\n",
    "        #significance.columns = list(temp.columns)\n",
    "        #print(significance)\n",
    "\n",
    "        #sign = pd.DataFrame(signs_table).T\n",
    "        #sign.columns = list(temp.columns)\n",
    "\n",
    "        #purity = abs((sign/num_folds)*(sign/significance)).T.replace([np.inf, -np.inf, np.NaN], 0)\n",
    "        #print(purity)\n",
    "\n",
    "        #ichosen = list(purity.T.columns.values[np.array(purity.T>=threshold).reshape(len(temp.columns,))])\n",
    "        #print(ichosen)\n",
    "        #chosen.append(ichosen)\n",
    "        \n",
    "        #print(chosen)\n",
    "        \n",
    "        #print(lags)\n",
    "        \n",
    "        #print(m)\n",
    "        #print(ps)          \n",
    "        \n",
    "        for i in range(0,len(chosen)):\n",
    "            values = chosen.reset_index().iloc[i]\n",
    "            name = values['name']\n",
    "            target = values['target']\n",
    "            lag = values['lag']\n",
    "            #print(lag)\n",
    "            aggregate = pd.DataFrame()\n",
    "\n",
    "            #test\n",
    "            innerSet = pd.concat([X_valid[name].shift(lag),y_valid],axis=1).dropna()\n",
    "\n",
    "            for p in range(0,len(innerSet)):     \n",
    "                #print(innerSet.iloc[p][name] )\n",
    "                if(innerSet.iloc[p][name] < 0):\n",
    "                    d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),innerSet.iloc[p][target], np.nan, 'l'])\n",
    "                    #print(\"lower\")\n",
    "                elif (innerSet.iloc[p][name] > 0):\n",
    "                    d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, innerSet.iloc[p][target], 'u'])\n",
    "                    #print(\"upper\")\n",
    "                else:\n",
    "                    d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, np.nan, np.nan])\n",
    "\n",
    "                aggregate = pd.concat([d.T,aggregate],axis=0)\n",
    "            #print(aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1])\n",
    "\n",
    "            aggregate.columns = \"Date\",\"l\",\"u\",\"class\"\n",
    "\n",
    "            pearson_coef, p_value = stats.pearsonr(np.array(innerSet.iloc[:,0]),np.array(innerSet.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "            #print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {innerSet.corr().iloc[0][1]}\")\n",
    "            if p_value < .05 and (values['pearson']*pearson_coef) > 0:\n",
    "\n",
    "                    newData = pd.concat([pd.DataFrame(innerSet[target]).set_index(innerSet[target].index.strftime('%Y-%m-%d')),aggregate.set_index(\"Date\")],axis=1).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "                    if newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['l'] or newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['u']:\n",
    "                        print(f\"target: {target}\")\n",
    "                        print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {pearson_coef}\", f\"p-value: {p_value}\")\n",
    "                        print(pd.DataFrame(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]).T)\n",
    "\n",
    "                        x_ticks = newData.index[np.arange(0, len(newData.index), 200)]\n",
    "\n",
    "                        plt.plot(newData[[target,\"l\",\"u\"]].cumsum())\n",
    "                        plt.legend(loc='upper left', fancybox=True, ncol=5, labels=[target,\"l\",\"u\"])\n",
    "                        #plt.legend(loc=\"upper left\",fontsize=8)\n",
    "\n",
    "                        plt.xticks(x_ticks, rotation = 45)\n",
    "                        plt.show()\n",
    "\n",
    "                        temp1 = pd.DataFrame([target, name, pearson_coef, p_value, lag, max(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][['l','u']]), newData[[target]].cumsum().iloc[-1][target] ]).T\n",
    "                        final = pd.concat([temp1,final],axis=0)\n",
    "\n",
    "final.columns = [\"target\",\"correlate\",\"pearson\",\"p-value\",\"lag\",\"TCR\",\"holdTCR\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edaae29-4918-4d61-bcb6-b2eeedbaae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100c95c-3b55-450a-b919-8f36936340c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27c5f0c-8226-4c96-b684-174c03d4b5b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530810c5-fa4b-457c-9d58-dfe7925b3a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c8ec73-994c-4c85-b928-52e9c9f63cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = pd.DataFrame()\n",
    "\n",
    "for i in range(0,len(final)):\n",
    "    values = final.reset_index().iloc[i]\n",
    "    name = values['correlate']\n",
    "    target = values['target']\n",
    "    lag = values['lag']\n",
    "    #print(lag)\n",
    "    aggregate = pd.DataFrame()\n",
    "\n",
    "    X_test = deltas.loc[test][set(deltas.columns).difference(target)]\n",
    "    y_test = deltas.loc[test][target]\n",
    "    \n",
    "    #test\n",
    "    innerSet = pd.concat([X_test[name].shift(lag),y_test],axis=1).dropna()\n",
    "\n",
    "    for p in range(0,len(innerSet)):     \n",
    "        #print(innerSet.iloc[p][name] )\n",
    "        if(innerSet.iloc[p][name] < 0):\n",
    "            d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),innerSet.iloc[p][target], np.nan, 'l'])\n",
    "            #print(\"lower\")\n",
    "        elif (innerSet.iloc[p][name] > 0):\n",
    "            d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, innerSet.iloc[p][target], 'u'])\n",
    "            #print(\"upper\")\n",
    "        else:\n",
    "            d = pd.DataFrame([innerSet.index[p].strftime('%Y-%m-%d'),np.nan, np.nan, np.nan])\n",
    "\n",
    "        aggregate = pd.concat([d.T,aggregate],axis=0)\n",
    "    #print(aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1])\n",
    "\n",
    "    aggregate.columns = \"Date\",\"l\",\"u\",\"class\"\n",
    "\n",
    "    pearson_coef, p_value = stats.pearsonr(np.array(innerSet.iloc[:,0]),np.array(innerSet.iloc[:,1])) #define the columns to perform calculations on\n",
    "\n",
    "    #print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {innerSet.corr().iloc[0][1]}\")\n",
    "    if p_value < .05:\n",
    "\n",
    "            newData = pd.concat([pd.DataFrame(innerSet[target]).set_index(innerSet[target].index.strftime('%Y-%m-%d')),aggregate.set_index(\"Date\")],axis=1).replace([np.inf, -np.inf, np.NaN], 0)\n",
    "\n",
    "            if newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['l'] or newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][target] < newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]['u']:\n",
    "                print(f\"target: {target}\")\n",
    "                print(f\"name: {name}\", f\"lag: {lag}\", f\"corr: {pearson_coef}\", f\"p-value: {p_value}\")\n",
    "                print(pd.DataFrame(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1]).T)\n",
    "\n",
    "                x_ticks = newData.index[np.arange(0, len(newData.index), 200)]\n",
    "\n",
    "                plt.plot(newData[[target,\"l\",\"u\"]].cumsum())\n",
    "                plt.legend(loc='upper left', fancybox=True, ncol=5, labels=[target,\"l\",\"u\"])\n",
    "                #plt.legend(loc=\"upper left\",fontsize=8)\n",
    "\n",
    "                plt.xticks(x_ticks, rotation = 45)\n",
    "                plt.show()\n",
    "\n",
    "                temp1 = pd.DataFrame([target, name, pearson_coef, p_value, lag, max(newData[[target,\"l\",\"u\"]].cumsum().iloc[-1][['l','u']]), newData[[target]].cumsum().iloc[-1][target] ]).T\n",
    "                results2 = pd.concat([temp1,results2],axis=0)\n",
    "                \n",
    "results2.columns = [\"target\",\"correlate\",\"pearson\",\"p-value\",\"lag\",\"TCR\",\"holdTCR\"]                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df7c793-e071-420b-aa9b-f6b7e08f2fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c4f0c4-ad8a-4291-b988-9a1bbcc9dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afbd82-67be-4636-acc6-9e88ef8761df",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([final['pearson'],results2['pearson']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76cd9f0-a1c1-4b62-bbfb-3a60f28a9306",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([final['pearson']*results2['pearson']],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b5a42-8ce8-49d3-8324-b706b77780e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate = pd.DataFrame()\n",
    "\n",
    "for s in Training:\n",
    "    #print(s)\n",
    "    set_dates = s\n",
    "    #print(set_dates[1])\n",
    "    #print(set_dates[-1])\n",
    "    \n",
    "    #rate of change compare\n",
    "    filtered2 =  pd.concat([truncatedData.loc[[i[0] for i in set_dates]][compare],truncatedData.loc[[i[0] for i in set_dates]][target]],axis=1).pct_change().dropna().replace([np.inf, -np.inf, np.NaN], 0)\n",
    "    #quantiles2 = filtered2[compare].quantile(q=[0, .25, .5, .75, 1], interpolation='linear')\n",
    "\n",
    "    #prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "    #colors = cycle(prop_cycle.by_key()['color'])\n",
    "    \n",
    "    #subset, Holdout = split_sequences(np.array(pd.DataFrame(filtered2.index.strftime('%Y-%m-%d'))), 126, 0)\n",
    "    \n",
    "    #for i in subset:\n",
    "        \n",
    "    #quantiles = pd.DataFrame(filtered2.iloc[0:-2][compare].quantile([0,.5,1]),columns=['min','median','max'])\n",
    "    #np.percentile((filtered2.iloc[0:-2][compare]),50)\n",
    "    \n",
    "    t = pd.DataFrame(filtered2.iloc[0:-3][compare].quantile([0,.5,1])).T\n",
    "    t.columns = ['min','median','max']\n",
    "    quantiles = t.reset_index(drop=True)\n",
    "\n",
    "    #lower = filtered2.iloc[0:-1][(filtered2.iloc[0:-2][compare]<=quantile)].index\n",
    "    #upper = ~filtered2.iloc[0:-2].index.isin(lower)\n",
    "\n",
    "\n",
    "\n",
    "    #my_dpi = 100\n",
    "    #fig, axes = plt.subplots(figsize=(12, 4),ncols=3, nrows=1)\n",
    "    #ax1, ax2, ax3 = axes.ravel()\n",
    "    #sns.set(style=\"ticks\")\n",
    "    #sns.despine(fig=fig)\n",
    "\n",
    "    #dataframe = filtered2.loc[dates]\n",
    "    #returns = dataframe[target].dropna()\n",
    "\n",
    "    #l = np.where(filtered2.iloc[0:-2][compare] <= quantile, filtered2.iloc[-1][target], 0)\n",
    "    #u = np.where(filtered2.iloc[upper][compare] > quantile, filtered2.iloc[-1][target], 0)\n",
    "    if((filtered2.iloc[-2][compare] <= quantiles['median'][0])):\n",
    "        d = pd.DataFrame([filtered2.iloc[-1][target], np.nan, 'l'])\n",
    "    else:\n",
    "        d = pd.DataFrame([np.nan, filtered2.iloc[-1][target], 'u'])\n",
    "    #d = pd.concat([pd.DataFrame(l.tolist()),pd.DataFrame(u.tolist())],axis=1)\n",
    "    #print(len(d))\n",
    "    #print(d)\n",
    "    \n",
    "    #print(pd.concat([d.T, quantiles.T.reset_index(drop=True)],axis=1))\n",
    "    #aggregate = pd.concat([d.T, quantiles.T.reset_index(drop=True), aggregate],axis=0)\n",
    "    aggregate = pd.concat([pd.concat([d.T, quantiles],axis=1),aggregate],axis=0)\n",
    "    #print(aggregate)\n",
    "    #print(len(aggregate))\n",
    "    #print(aggregate)\n",
    "    #d.index = filtered2.iloc[-1].name.strftime('%Y-%m-%d')\n",
    "   \n",
    "    #sns.regplot(x=compare, y=target, data=dataframe, ax=ax1)\n",
    "\n",
    "    #sns.violinplot(x=dataframe[compare].dropna(),color=next(colors), ax=ax2)\n",
    "\n",
    "    #sns.vioinplot(x=returns,color=next(colors), ax=ax3) \n",
    "    #plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9982434-a0db-4230-803b-0c250ef3c9ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82770c63-0235-4afa-9075-addb7841d22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Training)\n",
    "\n",
    "aggregate.columns = ['l','u','class','min','median','max']\n",
    "\n",
    "dates = []\n",
    "for item in Training:\n",
    "    last = item[-1]\n",
    "    dates.append(last[0])\n",
    "    \n",
    "aggregate.loc[:,['l','u']].replace([np.inf, -np.inf, np.NaN], 0).cumsum().iloc[-1]\n",
    "\n",
    "aggregate.index=dates\n",
    "\n",
    "#print(aggregate.cumsum().iloc[-1])\n",
    "#aggregate.reset_index()\n",
    "#ax = sns.regplot(x=aggregate.columns[1], y='index', data=aggregate.reset_index())\n",
    "\n",
    "x_ticks = aggregate.index[np.arange(0, len(aggregate.index), 200)]\n",
    "\n",
    "plt.plot(aggregate.loc[:,['l']].replace([np.inf, -np.inf, np.NaN], 0).cumsum())\n",
    "\n",
    "plt.xticks(x_ticks, rotation = 45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb49747-11d0-4e27-9d16-c3e4234164c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a51829-f0e8-4c01-8916-2c2deb6d496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = pd.concat([truncatedData[compare].pct_change(),truncatedData[target]],axis=1).loc[dates]\n",
    "temp2 = pd.concat([truncatedData[compare].pct_change(),truncatedData[target].pct_change()],axis=1).loc[dates]\n",
    "temp1.index = temp1.index.copy().strftime('%Y-%m-%d')\n",
    "temp2.index = temp2.index.copy().strftime('%Y-%m-%d')\n",
    "temp = pd.concat([temp1,temp2,aggregate],axis=1)\n",
    "newNames = [compare,target,compare+\"_pct_change\",target+\"_pct_change\"]\n",
    "newNames.extend(temp.columns[4:10])\n",
    "temp.columns = newNames\n",
    "\n",
    "temp.to_csv('../data/processed/output.csv', index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132e5e50-2826-47ee-8223-b8daa2f203fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "#scores = np.where(temp[compare] > 1, 1, 0)\n",
    "\n",
    "#idk why this library uses 2, 1 vs 1 and 0\n",
    "fpr, tpr, thresholds = metrics.roc_curve(np.where(temp[target+\"_pct_change\"] > 0, 2, 1), np.array(temp[compare+\"_pct_change\"].shift(-1)) , pos_label=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa15229-dd40-409c-86c4-094143a72967",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_roc_curve(clf, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d3179b-a4d3-46e6-9553-a3763ae8cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "#plt.plot(fpr,tpr, label='AUC = ' + str(round(roc_auc_score(y,m.oob_decision_function_[:,1]), 2)))\n",
    "#plt.legend(loc='lower right')\n",
    "\n",
    "from plot_metric.functions import BinaryClassification\n",
    "# Visualisation with plot_metric\n",
    "bc = BinaryClassification(np.where(temp[target+\"_pct_change\"] > 0, 1, 0), np.array(temp[compare+\"_pct_change\"]), labels=[\"Class 1\", \"Class 2\"])\n",
    "\n",
    "# Figures\n",
    "plt.figure(figsize=(5,5))\n",
    "bc.plot_roc_curve()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da249f-be20-4b24-b594-9ed3612fd179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"optimal cutoff\")\n",
    "#https://stackoverflow.com/questions/28719067/roc-curve-and-cut-off-point-python\n",
    "Find_Optimal_Cutoff(np.where(temp[target+\"_pct_change\"] > 0, 1, 0), np.array(temp[compare+\"_pct_change\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e19fe4-ed2b-464a-b0a2-08536a924dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import DataGenerator, KneeLocator\n",
    "kneedle = KneeLocator(fpr, tpr, S=1.0, curve=\"concave\", direction=\"increasing\")\n",
    "#kneedle.plot_knee_normalized()\n",
    "kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf2a1e-3f0a-49de-844d-dca3c37f787c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c724826-6c51-4e93-827e-c55cc83ab675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db525f5-aeb2-45fd-934b-efb782ecf9bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15badd1f-eab0-411a-aaf8-5ba8efe5387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_idx = np.argmax(tpr - fpr)\n",
    "optimal_threshold = thresholds[optimal_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415802f-c6dc-45b0-a604-a0439104ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(aggregate[aggregate['bifur']=='l'].iloc[:,0].cumsum(),  truncatedData[target].pct_change().loc[aggregate[aggregate['bifur']=='l'].iloc[:,0].index.tolist()])\n",
    "plt.show()\n",
    "aggregate[aggregate['bifur']=='l'].iloc[:,0].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b50107-1e96-4169-abd4-97efb6203f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(aggregate[aggregate['bifur']=='u'].iloc[:,1].cumsum(),  truncatedData[target].pct_change().loc[aggregate[aggregate['bifur']=='u'].iloc[:,1].index.tolist()])\n",
    "plt.show()\n",
    "aggregate[aggregate['bifur']=='u'].iloc[:,1].hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23aeba-1baf-43ba-8ed1-1f886304456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#252 trading days a year\n",
    "#30 days = 21\n",
    "#60 = 42\n",
    "#90 = 63\n",
    "\n",
    "#return = current - prior / prior\n",
    "\n",
    "#for i in range(1,63): #[1,21,42,63]\n",
    "for i in [1,21,42,63,84]: #[1,21,42,84]\n",
    "    print(i)\n",
    "    rate_of_change = (truncatedData[compare]-truncatedData[compare].shift(i))/truncatedData[compare].shift(i)\n",
    "    \n",
    "    newDF = pd.concat([rate_of_change,truncatedData[target].pct_change()],axis=1).dropna()\n",
    "\n",
    "    set1 = newDF[compare]\n",
    "    set2 = newDF[target]\n",
    "    \n",
    "    lags = range(0,85) #[0,21,42,63]\n",
    "    mcorrs_ = []\n",
    "    mlags = []\n",
    "    for j in lags:\n",
    "        \n",
    "        newSet = pd.concat([set1.shift(j),set2],axis=1).dropna()\n",
    "      \n",
    "        mcorrs_.append(np.array(newSet.corr())[1,0])\n",
    "        \n",
    "    plt.plot(mcorrs_)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d193fa-397f-4061-909e-5086d2087334",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([(truncatedData[compare]-truncatedData[compare].shift(1))/truncatedData[compare].shift(1),truncatedData[target].pct_change().shift(0)],axis=1).dropna().corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0985e2-7c25-4c96-bb60-b9dcb8e5148e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671a5775-b45a-4420-9eb5-56f125f350b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter((truncatedData[compare]-truncatedData[compare].shift(1))/truncatedData[compare].shift(1),truncatedData[target].pct_change().shift(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031f472-f7f1-4d61-9002-d2f9c109f327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.matshow(\n",
    "df = combined_set.loc[combined_set.index>=start_date.strftime('%Y-%m-%d')]\n",
    "\n",
    "r_ = df.corr()\n",
    "\n",
    "filter = r_[compare]\n",
    "                       \n",
    "filter = filter[filter<1]\n",
    "filter = filter.sort_values(kind=\"quicksort\", ascending=True)\n",
    "print(filter.head(10))\n",
    "print(filter.tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a40b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
