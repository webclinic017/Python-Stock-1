{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04103b66-7850-4afa-825d-bc11d787a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "import datetime as dt\n",
    "import pandas_market_calendars as mcal\n",
    "\n",
    "from finquant.portfolio import build_portfolio\n",
    "\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "import pandas_datareader as pdr\n",
    "import pandas as pd\n",
    "from IPython.display import *\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#data = pd.read_csv(\"https://raw.githubusercontent.com/leosmigel/analyzingalpha/master/sp500-historical-components-and-changes/sp500_history.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d6d08-8d05-4107-b66e-9dbab511dd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cycles_ = ['Expansion','Slowdown','Recession','Recovery']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d3be5-bf5a-4f4e-a1bd-af4483c0103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path=r\"C:\\Users\\User\\Documents\\wiki\\wiki\\dev\\python\\Python-Stock\\reports\\figures\\Business cycles.png\"\n",
    "display(Image.open(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab0a210-acfb-46fa-9470-9d5500b803be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d014a603-9bb9-435f-a66e-bc71f19c0753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d707b3-b31d-4e7a-801d-b3ccffccc07d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbfcf99-59bf-4a7a-81e7-4f1f2d40e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class sectors:\n",
    "\n",
    "    def __init__(self, start_date = np.NaN, end_date = np.NaN):\n",
    "        self.VANGUARD = \\\n",
    "            [ \\\n",
    "            \"VGT\", \\\n",
    "            \"VHT\", \\\n",
    "            \"VCR\", \\\n",
    "            \"VOX\", \\\n",
    "            \"VFH\", \\\n",
    "            \"VIS\", \\\n",
    "            \"VDC\", \\\n",
    "            \"VPU\", \\\n",
    "            \"VAW\", \\\n",
    "            \"VNQ\", \\\n",
    "            \"VDE\" \\\n",
    "            ]\n",
    "\n",
    "        self.SPDR = \\\n",
    "            [ \\\n",
    "            \"XLK\", \\\n",
    "            \"XLV\", \\\n",
    "            \"XLY\", \\\n",
    "            \"XLC\", \\\n",
    "            \"XLF\", \\\n",
    "            \"XLI\", \\\n",
    "            \"XLP\", \\\n",
    "            \"XLU\", \\\n",
    "            \"XLB\", \\\n",
    "            \"XLRE\", \\\n",
    "            \"XLE\" \\\n",
    "            ]\n",
    "\n",
    "        self.sectors = \\\n",
    "            [ \\\n",
    "            \"Information Technology\",\\\n",
    "            \"Health Care\",\\\n",
    "            \"Consumer Discretionary\",\\\n",
    "            \"Communication Services\",\\\n",
    "            \"Financials\",\\\n",
    "            \"Industrials\",\\\n",
    "            \"Consumer Staples\",\\\n",
    "            \"Utilities\",\\\n",
    "            \"Materials\",\\\n",
    "            \"Real Estate\",\\\n",
    "            \"Energy\"\\\n",
    "            ]\n",
    "\n",
    "    def get_Vanguard(self):\n",
    "        return(self.VANGUARD)\n",
    "\n",
    "    def get_sectors(self):\n",
    "        return(self.sectors)\n",
    "    \n",
    "    def get_SPDR(self):\n",
    "        return(self.SPDR) \n",
    "    \n",
    "class businessCycles:\n",
    "    \n",
    "    def __init__(self, start_date = np.NaN, end_date = np.NaN):\n",
    "        \n",
    "        self.Expansion = \\\n",
    "        ['Financials', 'Information Technology'],\\\n",
    "        ['Communication Services'],\\\n",
    "        ['Consumer Staples'],\\\n",
    "        ['Health Care','Utilities']\n",
    "\n",
    "        self.Slowdown = \\\n",
    "        ['Consumer Staples', 'Health Care'],\\\n",
    "        ['Industrials'],\\\n",
    "        ['Materials'],\\\n",
    "        ['Consumer Discretionary','Real Estate']    \n",
    "        \n",
    "        self.Recession = \\\n",
    "        ['Consumer Staples', 'Utilities'],\\\n",
    "        ['Industrials'],\\\n",
    "        ['Materials'],\\\n",
    "        ['Real Estate','Information Technology']            \n",
    "        \n",
    "        self.Recovery = \\\n",
    "        ['Consumer Discretionary', 'Real Estate'],\\\n",
    "        ['Materials'],\\\n",
    "        ['Health Care'],\\\n",
    "        ['Consumer Staples','Utilities']         \n",
    "        \n",
    "    def get_data(self):\n",
    "        return([self.Expansion, self.Slowdown, self.Recession, self.Recovery]) \n",
    "        \n",
    "def checkCycles(data_):\n",
    "    \n",
    "    bus_cycles = businessCycles()\n",
    "    \n",
    "    cycles = bus_cycles.get_data()\n",
    "\n",
    "    scores_ = np.zeros(shape=(len(cycles_)))\n",
    "    \n",
    "    for c in range(0,len(cycles)):\n",
    "\n",
    "        #print(cycles_[c])\n",
    "        businessCycleScores = 0\n",
    "\n",
    "        if np.mean(data_[cycles[c][0][0]])>np.mean(data_[cycles[c][1][0]]):\n",
    "            businessCycleScores = businessCycleScores + 1\n",
    "        if np.mean(data_[cycles[c][0][1]])>np.mean(data_[cycles[c][1][0]]):\n",
    "            businessCycleScores = businessCycleScores + 1\n",
    "\n",
    "        if np.mean(data_[cycles[c][1]])[0]>np.mean(data_[cycles[c][2]])[0]:#np.mean(data_[cycles[0][0][1]])\n",
    "            businessCycleScores = businessCycleScores + 1\n",
    "\n",
    "        if np.mean(data_[cycles[c][2]])[0]>np.mean(data_[cycles[c][3][0]]):\n",
    "            businessCycleScores = businessCycleScores + 1    \n",
    "        if np.mean(data_[cycles[c][2]])[0]>np.mean(data_[cycles[c][3][1]]):\n",
    "            businessCycleScores = businessCycleScores + 1  \n",
    "\n",
    "        scores_[c]=businessCycleScores/6\n",
    "        #print(businessCycleScores/6)\n",
    "        df_ = pd.DataFrame(scores_).T\n",
    "        df_.columns = cycles_\n",
    "        \n",
    "    percents = df_/df_.values.sum()\n",
    "        \n",
    "    return(percents)\n",
    "        \n",
    "def chart(data_):\n",
    "    \n",
    "    sum_ = pd.DataFrame(np.sum(np.array(data_),axis=0)).T\n",
    "    sum_.columns = data_.columns\n",
    "    print(sum_/len(data_))\n",
    "\n",
    "    bus_cycles = businessCycles()\n",
    "    \n",
    "    cycles = bus_cycles.get_data()\n",
    "\n",
    "    cycles_year = pd.DataFrame()\n",
    "    \n",
    "    for i in data_.index:\n",
    "        print(i)\n",
    "        x = data_.loc[i].sort_values(kind=\"quicksort\", ascending=False)\n",
    "        x_pos = x.index\n",
    "\n",
    "        cc=['colors']*len(x.index)\n",
    "        for n,val in enumerate(x):\n",
    "            #print(n)\n",
    "            if val<0:\n",
    "                cc[n]='red'\n",
    "            elif val>=0:\n",
    "                cc[n]='blue'\n",
    "\n",
    "        iter_ = 0\n",
    "        #for c in cycles:\n",
    "            #iter_ = iter_+1\n",
    "            #print(c)\n",
    "            #for i in c:\n",
    "                #print(i)\n",
    "                #for i_ in i:\n",
    "                    #print(i_)\n",
    "                    #print(x[i_])\n",
    "\n",
    "                #print(x[c[i][0]])\n",
    "\n",
    "        #plt.bar(x_pos, x,color=color_map(data_normalizer(likeability_scores)))\n",
    "        plt.bar(x_pos, x,color = cc)\n",
    "        #tempdf = checkCycles(pd.DataFrame(data_.loc[i]).T)\n",
    "        #print(tempdf)\n",
    "        #cycles_year = pd.concat([cycles_year,tempdf],axis=0)\n",
    "\n",
    "        #plt.xlabel(\"Energy Source\")\n",
    "        #plt.ylabel(\"Energy Output (GJ)\")\n",
    "        #plt.title(\"Energy output from various fuel sources\")\n",
    "\n",
    "        plt.xticks(range(0,len(x_pos)),x_pos, rotation = 75,size=10)\n",
    "\n",
    "        plt.show()   \n",
    "        \n",
    "    #print(cycles_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8e3b0f-86a4-40b6-8302-19ff5a0533fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4906457-4a4d-4e30-8eb4-6d88f6854264",
   "metadata": {},
   "outputs": [],
   "source": [
    "sectors_ = sectors()\n",
    "print(sectors_.get_Vanguard())\n",
    "print(sectors_.get_sectors())\n",
    "print(sectors_.get_SPDR())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f528e-4eee-4664-bd24-ff71310481b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_=widgets.DatePicker(\n",
    "    description='Pick a Date',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60779b-48ad-44f4-afcb-b92d60eae578",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8155d913-1b74-4d27-9540-86eabb3d355d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178970c-0c9a-473a-adf7-ad021b569361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84685348-e036-4c16-9dfa-7675079edb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks=sectors_.get_Vanguard()\n",
    "names = sectors_.get_sectors()\n",
    "\n",
    "stocks.append('^GSPC')\n",
    "stocks.append('EQL')\n",
    "names.append('^GSPC')\n",
    "names.append('EQL')\n",
    "\n",
    "#FRED_indicators = [\"OECDLOLITOAASTSAM\", \"BCI\", \"PPI\", \"USSLIND\", \"T103YM\", \"VIXCLS\", \"TB3MS\", \"WILL5000INDFC\" , \"GDP\", \"FEDFUNDS\"]\n",
    "#need BCI, LEI\n",
    "FRED_indicators = [\"OECDLOLITOAASTSAM\", \"PPIACO\",\"PCE\", \"USSLIND\", \"T10Y3M\",\"T5YIE\", \"VIXCLS\", \"TB3MS\", \"WILL5000INDFC\" , \"UNRATE\", \"GDP\", \"FEDFUNDS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4a9bad-1b54-44ab-b242-2f6b7e3b6e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stocks = ['ORCL', 'TSLA', 'IBM','YELP', 'MSFT']\n",
    "ls_key = 'Adj Close'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14da8cd-5782-4467-b5e2-668a2ba4241e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d017a21-4608-4c2e-807a-d56d3742059c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d3732-cee8-482d-885b-7157bfb31096",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data = sns.load_dataset('iris')\n",
    "#print('Original Dataset')\n",
    "#data.head()\n",
    " \n",
    "std_scaler = StandardScaler()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f8b32b-28c1-4f03-a058-c80ce0c3f0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6800c8ba-7513-4491-87d4-5242e36befee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "url = \"https://data.nasdaq.com/api/v3/datasets/ISM/MAN_PMI.csv?api_key=QgfDPCzvVmkDub4QqjQs\"\n",
    "#url = url+\"?start=\"+str(early_start)+\"?end=\"+str(end)\n",
    "#print(url)\n",
    "ISM = pd.read_csv(url).set_index(\"Date\")\n",
    "ISM.index = pd.to_datetime(ISM.index, errors='coerce',format='%Y-%m-%d')\n",
    "#.strftime('%Y-%m-%d')\n",
    "\n",
    "#early = nyse.schedule(start_date=early_start, end_date=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1db5b5ac-48af-4664-b597-602970d60523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95248099b5fd4c15b8679a3cf79b16c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Frequency:', index=1, options=('Y', 'Q'), value='Q'), Dropdown(desâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#filter_ = ['Y','6Mo','Q','M']\n",
    "\n",
    "cutoff = dt.datetime.today().strftime('%Y-%m-%d')\n",
    "#cutoff = test_.value.strftime('%Y-%m-%d')\n",
    "\n",
    "#filter_ = ['Y','6Mo','Q','M']\n",
    "filter_ = ['Y','Q']\n",
    "periods = [2,3,4,5,6,7,8,9]\n",
    "\n",
    "#filter_ = sum_.columns\n",
    "def f3(Y,X):\n",
    "    end_ = dt.datetime.strptime(cutoff, \"%Y-%m-%d\").date()\n",
    "\n",
    "    process=True\n",
    "    \n",
    "    if Y==\"Y\":\n",
    "        unit=52\n",
    "    elif Y==\"6Mo\":\n",
    "        unit=26*2\n",
    "    elif Y==\"Q\":\n",
    "        unit=13\n",
    "    #elif Y==\"M\":\n",
    "        #start_ = end_ - dt.timedelta(months=12*X)\n",
    "        #process=False\n",
    "        \n",
    "    if process:\n",
    "        start_ = end_ - dt.timedelta(weeks=unit*X)\n",
    "\n",
    "    nyse = mcal.get_calendar('NYSE')\n",
    "\n",
    "    #max lag due to indicators\n",
    "    n = 26\n",
    "\n",
    "    start = start_#date_time[0]\n",
    "    early_start = (dt.datetime.strptime(start.strftime('%Y-%m-%d'), '%Y-%m-%d') - pd.tseries.offsets.Week(n=unit) - pd.tseries.offsets.BusinessDay(n = np.max([n])+5)).strftime('%Y-%m-%d')\n",
    "    print(early_start)\n",
    "    end = (dt.datetime.strptime(str(end_), '%Y-%m-%d') + pd.tseries.offsets.BusinessDay(n = 1)).strftime('%Y-%m-%d')#date_time[-1]\n",
    "    print(end)\n",
    "\n",
    "    #import pandas_datareader.data as web\n",
    "    #f = web.DataReader(stocks, 'yahoo',early_start,end)\n",
    "\n",
    "    pf_pre = build_portfolio(\n",
    "        names=stocks, start_date=early_start, end_date=end, data_api=\"yfinance\"\n",
    "    )\n",
    "    \n",
    "    ISM_ = ISM.loc[(ISM.index>=pd.to_datetime(early_start))&(ISM.index<=pd.to_datetime(end))]    \n",
    "    \n",
    "    df = pdr.DataReader(FRED_indicators, 'fred', early_start, end)\n",
    "    \n",
    "    #df = pdr.DataReader(FRED_indicators, 'fred', early_start, end)\n",
    "    #print(df)\n",
    "    df = df.interpolate(method='time')\n",
    "\n",
    "    if Y==\"Y\":\n",
    "        data_ = pf_pre.data.asfreq('Y', method='pad').pct_change()[1:]\n",
    "        df = df.asfreq('Y', method='pad')[1:]\n",
    "        ISM_ = ISM_.asfreq('Y', method='pad')[1:]\n",
    "    else:\n",
    "        data_ = pf_pre.data.asfreq('Q', method='pad').pct_change()[1:]\n",
    "        df =  df.asfreq('Q', method='pad')[1:]#.pct_change()[1:]\n",
    "        ISM_ = ISM_.asfreq('Q', method='pad')[1:]\n",
    "        \n",
    "    #templist = sectors_.get_sectors()\n",
    "    data_.columns = names\n",
    "    data_.index = data_.index.strftime('%Y-%m-%d')\n",
    "    df.index = data_.index\n",
    "    ISM_.index = data_.index\n",
    "    \n",
    "    \n",
    "    df = pd.concat([df,ISM_],axis=1)\n",
    "    \n",
    "    #df = df.interpolate(method='time')\n",
    "    \n",
    "    df_scaled = std_scaler.fit_transform(df.to_numpy())\n",
    "    df = pd.DataFrame(df_scaled,columns=df.columns,index=df.index)\n",
    "    \n",
    "    \n",
    "    #print(checkCycles(data_))\n",
    "        \n",
    "    display(data_.style.background_gradient(cmap ='RdYlGn',axis=0))\n",
    "    chart(data_)\n",
    "    \n",
    "    tempdf = pd.DataFrame()\n",
    "    \n",
    "    #print(\"b4\")\n",
    "    for i in data_.index:\n",
    "        #print(i)\n",
    "        tempdf = pd.concat([tempdf,checkCycles(data_.loc[[i]])],axis=0)\n",
    "        \n",
    "    #print(\"a8r\")\n",
    "    tempdf.index = data_.index\n",
    "    print(tempdf)\n",
    "    \n",
    "    #for i in tempdf.columns:\n",
    "        #plt.plot(tempdf[[i]])\n",
    "    plt.plot(tempdf,label=tempdf.columns)\n",
    "    \n",
    "    plt.legend()\n",
    "    #ax.set_xlabel(pca_set.columns[1])\n",
    "    \n",
    "    plt.xticks(rotation = 60,size=10)\n",
    "    plt.show()\n",
    "    \n",
    "    display(df)\n",
    "    plt.plot(df,label=df.columns)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation = 60,size=10)\n",
    "    plt.show()\n",
    "    return(data_)\n",
    "\n",
    "x_widget = widgets.Dropdown(\n",
    "    options=periods,\n",
    "    value=2,\n",
    "    description=\"Periods:\",\n",
    ")\n",
    "\n",
    "y_widget = widgets.Dropdown(\n",
    "    options=['Y','Q'],\n",
    "    value='Q',\n",
    "    description='Frequency:',\n",
    ")\n",
    "\n",
    "\n",
    "out = widgets.interact(f3, Y=y_widget,X=x_widget)    \n",
    "\n",
    "#out.observe(on_value_change, names='value')    \n",
    "data_ = out.widget.result\n",
    "#display(data_.style.background_gradient(cmap ='RdYlGn',axis=0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbaede-dcb2-4320-8ff5-055d66480ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58931e03-e719-48b7-a4f3-b6f4813883ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fe3a7c-5a23-4e4f-80b3-6a4758c3c858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90cbba1-5687-4ba8-a255-4ce48297a875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e35dd-b8c4-458b-bc1a-5c1f286fea40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86c1f37-1f37-46f9-b4b3-f754c6cd4280",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77113e7e-ffa1-47e5-be05-a3442dbe35e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994ce6d-d656-4122-92a6-c197d84817b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56875d11-6c88-4218-af25-4d442309cade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51380e5c-7a61-4350-a4a9-2b8fb50076c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dates = sp500_adjustments['date'][sp500_adjustments['date']<=cutoff].unique()\n",
    "\n",
    "for d in dates:\n",
    "    print(d)\n",
    "    \n",
    "    #sp500_adjustments['variable']==\"added_ticker\"] && \n",
    "    adds = sp500_adjustments[((sp500_adjustments['date']<=d) & (sp500_adjustments['variable']==\"added_ticker\"))]\n",
    "    add_names, add_counts = np.unique(adds.name, return_counts=True)\n",
    "\n",
    "    dels = sp500_adjustments[((sp500_adjustments['date']<=d) & (sp500_adjustments['variable']==\"removed_ticker\"))]\n",
    "    del_names, del_counts = np.unique(dels.name, return_counts=True)\n",
    "\n",
    "    df = pd.concat([pd.concat([pd.DataFrame(add_names),pd.DataFrame(add_counts)],axis=1,ignore_index=1),pd.concat([pd.DataFrame(del_names),pd.DataFrame(del_counts*-1)],axis=1,ignore_index=1)],axis=0,ignore_index=1)\n",
    "    df.columns = ['name','tally']\n",
    "    \n",
    "    grouper = df.groupby('name')\n",
    "    #res = grouper.count()\n",
    "    aggregate = grouper.tally.sum()\n",
    "\n",
    "    sp500 = pd.DataFrame(aggregate[pd.DataFrame(aggregate).tally>0]).index\n",
    "    #print(sp500)\n",
    "    #print(len(sp500))\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6efec-2a86-4ea6-b42e-603cadbca9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
